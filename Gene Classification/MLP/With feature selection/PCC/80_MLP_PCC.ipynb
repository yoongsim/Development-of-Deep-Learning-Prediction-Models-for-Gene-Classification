{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "6\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n",
    "\n",
    "import tensorflow as tf\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras import regularizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fixed random seed for reproducibility \n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of dataGene:\n",
      "        log_2FoldChange            ET  CoExpression           PCC  \\\n",
      "count     41110.000000  41110.000000  41110.000000  41110.000000   \n",
      "mean         -0.037332      1.407395      0.991997     -0.361737   \n",
      "std           0.391444      0.784327      0.089101      0.463979   \n",
      "min          -1.000000      0.000000      0.000000     -1.000000   \n",
      "25%          -0.251534      1.000000      1.000000     -0.747963   \n",
      "50%           0.030675      2.000000      1.000000     -0.449089   \n",
      "75%           0.251534      2.000000      1.000000     -0.051646   \n",
      "max           1.000000      2.000000      1.000000      1.000000   \n",
      "\n",
      "                PPI  Root10DaysSeedling  Root14DaysSeedling  \\\n",
      "count  41110.000000        41110.000000        41110.000000   \n",
      "mean       0.914668           -0.522040           -0.646982   \n",
      "std        0.279379            0.498568            0.393549   \n",
      "min        0.000000           -1.000000           -1.000000   \n",
      "25%        1.000000           -0.901371           -0.965084   \n",
      "50%        1.000000           -0.663664           -0.680003   \n",
      "75%        1.000000           -0.378497           -0.559627   \n",
      "max        1.000000            1.000000            1.000000   \n",
      "\n",
      "       Root17DaysSeedling  Root21DaysSeedling  Root24DaysSeedling  ...  \\\n",
      "count        41110.000000        41110.000000        41110.000000  ...   \n",
      "mean            -0.700869           -0.669349           -0.670048  ...   \n",
      "std              0.378219            0.405860            0.390751  ...   \n",
      "min             -1.000000           -1.000000           -1.000000  ...   \n",
      "25%             -0.980226           -1.000000           -0.982003  ...   \n",
      "50%             -0.795609           -0.726665           -0.708584  ...   \n",
      "75%             -0.601266           -0.543621           -0.482133  ...   \n",
      "max              1.000000            1.000000            1.000000  ...   \n",
      "\n",
      "       Root52DaysSeedling  Shoot3DaysSeedling  Shoot10DaysSeedling  \\\n",
      "count        41110.000000        41110.000000         41110.000000   \n",
      "mean            -0.670345           -0.590806            -0.545055   \n",
      "std              0.478222            0.443552             0.477438   \n",
      "min             -1.000000           -1.000000            -1.000000   \n",
      "25%             -1.000000           -1.000000            -0.906055   \n",
      "50%             -0.853382           -0.676286            -0.698864   \n",
      "75%             -0.542371           -0.409775            -0.250588   \n",
      "max              1.000000            0.955179             1.000000   \n",
      "\n",
      "       Shoot14DaysSeedling  Shoot17DaysSeedling  Shoot21DaysSeedling  \\\n",
      "count         41110.000000         41110.000000         41110.000000   \n",
      "mean             -0.734141            -0.680810            -0.659443   \n",
      "std               0.413716             0.478189             0.463838   \n",
      "min              -1.000000            -1.000000            -1.000000   \n",
      "25%              -1.000000            -1.000000            -1.000000   \n",
      "50%              -0.924976            -0.954040            -0.874080   \n",
      "75%              -0.513759            -0.420386            -0.440577   \n",
      "max               0.997390             1.000000             1.000000   \n",
      "\n",
      "       Shoot35DaysSeedling  Leaf21DaysSeedling  Leaf45DaysOldPlant  \\\n",
      "count         41110.000000        41110.000000        41110.000000   \n",
      "mean             -0.558906           -0.828778           -0.585144   \n",
      "std               0.506423            0.327542            0.399046   \n",
      "min              -1.000000           -1.000000           -1.000000   \n",
      "25%              -0.962199           -1.000000           -0.901444   \n",
      "50%              -0.699035           -0.951894           -0.643376   \n",
      "75%              -0.352995           -0.883755           -0.451900   \n",
      "max               0.993958            1.000000            1.000000   \n",
      "\n",
      "              class  \n",
      "count  41110.000000  \n",
      "mean      59.092703  \n",
      "std       77.624892  \n",
      "min        0.000000  \n",
      "25%        8.000000  \n",
      "50%       25.000000  \n",
      "75%       77.000000  \n",
      "max      372.000000  \n",
      "\n",
      "[8 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "# load dataset (input variables = X, output variables = Y)\n",
    "df = pd.read_csv(\"2.csv\")\n",
    "\n",
    "#count the number of occurances for each osID\n",
    "OsID_counts = df['OsID'].value_counts()\n",
    "\n",
    "#filter for osIDs that have 10 or more occurances\n",
    "OsID_counts_filtered = OsID_counts[OsID_counts >= 10]\n",
    "\n",
    "#assign a label for each osID \n",
    "OsID_labels = {}\n",
    "class_no = 0\n",
    "for osID in OsID_counts_filtered.index:\n",
    "    OsID_labels[osID] = class_no\n",
    "    class_no +=1\n",
    "\n",
    "#filter the dataset with osID that contain 10 or more occurances\n",
    "dataGene = df[df['OsID'].isin(OsID_counts_filtered.index)]\n",
    "\n",
    "dataGene = dataGene.drop(['Class', 'Trait'],axis=1)\n",
    "\n",
    "# Add a new column 'class' to the filtered dataset\n",
    "dataGene['class'] = dataGene['OsID'].map(OsID_labels)\n",
    "\n",
    "print(\"Summary of dataGene:\\n\",dataGene.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X:\n",
      " (41110, 20)\n",
      "Shape of Y:\n",
      " (41110,)\n",
      "Summary of X:\n",
      "        CoExpression           PCC           PPI  Root10DaysSeedling  \\\n",
      "count  41110.000000  41110.000000  41110.000000        41110.000000   \n",
      "mean       0.991997     -0.361737      0.914668           -0.522040   \n",
      "std        0.089101      0.463979      0.279379            0.498568   \n",
      "min        0.000000     -1.000000      0.000000           -1.000000   \n",
      "25%        1.000000     -0.747963      1.000000           -0.901371   \n",
      "50%        1.000000     -0.449089      1.000000           -0.663664   \n",
      "75%        1.000000     -0.051646      1.000000           -0.378497   \n",
      "max        1.000000      1.000000      1.000000            1.000000   \n",
      "\n",
      "       Leaf21DaysSeedling  Leaf45DaysOldPlant  log_2FoldChange            ET  \\\n",
      "count        41110.000000        41110.000000     41110.000000  41110.000000   \n",
      "mean            -0.828778           -0.585144        -0.037332      1.407395   \n",
      "std              0.327542            0.399046         0.391444      0.784327   \n",
      "min             -1.000000           -1.000000        -1.000000      0.000000   \n",
      "25%             -1.000000           -0.901444        -0.251534      1.000000   \n",
      "50%             -0.951894           -0.643376         0.030675      2.000000   \n",
      "75%             -0.883755           -0.451900         0.251534      2.000000   \n",
      "max              1.000000            1.000000         1.000000      2.000000   \n",
      "\n",
      "       Shoot10DaysSeedling  Shoot3DaysSeedling  Shoot35DaysSeedling  \\\n",
      "count         41110.000000        41110.000000         41110.000000   \n",
      "mean             -0.545055           -0.590806            -0.558906   \n",
      "std               0.477438            0.443552             0.506423   \n",
      "min              -1.000000           -1.000000            -1.000000   \n",
      "25%              -0.906055           -1.000000            -0.962199   \n",
      "50%              -0.698864           -0.676286            -0.699035   \n",
      "75%              -0.250588           -0.409775            -0.352995   \n",
      "max               1.000000            0.955179             0.993958   \n",
      "\n",
      "       Shoot14DaysSeedling  Root17DaysSeedling  Shoot17DaysSeedling  \\\n",
      "count         41110.000000        41110.000000         41110.000000   \n",
      "mean             -0.734141           -0.700869            -0.680810   \n",
      "std               0.413716            0.378219             0.478189   \n",
      "min              -1.000000           -1.000000            -1.000000   \n",
      "25%              -1.000000           -0.980226            -1.000000   \n",
      "50%              -0.924976           -0.795609            -0.954040   \n",
      "75%              -0.513759           -0.601266            -0.420386   \n",
      "max               0.997390            1.000000             1.000000   \n",
      "\n",
      "       Shoot21DaysSeedling  Root24DaysSeedling  Root14DaysSeedling  \\\n",
      "count         41110.000000        41110.000000        41110.000000   \n",
      "mean             -0.659443           -0.670048           -0.646982   \n",
      "std               0.463838            0.390751            0.393549   \n",
      "min              -1.000000           -1.000000           -1.000000   \n",
      "25%              -1.000000           -0.982003           -0.965084   \n",
      "50%              -0.874080           -0.708584           -0.680003   \n",
      "75%              -0.440577           -0.482133           -0.559627   \n",
      "max               1.000000            1.000000            1.000000   \n",
      "\n",
      "       Root21DaysSeedling  Root52DaysSeedling  Root35DaysSeedling  \n",
      "count        41110.000000        41110.000000        41110.000000  \n",
      "mean            -0.669349           -0.670345           -0.596196  \n",
      "std              0.405860            0.478222            0.461679  \n",
      "min             -1.000000           -1.000000           -1.000000  \n",
      "25%             -1.000000           -1.000000           -0.937286  \n",
      "50%             -0.726665           -0.853382           -0.769184  \n",
      "75%             -0.543621           -0.542371           -0.323664  \n",
      "max              1.000000            1.000000            1.000000  \n",
      "Summary of Y:\n",
      " count    41110.000000\n",
      "mean        59.092703\n",
      "std         77.624892\n",
      "min          0.000000\n",
      "25%          8.000000\n",
      "50%         25.000000\n",
      "75%         77.000000\n",
      "max        372.000000\n",
      "Name: class, dtype: float64\n",
      "class\n",
      "0.0      1800\n",
      "1.0      1296\n",
      "2.0      1260\n",
      "3.0      1218\n",
      "4.0      1026\n",
      "         ... \n",
      "368.0      10\n",
      "369.0      10\n",
      "370.0      10\n",
      "371.0      10\n",
      "372.0      10\n",
      "Length: 373, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "X = dataGene.drop(['class','OsID'], axis=1) # exclude class & OsID column\n",
    "Y = dataGene['class']\n",
    "\n",
    "#input feature names in order of descending importance scores in PCC feature selection method\n",
    "feature_names = ['CoExpression', 'PCC', 'PPI', 'Root10DaysSeedling', 'Leaf21DaysSeedling',\n",
    "                 'Leaf45DaysOldPlant', 'log_2FoldChange', 'ET', 'Shoot10DaysSeedling', 'Shoot3DaysSeedling', \n",
    "                 'Shoot35DaysSeedling', 'Shoot14DaysSeedling', 'Root17DaysSeedling', 'Shoot17DaysSeedling', 'Shoot21DaysSeedling',\n",
    "                 'Root24DaysSeedling', 'Root14DaysSeedling', 'Root21DaysSeedling', 'Root52DaysSeedling', 'Root35DaysSeedling']\n",
    "\n",
    "X_fs = X.reindex(columns=feature_names)\n",
    "\n",
    "print(\"Shape of X:\\n\",X_fs.shape)\n",
    "print(\"Shape of Y:\\n\",Y.shape)\n",
    "\n",
    "# Statistical summary of the variables\n",
    "print(\"Summary of X:\\n\",X_fs.describe())\n",
    "print(\"Summary of Y:\\n\",Y.describe())\n",
    "\n",
    "# Check for class imbalance\n",
    "print(df.groupby(Y).size())\n",
    "\n",
    "# change both input and target variables datatype to ndarray\n",
    "\n",
    "X_fs = X_fs.values # 2-D array\n",
    "\n",
    "# select target variable \n",
    "\n",
    "Y = Y.values #1-D array\n",
    "Y = Y.reshape(-1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, n=1800 (4.378%)\n",
      "Class=1, n=1296 (3.153%)\n",
      "Class=2, n=1260 (3.065%)\n",
      "Class=3, n=1218 (2.963%)\n",
      "Class=4, n=1026 (2.496%)\n",
      "Class=5, n=1008 (2.452%)\n",
      "Class=6, n=930 (2.262%)\n",
      "Class=7, n=912 (2.218%)\n",
      "Class=8, n=880 (2.141%)\n",
      "Class=9, n=798 (1.941%)\n",
      "Class=10, n=792 (1.927%)\n",
      "Class=11, n=759 (1.846%)\n",
      "Class=12, n=729 (1.773%)\n",
      "Class=13, n=720 (1.751%)\n",
      "Class=14, n=702 (1.708%)\n",
      "Class=15, n=693 (1.686%)\n",
      "Class=16, n=672 (1.635%)\n",
      "Class=17, n=640 (1.557%)\n",
      "Class=18, n=625 (1.520%)\n",
      "Class=19, n=570 (1.387%)\n",
      "Class=20, n=546 (1.328%)\n",
      "Class=21, n=506 (1.231%)\n",
      "Class=22, n=483 (1.175%)\n",
      "Class=23, n=448 (1.090%)\n",
      "Class=24, n=432 (1.051%)\n",
      "Class=25, n=384 (0.934%)\n",
      "Class=26, n=360 (0.876%)\n",
      "Class=27, n=360 (0.876%)\n",
      "Class=28, n=320 (0.778%)\n",
      "Class=29, n=312 (0.759%)\n",
      "Class=30, n=312 (0.759%)\n",
      "Class=31, n=306 (0.744%)\n",
      "Class=32, n=304 (0.739%)\n",
      "Class=33, n=299 (0.727%)\n",
      "Class=34, n=297 (0.722%)\n",
      "Class=35, n=296 (0.720%)\n",
      "Class=36, n=280 (0.681%)\n",
      "Class=37, n=264 (0.642%)\n",
      "Class=38, n=260 (0.632%)\n",
      "Class=39, n=253 (0.615%)\n",
      "Class=40, n=252 (0.613%)\n",
      "Class=41, n=248 (0.603%)\n",
      "Class=42, n=242 (0.589%)\n",
      "Class=43, n=228 (0.555%)\n",
      "Class=44, n=216 (0.525%)\n",
      "Class=45, n=210 (0.511%)\n",
      "Class=46, n=200 (0.486%)\n",
      "Class=47, n=192 (0.467%)\n",
      "Class=48, n=180 (0.438%)\n",
      "Class=49, n=171 (0.416%)\n",
      "Class=50, n=168 (0.409%)\n",
      "Class=51, n=168 (0.409%)\n",
      "Class=52, n=162 (0.394%)\n",
      "Class=53, n=150 (0.365%)\n",
      "Class=54, n=148 (0.360%)\n",
      "Class=55, n=138 (0.336%)\n",
      "Class=56, n=135 (0.328%)\n",
      "Class=57, n=135 (0.328%)\n",
      "Class=58, n=133 (0.324%)\n",
      "Class=59, n=132 (0.321%)\n",
      "Class=60, n=132 (0.321%)\n",
      "Class=61, n=130 (0.316%)\n",
      "Class=62, n=130 (0.316%)\n",
      "Class=63, n=130 (0.316%)\n",
      "Class=64, n=128 (0.311%)\n",
      "Class=65, n=128 (0.311%)\n",
      "Class=66, n=126 (0.306%)\n",
      "Class=67, n=124 (0.302%)\n",
      "Class=68, n=124 (0.302%)\n",
      "Class=69, n=124 (0.302%)\n",
      "Class=70, n=120 (0.292%)\n",
      "Class=71, n=120 (0.292%)\n",
      "Class=72, n=118 (0.287%)\n",
      "Class=73, n=116 (0.282%)\n",
      "Class=74, n=114 (0.277%)\n",
      "Class=75, n=105 (0.255%)\n",
      "Class=76, n=104 (0.253%)\n",
      "Class=77, n=102 (0.248%)\n",
      "Class=78, n=99 (0.241%)\n",
      "Class=79, n=98 (0.238%)\n",
      "Class=80, n=98 (0.238%)\n",
      "Class=81, n=98 (0.238%)\n",
      "Class=82, n=98 (0.238%)\n",
      "Class=83, n=96 (0.234%)\n",
      "Class=84, n=96 (0.234%)\n",
      "Class=85, n=96 (0.234%)\n",
      "Class=86, n=93 (0.226%)\n",
      "Class=87, n=92 (0.224%)\n",
      "Class=88, n=92 (0.224%)\n",
      "Class=89, n=91 (0.221%)\n",
      "Class=90, n=88 (0.214%)\n",
      "Class=91, n=88 (0.214%)\n",
      "Class=92, n=86 (0.209%)\n",
      "Class=93, n=86 (0.209%)\n",
      "Class=94, n=84 (0.204%)\n",
      "Class=95, n=84 (0.204%)\n",
      "Class=96, n=84 (0.204%)\n",
      "Class=97, n=78 (0.190%)\n",
      "Class=98, n=78 (0.190%)\n",
      "Class=99, n=76 (0.185%)\n",
      "Class=100, n=75 (0.182%)\n",
      "Class=101, n=75 (0.182%)\n",
      "Class=102, n=73 (0.178%)\n",
      "Class=103, n=72 (0.175%)\n",
      "Class=104, n=72 (0.175%)\n",
      "Class=105, n=70 (0.170%)\n",
      "Class=106, n=69 (0.168%)\n",
      "Class=107, n=68 (0.165%)\n",
      "Class=108, n=67 (0.163%)\n",
      "Class=109, n=66 (0.161%)\n",
      "Class=110, n=66 (0.161%)\n",
      "Class=111, n=66 (0.161%)\n",
      "Class=112, n=66 (0.161%)\n",
      "Class=113, n=66 (0.161%)\n",
      "Class=114, n=65 (0.158%)\n",
      "Class=115, n=64 (0.156%)\n",
      "Class=116, n=63 (0.153%)\n",
      "Class=117, n=63 (0.153%)\n",
      "Class=118, n=62 (0.151%)\n",
      "Class=119, n=61 (0.148%)\n",
      "Class=120, n=60 (0.146%)\n",
      "Class=121, n=60 (0.146%)\n",
      "Class=122, n=60 (0.146%)\n",
      "Class=123, n=60 (0.146%)\n",
      "Class=124, n=60 (0.146%)\n",
      "Class=125, n=60 (0.146%)\n",
      "Class=126, n=60 (0.146%)\n",
      "Class=127, n=60 (0.146%)\n",
      "Class=128, n=60 (0.146%)\n",
      "Class=129, n=60 (0.146%)\n",
      "Class=130, n=59 (0.144%)\n",
      "Class=131, n=59 (0.144%)\n",
      "Class=132, n=58 (0.141%)\n",
      "Class=133, n=56 (0.136%)\n",
      "Class=134, n=56 (0.136%)\n",
      "Class=135, n=56 (0.136%)\n",
      "Class=136, n=56 (0.136%)\n",
      "Class=137, n=56 (0.136%)\n",
      "Class=138, n=56 (0.136%)\n",
      "Class=139, n=56 (0.136%)\n",
      "Class=140, n=56 (0.136%)\n",
      "Class=141, n=56 (0.136%)\n",
      "Class=142, n=55 (0.134%)\n",
      "Class=143, n=55 (0.134%)\n",
      "Class=144, n=54 (0.131%)\n",
      "Class=145, n=54 (0.131%)\n",
      "Class=146, n=54 (0.131%)\n",
      "Class=147, n=54 (0.131%)\n",
      "Class=148, n=54 (0.131%)\n",
      "Class=149, n=53 (0.129%)\n",
      "Class=150, n=52 (0.126%)\n",
      "Class=151, n=52 (0.126%)\n",
      "Class=152, n=52 (0.126%)\n",
      "Class=153, n=52 (0.126%)\n",
      "Class=154, n=50 (0.122%)\n",
      "Class=155, n=50 (0.122%)\n",
      "Class=156, n=49 (0.119%)\n",
      "Class=157, n=49 (0.119%)\n",
      "Class=158, n=48 (0.117%)\n",
      "Class=159, n=48 (0.117%)\n",
      "Class=160, n=48 (0.117%)\n",
      "Class=161, n=46 (0.112%)\n",
      "Class=162, n=45 (0.109%)\n",
      "Class=163, n=44 (0.107%)\n",
      "Class=164, n=44 (0.107%)\n",
      "Class=165, n=44 (0.107%)\n",
      "Class=166, n=42 (0.102%)\n",
      "Class=167, n=42 (0.102%)\n",
      "Class=168, n=42 (0.102%)\n",
      "Class=169, n=42 (0.102%)\n",
      "Class=170, n=42 (0.102%)\n",
      "Class=171, n=42 (0.102%)\n",
      "Class=172, n=42 (0.102%)\n",
      "Class=173, n=41 (0.100%)\n",
      "Class=174, n=41 (0.100%)\n",
      "Class=175, n=40 (0.097%)\n",
      "Class=176, n=40 (0.097%)\n",
      "Class=177, n=39 (0.095%)\n",
      "Class=178, n=39 (0.095%)\n",
      "Class=179, n=38 (0.092%)\n",
      "Class=180, n=37 (0.090%)\n",
      "Class=181, n=36 (0.088%)\n",
      "Class=182, n=35 (0.085%)\n",
      "Class=183, n=35 (0.085%)\n",
      "Class=184, n=35 (0.085%)\n",
      "Class=185, n=35 (0.085%)\n",
      "Class=186, n=34 (0.083%)\n",
      "Class=187, n=34 (0.083%)\n",
      "Class=188, n=34 (0.083%)\n",
      "Class=189, n=34 (0.083%)\n",
      "Class=190, n=32 (0.078%)\n",
      "Class=191, n=32 (0.078%)\n",
      "Class=192, n=32 (0.078%)\n",
      "Class=193, n=32 (0.078%)\n",
      "Class=194, n=32 (0.078%)\n",
      "Class=195, n=32 (0.078%)\n",
      "Class=196, n=31 (0.075%)\n",
      "Class=197, n=31 (0.075%)\n",
      "Class=198, n=31 (0.075%)\n",
      "Class=199, n=31 (0.075%)\n",
      "Class=200, n=30 (0.073%)\n",
      "Class=201, n=30 (0.073%)\n",
      "Class=202, n=30 (0.073%)\n",
      "Class=203, n=30 (0.073%)\n",
      "Class=204, n=30 (0.073%)\n",
      "Class=205, n=30 (0.073%)\n",
      "Class=206, n=30 (0.073%)\n",
      "Class=207, n=30 (0.073%)\n",
      "Class=208, n=30 (0.073%)\n",
      "Class=209, n=29 (0.071%)\n",
      "Class=210, n=29 (0.071%)\n",
      "Class=211, n=28 (0.068%)\n",
      "Class=212, n=28 (0.068%)\n",
      "Class=213, n=28 (0.068%)\n",
      "Class=214, n=28 (0.068%)\n",
      "Class=215, n=28 (0.068%)\n",
      "Class=216, n=28 (0.068%)\n",
      "Class=217, n=27 (0.066%)\n",
      "Class=218, n=27 (0.066%)\n",
      "Class=219, n=27 (0.066%)\n",
      "Class=220, n=27 (0.066%)\n",
      "Class=221, n=27 (0.066%)\n",
      "Class=222, n=27 (0.066%)\n",
      "Class=223, n=26 (0.063%)\n",
      "Class=224, n=26 (0.063%)\n",
      "Class=225, n=26 (0.063%)\n",
      "Class=226, n=26 (0.063%)\n",
      "Class=227, n=26 (0.063%)\n",
      "Class=228, n=25 (0.061%)\n",
      "Class=229, n=25 (0.061%)\n",
      "Class=230, n=25 (0.061%)\n",
      "Class=231, n=25 (0.061%)\n",
      "Class=232, n=24 (0.058%)\n",
      "Class=233, n=24 (0.058%)\n",
      "Class=234, n=24 (0.058%)\n",
      "Class=235, n=24 (0.058%)\n",
      "Class=236, n=24 (0.058%)\n",
      "Class=237, n=24 (0.058%)\n",
      "Class=238, n=24 (0.058%)\n",
      "Class=239, n=24 (0.058%)\n",
      "Class=240, n=24 (0.058%)\n",
      "Class=241, n=24 (0.058%)\n",
      "Class=242, n=24 (0.058%)\n",
      "Class=243, n=24 (0.058%)\n",
      "Class=244, n=23 (0.056%)\n",
      "Class=245, n=23 (0.056%)\n",
      "Class=246, n=22 (0.054%)\n",
      "Class=247, n=22 (0.054%)\n",
      "Class=248, n=22 (0.054%)\n",
      "Class=249, n=22 (0.054%)\n",
      "Class=250, n=22 (0.054%)\n",
      "Class=251, n=22 (0.054%)\n",
      "Class=252, n=22 (0.054%)\n",
      "Class=253, n=22 (0.054%)\n",
      "Class=254, n=22 (0.054%)\n",
      "Class=255, n=22 (0.054%)\n",
      "Class=256, n=22 (0.054%)\n",
      "Class=257, n=22 (0.054%)\n",
      "Class=258, n=22 (0.054%)\n",
      "Class=259, n=22 (0.054%)\n",
      "Class=260, n=22 (0.054%)\n",
      "Class=261, n=22 (0.054%)\n",
      "Class=262, n=22 (0.054%)\n",
      "Class=263, n=22 (0.054%)\n",
      "Class=264, n=21 (0.051%)\n",
      "Class=265, n=21 (0.051%)\n",
      "Class=266, n=21 (0.051%)\n",
      "Class=267, n=21 (0.051%)\n",
      "Class=268, n=21 (0.051%)\n",
      "Class=269, n=20 (0.049%)\n",
      "Class=270, n=20 (0.049%)\n",
      "Class=271, n=20 (0.049%)\n",
      "Class=272, n=20 (0.049%)\n",
      "Class=273, n=20 (0.049%)\n",
      "Class=274, n=20 (0.049%)\n",
      "Class=275, n=20 (0.049%)\n",
      "Class=276, n=20 (0.049%)\n",
      "Class=277, n=20 (0.049%)\n",
      "Class=278, n=20 (0.049%)\n",
      "Class=279, n=20 (0.049%)\n",
      "Class=280, n=19 (0.046%)\n",
      "Class=281, n=19 (0.046%)\n",
      "Class=282, n=19 (0.046%)\n",
      "Class=283, n=18 (0.044%)\n",
      "Class=284, n=18 (0.044%)\n",
      "Class=285, n=18 (0.044%)\n",
      "Class=286, n=18 (0.044%)\n",
      "Class=287, n=18 (0.044%)\n",
      "Class=288, n=18 (0.044%)\n",
      "Class=289, n=18 (0.044%)\n",
      "Class=290, n=18 (0.044%)\n",
      "Class=291, n=18 (0.044%)\n",
      "Class=292, n=17 (0.041%)\n",
      "Class=293, n=17 (0.041%)\n",
      "Class=294, n=17 (0.041%)\n",
      "Class=295, n=17 (0.041%)\n",
      "Class=296, n=17 (0.041%)\n",
      "Class=297, n=17 (0.041%)\n",
      "Class=298, n=16 (0.039%)\n",
      "Class=299, n=16 (0.039%)\n",
      "Class=300, n=16 (0.039%)\n",
      "Class=301, n=16 (0.039%)\n",
      "Class=302, n=16 (0.039%)\n",
      "Class=303, n=16 (0.039%)\n",
      "Class=304, n=16 (0.039%)\n",
      "Class=305, n=16 (0.039%)\n",
      "Class=306, n=15 (0.036%)\n",
      "Class=307, n=15 (0.036%)\n",
      "Class=308, n=15 (0.036%)\n",
      "Class=309, n=15 (0.036%)\n",
      "Class=310, n=15 (0.036%)\n",
      "Class=311, n=14 (0.034%)\n",
      "Class=312, n=14 (0.034%)\n",
      "Class=313, n=14 (0.034%)\n",
      "Class=314, n=14 (0.034%)\n",
      "Class=315, n=14 (0.034%)\n",
      "Class=316, n=14 (0.034%)\n",
      "Class=317, n=14 (0.034%)\n",
      "Class=318, n=14 (0.034%)\n",
      "Class=319, n=14 (0.034%)\n",
      "Class=320, n=14 (0.034%)\n",
      "Class=321, n=14 (0.034%)\n",
      "Class=322, n=14 (0.034%)\n",
      "Class=323, n=14 (0.034%)\n",
      "Class=324, n=14 (0.034%)\n",
      "Class=325, n=14 (0.034%)\n",
      "Class=326, n=14 (0.034%)\n",
      "Class=327, n=14 (0.034%)\n",
      "Class=328, n=13 (0.032%)\n",
      "Class=329, n=13 (0.032%)\n",
      "Class=330, n=13 (0.032%)\n",
      "Class=331, n=13 (0.032%)\n",
      "Class=332, n=13 (0.032%)\n",
      "Class=333, n=13 (0.032%)\n",
      "Class=334, n=13 (0.032%)\n",
      "Class=335, n=13 (0.032%)\n",
      "Class=336, n=13 (0.032%)\n",
      "Class=337, n=12 (0.029%)\n",
      "Class=338, n=12 (0.029%)\n",
      "Class=339, n=12 (0.029%)\n",
      "Class=340, n=12 (0.029%)\n",
      "Class=341, n=12 (0.029%)\n",
      "Class=342, n=12 (0.029%)\n",
      "Class=343, n=12 (0.029%)\n",
      "Class=344, n=12 (0.029%)\n",
      "Class=345, n=12 (0.029%)\n",
      "Class=346, n=12 (0.029%)\n",
      "Class=347, n=12 (0.029%)\n",
      "Class=348, n=12 (0.029%)\n",
      "Class=349, n=12 (0.029%)\n",
      "Class=350, n=12 (0.029%)\n",
      "Class=351, n=12 (0.029%)\n",
      "Class=352, n=12 (0.029%)\n",
      "Class=353, n=12 (0.029%)\n",
      "Class=354, n=12 (0.029%)\n",
      "Class=355, n=11 (0.027%)\n",
      "Class=356, n=11 (0.027%)\n",
      "Class=357, n=11 (0.027%)\n",
      "Class=358, n=11 (0.027%)\n",
      "Class=359, n=11 (0.027%)\n",
      "Class=360, n=11 (0.027%)\n",
      "Class=361, n=10 (0.024%)\n",
      "Class=362, n=10 (0.024%)\n",
      "Class=363, n=10 (0.024%)\n",
      "Class=364, n=10 (0.024%)\n",
      "Class=365, n=10 (0.024%)\n",
      "Class=366, n=10 (0.024%)\n",
      "Class=367, n=10 (0.024%)\n",
      "Class=368, n=10 (0.024%)\n",
      "Class=369, n=10 (0.024%)\n",
      "Class=370, n=10 (0.024%)\n",
      "Class=371, n=10 (0.024%)\n",
      "Class=372, n=10 (0.024%)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "# summarize distribution\n",
    "counter = Counter(Y.flatten())\n",
    "\n",
    "# sort counter by keys\n",
    "counter = dict(sorted(counter.items()))\n",
    "\n",
    "for k,v in counter.items():\n",
    " per = v / len(Y.flatten()) * 100\n",
    " print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n",
    "# plot the distribution\n",
    "plt.bar( counter.keys(), counter.values())\n",
    "\n",
    "plt.ylabel('No of gene samples')\n",
    "plt.xlabel('Class Index of OsID')\n",
    "plt.title('Distribution of Target Classes (OsID)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_confusion_matrix(cm):\n",
    "    plt.figure(figsize=(12,8))\n",
    "    sns.heatmap(cm,annot=True,fmt=\"d\", center=0, cmap='autumn') \n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare target data\n",
    "def prepare_targets(y_train, y_test):\n",
    "\tle = LabelEncoder()\n",
    "\t\n",
    "\t#fit the encoders only to the training data and then transform both train and test data\n",
    "\ty_train_enc = le.fit_transform(y_train)\n",
    "\ty_test_enc = le.transform(y_test)\n",
    "\n",
    "\treturn y_train_enc, y_test_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model (MLP)\n",
    "def MLP_model(input_dim):\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(60, input_dim=input_dim,bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(Dense(20,bias_initializer='normal',activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(Dense(20,bias_initializer='normal',activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n",
    "    model.add(Dense(373,kernel_initializer='normal', activation='softmax')) #softmax for multi-class classification, num_classes = 373\n",
    "\n",
    "    # Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of input features: 1\n",
      "Fold: 1\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 36s 15ms/step - loss: 5.0776 - accuracy: 0.0423 - val_loss: 5.0040 - val_accuracy: 0.0444\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 23s 13ms/step - loss: 4.9421 - accuracy: 0.0451 - val_loss: 4.9984 - val_accuracy: 0.0451\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 24s 13ms/step - loss: 4.9314 - accuracy: 0.0443 - val_loss: 4.9925 - val_accuracy: 0.0444\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 15s 8ms/step - loss: 4.9304 - accuracy: 0.0450 - val_loss: 4.9944 - val_accuracy: 0.0451\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 18s 10ms/step - loss: 4.9280 - accuracy: 0.0454 - val_loss: 4.9986 - val_accuracy: 0.0451\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 17s 9ms/step - loss: 4.9263 - accuracy: 0.0454 - val_loss: 5.0013 - val_accuracy: 0.0451\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 22s 12ms/step - loss: 4.9241 - accuracy: 0.0452 - val_loss: 4.9968 - val_accuracy: 0.0451\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 16s 9ms/step - loss: 4.9233 - accuracy: 0.0451 - val_loss: 5.0055 - val_accuracy: 0.0451\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 12s 7ms/step - loss: 4.9229 - accuracy: 0.0454 - val_loss: 5.0084 - val_accuracy: 0.0451\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 12s 7ms/step - loss: 4.9216 - accuracy: 0.0452 - val_loss: 5.0043 - val_accuracy: 0.0451\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9220 - accuracy: 0.0454 - val_loss: 5.0211 - val_accuracy: 0.0451\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 14s 7ms/step - loss: 4.9209 - accuracy: 0.0453 - val_loss: 5.0042 - val_accuracy: 0.0451\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 12s 7ms/step - loss: 4.9200 - accuracy: 0.0452 - val_loss: 5.0063 - val_accuracy: 0.0451\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9200 - accuracy: 0.0451 - val_loss: 5.0219 - val_accuracy: 0.0451\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9190 - accuracy: 0.0453 - val_loss: 5.0103 - val_accuracy: 0.0451\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9180 - accuracy: 0.0452 - val_loss: 5.0189 - val_accuracy: 0.0451\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9177 - accuracy: 0.0454 - val_loss: 5.0055 - val_accuracy: 0.0451\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9169 - accuracy: 0.0454 - val_loss: 5.0059 - val_accuracy: 0.0451\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9166 - accuracy: 0.0453 - val_loss: 5.0139 - val_accuracy: 0.0451\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9171 - accuracy: 0.0449 - val_loss: 5.0082 - val_accuracy: 0.0451\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9150 - accuracy: 0.0451 - val_loss: 5.0039 - val_accuracy: 0.0451\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 12s 7ms/step - loss: 4.9152 - accuracy: 0.0452 - val_loss: 5.0052 - val_accuracy: 0.0451\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 19s 10ms/step - loss: 4.9149 - accuracy: 0.0454 - val_loss: 5.0076 - val_accuracy: 0.0451\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 20s 11ms/step - loss: 4.9146 - accuracy: 0.0454 - val_loss: 5.0071 - val_accuracy: 0.0451\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 18s 10ms/step - loss: 4.9149 - accuracy: 0.0454 - val_loss: 5.0078 - val_accuracy: 0.0451\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 17s 9ms/step - loss: 4.9136 - accuracy: 0.0453 - val_loss: 5.0088 - val_accuracy: 0.0451\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 19s 11ms/step - loss: 4.9138 - accuracy: 0.0454 - val_loss: 5.0057 - val_accuracy: 0.0451\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 15s 8ms/step - loss: 4.9141 - accuracy: 0.0454 - val_loss: 5.0068 - val_accuracy: 0.0451\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 16s 9ms/step - loss: 4.9137 - accuracy: 0.0453 - val_loss: 5.0052 - val_accuracy: 0.0451\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 18s 10ms/step - loss: 4.9132 - accuracy: 0.0454 - val_loss: 5.0064 - val_accuracy: 0.0451\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 20s 11ms/step - loss: 4.9130 - accuracy: 0.0451 - val_loss: 5.0083 - val_accuracy: 0.0451\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 22s 12ms/step - loss: 4.9127 - accuracy: 0.0454 - val_loss: 5.0039 - val_accuracy: 0.0451\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 20s 11ms/step - loss: 4.9123 - accuracy: 0.0454 - val_loss: 5.0064 - val_accuracy: 0.0451\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 18s 10ms/step - loss: 4.9124 - accuracy: 0.0454 - val_loss: 5.0079 - val_accuracy: 0.0451\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 19s 10ms/step - loss: 4.9126 - accuracy: 0.0454 - val_loss: 5.0093 - val_accuracy: 0.0451\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 17s 9ms/step - loss: 4.9121 - accuracy: 0.0453 - val_loss: 5.0105 - val_accuracy: 0.0451\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 18s 9ms/step - loss: 4.9122 - accuracy: 0.0454 - val_loss: 5.0092 - val_accuracy: 0.0451\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 15s 8ms/step - loss: 4.9125 - accuracy: 0.0453 - val_loss: 5.0064 - val_accuracy: 0.0451\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 15s 8ms/step - loss: 4.9119 - accuracy: 0.0454 - val_loss: 5.0059 - val_accuracy: 0.0451\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 16s 9ms/step - loss: 4.9114 - accuracy: 0.0454 - val_loss: 5.0078 - val_accuracy: 0.0451\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 13s 7ms/step - loss: 4.9117 - accuracy: 0.0454 - val_loss: 5.0068 - val_accuracy: 0.0451\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9111 - accuracy: 0.0454 - val_loss: 5.0053 - val_accuracy: 0.0451\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9110 - accuracy: 0.0454 - val_loss: 5.0042 - val_accuracy: 0.0451\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9111 - accuracy: 0.0450 - val_loss: 5.0094 - val_accuracy: 0.0451\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9111 - accuracy: 0.0454 - val_loss: 5.0055 - val_accuracy: 0.0451\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9108 - accuracy: 0.0454 - val_loss: 5.0085 - val_accuracy: 0.0444\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9108 - accuracy: 0.0452 - val_loss: 5.0083 - val_accuracy: 0.0451\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9109 - accuracy: 0.0452 - val_loss: 5.0066 - val_accuracy: 0.0451\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9105 - accuracy: 0.0454 - val_loss: 5.0118 - val_accuracy: 0.0451\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 9s 5ms/step - loss: 4.9104 - accuracy: 0.0454 - val_loss: 5.0094 - val_accuracy: 0.0451\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9105 - accuracy: 0.0454 - val_loss: 5.0091 - val_accuracy: 0.0451\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9103 - accuracy: 0.0454 - val_loss: 5.0070 - val_accuracy: 0.0451\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9104 - accuracy: 0.0454 - val_loss: 5.0095 - val_accuracy: 0.0451\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9102 - accuracy: 0.0454 - val_loss: 5.0061 - val_accuracy: 0.0451\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9100 - accuracy: 0.0454 - val_loss: 5.0105 - val_accuracy: 0.0451\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9106 - accuracy: 0.0454 - val_loss: 5.0065 - val_accuracy: 0.0451\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9099 - accuracy: 0.0454 - val_loss: 5.0109 - val_accuracy: 0.0451\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9099 - accuracy: 0.0453 - val_loss: 5.0092 - val_accuracy: 0.0451\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9100 - accuracy: 0.0454 - val_loss: 5.0120 - val_accuracy: 0.0451\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9096 - accuracy: 0.0454 - val_loss: 5.0075 - val_accuracy: 0.0451\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9097 - accuracy: 0.0453 - val_loss: 5.0072 - val_accuracy: 0.0451\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9096 - accuracy: 0.0454 - val_loss: 5.0091 - val_accuracy: 0.0451\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9098 - accuracy: 0.0453 - val_loss: 5.0112 - val_accuracy: 0.0451\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9095 - accuracy: 0.0454 - val_loss: 5.0081 - val_accuracy: 0.0451\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9099 - accuracy: 0.0454 - val_loss: 5.0076 - val_accuracy: 0.0451\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9095 - accuracy: 0.0454 - val_loss: 5.0088 - val_accuracy: 0.0451\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9093 - accuracy: 0.0454 - val_loss: 5.0100 - val_accuracy: 0.0451\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9091 - accuracy: 0.0454 - val_loss: 5.0140 - val_accuracy: 0.0451\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9092 - accuracy: 0.0454 - val_loss: 5.0171 - val_accuracy: 0.0451\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 8s 5ms/step - loss: 4.9096 - accuracy: 0.0452 - val_loss: 5.0087 - val_accuracy: 0.0451\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9090 - accuracy: 0.0454 - val_loss: 5.0077 - val_accuracy: 0.0451\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9092 - accuracy: 0.0454 - val_loss: 5.0095 - val_accuracy: 0.0451\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 8s 5ms/step - loss: 4.9090 - accuracy: 0.0454 - val_loss: 5.0085 - val_accuracy: 0.0451\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9086 - accuracy: 0.0453 - val_loss: 5.0085 - val_accuracy: 0.0451\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9090 - accuracy: 0.0454 - val_loss: 5.0109 - val_accuracy: 0.0451\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9088 - accuracy: 0.0452 - val_loss: 5.0109 - val_accuracy: 0.0451\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 8s 5ms/step - loss: 4.9086 - accuracy: 0.0454 - val_loss: 5.0096 - val_accuracy: 0.0451\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9089 - accuracy: 0.0454 - val_loss: 5.0080 - val_accuracy: 0.0451\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 8s 5ms/step - loss: 4.9088 - accuracy: 0.0454 - val_loss: 5.0080 - val_accuracy: 0.0451\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9090 - accuracy: 0.0454 - val_loss: 5.0085 - val_accuracy: 0.0451\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 11s 4ms/step - loss: 5.0732 - accuracy: 0.0424 - val_loss: 5.0320 - val_accuracy: 0.0306\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9633 - accuracy: 0.0438 - val_loss: 5.0143 - val_accuracy: 0.0460\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9480 - accuracy: 0.0449 - val_loss: 5.0113 - val_accuracy: 0.0460\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9409 - accuracy: 0.0451 - val_loss: 5.0011 - val_accuracy: 0.0460\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9376 - accuracy: 0.0451 - val_loss: 5.0041 - val_accuracy: 0.0460\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9349 - accuracy: 0.0450 - val_loss: 5.0077 - val_accuracy: 0.0460\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9329 - accuracy: 0.0451 - val_loss: 4.9992 - val_accuracy: 0.0460\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9319 - accuracy: 0.0451 - val_loss: 5.0075 - val_accuracy: 0.0460\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9307 - accuracy: 0.0450 - val_loss: 5.0141 - val_accuracy: 0.0460\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9295 - accuracy: 0.0449 - val_loss: 5.0088 - val_accuracy: 0.0460\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9289 - accuracy: 0.0451 - val_loss: 5.0063 - val_accuracy: 0.0460\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9287 - accuracy: 0.0451 - val_loss: 5.0099 - val_accuracy: 0.0460\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9281 - accuracy: 0.0451 - val_loss: 5.0117 - val_accuracy: 0.0460\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9278 - accuracy: 0.0451 - val_loss: 5.0107 - val_accuracy: 0.0460\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9263 - accuracy: 0.0445 - val_loss: 5.0107 - val_accuracy: 0.0460\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9265 - accuracy: 0.0450 - val_loss: 5.0219 - val_accuracy: 0.0460\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9255 - accuracy: 0.0451 - val_loss: 5.0092 - val_accuracy: 0.0460\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9244 - accuracy: 0.0451 - val_loss: 5.0147 - val_accuracy: 0.0460\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9231 - accuracy: 0.0451 - val_loss: 5.0143 - val_accuracy: 0.0460\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9238 - accuracy: 0.0449 - val_loss: 5.0122 - val_accuracy: 0.0460\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9238 - accuracy: 0.0451 - val_loss: 5.0198 - val_accuracy: 0.0460\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9235 - accuracy: 0.0450 - val_loss: 5.0133 - val_accuracy: 0.0460\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9229 - accuracy: 0.0449 - val_loss: 5.0120 - val_accuracy: 0.0460\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9222 - accuracy: 0.0451 - val_loss: 5.0196 - val_accuracy: 0.0460\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9219 - accuracy: 0.0451 - val_loss: 5.0159 - val_accuracy: 0.0460\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9217 - accuracy: 0.0451 - val_loss: 5.0180 - val_accuracy: 0.0460\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9214 - accuracy: 0.0451 - val_loss: 5.0136 - val_accuracy: 0.0460\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9217 - accuracy: 0.0451 - val_loss: 5.0193 - val_accuracy: 0.0460\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9209 - accuracy: 0.0449 - val_loss: 5.0162 - val_accuracy: 0.0460\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9209 - accuracy: 0.0450 - val_loss: 5.0194 - val_accuracy: 0.0460\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9206 - accuracy: 0.0451 - val_loss: 5.0177 - val_accuracy: 0.0460\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9206 - accuracy: 0.0450 - val_loss: 5.0191 - val_accuracy: 0.0460\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9207 - accuracy: 0.0449 - val_loss: 5.0194 - val_accuracy: 0.0460\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9202 - accuracy: 0.0451 - val_loss: 5.0225 - val_accuracy: 0.0460\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9197 - accuracy: 0.0449 - val_loss: 5.0221 - val_accuracy: 0.0460\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9197 - accuracy: 0.0450 - val_loss: 5.0187 - val_accuracy: 0.0460\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9199 - accuracy: 0.0451 - val_loss: 5.0255 - val_accuracy: 0.0460\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9195 - accuracy: 0.0450 - val_loss: 5.0240 - val_accuracy: 0.0460\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9191 - accuracy: 0.0451 - val_loss: 5.0259 - val_accuracy: 0.0460\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9195 - accuracy: 0.0451 - val_loss: 5.0238 - val_accuracy: 0.0460\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9192 - accuracy: 0.0450 - val_loss: 5.0240 - val_accuracy: 0.0460\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9192 - accuracy: 0.0451 - val_loss: 5.0234 - val_accuracy: 0.0460\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9188 - accuracy: 0.0451 - val_loss: 5.0221 - val_accuracy: 0.0460\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9187 - accuracy: 0.0450 - val_loss: 5.0285 - val_accuracy: 0.0460\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9182 - accuracy: 0.0451 - val_loss: 5.0286 - val_accuracy: 0.0460\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9186 - accuracy: 0.0451 - val_loss: 5.0270 - val_accuracy: 0.0460\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9179 - accuracy: 0.0451 - val_loss: 5.0269 - val_accuracy: 0.0460\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9177 - accuracy: 0.0450 - val_loss: 5.0301 - val_accuracy: 0.0460\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9182 - accuracy: 0.0451 - val_loss: 5.0313 - val_accuracy: 0.0460\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9182 - accuracy: 0.0451 - val_loss: 5.0283 - val_accuracy: 0.0460\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9180 - accuracy: 0.0451 - val_loss: 5.0295 - val_accuracy: 0.0460\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9178 - accuracy: 0.0451 - val_loss: 5.0356 - val_accuracy: 0.0460\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9179 - accuracy: 0.0451 - val_loss: 5.0319 - val_accuracy: 0.0460\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9177 - accuracy: 0.0449 - val_loss: 5.0301 - val_accuracy: 0.0460\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9174 - accuracy: 0.0451 - val_loss: 5.0308 - val_accuracy: 0.0460\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9177 - accuracy: 0.0451 - val_loss: 5.0326 - val_accuracy: 0.0460\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9177 - accuracy: 0.0451 - val_loss: 5.0290 - val_accuracy: 0.0460\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9172 - accuracy: 0.0448 - val_loss: 5.0365 - val_accuracy: 0.0460\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9175 - accuracy: 0.0451 - val_loss: 5.0309 - val_accuracy: 0.0460\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9169 - accuracy: 0.0451 - val_loss: 5.0297 - val_accuracy: 0.0460\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9170 - accuracy: 0.0451 - val_loss: 5.0354 - val_accuracy: 0.0460\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9173 - accuracy: 0.0447 - val_loss: 5.0324 - val_accuracy: 0.0460\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9170 - accuracy: 0.0449 - val_loss: 5.0317 - val_accuracy: 0.0460\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9170 - accuracy: 0.0451 - val_loss: 5.0348 - val_accuracy: 0.0460\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9171 - accuracy: 0.0448 - val_loss: 5.0368 - val_accuracy: 0.0460\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9167 - accuracy: 0.0451 - val_loss: 5.0303 - val_accuracy: 0.0460\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9166 - accuracy: 0.0450 - val_loss: 5.0328 - val_accuracy: 0.0460\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9169 - accuracy: 0.0451 - val_loss: 5.0308 - val_accuracy: 0.0460\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9166 - accuracy: 0.0451 - val_loss: 5.0310 - val_accuracy: 0.0460\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9166 - accuracy: 0.0451 - val_loss: 5.0314 - val_accuracy: 0.0460\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9166 - accuracy: 0.0451 - val_loss: 5.0381 - val_accuracy: 0.0460\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9167 - accuracy: 0.0450 - val_loss: 5.0325 - val_accuracy: 0.0460\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9165 - accuracy: 0.0451 - val_loss: 5.0356 - val_accuracy: 0.0460\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9161 - accuracy: 0.0451 - val_loss: 5.0371 - val_accuracy: 0.0460\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9164 - accuracy: 0.0449 - val_loss: 5.0367 - val_accuracy: 0.0460\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9163 - accuracy: 0.0451 - val_loss: 5.0361 - val_accuracy: 0.0460\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9161 - accuracy: 0.0450 - val_loss: 5.0350 - val_accuracy: 0.0460\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9160 - accuracy: 0.0451 - val_loss: 5.0347 - val_accuracy: 0.0460\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9159 - accuracy: 0.0450 - val_loss: 5.0333 - val_accuracy: 0.0460\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.9163 - accuracy: 0.0451 - val_loss: 5.0343 - val_accuracy: 0.0460\n",
      "Average Validation Accuracy: 0.04534727334976196\n",
      "Average Validation Loss: 4.944447994232178\n",
      "Average Test Accuracy: 0.045035749673843384\n",
      "Final Test Accuracy for each fold: 0.045035749673843384\n",
      "Number of input features: 2\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 11s 4ms/step - loss: 5.0818 - accuracy: 0.0416 - val_loss: 5.0194 - val_accuracy: 0.0436\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.9248 - accuracy: 0.0489 - val_loss: 4.9436 - val_accuracy: 0.0513\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.8446 - accuracy: 0.0538 - val_loss: 4.9241 - val_accuracy: 0.0521\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.8089 - accuracy: 0.0551 - val_loss: 4.8936 - val_accuracy: 0.0585\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.7867 - accuracy: 0.0552 - val_loss: 4.9054 - val_accuracy: 0.0554\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7728 - accuracy: 0.0579 - val_loss: 4.8930 - val_accuracy: 0.0477\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7579 - accuracy: 0.0582 - val_loss: 4.9201 - val_accuracy: 0.0524\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7486 - accuracy: 0.0586 - val_loss: 4.8947 - val_accuracy: 0.0585\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.7401 - accuracy: 0.0606 - val_loss: 4.8998 - val_accuracy: 0.0524\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.7305 - accuracy: 0.0610 - val_loss: 4.9129 - val_accuracy: 0.0546\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7221 - accuracy: 0.0603 - val_loss: 4.9327 - val_accuracy: 0.0543\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.7161 - accuracy: 0.0600 - val_loss: 4.9439 - val_accuracy: 0.0568\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7104 - accuracy: 0.0619 - val_loss: 4.9532 - val_accuracy: 0.0548\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7036 - accuracy: 0.0596 - val_loss: 4.9476 - val_accuracy: 0.0504\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7000 - accuracy: 0.0615 - val_loss: 4.9645 - val_accuracy: 0.0605\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6940 - accuracy: 0.0620 - val_loss: 4.9675 - val_accuracy: 0.0568\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6895 - accuracy: 0.0632 - val_loss: 4.9736 - val_accuracy: 0.0565\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6845 - accuracy: 0.0609 - val_loss: 4.9690 - val_accuracy: 0.0559\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6803 - accuracy: 0.0631 - val_loss: 4.9875 - val_accuracy: 0.0570\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6741 - accuracy: 0.0633 - val_loss: 4.9942 - val_accuracy: 0.0623\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6701 - accuracy: 0.0672 - val_loss: 5.0015 - val_accuracy: 0.0539\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6652 - accuracy: 0.0649 - val_loss: 5.0111 - val_accuracy: 0.0596\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6611 - accuracy: 0.0674 - val_loss: 5.0331 - val_accuracy: 0.0607\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6556 - accuracy: 0.0664 - val_loss: 5.0204 - val_accuracy: 0.0629\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6501 - accuracy: 0.0659 - val_loss: 5.0614 - val_accuracy: 0.0640\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6458 - accuracy: 0.0655 - val_loss: 5.0487 - val_accuracy: 0.0647\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6414 - accuracy: 0.0654 - val_loss: 5.0614 - val_accuracy: 0.0649\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6376 - accuracy: 0.0664 - val_loss: 5.0775 - val_accuracy: 0.0572\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6335 - accuracy: 0.0671 - val_loss: 5.0633 - val_accuracy: 0.0623\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6294 - accuracy: 0.0671 - val_loss: 5.0889 - val_accuracy: 0.0603\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6252 - accuracy: 0.0672 - val_loss: 5.0679 - val_accuracy: 0.0656\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6227 - accuracy: 0.0672 - val_loss: 5.0972 - val_accuracy: 0.0603\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6184 - accuracy: 0.0671 - val_loss: 5.1172 - val_accuracy: 0.0689\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6154 - accuracy: 0.0663 - val_loss: 5.1196 - val_accuracy: 0.0645\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6121 - accuracy: 0.0661 - val_loss: 5.1274 - val_accuracy: 0.0675\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6107 - accuracy: 0.0656 - val_loss: 5.1451 - val_accuracy: 0.0620\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6055 - accuracy: 0.0684 - val_loss: 5.1116 - val_accuracy: 0.0722\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6022 - accuracy: 0.0662 - val_loss: 5.1380 - val_accuracy: 0.0642\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5997 - accuracy: 0.0694 - val_loss: 5.1744 - val_accuracy: 0.0576\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5954 - accuracy: 0.0709 - val_loss: 5.1494 - val_accuracy: 0.0689\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5935 - accuracy: 0.0680 - val_loss: 5.1604 - val_accuracy: 0.0724\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5909 - accuracy: 0.0699 - val_loss: 5.1887 - val_accuracy: 0.0662\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5884 - accuracy: 0.0708 - val_loss: 5.2059 - val_accuracy: 0.0704\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5852 - accuracy: 0.0715 - val_loss: 5.2219 - val_accuracy: 0.0667\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5820 - accuracy: 0.0695 - val_loss: 5.2081 - val_accuracy: 0.0642\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5789 - accuracy: 0.0713 - val_loss: 5.2103 - val_accuracy: 0.0671\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5764 - accuracy: 0.0699 - val_loss: 5.2220 - val_accuracy: 0.0664\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5738 - accuracy: 0.0719 - val_loss: 5.2066 - val_accuracy: 0.0706\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5719 - accuracy: 0.0707 - val_loss: 5.2207 - val_accuracy: 0.0684\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5697 - accuracy: 0.0686 - val_loss: 5.2379 - val_accuracy: 0.0686\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5676 - accuracy: 0.0701 - val_loss: 5.2350 - val_accuracy: 0.0726\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5655 - accuracy: 0.0713 - val_loss: 5.2387 - val_accuracy: 0.0675\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5620 - accuracy: 0.0736 - val_loss: 5.2721 - val_accuracy: 0.0572\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5606 - accuracy: 0.0710 - val_loss: 5.2989 - val_accuracy: 0.0627\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5578 - accuracy: 0.0702 - val_loss: 5.2682 - val_accuracy: 0.0728\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5563 - accuracy: 0.0713 - val_loss: 5.2552 - val_accuracy: 0.0735\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5534 - accuracy: 0.0726 - val_loss: 5.2792 - val_accuracy: 0.0708\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5502 - accuracy: 0.0727 - val_loss: 5.2678 - val_accuracy: 0.0777\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5474 - accuracy: 0.0724 - val_loss: 5.2958 - val_accuracy: 0.0706\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5460 - accuracy: 0.0732 - val_loss: 5.2924 - val_accuracy: 0.0783\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5425 - accuracy: 0.0713 - val_loss: 5.2940 - val_accuracy: 0.0728\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5412 - accuracy: 0.0738 - val_loss: 5.3113 - val_accuracy: 0.0717\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5375 - accuracy: 0.0733 - val_loss: 5.3625 - val_accuracy: 0.0697\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5352 - accuracy: 0.0737 - val_loss: 5.3137 - val_accuracy: 0.0803\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5342 - accuracy: 0.0741 - val_loss: 5.3927 - val_accuracy: 0.0675\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5329 - accuracy: 0.0738 - val_loss: 5.3112 - val_accuracy: 0.0717\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5300 - accuracy: 0.0723 - val_loss: 5.3283 - val_accuracy: 0.0700\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5272 - accuracy: 0.0693 - val_loss: 5.3677 - val_accuracy: 0.0691\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5250 - accuracy: 0.0760 - val_loss: 5.3156 - val_accuracy: 0.0737\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5226 - accuracy: 0.0744 - val_loss: 5.3482 - val_accuracy: 0.0827\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5215 - accuracy: 0.0753 - val_loss: 5.3483 - val_accuracy: 0.0719\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5176 - accuracy: 0.0742 - val_loss: 5.4058 - val_accuracy: 0.0719\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5175 - accuracy: 0.0719 - val_loss: 5.3419 - val_accuracy: 0.0755\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5130 - accuracy: 0.0750 - val_loss: 5.3935 - val_accuracy: 0.0772\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5136 - accuracy: 0.0738 - val_loss: 5.3943 - val_accuracy: 0.0730\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5115 - accuracy: 0.0735 - val_loss: 5.4040 - val_accuracy: 0.0849\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5078 - accuracy: 0.0751 - val_loss: 5.3931 - val_accuracy: 0.0689\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5094 - accuracy: 0.0758 - val_loss: 5.3935 - val_accuracy: 0.0759\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5070 - accuracy: 0.0737 - val_loss: 5.4712 - val_accuracy: 0.0746\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5031 - accuracy: 0.0768 - val_loss: 5.4409 - val_accuracy: 0.0722\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 4ms/step - loss: 5.0596 - accuracy: 0.0469 - val_loss: 4.9819 - val_accuracy: 0.0502\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.8806 - accuracy: 0.0541 - val_loss: 4.9542 - val_accuracy: 0.0502\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.8363 - accuracy: 0.0568 - val_loss: 4.9111 - val_accuracy: 0.0515\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.8089 - accuracy: 0.0582 - val_loss: 4.9088 - val_accuracy: 0.0612\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7892 - accuracy: 0.0572 - val_loss: 4.9027 - val_accuracy: 0.0576\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7731 - accuracy: 0.0570 - val_loss: 4.8963 - val_accuracy: 0.0535\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7625 - accuracy: 0.0572 - val_loss: 4.8961 - val_accuracy: 0.0568\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7532 - accuracy: 0.0578 - val_loss: 4.9220 - val_accuracy: 0.0651\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7439 - accuracy: 0.0585 - val_loss: 4.9205 - val_accuracy: 0.0506\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7369 - accuracy: 0.0604 - val_loss: 4.9201 - val_accuracy: 0.0576\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7282 - accuracy: 0.0601 - val_loss: 4.9255 - val_accuracy: 0.0583\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7206 - accuracy: 0.0593 - val_loss: 4.9413 - val_accuracy: 0.0519\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7103 - accuracy: 0.0596 - val_loss: 4.9222 - val_accuracy: 0.0526\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.7051 - accuracy: 0.0580 - val_loss: 4.9343 - val_accuracy: 0.0532\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6982 - accuracy: 0.0595 - val_loss: 4.9576 - val_accuracy: 0.0510\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6901 - accuracy: 0.0598 - val_loss: 4.9596 - val_accuracy: 0.0590\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6843 - accuracy: 0.0621 - val_loss: 4.9486 - val_accuracy: 0.0526\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6801 - accuracy: 0.0620 - val_loss: 4.9767 - val_accuracy: 0.0557\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6747 - accuracy: 0.0626 - val_loss: 4.9828 - val_accuracy: 0.0667\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6679 - accuracy: 0.0630 - val_loss: 4.9701 - val_accuracy: 0.0570\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6633 - accuracy: 0.0626 - val_loss: 4.9812 - val_accuracy: 0.0519\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6585 - accuracy: 0.0635 - val_loss: 4.9896 - val_accuracy: 0.0629\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6520 - accuracy: 0.0645 - val_loss: 5.0038 - val_accuracy: 0.0607\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6471 - accuracy: 0.0637 - val_loss: 5.0275 - val_accuracy: 0.0587\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6405 - accuracy: 0.0664 - val_loss: 5.0279 - val_accuracy: 0.0596\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.6365 - accuracy: 0.0691 - val_loss: 5.0045 - val_accuracy: 0.0664\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6314 - accuracy: 0.0669 - val_loss: 5.0455 - val_accuracy: 0.0598\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6267 - accuracy: 0.0675 - val_loss: 5.0549 - val_accuracy: 0.0618\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6205 - accuracy: 0.0701 - val_loss: 5.0793 - val_accuracy: 0.0739\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6159 - accuracy: 0.0678 - val_loss: 5.0775 - val_accuracy: 0.0605\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6125 - accuracy: 0.0689 - val_loss: 5.0694 - val_accuracy: 0.0678\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6077 - accuracy: 0.0699 - val_loss: 5.1026 - val_accuracy: 0.0649\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6034 - accuracy: 0.0696 - val_loss: 5.1168 - val_accuracy: 0.0700\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5996 - accuracy: 0.0698 - val_loss: 5.1289 - val_accuracy: 0.0629\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5951 - accuracy: 0.0717 - val_loss: 5.1128 - val_accuracy: 0.0675\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5922 - accuracy: 0.0707 - val_loss: 5.1539 - val_accuracy: 0.0620\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5880 - accuracy: 0.0682 - val_loss: 5.1399 - val_accuracy: 0.0583\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5854 - accuracy: 0.0733 - val_loss: 5.1634 - val_accuracy: 0.0667\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5831 - accuracy: 0.0699 - val_loss: 5.1643 - val_accuracy: 0.0572\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5782 - accuracy: 0.0690 - val_loss: 5.1466 - val_accuracy: 0.0634\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5766 - accuracy: 0.0706 - val_loss: 5.2120 - val_accuracy: 0.0667\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5746 - accuracy: 0.0689 - val_loss: 5.1909 - val_accuracy: 0.0697\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5724 - accuracy: 0.0722 - val_loss: 5.2178 - val_accuracy: 0.0614\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5696 - accuracy: 0.0704 - val_loss: 5.2003 - val_accuracy: 0.0649\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5666 - accuracy: 0.0704 - val_loss: 5.2224 - val_accuracy: 0.0574\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5658 - accuracy: 0.0710 - val_loss: 5.2299 - val_accuracy: 0.0570\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5631 - accuracy: 0.0714 - val_loss: 5.2311 - val_accuracy: 0.0627\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5617 - accuracy: 0.0713 - val_loss: 5.2359 - val_accuracy: 0.0678\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5589 - accuracy: 0.0691 - val_loss: 5.2569 - val_accuracy: 0.0605\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5558 - accuracy: 0.0708 - val_loss: 5.2785 - val_accuracy: 0.0733\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5553 - accuracy: 0.0708 - val_loss: 5.3039 - val_accuracy: 0.0598\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5525 - accuracy: 0.0723 - val_loss: 5.3295 - val_accuracy: 0.0570\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5499 - accuracy: 0.0706 - val_loss: 5.3157 - val_accuracy: 0.0636\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5488 - accuracy: 0.0712 - val_loss: 5.2718 - val_accuracy: 0.0697\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5464 - accuracy: 0.0715 - val_loss: 5.3179 - val_accuracy: 0.0609\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5458 - accuracy: 0.0700 - val_loss: 5.3270 - val_accuracy: 0.0601\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5433 - accuracy: 0.0702 - val_loss: 5.3176 - val_accuracy: 0.0616\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5410 - accuracy: 0.0701 - val_loss: 5.3516 - val_accuracy: 0.0645\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5394 - accuracy: 0.0710 - val_loss: 5.3625 - val_accuracy: 0.0697\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5397 - accuracy: 0.0707 - val_loss: 5.3513 - val_accuracy: 0.0671\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5367 - accuracy: 0.0682 - val_loss: 5.3751 - val_accuracy: 0.0649\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5335 - accuracy: 0.0714 - val_loss: 5.3490 - val_accuracy: 0.0686\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5348 - accuracy: 0.0698 - val_loss: 5.3388 - val_accuracy: 0.0605\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5323 - accuracy: 0.0701 - val_loss: 5.3500 - val_accuracy: 0.0739\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5306 - accuracy: 0.0720 - val_loss: 5.3699 - val_accuracy: 0.0680\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5287 - accuracy: 0.0702 - val_loss: 5.3747 - val_accuracy: 0.0612\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5281 - accuracy: 0.0722 - val_loss: 5.3897 - val_accuracy: 0.0684\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5275 - accuracy: 0.0696 - val_loss: 5.3896 - val_accuracy: 0.0563\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5254 - accuracy: 0.0709 - val_loss: 5.3845 - val_accuracy: 0.0629\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5240 - accuracy: 0.0706 - val_loss: 5.3732 - val_accuracy: 0.0645\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5231 - accuracy: 0.0700 - val_loss: 5.4312 - val_accuracy: 0.0653\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5215 - accuracy: 0.0694 - val_loss: 5.4588 - val_accuracy: 0.0664\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5225 - accuracy: 0.0719 - val_loss: 5.4068 - val_accuracy: 0.0649\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5198 - accuracy: 0.0720 - val_loss: 5.4179 - val_accuracy: 0.0616\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5178 - accuracy: 0.0716 - val_loss: 5.3943 - val_accuracy: 0.0678\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5167 - accuracy: 0.0728 - val_loss: 5.5161 - val_accuracy: 0.0682\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5158 - accuracy: 0.0698 - val_loss: 5.4751 - val_accuracy: 0.0669\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5155 - accuracy: 0.0720 - val_loss: 5.4721 - val_accuracy: 0.0686\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5157 - accuracy: 0.0723 - val_loss: 5.3940 - val_accuracy: 0.0647\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5123 - accuracy: 0.0725 - val_loss: 5.4816 - val_accuracy: 0.0636\n",
      "Average Validation Accuracy: 0.0699632316827774\n",
      "Average Validation Loss: 5.2105231285095215\n",
      "Average Test Accuracy: 0.07098105549812317\n",
      "Final Test Accuracy for each fold: 0.07407680153846741\n",
      "Number of input features: 3\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 4ms/step - loss: 4.9408 - accuracy: 0.0689 - val_loss: 4.7615 - val_accuracy: 0.0759\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6294 - accuracy: 0.0849 - val_loss: 4.6932 - val_accuracy: 0.0785\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5743 - accuracy: 0.0845 - val_loss: 4.6735 - val_accuracy: 0.0792\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.5485 - accuracy: 0.0847 - val_loss: 4.6643 - val_accuracy: 0.0735\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5302 - accuracy: 0.0848 - val_loss: 4.6499 - val_accuracy: 0.0779\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5150 - accuracy: 0.0845 - val_loss: 4.6532 - val_accuracy: 0.0799\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 4.5029 - accuracy: 0.0854 - val_loss: 4.6479 - val_accuracy: 0.0735\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4890 - accuracy: 0.0850 - val_loss: 4.6587 - val_accuracy: 0.0752\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4769 - accuracy: 0.0881 - val_loss: 4.6625 - val_accuracy: 0.0759\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4641 - accuracy: 0.0868 - val_loss: 4.6510 - val_accuracy: 0.0779\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4548 - accuracy: 0.0893 - val_loss: 4.6651 - val_accuracy: 0.0829\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4442 - accuracy: 0.0902 - val_loss: 4.6715 - val_accuracy: 0.0816\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4383 - accuracy: 0.0899 - val_loss: 4.6741 - val_accuracy: 0.0792\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4297 - accuracy: 0.0905 - val_loss: 4.6627 - val_accuracy: 0.0805\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4262 - accuracy: 0.0908 - val_loss: 4.6710 - val_accuracy: 0.0805\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4197 - accuracy: 0.0915 - val_loss: 4.6885 - val_accuracy: 0.0832\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4140 - accuracy: 0.0920 - val_loss: 4.6762 - val_accuracy: 0.0825\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4076 - accuracy: 0.0932 - val_loss: 4.7008 - val_accuracy: 0.0818\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4041 - accuracy: 0.0907 - val_loss: 4.6865 - val_accuracy: 0.0814\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3992 - accuracy: 0.0909 - val_loss: 4.7142 - val_accuracy: 0.0812\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3957 - accuracy: 0.0905 - val_loss: 4.7158 - val_accuracy: 0.0869\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3907 - accuracy: 0.0913 - val_loss: 4.7078 - val_accuracy: 0.0818\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3854 - accuracy: 0.0905 - val_loss: 4.7188 - val_accuracy: 0.0777\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3850 - accuracy: 0.0901 - val_loss: 4.7322 - val_accuracy: 0.0816\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3805 - accuracy: 0.0927 - val_loss: 4.7537 - val_accuracy: 0.0796\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3768 - accuracy: 0.0920 - val_loss: 4.7403 - val_accuracy: 0.0812\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3731 - accuracy: 0.0919 - val_loss: 4.7608 - val_accuracy: 0.0832\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3691 - accuracy: 0.0926 - val_loss: 4.8009 - val_accuracy: 0.0858\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3670 - accuracy: 0.0897 - val_loss: 4.7827 - val_accuracy: 0.0818\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.3609 - accuracy: 0.0940 - val_loss: 4.8054 - val_accuracy: 0.0838\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3593 - accuracy: 0.0941 - val_loss: 4.7874 - val_accuracy: 0.0836\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3569 - accuracy: 0.0935 - val_loss: 4.7822 - val_accuracy: 0.0924\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3520 - accuracy: 0.0936 - val_loss: 4.8256 - val_accuracy: 0.0865\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3501 - accuracy: 0.0945 - val_loss: 4.8049 - val_accuracy: 0.0865\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3460 - accuracy: 0.0928 - val_loss: 4.8294 - val_accuracy: 0.0867\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3435 - accuracy: 0.0939 - val_loss: 4.8360 - val_accuracy: 0.0924\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3398 - accuracy: 0.0938 - val_loss: 4.8660 - val_accuracy: 0.0834\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.3353 - accuracy: 0.0935 - val_loss: 4.8699 - val_accuracy: 0.0939\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.3325 - accuracy: 0.0953 - val_loss: 4.8572 - val_accuracy: 0.0900\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3306 - accuracy: 0.0969 - val_loss: 4.8490 - val_accuracy: 0.0836\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3259 - accuracy: 0.0952 - val_loss: 4.8446 - val_accuracy: 0.0898\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3247 - accuracy: 0.0966 - val_loss: 4.8432 - val_accuracy: 0.0902\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.3222 - accuracy: 0.0955 - val_loss: 4.8780 - val_accuracy: 0.0955\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3199 - accuracy: 0.0965 - val_loss: 4.8556 - val_accuracy: 0.0948\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3177 - accuracy: 0.0956 - val_loss: 4.8868 - val_accuracy: 0.0843\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3160 - accuracy: 0.0980 - val_loss: 4.8831 - val_accuracy: 0.0889\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3110 - accuracy: 0.0974 - val_loss: 4.9006 - val_accuracy: 0.0972\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3097 - accuracy: 0.1006 - val_loss: 4.8925 - val_accuracy: 0.0895\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3074 - accuracy: 0.0986 - val_loss: 4.8810 - val_accuracy: 0.0895\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3048 - accuracy: 0.0987 - val_loss: 4.8996 - val_accuracy: 0.0966\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3016 - accuracy: 0.0971 - val_loss: 4.9269 - val_accuracy: 0.0924\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3011 - accuracy: 0.0993 - val_loss: 4.9191 - val_accuracy: 0.0922\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2965 - accuracy: 0.0997 - val_loss: 4.9292 - val_accuracy: 0.0904\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2950 - accuracy: 0.0992 - val_loss: 4.9045 - val_accuracy: 0.0895\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2937 - accuracy: 0.1007 - val_loss: 4.9474 - val_accuracy: 0.0887\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2914 - accuracy: 0.0998 - val_loss: 4.9076 - val_accuracy: 0.0900\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2893 - accuracy: 0.0982 - val_loss: 4.9430 - val_accuracy: 0.0957\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2871 - accuracy: 0.1010 - val_loss: 4.9501 - val_accuracy: 0.0902\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2853 - accuracy: 0.1002 - val_loss: 4.9410 - val_accuracy: 0.0887\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2828 - accuracy: 0.0987 - val_loss: 4.9340 - val_accuracy: 0.0950\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2823 - accuracy: 0.0985 - val_loss: 5.0015 - val_accuracy: 0.0933\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2789 - accuracy: 0.1018 - val_loss: 4.9335 - val_accuracy: 0.0988\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2788 - accuracy: 0.0985 - val_loss: 4.9810 - val_accuracy: 0.0913\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2787 - accuracy: 0.1012 - val_loss: 4.9981 - val_accuracy: 0.0924\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2781 - accuracy: 0.1026 - val_loss: 4.9845 - val_accuracy: 0.0928\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2736 - accuracy: 0.1033 - val_loss: 5.0106 - val_accuracy: 0.0926\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2724 - accuracy: 0.1013 - val_loss: 5.0101 - val_accuracy: 0.0911\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2714 - accuracy: 0.1032 - val_loss: 5.0091 - val_accuracy: 0.0928\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2714 - accuracy: 0.1032 - val_loss: 5.0028 - val_accuracy: 0.0889\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2687 - accuracy: 0.1023 - val_loss: 5.0061 - val_accuracy: 0.0902\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2685 - accuracy: 0.1017 - val_loss: 4.9940 - val_accuracy: 0.0922\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2665 - accuracy: 0.1005 - val_loss: 5.0215 - val_accuracy: 0.0867\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.2666 - accuracy: 0.0994 - val_loss: 5.0226 - val_accuracy: 0.0876\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2637 - accuracy: 0.0995 - val_loss: 5.0120 - val_accuracy: 0.0968\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2623 - accuracy: 0.1024 - val_loss: 5.0418 - val_accuracy: 0.0939\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2614 - accuracy: 0.0996 - val_loss: 5.0246 - val_accuracy: 0.0983\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2598 - accuracy: 0.0989 - val_loss: 5.0620 - val_accuracy: 0.0944\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2570 - accuracy: 0.1021 - val_loss: 5.0828 - val_accuracy: 0.0926\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2593 - accuracy: 0.1036 - val_loss: 5.0637 - val_accuracy: 0.0953\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.2563 - accuracy: 0.1019 - val_loss: 5.0228 - val_accuracy: 0.0880\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 4ms/step - loss: 4.9616 - accuracy: 0.0672 - val_loss: 4.7962 - val_accuracy: 0.0843\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.6503 - accuracy: 0.0830 - val_loss: 4.7239 - val_accuracy: 0.0867\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5941 - accuracy: 0.0846 - val_loss: 4.7046 - val_accuracy: 0.0854\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5602 - accuracy: 0.0845 - val_loss: 4.6847 - val_accuracy: 0.0840\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5335 - accuracy: 0.0849 - val_loss: 4.6613 - val_accuracy: 0.0865\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.5110 - accuracy: 0.0840 - val_loss: 4.6478 - val_accuracy: 0.0854\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4935 - accuracy: 0.0850 - val_loss: 4.6258 - val_accuracy: 0.0882\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4773 - accuracy: 0.0874 - val_loss: 4.6282 - val_accuracy: 0.0953\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4628 - accuracy: 0.0888 - val_loss: 4.6411 - val_accuracy: 0.0862\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4529 - accuracy: 0.0890 - val_loss: 4.6299 - val_accuracy: 0.0977\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4414 - accuracy: 0.0929 - val_loss: 4.6415 - val_accuracy: 0.0880\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4346 - accuracy: 0.0916 - val_loss: 4.6563 - val_accuracy: 0.0911\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4243 - accuracy: 0.0940 - val_loss: 4.6685 - val_accuracy: 0.1021\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4192 - accuracy: 0.0914 - val_loss: 4.6598 - val_accuracy: 0.0972\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4104 - accuracy: 0.0942 - val_loss: 4.7076 - val_accuracy: 0.0937\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.4042 - accuracy: 0.0958 - val_loss: 4.6884 - val_accuracy: 0.0979\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3955 - accuracy: 0.0956 - val_loss: 4.6976 - val_accuracy: 0.0909\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3894 - accuracy: 0.0958 - val_loss: 4.7233 - val_accuracy: 0.0913\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3833 - accuracy: 0.0948 - val_loss: 4.7242 - val_accuracy: 0.0970\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3770 - accuracy: 0.0994 - val_loss: 4.7416 - val_accuracy: 0.0964\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3728 - accuracy: 0.0948 - val_loss: 4.7570 - val_accuracy: 0.0939\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3666 - accuracy: 0.0973 - val_loss: 4.7660 - val_accuracy: 0.0915\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3601 - accuracy: 0.0975 - val_loss: 4.7760 - val_accuracy: 0.0999\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3564 - accuracy: 0.0980 - val_loss: 4.8085 - val_accuracy: 0.1083\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3517 - accuracy: 0.1009 - val_loss: 4.8090 - val_accuracy: 0.0926\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3490 - accuracy: 0.0971 - val_loss: 4.8158 - val_accuracy: 0.0968\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3449 - accuracy: 0.1005 - val_loss: 4.8789 - val_accuracy: 0.0950\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3410 - accuracy: 0.1008 - val_loss: 4.8893 - val_accuracy: 0.0917\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3385 - accuracy: 0.0988 - val_loss: 4.8595 - val_accuracy: 0.0946\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3338 - accuracy: 0.0983 - val_loss: 4.8913 - val_accuracy: 0.1067\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 6s 4ms/step - loss: 4.3314 - accuracy: 0.1014 - val_loss: 4.8813 - val_accuracy: 0.0994\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3290 - accuracy: 0.0976 - val_loss: 4.9091 - val_accuracy: 0.1014\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3261 - accuracy: 0.0978 - val_loss: 4.9007 - val_accuracy: 0.1030\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3216 - accuracy: 0.1019 - val_loss: 4.9775 - val_accuracy: 0.0913\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3221 - accuracy: 0.0993 - val_loss: 4.9274 - val_accuracy: 0.0990\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3186 - accuracy: 0.0993 - val_loss: 4.9831 - val_accuracy: 0.0983\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3174 - accuracy: 0.0997 - val_loss: 5.0355 - val_accuracy: 0.0898\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3145 - accuracy: 0.1009 - val_loss: 5.0046 - val_accuracy: 0.0979\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3108 - accuracy: 0.1007 - val_loss: 5.0065 - val_accuracy: 0.1014\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 9s 5ms/step - loss: 4.3102 - accuracy: 0.0989 - val_loss: 4.9928 - val_accuracy: 0.0983\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.3079 - accuracy: 0.0996 - val_loss: 4.9927 - val_accuracy: 0.1012\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3060 - accuracy: 0.1009 - val_loss: 5.0468 - val_accuracy: 0.0933\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3046 - accuracy: 0.1007 - val_loss: 5.0675 - val_accuracy: 0.0968\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.3019 - accuracy: 0.1011 - val_loss: 4.9775 - val_accuracy: 0.0983\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2988 - accuracy: 0.0993 - val_loss: 5.0431 - val_accuracy: 0.1030\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2969 - accuracy: 0.1000 - val_loss: 5.0752 - val_accuracy: 0.0983\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2953 - accuracy: 0.0995 - val_loss: 5.1141 - val_accuracy: 0.0944\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2914 - accuracy: 0.1009 - val_loss: 5.0888 - val_accuracy: 0.0968\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2881 - accuracy: 0.0991 - val_loss: 5.0822 - val_accuracy: 0.0994\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2881 - accuracy: 0.1018 - val_loss: 5.0943 - val_accuracy: 0.1006\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2842 - accuracy: 0.0998 - val_loss: 5.1342 - val_accuracy: 0.1010\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2827 - accuracy: 0.1030 - val_loss: 5.0682 - val_accuracy: 0.0994\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2802 - accuracy: 0.1032 - val_loss: 5.0766 - val_accuracy: 0.1010\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2807 - accuracy: 0.1002 - val_loss: 5.1441 - val_accuracy: 0.0986\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2782 - accuracy: 0.1015 - val_loss: 5.1531 - val_accuracy: 0.0950\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2758 - accuracy: 0.1008 - val_loss: 5.1215 - val_accuracy: 0.0953\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2711 - accuracy: 0.1009 - val_loss: 5.1678 - val_accuracy: 0.0953\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2693 - accuracy: 0.1013 - val_loss: 5.1484 - val_accuracy: 0.0924\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2681 - accuracy: 0.1038 - val_loss: 5.1688 - val_accuracy: 0.0988\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2670 - accuracy: 0.1008 - val_loss: 5.1867 - val_accuracy: 0.1021\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2624 - accuracy: 0.1010 - val_loss: 5.1896 - val_accuracy: 0.1058\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2603 - accuracy: 0.1027 - val_loss: 5.2066 - val_accuracy: 0.0977\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2583 - accuracy: 0.1024 - val_loss: 5.2411 - val_accuracy: 0.1017\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2559 - accuracy: 0.1015 - val_loss: 5.1831 - val_accuracy: 0.0957\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2553 - accuracy: 0.1022 - val_loss: 5.2362 - val_accuracy: 0.1019\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2530 - accuracy: 0.0999 - val_loss: 5.2407 - val_accuracy: 0.0948\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 4.2533 - accuracy: 0.1012 - val_loss: 5.2145 - val_accuracy: 0.1036\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2484 - accuracy: 0.1051 - val_loss: 5.2694 - val_accuracy: 0.1036\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2462 - accuracy: 0.1013 - val_loss: 5.1855 - val_accuracy: 0.1091\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2462 - accuracy: 0.1015 - val_loss: 5.1915 - val_accuracy: 0.0990\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2451 - accuracy: 0.1022 - val_loss: 5.2417 - val_accuracy: 0.0955\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2424 - accuracy: 0.1022 - val_loss: 5.2222 - val_accuracy: 0.0922\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2406 - accuracy: 0.0999 - val_loss: 5.3147 - val_accuracy: 0.0994\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2380 - accuracy: 0.1010 - val_loss: 5.2830 - val_accuracy: 0.0990\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2369 - accuracy: 0.0996 - val_loss: 5.2308 - val_accuracy: 0.1091\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2340 - accuracy: 0.1026 - val_loss: 5.2895 - val_accuracy: 0.1008\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2349 - accuracy: 0.1024 - val_loss: 5.2667 - val_accuracy: 0.1021\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2331 - accuracy: 0.1037 - val_loss: 5.3271 - val_accuracy: 0.0999\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2302 - accuracy: 0.1015 - val_loss: 5.3414 - val_accuracy: 0.1047\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 4.2313 - accuracy: 0.1010 - val_loss: 5.3363 - val_accuracy: 0.1010\n",
      "Average Validation Accuracy: 0.09595924988389015\n",
      "Average Validation Loss: 5.003463506698608\n",
      "Average Test Accuracy: 0.09847423806786537\n",
      "Final Test Accuracy for each fold: 0.10201223194599152\n",
      "Number of input features: 4\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 11s 4ms/step - loss: 4.5372 - accuracy: 0.1132 - val_loss: 4.1101 - val_accuracy: 0.1745\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 3.7248 - accuracy: 0.1999 - val_loss: 3.6077 - val_accuracy: 0.2387\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 3.2285 - accuracy: 0.2691 - val_loss: 3.2638 - val_accuracy: 0.2880\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.9146 - accuracy: 0.3090 - val_loss: 3.0239 - val_accuracy: 0.3041\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.6907 - accuracy: 0.3386 - val_loss: 2.8339 - val_accuracy: 0.3364\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.5227 - accuracy: 0.3675 - val_loss: 2.6955 - val_accuracy: 0.3518\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.3951 - accuracy: 0.3879 - val_loss: 2.5608 - val_accuracy: 0.3894\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.2706 - accuracy: 0.4132 - val_loss: 2.4940 - val_accuracy: 0.4062\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.1792 - accuracy: 0.4246 - val_loss: 2.3699 - val_accuracy: 0.4207\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.0971 - accuracy: 0.4407 - val_loss: 2.3230 - val_accuracy: 0.4453\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.0439 - accuracy: 0.4439 - val_loss: 2.2401 - val_accuracy: 0.4420\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9941 - accuracy: 0.4546 - val_loss: 2.2592 - val_accuracy: 0.4108\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 9s 5ms/step - loss: 1.9605 - accuracy: 0.4633 - val_loss: 2.1752 - val_accuracy: 0.4587\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9164 - accuracy: 0.4701 - val_loss: 2.0935 - val_accuracy: 0.4779\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.8830 - accuracy: 0.4775 - val_loss: 2.1190 - val_accuracy: 0.4084\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.8601 - accuracy: 0.4765 - val_loss: 2.0560 - val_accuracy: 0.4673\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8412 - accuracy: 0.4820 - val_loss: 2.0335 - val_accuracy: 0.4524\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8176 - accuracy: 0.4876 - val_loss: 2.1116 - val_accuracy: 0.4211\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7960 - accuracy: 0.4895 - val_loss: 2.0247 - val_accuracy: 0.4634\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.7791 - accuracy: 0.4917 - val_loss: 1.9831 - val_accuracy: 0.4636\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.7616 - accuracy: 0.4930 - val_loss: 1.9789 - val_accuracy: 0.4942\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7436 - accuracy: 0.5038 - val_loss: 2.0467 - val_accuracy: 0.4601\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7374 - accuracy: 0.4988 - val_loss: 2.0846 - val_accuracy: 0.4156\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.7241 - accuracy: 0.5040 - val_loss: 1.9413 - val_accuracy: 0.5133\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7202 - accuracy: 0.5064 - val_loss: 1.9160 - val_accuracy: 0.5085\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6983 - accuracy: 0.5121 - val_loss: 1.9482 - val_accuracy: 0.4961\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6929 - accuracy: 0.5085 - val_loss: 1.9308 - val_accuracy: 0.4981\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.6822 - accuracy: 0.5119 - val_loss: 1.9638 - val_accuracy: 0.4477\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.6668 - accuracy: 0.5175 - val_loss: 1.9944 - val_accuracy: 0.4532\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.6721 - accuracy: 0.5117 - val_loss: 1.8784 - val_accuracy: 0.5179\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6648 - accuracy: 0.5202 - val_loss: 1.9133 - val_accuracy: 0.4845\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6475 - accuracy: 0.5202 - val_loss: 1.9460 - val_accuracy: 0.5085\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6390 - accuracy: 0.5232 - val_loss: 1.8642 - val_accuracy: 0.5281\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.6419 - accuracy: 0.5247 - val_loss: 1.9874 - val_accuracy: 0.5039\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.6261 - accuracy: 0.5275 - val_loss: 1.8749 - val_accuracy: 0.5204\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6297 - accuracy: 0.5280 - val_loss: 1.8704 - val_accuracy: 0.5371\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6165 - accuracy: 0.5295 - val_loss: 1.9790 - val_accuracy: 0.4592\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.6108 - accuracy: 0.5327 - val_loss: 1.9437 - val_accuracy: 0.4882\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6299 - accuracy: 0.5280 - val_loss: 1.8542 - val_accuracy: 0.5252\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5932 - accuracy: 0.5417 - val_loss: 1.8712 - val_accuracy: 0.5210\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5960 - accuracy: 0.5378 - val_loss: 1.9169 - val_accuracy: 0.4491\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5872 - accuracy: 0.5362 - val_loss: 1.8645 - val_accuracy: 0.5085\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5765 - accuracy: 0.5389 - val_loss: 1.8579 - val_accuracy: 0.5098\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.5758 - accuracy: 0.5341 - val_loss: 1.8562 - val_accuracy: 0.5397\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.5744 - accuracy: 0.5347 - val_loss: 1.8463 - val_accuracy: 0.5263\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5690 - accuracy: 0.5411 - val_loss: 1.8474 - val_accuracy: 0.5344\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5707 - accuracy: 0.5395 - val_loss: 1.8535 - val_accuracy: 0.5408\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5572 - accuracy: 0.5465 - val_loss: 1.8629 - val_accuracy: 0.5402\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5495 - accuracy: 0.5454 - val_loss: 1.8788 - val_accuracy: 0.5397\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.5573 - accuracy: 0.5436 - val_loss: 1.8299 - val_accuracy: 0.5311\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5475 - accuracy: 0.5468 - val_loss: 1.9617 - val_accuracy: 0.4711\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5359 - accuracy: 0.5508 - val_loss: 1.8616 - val_accuracy: 0.5285\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5402 - accuracy: 0.5501 - val_loss: 1.9744 - val_accuracy: 0.4697\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5368 - accuracy: 0.5511 - val_loss: 1.8959 - val_accuracy: 0.5153\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5338 - accuracy: 0.5439 - val_loss: 1.8487 - val_accuracy: 0.5320\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5145 - accuracy: 0.5529 - val_loss: 1.8361 - val_accuracy: 0.5248\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5084 - accuracy: 0.5496 - val_loss: 1.8985 - val_accuracy: 0.5032\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.5134 - accuracy: 0.5514 - val_loss: 1.8281 - val_accuracy: 0.5369\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5021 - accuracy: 0.5531 - val_loss: 2.2681 - val_accuracy: 0.4495\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5097 - accuracy: 0.5555 - val_loss: 1.8729 - val_accuracy: 0.4867\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4958 - accuracy: 0.5589 - val_loss: 1.7935 - val_accuracy: 0.5553\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.4904 - accuracy: 0.5542 - val_loss: 1.8251 - val_accuracy: 0.5463\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4962 - accuracy: 0.5598 - val_loss: 1.9553 - val_accuracy: 0.4741\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4986 - accuracy: 0.5548 - val_loss: 1.8204 - val_accuracy: 0.5485\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4830 - accuracy: 0.5578 - val_loss: 1.8750 - val_accuracy: 0.5531\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4932 - accuracy: 0.5564 - val_loss: 1.8581 - val_accuracy: 0.5463\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4879 - accuracy: 0.5586 - val_loss: 1.8137 - val_accuracy: 0.5421\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4937 - accuracy: 0.5530 - val_loss: 1.8204 - val_accuracy: 0.5604\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.4695 - accuracy: 0.5595 - val_loss: 1.8404 - val_accuracy: 0.5540\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4818 - accuracy: 0.5556 - val_loss: 1.8202 - val_accuracy: 0.5582\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4704 - accuracy: 0.5609 - val_loss: 1.8734 - val_accuracy: 0.5417\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4832 - accuracy: 0.5558 - val_loss: 1.8470 - val_accuracy: 0.5344\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4736 - accuracy: 0.5605 - val_loss: 1.7967 - val_accuracy: 0.5644\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4625 - accuracy: 0.5632 - val_loss: 1.8517 - val_accuracy: 0.5661\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.4622 - accuracy: 0.5606 - val_loss: 1.8302 - val_accuracy: 0.5531\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4561 - accuracy: 0.5695 - val_loss: 1.7876 - val_accuracy: 0.5710\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4715 - accuracy: 0.5630 - val_loss: 1.8399 - val_accuracy: 0.5670\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4484 - accuracy: 0.5659 - val_loss: 1.8374 - val_accuracy: 0.5674\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4627 - accuracy: 0.5592 - val_loss: 1.8634 - val_accuracy: 0.5454\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4550 - accuracy: 0.5662 - val_loss: 1.8430 - val_accuracy: 0.5461\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 4ms/step - loss: 4.5679 - accuracy: 0.1011 - val_loss: 4.1496 - val_accuracy: 0.1747\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 3.8467 - accuracy: 0.1729 - val_loss: 3.7693 - val_accuracy: 0.2064\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 3.4542 - accuracy: 0.2247 - val_loss: 3.4880 - val_accuracy: 0.2880\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 3.1393 - accuracy: 0.2797 - val_loss: 3.2553 - val_accuracy: 0.2924\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.9048 - accuracy: 0.3131 - val_loss: 3.1025 - val_accuracy: 0.3307\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.7086 - accuracy: 0.3505 - val_loss: 2.9178 - val_accuracy: 0.3186\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.5675 - accuracy: 0.3615 - val_loss: 2.8126 - val_accuracy: 0.3747\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.4694 - accuracy: 0.3752 - val_loss: 2.7542 - val_accuracy: 0.3421\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.3936 - accuracy: 0.3903 - val_loss: 2.6543 - val_accuracy: 0.4084\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.3354 - accuracy: 0.3975 - val_loss: 2.6526 - val_accuracy: 0.3723\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.2825 - accuracy: 0.4032 - val_loss: 2.5598 - val_accuracy: 0.4004\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.2346 - accuracy: 0.4190 - val_loss: 2.5942 - val_accuracy: 0.3813\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.1919 - accuracy: 0.4196 - val_loss: 2.5027 - val_accuracy: 0.4328\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.1706 - accuracy: 0.4232 - val_loss: 2.5061 - val_accuracy: 0.4044\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.1349 - accuracy: 0.4229 - val_loss: 2.4765 - val_accuracy: 0.4266\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.1105 - accuracy: 0.4348 - val_loss: 2.3758 - val_accuracy: 0.4469\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.0869 - accuracy: 0.4350 - val_loss: 2.3968 - val_accuracy: 0.4275\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.0839 - accuracy: 0.4297 - val_loss: 2.3743 - val_accuracy: 0.4376\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.0619 - accuracy: 0.4429 - val_loss: 2.3306 - val_accuracy: 0.4486\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.0339 - accuracy: 0.4496 - val_loss: 2.3460 - val_accuracy: 0.4315\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.0309 - accuracy: 0.4443 - val_loss: 2.3631 - val_accuracy: 0.4249\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.0181 - accuracy: 0.4446 - val_loss: 2.3044 - val_accuracy: 0.4660\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.0068 - accuracy: 0.4473 - val_loss: 2.2509 - val_accuracy: 0.4717\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9783 - accuracy: 0.4529 - val_loss: 2.3764 - val_accuracy: 0.4051\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.9999 - accuracy: 0.4432 - val_loss: 2.2360 - val_accuracy: 0.4746\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9711 - accuracy: 0.4569 - val_loss: 2.2560 - val_accuracy: 0.4328\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9672 - accuracy: 0.4554 - val_loss: 2.3044 - val_accuracy: 0.4504\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9553 - accuracy: 0.4619 - val_loss: 2.2350 - val_accuracy: 0.4506\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.9403 - accuracy: 0.4616 - val_loss: 2.2797 - val_accuracy: 0.4273\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9431 - accuracy: 0.4621 - val_loss: 2.2707 - val_accuracy: 0.4519\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9180 - accuracy: 0.4707 - val_loss: 2.2956 - val_accuracy: 0.4510\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9199 - accuracy: 0.4643 - val_loss: 2.2021 - val_accuracy: 0.4755\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9173 - accuracy: 0.4736 - val_loss: 2.2096 - val_accuracy: 0.4750\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8949 - accuracy: 0.4738 - val_loss: 2.2957 - val_accuracy: 0.4383\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8986 - accuracy: 0.4746 - val_loss: 2.2231 - val_accuracy: 0.4565\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8893 - accuracy: 0.4699 - val_loss: 2.1940 - val_accuracy: 0.4689\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8819 - accuracy: 0.4776 - val_loss: 2.1837 - val_accuracy: 0.4638\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8823 - accuracy: 0.4747 - val_loss: 2.1742 - val_accuracy: 0.4733\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8690 - accuracy: 0.4776 - val_loss: 2.1571 - val_accuracy: 0.4922\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8730 - accuracy: 0.4764 - val_loss: 2.1489 - val_accuracy: 0.4948\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8493 - accuracy: 0.4894 - val_loss: 2.3675 - val_accuracy: 0.4187\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8628 - accuracy: 0.4803 - val_loss: 2.1845 - val_accuracy: 0.4867\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8686 - accuracy: 0.4818 - val_loss: 2.3476 - val_accuracy: 0.4075\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8305 - accuracy: 0.4880 - val_loss: 2.1916 - val_accuracy: 0.4790\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8650 - accuracy: 0.4774 - val_loss: 2.0876 - val_accuracy: 0.5083\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8226 - accuracy: 0.4930 - val_loss: 2.1163 - val_accuracy: 0.4931\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8321 - accuracy: 0.4876 - val_loss: 2.1065 - val_accuracy: 0.5118\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8257 - accuracy: 0.4886 - val_loss: 2.1521 - val_accuracy: 0.4746\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8278 - accuracy: 0.4885 - val_loss: 2.1098 - val_accuracy: 0.4959\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8229 - accuracy: 0.4854 - val_loss: 2.1523 - val_accuracy: 0.4834\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8009 - accuracy: 0.4960 - val_loss: 2.1766 - val_accuracy: 0.4746\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8059 - accuracy: 0.4947 - val_loss: 2.1668 - val_accuracy: 0.4779\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7980 - accuracy: 0.4919 - val_loss: 2.0896 - val_accuracy: 0.4913\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8050 - accuracy: 0.4900 - val_loss: 2.0821 - val_accuracy: 0.5140\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7900 - accuracy: 0.4936 - val_loss: 2.0736 - val_accuracy: 0.4891\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.7957 - accuracy: 0.4940 - val_loss: 2.0780 - val_accuracy: 0.4900\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8274 - accuracy: 0.4851 - val_loss: 2.0682 - val_accuracy: 0.5034\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7894 - accuracy: 0.4993 - val_loss: 2.1603 - val_accuracy: 0.4363\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8015 - accuracy: 0.4978 - val_loss: 2.0764 - val_accuracy: 0.4931\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7835 - accuracy: 0.4977 - val_loss: 2.0375 - val_accuracy: 0.5281\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7858 - accuracy: 0.4938 - val_loss: 2.0967 - val_accuracy: 0.5006\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7806 - accuracy: 0.4953 - val_loss: 2.0796 - val_accuracy: 0.5021\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7731 - accuracy: 0.5007 - val_loss: 2.1903 - val_accuracy: 0.4854\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.8006 - accuracy: 0.4904 - val_loss: 2.0806 - val_accuracy: 0.4669\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7858 - accuracy: 0.4996 - val_loss: 2.0521 - val_accuracy: 0.5371\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7742 - accuracy: 0.5055 - val_loss: 2.0510 - val_accuracy: 0.5036\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7715 - accuracy: 0.5024 - val_loss: 2.2708 - val_accuracy: 0.4081\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7750 - accuracy: 0.4992 - val_loss: 2.0067 - val_accuracy: 0.5219\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7451 - accuracy: 0.5085 - val_loss: 2.0342 - val_accuracy: 0.5039\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.7594 - accuracy: 0.5053 - val_loss: 2.0470 - val_accuracy: 0.5056\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7418 - accuracy: 0.5070 - val_loss: 1.9878 - val_accuracy: 0.5074\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7540 - accuracy: 0.5027 - val_loss: 2.0420 - val_accuracy: 0.5056\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.7323 - accuracy: 0.5119 - val_loss: 2.1131 - val_accuracy: 0.4603\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7492 - accuracy: 0.5036 - val_loss: 2.0004 - val_accuracy: 0.5289\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7549 - accuracy: 0.5047 - val_loss: 2.1393 - val_accuracy: 0.4713\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7955 - accuracy: 0.4988 - val_loss: 2.0292 - val_accuracy: 0.4847\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7378 - accuracy: 0.5109 - val_loss: 1.9953 - val_accuracy: 0.4724\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7247 - accuracy: 0.5100 - val_loss: 2.1427 - val_accuracy: 0.4682\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7295 - accuracy: 0.5106 - val_loss: 2.1515 - val_accuracy: 0.4922\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7328 - accuracy: 0.5094 - val_loss: 1.9806 - val_accuracy: 0.5377\n",
      "Average Validation Accuracy: 0.5520455837249756\n",
      "Average Validation Loss: 1.7112756967544556\n",
      "Average Test Accuracy: 0.5519643127918243\n",
      "Final Test Accuracy for each fold: 0.5602564811706543\n",
      "Number of input features: 5\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 4ms/step - loss: 4.3197 - accuracy: 0.1526 - val_loss: 3.6992 - val_accuracy: 0.2642\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 3.1654 - accuracy: 0.3006 - val_loss: 3.0441 - val_accuracy: 0.3243\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.6132 - accuracy: 0.3787 - val_loss: 2.6308 - val_accuracy: 0.4051\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.2258 - accuracy: 0.4339 - val_loss: 2.3231 - val_accuracy: 0.4708\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9547 - accuracy: 0.4815 - val_loss: 2.1409 - val_accuracy: 0.4761\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7650 - accuracy: 0.5178 - val_loss: 2.0047 - val_accuracy: 0.5204\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6237 - accuracy: 0.5503 - val_loss: 1.8582 - val_accuracy: 0.5333\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5137 - accuracy: 0.5705 - val_loss: 1.7538 - val_accuracy: 0.5248\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4220 - accuracy: 0.5888 - val_loss: 1.6787 - val_accuracy: 0.5989\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.3544 - accuracy: 0.6009 - val_loss: 1.6422 - val_accuracy: 0.5804\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.2922 - accuracy: 0.6167 - val_loss: 1.6016 - val_accuracy: 0.5949\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.2441 - accuracy: 0.6236 - val_loss: 1.5285 - val_accuracy: 0.6174\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.2136 - accuracy: 0.6371 - val_loss: 1.4808 - val_accuracy: 0.6167\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1776 - accuracy: 0.6395 - val_loss: 1.4219 - val_accuracy: 0.6596\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1451 - accuracy: 0.6432 - val_loss: 1.4610 - val_accuracy: 0.6139\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1279 - accuracy: 0.6546 - val_loss: 1.3669 - val_accuracy: 0.6315\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0926 - accuracy: 0.6656 - val_loss: 1.3608 - val_accuracy: 0.6495\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0701 - accuracy: 0.6711 - val_loss: 1.3445 - val_accuracy: 0.6746\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0418 - accuracy: 0.6755 - val_loss: 1.3720 - val_accuracy: 0.6493\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0391 - accuracy: 0.6746 - val_loss: 1.2893 - val_accuracy: 0.6689\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0187 - accuracy: 0.6816 - val_loss: 1.2830 - val_accuracy: 0.6902\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0146 - accuracy: 0.6830 - val_loss: 1.2853 - val_accuracy: 0.6810\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9949 - accuracy: 0.6873 - val_loss: 1.2864 - val_accuracy: 0.6836\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 0.9891 - accuracy: 0.6897 - val_loss: 1.3602 - val_accuracy: 0.6548\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9795 - accuracy: 0.6891 - val_loss: 1.3014 - val_accuracy: 0.6264\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9739 - accuracy: 0.6923 - val_loss: 1.2745 - val_accuracy: 0.6559\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9537 - accuracy: 0.7012 - val_loss: 1.2093 - val_accuracy: 0.6939\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9385 - accuracy: 0.7053 - val_loss: 1.2078 - val_accuracy: 0.6898\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9424 - accuracy: 0.7010 - val_loss: 1.2354 - val_accuracy: 0.6689\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9467 - accuracy: 0.7016 - val_loss: 1.1713 - val_accuracy: 0.6944\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9295 - accuracy: 0.7044 - val_loss: 1.2082 - val_accuracy: 0.6715\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9193 - accuracy: 0.7091 - val_loss: 1.2278 - val_accuracy: 0.6948\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9193 - accuracy: 0.7042 - val_loss: 1.1918 - val_accuracy: 0.6909\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9103 - accuracy: 0.7100 - val_loss: 1.2378 - val_accuracy: 0.6537\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9003 - accuracy: 0.7145 - val_loss: 1.1993 - val_accuracy: 0.6704\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9071 - accuracy: 0.7066 - val_loss: 1.1686 - val_accuracy: 0.6893\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8861 - accuracy: 0.7146 - val_loss: 1.2275 - val_accuracy: 0.6887\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8852 - accuracy: 0.7142 - val_loss: 1.1657 - val_accuracy: 0.6900\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8828 - accuracy: 0.7181 - val_loss: 1.1290 - val_accuracy: 0.7173\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8977 - accuracy: 0.7118 - val_loss: 1.1402 - val_accuracy: 0.7001\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8706 - accuracy: 0.7251 - val_loss: 1.1514 - val_accuracy: 0.6922\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8710 - accuracy: 0.7170 - val_loss: 1.1077 - val_accuracy: 0.7221\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8537 - accuracy: 0.7295 - val_loss: 1.1627 - val_accuracy: 0.6867\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8807 - accuracy: 0.7210 - val_loss: 1.1204 - val_accuracy: 0.7300\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8545 - accuracy: 0.7264 - val_loss: 1.1022 - val_accuracy: 0.7146\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8459 - accuracy: 0.7288 - val_loss: 1.1004 - val_accuracy: 0.7364\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8630 - accuracy: 0.7243 - val_loss: 1.1322 - val_accuracy: 0.7019\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8427 - accuracy: 0.7248 - val_loss: 1.1275 - val_accuracy: 0.6979\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8414 - accuracy: 0.7300 - val_loss: 1.1279 - val_accuracy: 0.7067\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 0.8456 - accuracy: 0.7234 - val_loss: 1.0943 - val_accuracy: 0.7034\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8291 - accuracy: 0.7346 - val_loss: 1.0750 - val_accuracy: 0.7342\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8387 - accuracy: 0.7330 - val_loss: 1.0947 - val_accuracy: 0.7252\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8330 - accuracy: 0.7365 - val_loss: 1.0892 - val_accuracy: 0.7072\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 0.8352 - accuracy: 0.7310 - val_loss: 1.1452 - val_accuracy: 0.7116\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8172 - accuracy: 0.7392 - val_loss: 1.1456 - val_accuracy: 0.7155\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8354 - accuracy: 0.7314 - val_loss: 1.1029 - val_accuracy: 0.7364\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8078 - accuracy: 0.7387 - val_loss: 1.0975 - val_accuracy: 0.7305\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8325 - accuracy: 0.7304 - val_loss: 1.0814 - val_accuracy: 0.7393\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 0.8037 - accuracy: 0.7438 - val_loss: 1.1522 - val_accuracy: 0.7045\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8126 - accuracy: 0.7357 - val_loss: 1.0541 - val_accuracy: 0.7490\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8172 - accuracy: 0.7415 - val_loss: 1.1086 - val_accuracy: 0.7212\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8083 - accuracy: 0.7436 - val_loss: 1.0490 - val_accuracy: 0.7402\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7954 - accuracy: 0.7428 - val_loss: 1.1307 - val_accuracy: 0.6955\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8109 - accuracy: 0.7394 - val_loss: 1.0521 - val_accuracy: 0.7483\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7905 - accuracy: 0.7434 - val_loss: 1.0833 - val_accuracy: 0.7344\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7868 - accuracy: 0.7444 - val_loss: 1.0776 - val_accuracy: 0.7523\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7913 - accuracy: 0.7440 - val_loss: 1.1613 - val_accuracy: 0.7322\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7761 - accuracy: 0.7507 - val_loss: 1.0602 - val_accuracy: 0.7322\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7879 - accuracy: 0.7418 - val_loss: 1.0716 - val_accuracy: 0.7208\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7764 - accuracy: 0.7503 - val_loss: 1.0852 - val_accuracy: 0.7450\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7820 - accuracy: 0.7470 - val_loss: 1.0457 - val_accuracy: 0.7613\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7761 - accuracy: 0.7495 - val_loss: 1.0823 - val_accuracy: 0.7320\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7733 - accuracy: 0.7524 - val_loss: 1.1037 - val_accuracy: 0.7109\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7696 - accuracy: 0.7509 - val_loss: 1.0590 - val_accuracy: 0.7584\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7638 - accuracy: 0.7473 - val_loss: 1.1439 - val_accuracy: 0.7426\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7755 - accuracy: 0.7499 - val_loss: 1.2804 - val_accuracy: 0.6627\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7533 - accuracy: 0.7559 - val_loss: 1.0623 - val_accuracy: 0.7492\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7565 - accuracy: 0.7530 - val_loss: 1.1662 - val_accuracy: 0.7364\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7622 - accuracy: 0.7559 - val_loss: 1.0686 - val_accuracy: 0.7397\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7633 - accuracy: 0.7543 - val_loss: 1.0389 - val_accuracy: 0.7685\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 4ms/step - loss: 4.6907 - accuracy: 0.0835 - val_loss: 4.2753 - val_accuracy: 0.1391\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 3.8869 - accuracy: 0.1894 - val_loss: 3.7959 - val_accuracy: 0.2330\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 3.3566 - accuracy: 0.2713 - val_loss: 3.3984 - val_accuracy: 0.3329\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.8945 - accuracy: 0.3337 - val_loss: 3.0546 - val_accuracy: 0.3619\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.5354 - accuracy: 0.3855 - val_loss: 2.7744 - val_accuracy: 0.3894\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.2992 - accuracy: 0.4236 - val_loss: 2.7064 - val_accuracy: 0.3987\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 2.1332 - accuracy: 0.4456 - val_loss: 2.5379 - val_accuracy: 0.4084\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.9980 - accuracy: 0.4716 - val_loss: 2.3915 - val_accuracy: 0.4526\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.8887 - accuracy: 0.4881 - val_loss: 2.2552 - val_accuracy: 0.5061\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7914 - accuracy: 0.5096 - val_loss: 2.2197 - val_accuracy: 0.5118\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.7102 - accuracy: 0.5231 - val_loss: 2.1126 - val_accuracy: 0.4983\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.6374 - accuracy: 0.5393 - val_loss: 2.0242 - val_accuracy: 0.5540\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.5793 - accuracy: 0.5512 - val_loss: 1.9436 - val_accuracy: 0.5461\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.5186 - accuracy: 0.5659 - val_loss: 1.8673 - val_accuracy: 0.5597\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4800 - accuracy: 0.5760 - val_loss: 1.8118 - val_accuracy: 0.5804\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4547 - accuracy: 0.5800 - val_loss: 1.7624 - val_accuracy: 0.5747\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.4112 - accuracy: 0.5907 - val_loss: 1.7304 - val_accuracy: 0.5925\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.3820 - accuracy: 0.5898 - val_loss: 1.7186 - val_accuracy: 0.5793\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.3601 - accuracy: 0.6005 - val_loss: 1.6837 - val_accuracy: 0.6044\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.3380 - accuracy: 0.6028 - val_loss: 1.6543 - val_accuracy: 0.6099\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.3239 - accuracy: 0.6098 - val_loss: 1.5936 - val_accuracy: 0.6231\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.2919 - accuracy: 0.6146 - val_loss: 1.6028 - val_accuracy: 0.5960\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.2789 - accuracy: 0.6175 - val_loss: 1.6230 - val_accuracy: 0.6229\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.2564 - accuracy: 0.6225 - val_loss: 1.5877 - val_accuracy: 0.6112\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.2489 - accuracy: 0.6295 - val_loss: 1.5846 - val_accuracy: 0.6040\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.2293 - accuracy: 0.6258 - val_loss: 1.5803 - val_accuracy: 0.6211\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.2149 - accuracy: 0.6361 - val_loss: 1.5024 - val_accuracy: 0.6306\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.2158 - accuracy: 0.6329 - val_loss: 1.5571 - val_accuracy: 0.6216\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1906 - accuracy: 0.6395 - val_loss: 1.5148 - val_accuracy: 0.6242\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1860 - accuracy: 0.6377 - val_loss: 1.5662 - val_accuracy: 0.6062\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1785 - accuracy: 0.6336 - val_loss: 1.4880 - val_accuracy: 0.6321\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1668 - accuracy: 0.6415 - val_loss: 1.4590 - val_accuracy: 0.6383\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1408 - accuracy: 0.6515 - val_loss: 1.4828 - val_accuracy: 0.6469\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1416 - accuracy: 0.6502 - val_loss: 1.4396 - val_accuracy: 0.6477\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1328 - accuracy: 0.6491 - val_loss: 1.4934 - val_accuracy: 0.6132\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.1240 - accuracy: 0.6545 - val_loss: 1.4317 - val_accuracy: 0.6365\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1135 - accuracy: 0.6564 - val_loss: 1.4331 - val_accuracy: 0.6587\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.1095 - accuracy: 0.6580 - val_loss: 1.3790 - val_accuracy: 0.6455\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0975 - accuracy: 0.6601 - val_loss: 1.5913 - val_accuracy: 0.5954\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0828 - accuracy: 0.6653 - val_loss: 1.4113 - val_accuracy: 0.6209\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0948 - accuracy: 0.6564 - val_loss: 1.4179 - val_accuracy: 0.6321\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0874 - accuracy: 0.6636 - val_loss: 1.3390 - val_accuracy: 0.6563\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0841 - accuracy: 0.6633 - val_loss: 1.4281 - val_accuracy: 0.6389\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0713 - accuracy: 0.6668 - val_loss: 1.3527 - val_accuracy: 0.6649\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0528 - accuracy: 0.6730 - val_loss: 1.3844 - val_accuracy: 0.6246\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0626 - accuracy: 0.6647 - val_loss: 1.3016 - val_accuracy: 0.6620\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0546 - accuracy: 0.6691 - val_loss: 1.3033 - val_accuracy: 0.6770\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0466 - accuracy: 0.6749 - val_loss: 1.3197 - val_accuracy: 0.6871\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0427 - accuracy: 0.6768 - val_loss: 1.3257 - val_accuracy: 0.6596\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0279 - accuracy: 0.6808 - val_loss: 1.3373 - val_accuracy: 0.6444\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0248 - accuracy: 0.6796 - val_loss: 1.3095 - val_accuracy: 0.6581\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0255 - accuracy: 0.6777 - val_loss: 1.2978 - val_accuracy: 0.6631\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0110 - accuracy: 0.6823 - val_loss: 1.6122 - val_accuracy: 0.6108\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0130 - accuracy: 0.6853 - val_loss: 1.2918 - val_accuracy: 0.6605\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9890 - accuracy: 0.6903 - val_loss: 1.2338 - val_accuracy: 0.6860\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.0016 - accuracy: 0.6873 - val_loss: 1.2821 - val_accuracy: 0.6486\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9774 - accuracy: 0.6900 - val_loss: 1.2895 - val_accuracy: 0.6524\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9778 - accuracy: 0.6977 - val_loss: 1.2290 - val_accuracy: 0.6944\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9929 - accuracy: 0.6869 - val_loss: 1.2295 - val_accuracy: 0.6902\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9747 - accuracy: 0.6927 - val_loss: 1.2814 - val_accuracy: 0.6801\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9799 - accuracy: 0.6867 - val_loss: 1.2651 - val_accuracy: 0.6717\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9851 - accuracy: 0.6895 - val_loss: 1.2722 - val_accuracy: 0.6592\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9636 - accuracy: 0.6950 - val_loss: 1.2575 - val_accuracy: 0.6697\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9582 - accuracy: 0.6958 - val_loss: 1.2557 - val_accuracy: 0.6887\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9638 - accuracy: 0.6945 - val_loss: 1.2167 - val_accuracy: 0.6977\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9545 - accuracy: 0.7011 - val_loss: 1.1990 - val_accuracy: 0.6871\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9612 - accuracy: 0.6972 - val_loss: 1.2482 - val_accuracy: 0.6583\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9522 - accuracy: 0.7017 - val_loss: 1.2040 - val_accuracy: 0.6865\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9602 - accuracy: 0.6977 - val_loss: 1.1740 - val_accuracy: 0.7080\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9424 - accuracy: 0.7000 - val_loss: 1.2408 - val_accuracy: 0.7017\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9474 - accuracy: 0.6995 - val_loss: 1.2101 - val_accuracy: 0.6823\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.9394 - accuracy: 0.7019 - val_loss: 1.1887 - val_accuracy: 0.6937\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.9438 - accuracy: 0.7015 - val_loss: 1.2353 - val_accuracy: 0.6574\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9344 - accuracy: 0.7040 - val_loss: 1.2359 - val_accuracy: 0.6750\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9303 - accuracy: 0.7085 - val_loss: 1.2123 - val_accuracy: 0.6891\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9200 - accuracy: 0.7093 - val_loss: 1.2484 - val_accuracy: 0.6748\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9315 - accuracy: 0.7007 - val_loss: 1.2057 - val_accuracy: 0.6917\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9193 - accuracy: 0.7119 - val_loss: 1.1352 - val_accuracy: 0.6869\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9081 - accuracy: 0.7124 - val_loss: 1.1566 - val_accuracy: 0.7080\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9223 - accuracy: 0.7067 - val_loss: 1.1471 - val_accuracy: 0.7133\n",
      "Average Validation Accuracy: 0.754491925239563\n",
      "Average Validation Loss: 0.892365574836731\n",
      "Average Test Accuracy: 0.748175710439682\n",
      "Final Test Accuracy for each fold: 0.7760742902755737\n",
      "Number of input features: 6\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 4.0042 - accuracy: 0.2193 - val_loss: 3.0885 - val_accuracy: 0.3393\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 2.3960 - accuracy: 0.4756 - val_loss: 2.2397 - val_accuracy: 0.5133\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 1.6964 - accuracy: 0.5998 - val_loss: 1.7231 - val_accuracy: 0.6290\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.2793 - accuracy: 0.6809 - val_loss: 1.4818 - val_accuracy: 0.6876\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.0373 - accuracy: 0.7272 - val_loss: 1.2708 - val_accuracy: 0.7206\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8877 - accuracy: 0.7585 - val_loss: 1.1612 - val_accuracy: 0.7567\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8007 - accuracy: 0.7757 - val_loss: 1.0669 - val_accuracy: 0.7784\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7306 - accuracy: 0.7935 - val_loss: 1.0771 - val_accuracy: 0.7712\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6875 - accuracy: 0.7985 - val_loss: 0.9701 - val_accuracy: 0.7998\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6387 - accuracy: 0.8126 - val_loss: 0.8892 - val_accuracy: 0.8079\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6120 - accuracy: 0.8136 - val_loss: 0.8778 - val_accuracy: 0.8046\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5813 - accuracy: 0.8238 - val_loss: 0.8943 - val_accuracy: 0.7976\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.5548 - accuracy: 0.8318 - val_loss: 0.8861 - val_accuracy: 0.7886\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.5426 - accuracy: 0.8350 - val_loss: 0.7952 - val_accuracy: 0.8229\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5155 - accuracy: 0.8414 - val_loss: 0.8418 - val_accuracy: 0.7949\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5018 - accuracy: 0.8420 - val_loss: 0.7904 - val_accuracy: 0.8242\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4865 - accuracy: 0.8470 - val_loss: 0.7986 - val_accuracy: 0.8209\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4699 - accuracy: 0.8561 - val_loss: 0.7618 - val_accuracy: 0.8211\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4602 - accuracy: 0.8548 - val_loss: 0.7483 - val_accuracy: 0.8334\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4552 - accuracy: 0.8578 - val_loss: 0.7179 - val_accuracy: 0.8550\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4452 - accuracy: 0.8638 - val_loss: 0.7848 - val_accuracy: 0.8403\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4353 - accuracy: 0.8635 - val_loss: 0.7487 - val_accuracy: 0.8273\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4304 - accuracy: 0.8682 - val_loss: 0.6988 - val_accuracy: 0.8398\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4157 - accuracy: 0.8674 - val_loss: 0.8317 - val_accuracy: 0.8330\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4097 - accuracy: 0.8718 - val_loss: 0.6826 - val_accuracy: 0.8539\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4022 - accuracy: 0.8723 - val_loss: 0.6387 - val_accuracy: 0.8783\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4017 - accuracy: 0.8752 - val_loss: 0.6344 - val_accuracy: 0.8763\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3989 - accuracy: 0.8745 - val_loss: 0.6315 - val_accuracy: 0.8750\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3708 - accuracy: 0.8853 - val_loss: 0.6384 - val_accuracy: 0.8801\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3803 - accuracy: 0.8775 - val_loss: 0.6573 - val_accuracy: 0.8627\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3679 - accuracy: 0.8874 - val_loss: 0.6476 - val_accuracy: 0.8495\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3709 - accuracy: 0.8842 - val_loss: 0.6935 - val_accuracy: 0.8543\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3621 - accuracy: 0.8864 - val_loss: 0.6288 - val_accuracy: 0.8790\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3507 - accuracy: 0.8873 - val_loss: 0.6434 - val_accuracy: 0.8598\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3482 - accuracy: 0.8948 - val_loss: 0.6142 - val_accuracy: 0.8862\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3520 - accuracy: 0.8893 - val_loss: 0.5853 - val_accuracy: 0.8794\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3440 - accuracy: 0.8937 - val_loss: 0.5472 - val_accuracy: 0.8878\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3465 - accuracy: 0.8893 - val_loss: 0.6637 - val_accuracy: 0.8317\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3288 - accuracy: 0.8969 - val_loss: 0.5874 - val_accuracy: 0.8827\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3425 - accuracy: 0.8919 - val_loss: 0.5982 - val_accuracy: 0.8684\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3266 - accuracy: 0.8989 - val_loss: 0.5807 - val_accuracy: 0.8695\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3288 - accuracy: 0.8968 - val_loss: 0.6345 - val_accuracy: 0.8636\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3215 - accuracy: 0.9001 - val_loss: 0.5598 - val_accuracy: 0.8766\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3293 - accuracy: 0.8995 - val_loss: 0.5510 - val_accuracy: 0.8840\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3149 - accuracy: 0.9031 - val_loss: 0.6207 - val_accuracy: 0.8667\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3154 - accuracy: 0.9029 - val_loss: 0.5386 - val_accuracy: 0.9017\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3149 - accuracy: 0.9033 - val_loss: 0.5479 - val_accuracy: 0.8917\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3086 - accuracy: 0.9054 - val_loss: 0.5298 - val_accuracy: 0.9116\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3330 - accuracy: 0.8955 - val_loss: 0.5455 - val_accuracy: 0.8821\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2973 - accuracy: 0.9078 - val_loss: 0.5565 - val_accuracy: 0.8849\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3117 - accuracy: 0.9010 - val_loss: 0.5998 - val_accuracy: 0.8755\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3083 - accuracy: 0.9036 - val_loss: 0.5875 - val_accuracy: 0.8836\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3119 - accuracy: 0.9032 - val_loss: 0.5455 - val_accuracy: 0.8900\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3061 - accuracy: 0.9045 - val_loss: 0.4855 - val_accuracy: 0.9080\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2952 - accuracy: 0.9088 - val_loss: 0.5613 - val_accuracy: 0.8889\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2961 - accuracy: 0.9107 - val_loss: 0.5747 - val_accuracy: 0.8711\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2902 - accuracy: 0.9109 - val_loss: 0.5191 - val_accuracy: 0.8946\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3004 - accuracy: 0.9071 - val_loss: 0.6380 - val_accuracy: 0.8719\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2963 - accuracy: 0.9065 - val_loss: 0.5187 - val_accuracy: 0.9014\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2924 - accuracy: 0.9081 - val_loss: 0.6306 - val_accuracy: 0.8733\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2924 - accuracy: 0.9084 - val_loss: 0.6273 - val_accuracy: 0.8631\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2868 - accuracy: 0.9122 - val_loss: 0.4885 - val_accuracy: 0.9212\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2893 - accuracy: 0.9109 - val_loss: 0.4873 - val_accuracy: 0.9129\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2772 - accuracy: 0.9151 - val_loss: 0.4981 - val_accuracy: 0.9089\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2761 - accuracy: 0.9146 - val_loss: 0.5054 - val_accuracy: 0.8981\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2764 - accuracy: 0.9157 - val_loss: 0.5367 - val_accuracy: 0.8948\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2790 - accuracy: 0.9113 - val_loss: 0.5201 - val_accuracy: 0.9025\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2775 - accuracy: 0.9147 - val_loss: 0.5430 - val_accuracy: 0.8968\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2777 - accuracy: 0.9153 - val_loss: 0.4860 - val_accuracy: 0.9017\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2796 - accuracy: 0.9104 - val_loss: 0.5159 - val_accuracy: 0.9017\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2727 - accuracy: 0.9168 - val_loss: 0.4841 - val_accuracy: 0.9208\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2690 - accuracy: 0.9196 - val_loss: 0.5399 - val_accuracy: 0.8950\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2682 - accuracy: 0.9164 - val_loss: 0.4865 - val_accuracy: 0.9072\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2589 - accuracy: 0.9201 - val_loss: 0.5109 - val_accuracy: 0.9107\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2772 - accuracy: 0.9125 - val_loss: 0.5237 - val_accuracy: 0.9006\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2616 - accuracy: 0.9190 - val_loss: 0.5023 - val_accuracy: 0.9131\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2709 - accuracy: 0.9197 - val_loss: 0.4917 - val_accuracy: 0.9223\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2583 - accuracy: 0.9221 - val_loss: 0.4811 - val_accuracy: 0.9298\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2606 - accuracy: 0.9199 - val_loss: 0.5064 - val_accuracy: 0.8922\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2674 - accuracy: 0.9185 - val_loss: 0.4787 - val_accuracy: 0.9294\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 4.1564 - accuracy: 0.1922 - val_loss: 3.3810 - val_accuracy: 0.3758\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 2.6531 - accuracy: 0.4539 - val_loss: 2.5183 - val_accuracy: 0.5248\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.8967 - accuracy: 0.5827 - val_loss: 1.9999 - val_accuracy: 0.6319\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.4326 - accuracy: 0.6651 - val_loss: 1.7156 - val_accuracy: 0.6697\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.1617 - accuracy: 0.7082 - val_loss: 1.4813 - val_accuracy: 0.7259\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9876 - accuracy: 0.7385 - val_loss: 1.3819 - val_accuracy: 0.7263\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8708 - accuracy: 0.7650 - val_loss: 1.2761 - val_accuracy: 0.7573\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7911 - accuracy: 0.7817 - val_loss: 1.1671 - val_accuracy: 0.7677\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.7186 - accuracy: 0.7966 - val_loss: 1.1242 - val_accuracy: 0.7787\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6719 - accuracy: 0.8102 - val_loss: 0.9972 - val_accuracy: 0.8130\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.6250 - accuracy: 0.8203 - val_loss: 0.9956 - val_accuracy: 0.7989\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5949 - accuracy: 0.8244 - val_loss: 0.9543 - val_accuracy: 0.8255\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5687 - accuracy: 0.8313 - val_loss: 0.9073 - val_accuracy: 0.8220\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.5315 - accuracy: 0.8413 - val_loss: 0.7972 - val_accuracy: 0.8532\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5267 - accuracy: 0.8447 - val_loss: 0.8682 - val_accuracy: 0.8046\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5085 - accuracy: 0.8447 - val_loss: 0.7852 - val_accuracy: 0.8372\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4968 - accuracy: 0.8485 - val_loss: 0.7881 - val_accuracy: 0.8502\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4679 - accuracy: 0.8598 - val_loss: 0.7563 - val_accuracy: 0.8422\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4623 - accuracy: 0.8585 - val_loss: 0.8414 - val_accuracy: 0.8128\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4701 - accuracy: 0.8555 - val_loss: 0.7082 - val_accuracy: 0.8708\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4343 - accuracy: 0.8650 - val_loss: 0.9158 - val_accuracy: 0.7903\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4436 - accuracy: 0.8642 - val_loss: 0.7841 - val_accuracy: 0.8282\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4131 - accuracy: 0.8729 - val_loss: 0.7949 - val_accuracy: 0.8141\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4219 - accuracy: 0.8729 - val_loss: 0.6944 - val_accuracy: 0.8649\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4207 - accuracy: 0.8717 - val_loss: 0.6600 - val_accuracy: 0.8682\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4031 - accuracy: 0.8758 - val_loss: 0.7834 - val_accuracy: 0.8323\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4023 - accuracy: 0.8750 - val_loss: 0.6524 - val_accuracy: 0.8759\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3813 - accuracy: 0.8875 - val_loss: 0.6843 - val_accuracy: 0.8607\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4049 - accuracy: 0.8748 - val_loss: 0.6378 - val_accuracy: 0.8812\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3745 - accuracy: 0.8883 - val_loss: 0.7158 - val_accuracy: 0.8453\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3778 - accuracy: 0.8827 - val_loss: 0.6053 - val_accuracy: 0.8968\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3746 - accuracy: 0.8846 - val_loss: 0.6152 - val_accuracy: 0.8860\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3733 - accuracy: 0.8857 - val_loss: 0.6249 - val_accuracy: 0.9010\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3464 - accuracy: 0.8947 - val_loss: 0.6732 - val_accuracy: 0.8464\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3660 - accuracy: 0.8852 - val_loss: 0.6384 - val_accuracy: 0.8889\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3490 - accuracy: 0.8964 - val_loss: 0.6904 - val_accuracy: 0.8576\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3509 - accuracy: 0.8928 - val_loss: 0.6573 - val_accuracy: 0.8799\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3355 - accuracy: 0.9003 - val_loss: 0.7023 - val_accuracy: 0.8675\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3451 - accuracy: 0.8964 - val_loss: 0.6209 - val_accuracy: 0.8884\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3372 - accuracy: 0.8962 - val_loss: 0.5690 - val_accuracy: 0.9164\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3429 - accuracy: 0.8925 - val_loss: 0.6415 - val_accuracy: 0.8759\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3200 - accuracy: 0.9052 - val_loss: 0.7121 - val_accuracy: 0.8642\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3367 - accuracy: 0.8988 - val_loss: 0.5893 - val_accuracy: 0.9043\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3156 - accuracy: 0.9047 - val_loss: 0.5897 - val_accuracy: 0.8950\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3231 - accuracy: 0.9027 - val_loss: 0.8573 - val_accuracy: 0.8238\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3147 - accuracy: 0.9033 - val_loss: 0.6774 - val_accuracy: 0.8735\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3230 - accuracy: 0.9019 - val_loss: 0.6013 - val_accuracy: 0.9098\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3112 - accuracy: 0.9054 - val_loss: 0.6545 - val_accuracy: 0.8735\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3168 - accuracy: 0.9038 - val_loss: 0.6365 - val_accuracy: 0.8858\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3121 - accuracy: 0.9027 - val_loss: 0.6616 - val_accuracy: 0.8572\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2973 - accuracy: 0.9089 - val_loss: 0.6078 - val_accuracy: 0.8990\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3094 - accuracy: 0.9096 - val_loss: 0.5672 - val_accuracy: 0.9107\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3003 - accuracy: 0.9103 - val_loss: 0.7042 - val_accuracy: 0.8796\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2998 - accuracy: 0.9090 - val_loss: 0.6214 - val_accuracy: 0.8933\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2984 - accuracy: 0.9100 - val_loss: 0.5992 - val_accuracy: 0.8832\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2944 - accuracy: 0.9129 - val_loss: 0.6223 - val_accuracy: 0.8933\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3024 - accuracy: 0.9047 - val_loss: 0.6450 - val_accuracy: 0.8814\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2903 - accuracy: 0.9102 - val_loss: 0.6022 - val_accuracy: 0.8948\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2933 - accuracy: 0.9120 - val_loss: 0.6307 - val_accuracy: 0.8977\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3052 - accuracy: 0.9077 - val_loss: 0.6513 - val_accuracy: 0.8796\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2852 - accuracy: 0.9139 - val_loss: 0.5993 - val_accuracy: 0.8946\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2822 - accuracy: 0.9161 - val_loss: 0.5597 - val_accuracy: 0.9241\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2822 - accuracy: 0.9161 - val_loss: 0.8842 - val_accuracy: 0.7960\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2867 - accuracy: 0.9138 - val_loss: 0.5400 - val_accuracy: 0.9254\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2815 - accuracy: 0.9161 - val_loss: 0.5766 - val_accuracy: 0.9226\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2959 - accuracy: 0.9128 - val_loss: 0.5430 - val_accuracy: 0.9250\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2705 - accuracy: 0.9151 - val_loss: 0.5858 - val_accuracy: 0.9008\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2977 - accuracy: 0.9112 - val_loss: 0.5556 - val_accuracy: 0.9074\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2721 - accuracy: 0.9169 - val_loss: 0.6245 - val_accuracy: 0.8849\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2817 - accuracy: 0.9152 - val_loss: 0.5312 - val_accuracy: 0.9292\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2723 - accuracy: 0.9198 - val_loss: 0.5445 - val_accuracy: 0.9204\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2830 - accuracy: 0.9139 - val_loss: 0.7231 - val_accuracy: 0.8634\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2601 - accuracy: 0.9220 - val_loss: 0.5822 - val_accuracy: 0.9204\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2616 - accuracy: 0.9212 - val_loss: 0.7362 - val_accuracy: 0.8484\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2794 - accuracy: 0.9162 - val_loss: 0.6622 - val_accuracy: 0.8805\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2702 - accuracy: 0.9173 - val_loss: 0.5768 - val_accuracy: 0.9179\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2680 - accuracy: 0.9182 - val_loss: 0.6042 - val_accuracy: 0.9153\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2612 - accuracy: 0.9200 - val_loss: 0.5555 - val_accuracy: 0.9226\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2665 - accuracy: 0.9189 - val_loss: 0.5692 - val_accuracy: 0.9144\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2663 - accuracy: 0.9190 - val_loss: 0.5799 - val_accuracy: 0.9105\n",
      "Average Validation Accuracy: 0.9292373955249786\n",
      "Average Validation Loss: 0.33640776574611664\n",
      "Average Test Accuracy: 0.9266602694988251\n",
      "Final Test Accuracy for each fold: 0.9388958215713501\n",
      "Number of input features: 7\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 4.1294 - accuracy: 0.2069 - val_loss: 3.2869 - val_accuracy: 0.3287\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 2.5729 - accuracy: 0.4660 - val_loss: 2.2961 - val_accuracy: 0.5474\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.7304 - accuracy: 0.6000 - val_loss: 1.7053 - val_accuracy: 0.6297\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.2424 - accuracy: 0.6863 - val_loss: 1.3718 - val_accuracy: 0.6975\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9685 - accuracy: 0.7402 - val_loss: 1.1525 - val_accuracy: 0.7474\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8145 - accuracy: 0.7735 - val_loss: 1.0566 - val_accuracy: 0.7703\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7107 - accuracy: 0.7996 - val_loss: 0.9233 - val_accuracy: 0.7993\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6537 - accuracy: 0.8036 - val_loss: 0.8430 - val_accuracy: 0.8042\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5849 - accuracy: 0.8254 - val_loss: 0.8530 - val_accuracy: 0.7813\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.5660 - accuracy: 0.8242 - val_loss: 0.7582 - val_accuracy: 0.8436\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5300 - accuracy: 0.8363 - val_loss: 0.8128 - val_accuracy: 0.8141\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.5066 - accuracy: 0.8436 - val_loss: 0.7491 - val_accuracy: 0.8275\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4803 - accuracy: 0.8517 - val_loss: 0.7146 - val_accuracy: 0.8524\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4555 - accuracy: 0.8586 - val_loss: 0.6827 - val_accuracy: 0.8506\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4490 - accuracy: 0.8546 - val_loss: 0.6529 - val_accuracy: 0.8499\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4318 - accuracy: 0.8622 - val_loss: 0.6241 - val_accuracy: 0.8625\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4186 - accuracy: 0.8686 - val_loss: 0.6464 - val_accuracy: 0.8526\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4133 - accuracy: 0.8716 - val_loss: 0.6298 - val_accuracy: 0.8618\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3919 - accuracy: 0.8798 - val_loss: 0.6396 - val_accuracy: 0.8552\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3966 - accuracy: 0.8755 - val_loss: 0.6971 - val_accuracy: 0.8288\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3835 - accuracy: 0.8795 - val_loss: 0.6358 - val_accuracy: 0.8517\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3712 - accuracy: 0.8819 - val_loss: 0.6311 - val_accuracy: 0.8629\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3643 - accuracy: 0.8840 - val_loss: 0.6830 - val_accuracy: 0.8554\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3580 - accuracy: 0.8866 - val_loss: 0.5604 - val_accuracy: 0.8708\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3511 - accuracy: 0.8883 - val_loss: 0.5441 - val_accuracy: 0.8946\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3452 - accuracy: 0.8915 - val_loss: 0.6428 - val_accuracy: 0.8570\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3371 - accuracy: 0.8937 - val_loss: 0.5132 - val_accuracy: 0.9028\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3381 - accuracy: 0.8936 - val_loss: 0.6011 - val_accuracy: 0.8568\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 9s 5ms/step - loss: 0.3327 - accuracy: 0.8958 - val_loss: 0.5050 - val_accuracy: 0.9010\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3104 - accuracy: 0.9015 - val_loss: 0.5395 - val_accuracy: 0.8873\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3237 - accuracy: 0.8961 - val_loss: 0.5069 - val_accuracy: 0.8979\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3145 - accuracy: 0.8974 - val_loss: 0.4828 - val_accuracy: 0.9131\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3059 - accuracy: 0.9020 - val_loss: 0.5232 - val_accuracy: 0.8873\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3136 - accuracy: 0.9002 - val_loss: 0.5331 - val_accuracy: 0.9001\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3005 - accuracy: 0.9087 - val_loss: 0.4865 - val_accuracy: 0.9054\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2969 - accuracy: 0.9072 - val_loss: 0.5281 - val_accuracy: 0.9023\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3018 - accuracy: 0.9081 - val_loss: 0.4900 - val_accuracy: 0.8986\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2941 - accuracy: 0.9060 - val_loss: 0.5056 - val_accuracy: 0.8972\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2886 - accuracy: 0.9109 - val_loss: 0.4715 - val_accuracy: 0.9056\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2874 - accuracy: 0.9103 - val_loss: 0.5285 - val_accuracy: 0.9074\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2908 - accuracy: 0.9084 - val_loss: 0.5034 - val_accuracy: 0.9072\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2782 - accuracy: 0.9152 - val_loss: 0.4937 - val_accuracy: 0.8968\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2786 - accuracy: 0.9147 - val_loss: 0.5246 - val_accuracy: 0.8904\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2758 - accuracy: 0.9142 - val_loss: 0.5423 - val_accuracy: 0.8790\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2667 - accuracy: 0.9155 - val_loss: 0.4940 - val_accuracy: 0.9085\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2677 - accuracy: 0.9178 - val_loss: 0.6234 - val_accuracy: 0.8966\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2742 - accuracy: 0.9127 - val_loss: 0.4597 - val_accuracy: 0.9195\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2629 - accuracy: 0.9198 - val_loss: 0.4534 - val_accuracy: 0.9105\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2605 - accuracy: 0.9191 - val_loss: 0.5155 - val_accuracy: 0.8988\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2628 - accuracy: 0.9181 - val_loss: 0.5788 - val_accuracy: 0.8862\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2604 - accuracy: 0.9220 - val_loss: 0.4564 - val_accuracy: 0.9219\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2526 - accuracy: 0.9217 - val_loss: 0.4624 - val_accuracy: 0.9223\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2446 - accuracy: 0.9250 - val_loss: 0.5394 - val_accuracy: 0.9050\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2498 - accuracy: 0.9226 - val_loss: 0.4882 - val_accuracy: 0.9080\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2623 - accuracy: 0.9206 - val_loss: 0.5910 - val_accuracy: 0.8900\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2576 - accuracy: 0.9232 - val_loss: 0.4513 - val_accuracy: 0.9195\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2395 - accuracy: 0.9251 - val_loss: 0.5006 - val_accuracy: 0.9069\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2581 - accuracy: 0.9207 - val_loss: 0.4967 - val_accuracy: 0.9177\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2427 - accuracy: 0.9255 - val_loss: 0.4267 - val_accuracy: 0.9329\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2531 - accuracy: 0.9232 - val_loss: 0.5244 - val_accuracy: 0.8979\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2324 - accuracy: 0.9288 - val_loss: 0.4544 - val_accuracy: 0.9287\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2425 - accuracy: 0.9263 - val_loss: 0.4556 - val_accuracy: 0.9226\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2310 - accuracy: 0.9303 - val_loss: 0.4398 - val_accuracy: 0.9322\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2324 - accuracy: 0.9293 - val_loss: 0.4754 - val_accuracy: 0.9272\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2396 - accuracy: 0.9278 - val_loss: 0.4589 - val_accuracy: 0.9221\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2366 - accuracy: 0.9284 - val_loss: 0.4435 - val_accuracy: 0.9358\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2281 - accuracy: 0.9324 - val_loss: 0.4725 - val_accuracy: 0.9219\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2312 - accuracy: 0.9302 - val_loss: 0.4635 - val_accuracy: 0.9285\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2352 - accuracy: 0.9298 - val_loss: 0.4785 - val_accuracy: 0.9138\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2309 - accuracy: 0.9304 - val_loss: 0.4258 - val_accuracy: 0.9395\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2261 - accuracy: 0.9362 - val_loss: 0.4514 - val_accuracy: 0.9250\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2235 - accuracy: 0.9323 - val_loss: 0.4954 - val_accuracy: 0.9245\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2290 - accuracy: 0.9343 - val_loss: 0.4500 - val_accuracy: 0.9395\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2232 - accuracy: 0.9341 - val_loss: 0.4931 - val_accuracy: 0.9215\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2239 - accuracy: 0.9327 - val_loss: 0.4825 - val_accuracy: 0.9190\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2163 - accuracy: 0.9347 - val_loss: 0.4347 - val_accuracy: 0.9415\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2237 - accuracy: 0.9340 - val_loss: 0.4791 - val_accuracy: 0.9210\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2230 - accuracy: 0.9331 - val_loss: 0.4577 - val_accuracy: 0.9294\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2143 - accuracy: 0.9355 - val_loss: 0.4760 - val_accuracy: 0.9237\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2070 - accuracy: 0.9376 - val_loss: 0.5106 - val_accuracy: 0.9175\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 3ms/step - loss: 4.2070 - accuracy: 0.1845 - val_loss: 3.4244 - val_accuracy: 0.3278\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 2.6364 - accuracy: 0.4540 - val_loss: 2.4948 - val_accuracy: 0.5426\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.8218 - accuracy: 0.5935 - val_loss: 1.9563 - val_accuracy: 0.6491\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.3463 - accuracy: 0.6838 - val_loss: 1.6676 - val_accuracy: 0.7087\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.0690 - accuracy: 0.7361 - val_loss: 1.4260 - val_accuracy: 0.7496\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8999 - accuracy: 0.7644 - val_loss: 1.2715 - val_accuracy: 0.7747\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7741 - accuracy: 0.7926 - val_loss: 1.2082 - val_accuracy: 0.7754\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6763 - accuracy: 0.8103 - val_loss: 1.0887 - val_accuracy: 0.7996\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6139 - accuracy: 0.8250 - val_loss: 1.0090 - val_accuracy: 0.8147\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5630 - accuracy: 0.8354 - val_loss: 0.9515 - val_accuracy: 0.8249\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5205 - accuracy: 0.8468 - val_loss: 0.8700 - val_accuracy: 0.8508\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4872 - accuracy: 0.8556 - val_loss: 0.8158 - val_accuracy: 0.8814\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4623 - accuracy: 0.8646 - val_loss: 0.8627 - val_accuracy: 0.8392\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4376 - accuracy: 0.8686 - val_loss: 0.7906 - val_accuracy: 0.8704\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4135 - accuracy: 0.8774 - val_loss: 0.8536 - val_accuracy: 0.8504\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3971 - accuracy: 0.8846 - val_loss: 0.8034 - val_accuracy: 0.8693\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3834 - accuracy: 0.8860 - val_loss: 0.7949 - val_accuracy: 0.8565\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3702 - accuracy: 0.8911 - val_loss: 0.7215 - val_accuracy: 0.8924\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3534 - accuracy: 0.8952 - val_loss: 0.8957 - val_accuracy: 0.8326\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3494 - accuracy: 0.8954 - val_loss: 0.7832 - val_accuracy: 0.8746\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3344 - accuracy: 0.9003 - val_loss: 0.7458 - val_accuracy: 0.8845\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3264 - accuracy: 0.9022 - val_loss: 0.7241 - val_accuracy: 0.8942\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3268 - accuracy: 0.9042 - val_loss: 0.7870 - val_accuracy: 0.8763\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3180 - accuracy: 0.9069 - val_loss: 0.7421 - val_accuracy: 0.8737\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3089 - accuracy: 0.9054 - val_loss: 0.7088 - val_accuracy: 0.8966\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3072 - accuracy: 0.9074 - val_loss: 0.7529 - val_accuracy: 0.8730\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2934 - accuracy: 0.9138 - val_loss: 0.6470 - val_accuracy: 0.9182\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2938 - accuracy: 0.9108 - val_loss: 0.6554 - val_accuracy: 0.9096\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2901 - accuracy: 0.9098 - val_loss: 0.6885 - val_accuracy: 0.9030\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2793 - accuracy: 0.9150 - val_loss: 0.6858 - val_accuracy: 0.9021\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2704 - accuracy: 0.9203 - val_loss: 0.6352 - val_accuracy: 0.9184\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2715 - accuracy: 0.9187 - val_loss: 0.6946 - val_accuracy: 0.9010\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2749 - accuracy: 0.9164 - val_loss: 0.6358 - val_accuracy: 0.9230\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2608 - accuracy: 0.9222 - val_loss: 0.6613 - val_accuracy: 0.9140\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2706 - accuracy: 0.9213 - val_loss: 0.7067 - val_accuracy: 0.8966\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2643 - accuracy: 0.9238 - val_loss: 0.6847 - val_accuracy: 0.9041\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2507 - accuracy: 0.9266 - val_loss: 0.6480 - val_accuracy: 0.9164\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2581 - accuracy: 0.9235 - val_loss: 0.8214 - val_accuracy: 0.8541\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2617 - accuracy: 0.9242 - val_loss: 0.6825 - val_accuracy: 0.9078\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2592 - accuracy: 0.9208 - val_loss: 0.6666 - val_accuracy: 0.9100\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2512 - accuracy: 0.9263 - val_loss: 0.6295 - val_accuracy: 0.9184\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2508 - accuracy: 0.9277 - val_loss: 0.7266 - val_accuracy: 0.8884\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2453 - accuracy: 0.9275 - val_loss: 0.6212 - val_accuracy: 0.9307\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2390 - accuracy: 0.9283 - val_loss: 0.7985 - val_accuracy: 0.8840\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2383 - accuracy: 0.9298 - val_loss: 0.6564 - val_accuracy: 0.9208\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2240 - accuracy: 0.9346 - val_loss: 0.6647 - val_accuracy: 0.9063\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2409 - accuracy: 0.9288 - val_loss: 0.5941 - val_accuracy: 0.9371\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2291 - accuracy: 0.9329 - val_loss: 0.6243 - val_accuracy: 0.9190\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2361 - accuracy: 0.9301 - val_loss: 0.5923 - val_accuracy: 0.9309\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2292 - accuracy: 0.9306 - val_loss: 0.6104 - val_accuracy: 0.9272\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2367 - accuracy: 0.9301 - val_loss: 0.6063 - val_accuracy: 0.9217\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2166 - accuracy: 0.9378 - val_loss: 0.6260 - val_accuracy: 0.9182\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2168 - accuracy: 0.9368 - val_loss: 0.6758 - val_accuracy: 0.8977\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2287 - accuracy: 0.9322 - val_loss: 0.6762 - val_accuracy: 0.9034\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2104 - accuracy: 0.9380 - val_loss: 0.6513 - val_accuracy: 0.9155\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2224 - accuracy: 0.9338 - val_loss: 0.6194 - val_accuracy: 0.9261\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2231 - accuracy: 0.9343 - val_loss: 0.5901 - val_accuracy: 0.9329\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2120 - accuracy: 0.9374 - val_loss: 0.6088 - val_accuracy: 0.9285\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2194 - accuracy: 0.9355 - val_loss: 0.6032 - val_accuracy: 0.9276\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2051 - accuracy: 0.9417 - val_loss: 0.5892 - val_accuracy: 0.9338\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.2232 - accuracy: 0.9329 - val_loss: 0.6370 - val_accuracy: 0.9232\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2144 - accuracy: 0.9356 - val_loss: 0.6494 - val_accuracy: 0.9239\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2060 - accuracy: 0.9383 - val_loss: 0.6217 - val_accuracy: 0.9234\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2055 - accuracy: 0.9410 - val_loss: 0.5838 - val_accuracy: 0.9298\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2060 - accuracy: 0.9367 - val_loss: 0.6830 - val_accuracy: 0.9129\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2116 - accuracy: 0.9389 - val_loss: 0.6330 - val_accuracy: 0.9122\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1912 - accuracy: 0.9473 - val_loss: 0.6192 - val_accuracy: 0.9261\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2101 - accuracy: 0.9388 - val_loss: 0.7113 - val_accuracy: 0.8862\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2055 - accuracy: 0.9400 - val_loss: 0.6271 - val_accuracy: 0.9116\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2005 - accuracy: 0.9412 - val_loss: 0.6089 - val_accuracy: 0.9256\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2028 - accuracy: 0.9421 - val_loss: 0.5855 - val_accuracy: 0.9254\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2076 - accuracy: 0.9358 - val_loss: 0.6872 - val_accuracy: 0.9065\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2049 - accuracy: 0.9405 - val_loss: 0.6010 - val_accuracy: 0.9287\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1876 - accuracy: 0.9442 - val_loss: 0.6055 - val_accuracy: 0.9329\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1924 - accuracy: 0.9456 - val_loss: 0.6317 - val_accuracy: 0.9221\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1897 - accuracy: 0.9446 - val_loss: 0.6059 - val_accuracy: 0.9208\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1952 - accuracy: 0.9444 - val_loss: 0.5439 - val_accuracy: 0.9459\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2093 - accuracy: 0.9393 - val_loss: 0.6249 - val_accuracy: 0.9287\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1884 - accuracy: 0.9451 - val_loss: 0.5879 - val_accuracy: 0.9265\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1984 - accuracy: 0.9421 - val_loss: 0.5890 - val_accuracy: 0.9322\n",
      "Average Validation Accuracy: 0.936209112405777\n",
      "Average Validation Loss: 0.34607191383838654\n",
      "Average Test Accuracy: 0.9336625635623932\n",
      "Final Test Accuracy for each fold: 0.9432446360588074\n",
      "Number of input features: 8\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 4.0729 - accuracy: 0.1791 - val_loss: 3.3074 - val_accuracy: 0.2904\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 2.6916 - accuracy: 0.4255 - val_loss: 2.4469 - val_accuracy: 0.4961\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.9717 - accuracy: 0.5592 - val_loss: 1.9282 - val_accuracy: 0.6059\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.5551 - accuracy: 0.6396 - val_loss: 1.6530 - val_accuracy: 0.6554\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.2866 - accuracy: 0.6887 - val_loss: 1.4039 - val_accuracy: 0.7274\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.0812 - accuracy: 0.7250 - val_loss: 1.3067 - val_accuracy: 0.7406\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9373 - accuracy: 0.7549 - val_loss: 1.1587 - val_accuracy: 0.7657\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8257 - accuracy: 0.7762 - val_loss: 1.0922 - val_accuracy: 0.7800\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7265 - accuracy: 0.7973 - val_loss: 0.9951 - val_accuracy: 0.8134\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6677 - accuracy: 0.8050 - val_loss: 0.9492 - val_accuracy: 0.8224\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6099 - accuracy: 0.8173 - val_loss: 0.9135 - val_accuracy: 0.8262\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5837 - accuracy: 0.8242 - val_loss: 0.8874 - val_accuracy: 0.8213\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5333 - accuracy: 0.8363 - val_loss: 0.8548 - val_accuracy: 0.8506\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5147 - accuracy: 0.8437 - val_loss: 0.8422 - val_accuracy: 0.8337\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5019 - accuracy: 0.8429 - val_loss: 0.8063 - val_accuracy: 0.8484\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4835 - accuracy: 0.8515 - val_loss: 0.8715 - val_accuracy: 0.8134\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4537 - accuracy: 0.8605 - val_loss: 0.7622 - val_accuracy: 0.8612\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4482 - accuracy: 0.8620 - val_loss: 0.7728 - val_accuracy: 0.8504\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4288 - accuracy: 0.8687 - val_loss: 0.8894 - val_accuracy: 0.8189\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4288 - accuracy: 0.8646 - val_loss: 0.6989 - val_accuracy: 0.8713\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4087 - accuracy: 0.8724 - val_loss: 0.7337 - val_accuracy: 0.8678\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3925 - accuracy: 0.8777 - val_loss: 0.6961 - val_accuracy: 0.8801\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3980 - accuracy: 0.8791 - val_loss: 0.7394 - val_accuracy: 0.8416\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3867 - accuracy: 0.8778 - val_loss: 0.7290 - val_accuracy: 0.8631\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3631 - accuracy: 0.8886 - val_loss: 0.7250 - val_accuracy: 0.8719\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3696 - accuracy: 0.8824 - val_loss: 0.7293 - val_accuracy: 0.8647\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3636 - accuracy: 0.8891 - val_loss: 0.6536 - val_accuracy: 0.8953\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3459 - accuracy: 0.8903 - val_loss: 0.6857 - val_accuracy: 0.8717\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.3524 - accuracy: 0.8909 - val_loss: 0.6924 - val_accuracy: 0.8695\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3388 - accuracy: 0.8958 - val_loss: 0.6912 - val_accuracy: 0.8862\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3599 - accuracy: 0.8893 - val_loss: 0.6945 - val_accuracy: 0.8750\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3360 - accuracy: 0.8983 - val_loss: 0.6454 - val_accuracy: 0.8779\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3385 - accuracy: 0.8939 - val_loss: 0.6738 - val_accuracy: 0.8889\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3288 - accuracy: 0.8961 - val_loss: 0.6399 - val_accuracy: 0.8869\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3170 - accuracy: 0.8983 - val_loss: 0.6152 - val_accuracy: 0.8988\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3169 - accuracy: 0.9017 - val_loss: 0.6081 - val_accuracy: 0.9107\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3218 - accuracy: 0.9003 - val_loss: 0.7188 - val_accuracy: 0.8570\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3118 - accuracy: 0.9040 - val_loss: 0.6737 - val_accuracy: 0.8882\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3056 - accuracy: 0.9067 - val_loss: 0.6165 - val_accuracy: 0.8871\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3084 - accuracy: 0.9069 - val_loss: 0.5681 - val_accuracy: 0.9133\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2980 - accuracy: 0.9094 - val_loss: 0.6118 - val_accuracy: 0.8873\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2949 - accuracy: 0.9095 - val_loss: 0.5761 - val_accuracy: 0.9019\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2945 - accuracy: 0.9095 - val_loss: 0.6603 - val_accuracy: 0.8750\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3063 - accuracy: 0.9039 - val_loss: 0.5923 - val_accuracy: 0.8900\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2961 - accuracy: 0.9080 - val_loss: 0.5620 - val_accuracy: 0.9107\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2885 - accuracy: 0.9137 - val_loss: 0.7202 - val_accuracy: 0.8598\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2849 - accuracy: 0.9127 - val_loss: 0.5470 - val_accuracy: 0.9267\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2777 - accuracy: 0.9169 - val_loss: 0.7529 - val_accuracy: 0.8651\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2752 - accuracy: 0.9171 - val_loss: 0.5444 - val_accuracy: 0.9177\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2747 - accuracy: 0.9142 - val_loss: 0.5641 - val_accuracy: 0.9243\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2762 - accuracy: 0.9169 - val_loss: 0.6151 - val_accuracy: 0.8917\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2645 - accuracy: 0.9197 - val_loss: 0.5745 - val_accuracy: 0.9045\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2719 - accuracy: 0.9152 - val_loss: 0.5411 - val_accuracy: 0.9197\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2779 - accuracy: 0.9150 - val_loss: 0.5434 - val_accuracy: 0.9193\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2742 - accuracy: 0.9164 - val_loss: 0.5610 - val_accuracy: 0.9179\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2610 - accuracy: 0.9224 - val_loss: 0.5353 - val_accuracy: 0.9221\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2633 - accuracy: 0.9187 - val_loss: 0.5578 - val_accuracy: 0.9063\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2669 - accuracy: 0.9184 - val_loss: 0.5287 - val_accuracy: 0.9177\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2581 - accuracy: 0.9203 - val_loss: 0.5695 - val_accuracy: 0.9006\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2499 - accuracy: 0.9238 - val_loss: 0.5575 - val_accuracy: 0.9080\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2616 - accuracy: 0.9211 - val_loss: 0.5354 - val_accuracy: 0.9098\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2505 - accuracy: 0.9263 - val_loss: 0.5129 - val_accuracy: 0.9212\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2603 - accuracy: 0.9186 - val_loss: 0.5154 - val_accuracy: 0.9250\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2492 - accuracy: 0.9260 - val_loss: 0.5102 - val_accuracy: 0.9190\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2610 - accuracy: 0.9203 - val_loss: 0.4929 - val_accuracy: 0.9358\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2510 - accuracy: 0.9219 - val_loss: 0.4875 - val_accuracy: 0.9263\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2613 - accuracy: 0.9227 - val_loss: 0.4814 - val_accuracy: 0.9309\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2286 - accuracy: 0.9327 - val_loss: 0.5152 - val_accuracy: 0.9206\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2547 - accuracy: 0.9220 - val_loss: 0.4849 - val_accuracy: 0.9307\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2373 - accuracy: 0.9304 - val_loss: 0.6243 - val_accuracy: 0.8902\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2494 - accuracy: 0.9253 - val_loss: 0.5261 - val_accuracy: 0.9116\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2392 - accuracy: 0.9300 - val_loss: 0.5606 - val_accuracy: 0.9089\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2685 - accuracy: 0.9212 - val_loss: 0.4740 - val_accuracy: 0.9410\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2127 - accuracy: 0.9405 - val_loss: 0.4745 - val_accuracy: 0.9322\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2456 - accuracy: 0.9274 - val_loss: 0.4964 - val_accuracy: 0.9278\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2271 - accuracy: 0.9339 - val_loss: 0.5293 - val_accuracy: 0.9091\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2320 - accuracy: 0.9303 - val_loss: 0.5582 - val_accuracy: 0.8975\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2531 - accuracy: 0.9241 - val_loss: 0.5373 - val_accuracy: 0.9072\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2202 - accuracy: 0.9342 - val_loss: 0.4705 - val_accuracy: 0.9263\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2367 - accuracy: 0.9339 - val_loss: 0.4526 - val_accuracy: 0.9470\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 5ms/step - loss: 3.9175 - accuracy: 0.2017 - val_loss: 3.2035 - val_accuracy: 0.3553\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 2.5051 - accuracy: 0.4519 - val_loss: 2.4101 - val_accuracy: 0.5578\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 1.7854 - accuracy: 0.5987 - val_loss: 2.0193 - val_accuracy: 0.6495\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 1.3601 - accuracy: 0.6805 - val_loss: 1.7115 - val_accuracy: 0.6774\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 1.1046 - accuracy: 0.7179 - val_loss: 1.5052 - val_accuracy: 0.7076\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.9235 - accuracy: 0.7569 - val_loss: 1.3594 - val_accuracy: 0.7549\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.8046 - accuracy: 0.7817 - val_loss: 1.2260 - val_accuracy: 0.7780\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.7066 - accuracy: 0.7954 - val_loss: 1.1646 - val_accuracy: 0.7905\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.6350 - accuracy: 0.8119 - val_loss: 1.0298 - val_accuracy: 0.8141\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5832 - accuracy: 0.8284 - val_loss: 1.0425 - val_accuracy: 0.8207\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5399 - accuracy: 0.8393 - val_loss: 0.9426 - val_accuracy: 0.8372\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4952 - accuracy: 0.8507 - val_loss: 0.9412 - val_accuracy: 0.8293\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4730 - accuracy: 0.8534 - val_loss: 0.8406 - val_accuracy: 0.8427\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4469 - accuracy: 0.8631 - val_loss: 0.8932 - val_accuracy: 0.8339\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4324 - accuracy: 0.8679 - val_loss: 0.8114 - val_accuracy: 0.8689\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4025 - accuracy: 0.8749 - val_loss: 0.7881 - val_accuracy: 0.8680\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3928 - accuracy: 0.8787 - val_loss: 0.8141 - val_accuracy: 0.8453\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3850 - accuracy: 0.8788 - val_loss: 0.7387 - val_accuracy: 0.8722\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3735 - accuracy: 0.8834 - val_loss: 0.7049 - val_accuracy: 0.8898\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3509 - accuracy: 0.8891 - val_loss: 0.8056 - val_accuracy: 0.8559\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3427 - accuracy: 0.8929 - val_loss: 0.7462 - val_accuracy: 0.8827\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3451 - accuracy: 0.8943 - val_loss: 0.7274 - val_accuracy: 0.8838\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3335 - accuracy: 0.8966 - val_loss: 0.7522 - val_accuracy: 0.8904\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3285 - accuracy: 0.8973 - val_loss: 0.7180 - val_accuracy: 0.8865\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3154 - accuracy: 0.9031 - val_loss: 0.6731 - val_accuracy: 0.9034\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3181 - accuracy: 0.9009 - val_loss: 0.7769 - val_accuracy: 0.8583\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3022 - accuracy: 0.9059 - val_loss: 0.7762 - val_accuracy: 0.8458\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3036 - accuracy: 0.9065 - val_loss: 0.6962 - val_accuracy: 0.8860\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2894 - accuracy: 0.9109 - val_loss: 0.6922 - val_accuracy: 0.8955\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2981 - accuracy: 0.9072 - val_loss: 0.7796 - val_accuracy: 0.8691\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2925 - accuracy: 0.9119 - val_loss: 0.6898 - val_accuracy: 0.8966\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2808 - accuracy: 0.9163 - val_loss: 0.7158 - val_accuracy: 0.8946\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2756 - accuracy: 0.9161 - val_loss: 0.7210 - val_accuracy: 0.8656\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2855 - accuracy: 0.9108 - val_loss: 0.6699 - val_accuracy: 0.8970\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2791 - accuracy: 0.9141 - val_loss: 0.6581 - val_accuracy: 0.9085\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2749 - accuracy: 0.9188 - val_loss: 0.6651 - val_accuracy: 0.8972\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2604 - accuracy: 0.9193 - val_loss: 0.6243 - val_accuracy: 0.9199\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2695 - accuracy: 0.9183 - val_loss: 0.6549 - val_accuracy: 0.9012\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2800 - accuracy: 0.9208 - val_loss: 0.6257 - val_accuracy: 0.9111\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2585 - accuracy: 0.9223 - val_loss: 0.6596 - val_accuracy: 0.9036\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2686 - accuracy: 0.9185 - val_loss: 0.6740 - val_accuracy: 0.8937\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2842 - accuracy: 0.9169 - val_loss: 0.6329 - val_accuracy: 0.9135\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2506 - accuracy: 0.9254 - val_loss: 0.6148 - val_accuracy: 0.9193\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2462 - accuracy: 0.9254 - val_loss: 0.6695 - val_accuracy: 0.9032\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2417 - accuracy: 0.9267 - val_loss: 0.6371 - val_accuracy: 0.9074\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2624 - accuracy: 0.9207 - val_loss: 0.6247 - val_accuracy: 0.9080\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2460 - accuracy: 0.9259 - val_loss: 0.5778 - val_accuracy: 0.9223\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2428 - accuracy: 0.9244 - val_loss: 0.5669 - val_accuracy: 0.9274\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2439 - accuracy: 0.9265 - val_loss: 0.5984 - val_accuracy: 0.9127\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2337 - accuracy: 0.9287 - val_loss: 0.6201 - val_accuracy: 0.9129\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2392 - accuracy: 0.9273 - val_loss: 0.5805 - val_accuracy: 0.9263\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2453 - accuracy: 0.9266 - val_loss: 0.5530 - val_accuracy: 0.9382\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2323 - accuracy: 0.9299 - val_loss: 0.5584 - val_accuracy: 0.9272\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2303 - accuracy: 0.9298 - val_loss: 0.5582 - val_accuracy: 0.9316\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2249 - accuracy: 0.9316 - val_loss: 0.6034 - val_accuracy: 0.9173\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2414 - accuracy: 0.9297 - val_loss: 0.7089 - val_accuracy: 0.8812\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2328 - accuracy: 0.9317 - val_loss: 0.5957 - val_accuracy: 0.9186\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2283 - accuracy: 0.9319 - val_loss: 0.6310 - val_accuracy: 0.9120\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2272 - accuracy: 0.9315 - val_loss: 0.6193 - val_accuracy: 0.9021\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2298 - accuracy: 0.9312 - val_loss: 0.5993 - val_accuracy: 0.9067\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2230 - accuracy: 0.9322 - val_loss: 0.6508 - val_accuracy: 0.8988\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2318 - accuracy: 0.9329 - val_loss: 0.5266 - val_accuracy: 0.9311\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2116 - accuracy: 0.9376 - val_loss: 0.5484 - val_accuracy: 0.9265\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2365 - accuracy: 0.9312 - val_loss: 0.5618 - val_accuracy: 0.9270\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2071 - accuracy: 0.9394 - val_loss: 0.5568 - val_accuracy: 0.9237\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2181 - accuracy: 0.9364 - val_loss: 0.5465 - val_accuracy: 0.9289\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2213 - accuracy: 0.9338 - val_loss: 0.5888 - val_accuracy: 0.9146\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2223 - accuracy: 0.9382 - val_loss: 0.5568 - val_accuracy: 0.9300\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2126 - accuracy: 0.9387 - val_loss: 0.5702 - val_accuracy: 0.9164\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2001 - accuracy: 0.9445 - val_loss: 0.5516 - val_accuracy: 0.9322\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2176 - accuracy: 0.9346 - val_loss: 0.5475 - val_accuracy: 0.9195\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2192 - accuracy: 0.9363 - val_loss: 0.6553 - val_accuracy: 0.8979\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2027 - accuracy: 0.9404 - val_loss: 0.5052 - val_accuracy: 0.9351\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2224 - accuracy: 0.9332 - val_loss: 0.5226 - val_accuracy: 0.9281\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2057 - accuracy: 0.9407 - val_loss: 0.5228 - val_accuracy: 0.9355\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2042 - accuracy: 0.9426 - val_loss: 0.5336 - val_accuracy: 0.9272\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2118 - accuracy: 0.9351 - val_loss: 0.4964 - val_accuracy: 0.9377\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2052 - accuracy: 0.9393 - val_loss: 0.5824 - val_accuracy: 0.9052\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1991 - accuracy: 0.9439 - val_loss: 0.5329 - val_accuracy: 0.9256\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2037 - accuracy: 0.9409 - val_loss: 0.5883 - val_accuracy: 0.9102\n",
      "Average Validation Accuracy: 0.9369705319404602\n",
      "Average Validation Loss: 0.32127413153648376\n",
      "Average Test Accuracy: 0.935873806476593\n",
      "Final Test Accuracy for each fold: 0.9529741406440735\n",
      "Number of input features: 9\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.7638 - accuracy: 0.2635 - val_loss: 2.7102 - val_accuracy: 0.4667\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 1.9606 - accuracy: 0.6037 - val_loss: 1.6416 - val_accuracy: 0.6948\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.2116 - accuracy: 0.7441 - val_loss: 1.2046 - val_accuracy: 0.7688\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8484 - accuracy: 0.8026 - val_loss: 0.9170 - val_accuracy: 0.8238\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6547 - accuracy: 0.8332 - val_loss: 0.8117 - val_accuracy: 0.8398\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5346 - accuracy: 0.8570 - val_loss: 0.7991 - val_accuracy: 0.8152\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4589 - accuracy: 0.8780 - val_loss: 0.6454 - val_accuracy: 0.8565\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4027 - accuracy: 0.8878 - val_loss: 0.6192 - val_accuracy: 0.8697\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3764 - accuracy: 0.8963 - val_loss: 0.5761 - val_accuracy: 0.8895\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3466 - accuracy: 0.8997 - val_loss: 0.5447 - val_accuracy: 0.8920\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3137 - accuracy: 0.9111 - val_loss: 0.4966 - val_accuracy: 0.9058\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2975 - accuracy: 0.9140 - val_loss: 0.4909 - val_accuracy: 0.9050\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2936 - accuracy: 0.9149 - val_loss: 0.4377 - val_accuracy: 0.9259\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2625 - accuracy: 0.9250 - val_loss: 0.4730 - val_accuracy: 0.9105\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2617 - accuracy: 0.9252 - val_loss: 0.4489 - val_accuracy: 0.9138\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2438 - accuracy: 0.9306 - val_loss: 0.4728 - val_accuracy: 0.9065\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2495 - accuracy: 0.9300 - val_loss: 0.4195 - val_accuracy: 0.9267\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2227 - accuracy: 0.9396 - val_loss: 0.4415 - val_accuracy: 0.9182\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2314 - accuracy: 0.9376 - val_loss: 0.3878 - val_accuracy: 0.9393\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2142 - accuracy: 0.9436 - val_loss: 0.4095 - val_accuracy: 0.9380\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 6s 4ms/step - loss: 0.2219 - accuracy: 0.9384 - val_loss: 0.4331 - val_accuracy: 0.9320\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1965 - accuracy: 0.9471 - val_loss: 0.4054 - val_accuracy: 0.9300\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2206 - accuracy: 0.9402 - val_loss: 0.3924 - val_accuracy: 0.9373\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1981 - accuracy: 0.9498 - val_loss: 0.4270 - val_accuracy: 0.9320\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1984 - accuracy: 0.9491 - val_loss: 0.4388 - val_accuracy: 0.9124\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1938 - accuracy: 0.9483 - val_loss: 0.3811 - val_accuracy: 0.9452\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1817 - accuracy: 0.9514 - val_loss: 0.3544 - val_accuracy: 0.9505\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1809 - accuracy: 0.9543 - val_loss: 0.4242 - val_accuracy: 0.9261\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1871 - accuracy: 0.9506 - val_loss: 0.4008 - val_accuracy: 0.9439\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1718 - accuracy: 0.9557 - val_loss: 0.3754 - val_accuracy: 0.9424\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1762 - accuracy: 0.9539 - val_loss: 0.4114 - val_accuracy: 0.9417\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1753 - accuracy: 0.9551 - val_loss: 0.4095 - val_accuracy: 0.9364\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1782 - accuracy: 0.9545 - val_loss: 0.3759 - val_accuracy: 0.9463\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1726 - accuracy: 0.9535 - val_loss: 0.4040 - val_accuracy: 0.9360\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1567 - accuracy: 0.9607 - val_loss: 0.4089 - val_accuracy: 0.9307\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1696 - accuracy: 0.9563 - val_loss: 0.3768 - val_accuracy: 0.9382\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1577 - accuracy: 0.9600 - val_loss: 0.3761 - val_accuracy: 0.9465\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1701 - accuracy: 0.9572 - val_loss: 0.3807 - val_accuracy: 0.9393\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1640 - accuracy: 0.9578 - val_loss: 0.3517 - val_accuracy: 0.9551\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1608 - accuracy: 0.9584 - val_loss: 0.3981 - val_accuracy: 0.9446\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1477 - accuracy: 0.9626 - val_loss: 0.3311 - val_accuracy: 0.9553\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1691 - accuracy: 0.9570 - val_loss: 0.3516 - val_accuracy: 0.9547\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1495 - accuracy: 0.9641 - val_loss: 0.3420 - val_accuracy: 0.9558\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1612 - accuracy: 0.9609 - val_loss: 0.3548 - val_accuracy: 0.9463\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1474 - accuracy: 0.9627 - val_loss: 0.3957 - val_accuracy: 0.9393\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.1515 - accuracy: 0.9622 - val_loss: 0.3218 - val_accuracy: 0.9633\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1606 - accuracy: 0.9603 - val_loss: 0.3341 - val_accuracy: 0.9615\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1448 - accuracy: 0.9635 - val_loss: 0.3614 - val_accuracy: 0.9531\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1441 - accuracy: 0.9656 - val_loss: 0.3579 - val_accuracy: 0.9417\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1395 - accuracy: 0.9654 - val_loss: 0.3630 - val_accuracy: 0.9514\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1566 - accuracy: 0.9579 - val_loss: 0.3564 - val_accuracy: 0.9494\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1320 - accuracy: 0.9681 - val_loss: 0.3199 - val_accuracy: 0.9611\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1354 - accuracy: 0.9665 - val_loss: 0.3120 - val_accuracy: 0.9628\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1616 - accuracy: 0.9600 - val_loss: 0.3543 - val_accuracy: 0.9542\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1440 - accuracy: 0.9660 - val_loss: 0.3178 - val_accuracy: 0.9661\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1381 - accuracy: 0.9656 - val_loss: 0.3802 - val_accuracy: 0.9424\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1359 - accuracy: 0.9672 - val_loss: 0.3310 - val_accuracy: 0.9593\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1367 - accuracy: 0.9677 - val_loss: 0.3092 - val_accuracy: 0.9672\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1270 - accuracy: 0.9703 - val_loss: 0.3337 - val_accuracy: 0.9597\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1447 - accuracy: 0.9644 - val_loss: 0.3358 - val_accuracy: 0.9578\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1242 - accuracy: 0.9702 - val_loss: 0.3690 - val_accuracy: 0.9413\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1392 - accuracy: 0.9680 - val_loss: 0.3218 - val_accuracy: 0.9567\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1331 - accuracy: 0.9664 - val_loss: 0.3325 - val_accuracy: 0.9560\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1296 - accuracy: 0.9672 - val_loss: 0.3090 - val_accuracy: 0.9692\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1311 - accuracy: 0.9685 - val_loss: 0.3279 - val_accuracy: 0.9562\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1388 - accuracy: 0.9673 - val_loss: 0.3103 - val_accuracy: 0.9663\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1230 - accuracy: 0.9721 - val_loss: 0.3546 - val_accuracy: 0.9542\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1289 - accuracy: 0.9698 - val_loss: 0.3499 - val_accuracy: 0.9551\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1321 - accuracy: 0.9678 - val_loss: 0.3144 - val_accuracy: 0.9661\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1267 - accuracy: 0.9702 - val_loss: 0.3128 - val_accuracy: 0.9633\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1310 - accuracy: 0.9681 - val_loss: 0.3229 - val_accuracy: 0.9648\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1199 - accuracy: 0.9714 - val_loss: 0.3662 - val_accuracy: 0.9536\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1314 - accuracy: 0.9699 - val_loss: 0.4221 - val_accuracy: 0.9402\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1199 - accuracy: 0.9728 - val_loss: 0.3712 - val_accuracy: 0.9509\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1226 - accuracy: 0.9712 - val_loss: 0.3151 - val_accuracy: 0.9685\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1347 - accuracy: 0.9681 - val_loss: 0.3143 - val_accuracy: 0.9663\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1189 - accuracy: 0.9738 - val_loss: 0.3413 - val_accuracy: 0.9644\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1350 - accuracy: 0.9687 - val_loss: 0.3456 - val_accuracy: 0.9527\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1100 - accuracy: 0.9752 - val_loss: 0.3400 - val_accuracy: 0.9611\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1271 - accuracy: 0.9693 - val_loss: 0.3349 - val_accuracy: 0.9589\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.4757 - accuracy: 0.3129 - val_loss: 2.4681 - val_accuracy: 0.4785\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.7122 - accuracy: 0.6325 - val_loss: 1.6706 - val_accuracy: 0.6867\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.0870 - accuracy: 0.7452 - val_loss: 1.2404 - val_accuracy: 0.7553\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.7833 - accuracy: 0.8067 - val_loss: 0.9858 - val_accuracy: 0.8251\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6228 - accuracy: 0.8394 - val_loss: 0.8487 - val_accuracy: 0.8480\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5252 - accuracy: 0.8593 - val_loss: 0.7245 - val_accuracy: 0.8746\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4552 - accuracy: 0.8730 - val_loss: 0.7365 - val_accuracy: 0.8669\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4119 - accuracy: 0.8879 - val_loss: 0.6918 - val_accuracy: 0.8645\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3622 - accuracy: 0.9014 - val_loss: 0.5762 - val_accuracy: 0.8955\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3457 - accuracy: 0.9044 - val_loss: 0.5895 - val_accuracy: 0.8880\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.3223 - accuracy: 0.9074 - val_loss: 0.5651 - val_accuracy: 0.8931\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2979 - accuracy: 0.9135 - val_loss: 0.5713 - val_accuracy: 0.8755\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2885 - accuracy: 0.9176 - val_loss: 0.5306 - val_accuracy: 0.9094\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2838 - accuracy: 0.9200 - val_loss: 0.4958 - val_accuracy: 0.9052\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2634 - accuracy: 0.9253 - val_loss: 0.5633 - val_accuracy: 0.8766\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2624 - accuracy: 0.9267 - val_loss: 0.4617 - val_accuracy: 0.9201\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2483 - accuracy: 0.9294 - val_loss: 0.4867 - val_accuracy: 0.9074\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2557 - accuracy: 0.9285 - val_loss: 0.5041 - val_accuracy: 0.9067\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2326 - accuracy: 0.9339 - val_loss: 0.4776 - val_accuracy: 0.9151\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2348 - accuracy: 0.9351 - val_loss: 0.4625 - val_accuracy: 0.9179\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2165 - accuracy: 0.9401 - val_loss: 0.4666 - val_accuracy: 0.9206\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2250 - accuracy: 0.9377 - val_loss: 0.4801 - val_accuracy: 0.9006\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2147 - accuracy: 0.9419 - val_loss: 0.4292 - val_accuracy: 0.9254\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2067 - accuracy: 0.9425 - val_loss: 0.4234 - val_accuracy: 0.9327\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2143 - accuracy: 0.9442 - val_loss: 0.4147 - val_accuracy: 0.9318\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1961 - accuracy: 0.9488 - val_loss: 0.4018 - val_accuracy: 0.9382\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1941 - accuracy: 0.9483 - val_loss: 0.3690 - val_accuracy: 0.9459\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1990 - accuracy: 0.9498 - val_loss: 0.3789 - val_accuracy: 0.9402\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1809 - accuracy: 0.9535 - val_loss: 0.3764 - val_accuracy: 0.9369\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1940 - accuracy: 0.9509 - val_loss: 0.3808 - val_accuracy: 0.9419\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1811 - accuracy: 0.9517 - val_loss: 0.4033 - val_accuracy: 0.9360\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1777 - accuracy: 0.9547 - val_loss: 0.4012 - val_accuracy: 0.9338\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1837 - accuracy: 0.9534 - val_loss: 0.3742 - val_accuracy: 0.9415\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1796 - accuracy: 0.9544 - val_loss: 0.4023 - val_accuracy: 0.9371\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1785 - accuracy: 0.9514 - val_loss: 0.3370 - val_accuracy: 0.9531\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1678 - accuracy: 0.9566 - val_loss: 0.3990 - val_accuracy: 0.9360\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1683 - accuracy: 0.9576 - val_loss: 0.3740 - val_accuracy: 0.9419\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1847 - accuracy: 0.9544 - val_loss: 0.4130 - val_accuracy: 0.9272\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1581 - accuracy: 0.9598 - val_loss: 0.4241 - val_accuracy: 0.9237\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1642 - accuracy: 0.9602 - val_loss: 0.3933 - val_accuracy: 0.9316\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1606 - accuracy: 0.9587 - val_loss: 0.4153 - val_accuracy: 0.9424\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1623 - accuracy: 0.9593 - val_loss: 0.3618 - val_accuracy: 0.9573\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1584 - accuracy: 0.9614 - val_loss: 0.3720 - val_accuracy: 0.9435\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1560 - accuracy: 0.9626 - val_loss: 0.3990 - val_accuracy: 0.9296\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1515 - accuracy: 0.9616 - val_loss: 0.4642 - val_accuracy: 0.9322\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1539 - accuracy: 0.9630 - val_loss: 0.3674 - val_accuracy: 0.9413\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1571 - accuracy: 0.9597 - val_loss: 0.3524 - val_accuracy: 0.9485\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1446 - accuracy: 0.9667 - val_loss: 0.3538 - val_accuracy: 0.9474\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1620 - accuracy: 0.9615 - val_loss: 0.3625 - val_accuracy: 0.9474\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1400 - accuracy: 0.9669 - val_loss: 0.3554 - val_accuracy: 0.9472\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1431 - accuracy: 0.9658 - val_loss: 0.3727 - val_accuracy: 0.9364\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1563 - accuracy: 0.9604 - val_loss: 0.3278 - val_accuracy: 0.9578\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1450 - accuracy: 0.9648 - val_loss: 0.3553 - val_accuracy: 0.9514\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1411 - accuracy: 0.9658 - val_loss: 0.3616 - val_accuracy: 0.9437\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1481 - accuracy: 0.9648 - val_loss: 0.3435 - val_accuracy: 0.9494\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1339 - accuracy: 0.9676 - val_loss: 0.3500 - val_accuracy: 0.9540\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1432 - accuracy: 0.9630 - val_loss: 0.3462 - val_accuracy: 0.9536\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1390 - accuracy: 0.9661 - val_loss: 0.4079 - val_accuracy: 0.9375\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1472 - accuracy: 0.9633 - val_loss: 0.3904 - val_accuracy: 0.9457\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1293 - accuracy: 0.9698 - val_loss: 0.4031 - val_accuracy: 0.9320\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1374 - accuracy: 0.9677 - val_loss: 0.3709 - val_accuracy: 0.9452\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1347 - accuracy: 0.9686 - val_loss: 0.3314 - val_accuracy: 0.9534\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1363 - accuracy: 0.9640 - val_loss: 0.3779 - val_accuracy: 0.9408\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1273 - accuracy: 0.9692 - val_loss: 0.4059 - val_accuracy: 0.9450\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1401 - accuracy: 0.9663 - val_loss: 0.3632 - val_accuracy: 0.9483\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1298 - accuracy: 0.9694 - val_loss: 0.3109 - val_accuracy: 0.9602\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1351 - accuracy: 0.9684 - val_loss: 0.3185 - val_accuracy: 0.9613\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1307 - accuracy: 0.9691 - val_loss: 0.3789 - val_accuracy: 0.9366\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1255 - accuracy: 0.9712 - val_loss: 0.3475 - val_accuracy: 0.9553\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1325 - accuracy: 0.9675 - val_loss: 0.3237 - val_accuracy: 0.9551\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1337 - accuracy: 0.9677 - val_loss: 0.3065 - val_accuracy: 0.9650\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1204 - accuracy: 0.9706 - val_loss: 0.3300 - val_accuracy: 0.9542\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1249 - accuracy: 0.9711 - val_loss: 0.3172 - val_accuracy: 0.9655\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1310 - accuracy: 0.9693 - val_loss: 0.3412 - val_accuracy: 0.9516\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1149 - accuracy: 0.9726 - val_loss: 0.3241 - val_accuracy: 0.9582\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1356 - accuracy: 0.9693 - val_loss: 0.3172 - val_accuracy: 0.9615\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1271 - accuracy: 0.9708 - val_loss: 0.2951 - val_accuracy: 0.9699\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1260 - accuracy: 0.9701 - val_loss: 0.3436 - val_accuracy: 0.9556\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1293 - accuracy: 0.9698 - val_loss: 0.3227 - val_accuracy: 0.9600\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1280 - accuracy: 0.9701 - val_loss: 0.3519 - val_accuracy: 0.9527\n",
      "Average Validation Accuracy: 0.9642013907432556\n",
      "Average Validation Loss: 0.2085384875535965\n",
      "Average Test Accuracy: 0.9665364623069763\n",
      "Final Test Accuracy for each fold: 0.9669049978256226\n",
      "Number of input features: 10\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 4.0324 - accuracy: 0.2089 - val_loss: 3.0997 - val_accuracy: 0.4233\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 2.2446 - accuracy: 0.5764 - val_loss: 1.9347 - val_accuracy: 0.6638\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.4108 - accuracy: 0.7181 - val_loss: 1.4267 - val_accuracy: 0.7494\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.0150 - accuracy: 0.7879 - val_loss: 1.1235 - val_accuracy: 0.8123\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7802 - accuracy: 0.8267 - val_loss: 0.9493 - val_accuracy: 0.8427\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6229 - accuracy: 0.8570 - val_loss: 0.8173 - val_accuracy: 0.8550\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5181 - accuracy: 0.8763 - val_loss: 0.7257 - val_accuracy: 0.8766\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4408 - accuracy: 0.8903 - val_loss: 0.6875 - val_accuracy: 0.8805\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3903 - accuracy: 0.9000 - val_loss: 0.6490 - val_accuracy: 0.8761\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3518 - accuracy: 0.9078 - val_loss: 0.5739 - val_accuracy: 0.9056\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3222 - accuracy: 0.9146 - val_loss: 0.5772 - val_accuracy: 0.9012\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3112 - accuracy: 0.9155 - val_loss: 0.5195 - val_accuracy: 0.9107\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2799 - accuracy: 0.9232 - val_loss: 0.4963 - val_accuracy: 0.9210\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2799 - accuracy: 0.9234 - val_loss: 0.4812 - val_accuracy: 0.9278\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2573 - accuracy: 0.9287 - val_loss: 0.4691 - val_accuracy: 0.9322\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2470 - accuracy: 0.9334 - val_loss: 0.5503 - val_accuracy: 0.8994\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2413 - accuracy: 0.9343 - val_loss: 0.4542 - val_accuracy: 0.9309\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2394 - accuracy: 0.9346 - val_loss: 0.4236 - val_accuracy: 0.9342\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2231 - accuracy: 0.9383 - val_loss: 0.4194 - val_accuracy: 0.9426\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2283 - accuracy: 0.9376 - val_loss: 0.4570 - val_accuracy: 0.9287\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2125 - accuracy: 0.9424 - val_loss: 0.4078 - val_accuracy: 0.9472\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2037 - accuracy: 0.9433 - val_loss: 0.4391 - val_accuracy: 0.9318\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2054 - accuracy: 0.9426 - val_loss: 0.3978 - val_accuracy: 0.9441\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1978 - accuracy: 0.9467 - val_loss: 0.4142 - val_accuracy: 0.9397\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1933 - accuracy: 0.9485 - val_loss: 0.4116 - val_accuracy: 0.9399\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1871 - accuracy: 0.9498 - val_loss: 0.4233 - val_accuracy: 0.9344\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1850 - accuracy: 0.9510 - val_loss: 0.4402 - val_accuracy: 0.9338\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1846 - accuracy: 0.9525 - val_loss: 0.3711 - val_accuracy: 0.9564\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1710 - accuracy: 0.9565 - val_loss: 0.4192 - val_accuracy: 0.9393\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1738 - accuracy: 0.9539 - val_loss: 0.4022 - val_accuracy: 0.9441\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1764 - accuracy: 0.9556 - val_loss: 0.3798 - val_accuracy: 0.9531\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1653 - accuracy: 0.9559 - val_loss: 0.3921 - val_accuracy: 0.9441\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1608 - accuracy: 0.9595 - val_loss: 0.3708 - val_accuracy: 0.9523\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1613 - accuracy: 0.9570 - val_loss: 0.4141 - val_accuracy: 0.9397\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1547 - accuracy: 0.9602 - val_loss: 0.3389 - val_accuracy: 0.9714\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1598 - accuracy: 0.9594 - val_loss: 0.3803 - val_accuracy: 0.9527\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1484 - accuracy: 0.9628 - val_loss: 0.3456 - val_accuracy: 0.9597\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1541 - accuracy: 0.9598 - val_loss: 0.4038 - val_accuracy: 0.9384\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1583 - accuracy: 0.9612 - val_loss: 0.3654 - val_accuracy: 0.9520\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1428 - accuracy: 0.9638 - val_loss: 0.3649 - val_accuracy: 0.9553\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1564 - accuracy: 0.9574 - val_loss: 0.3861 - val_accuracy: 0.9474\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1430 - accuracy: 0.9659 - val_loss: 0.3447 - val_accuracy: 0.9573\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1348 - accuracy: 0.9662 - val_loss: 0.3511 - val_accuracy: 0.9624\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1453 - accuracy: 0.9636 - val_loss: 0.3446 - val_accuracy: 0.9573\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1460 - accuracy: 0.9627 - val_loss: 0.3260 - val_accuracy: 0.9646\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1323 - accuracy: 0.9680 - val_loss: 0.3121 - val_accuracy: 0.9626\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1429 - accuracy: 0.9651 - val_loss: 0.3300 - val_accuracy: 0.9597\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1322 - accuracy: 0.9677 - val_loss: 0.3616 - val_accuracy: 0.9496\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1432 - accuracy: 0.9639 - val_loss: 0.3206 - val_accuracy: 0.9677\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1283 - accuracy: 0.9688 - val_loss: 0.3467 - val_accuracy: 0.9641\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1464 - accuracy: 0.9638 - val_loss: 0.3215 - val_accuracy: 0.9600\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1228 - accuracy: 0.9682 - val_loss: 0.3354 - val_accuracy: 0.9591\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1306 - accuracy: 0.9691 - val_loss: 0.3242 - val_accuracy: 0.9604\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1315 - accuracy: 0.9672 - val_loss: 0.3108 - val_accuracy: 0.9666\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1237 - accuracy: 0.9691 - val_loss: 0.2984 - val_accuracy: 0.9710\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1320 - accuracy: 0.9694 - val_loss: 0.3464 - val_accuracy: 0.9509\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1265 - accuracy: 0.9716 - val_loss: 0.3291 - val_accuracy: 0.9604\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1271 - accuracy: 0.9694 - val_loss: 0.3824 - val_accuracy: 0.9355\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1249 - accuracy: 0.9712 - val_loss: 0.3051 - val_accuracy: 0.9637\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1250 - accuracy: 0.9715 - val_loss: 0.3308 - val_accuracy: 0.9564\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1266 - accuracy: 0.9694 - val_loss: 0.3058 - val_accuracy: 0.9666\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1098 - accuracy: 0.9754 - val_loss: 0.3457 - val_accuracy: 0.9584\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1237 - accuracy: 0.9710 - val_loss: 0.2992 - val_accuracy: 0.9696\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1188 - accuracy: 0.9742 - val_loss: 0.3090 - val_accuracy: 0.9644\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1163 - accuracy: 0.9734 - val_loss: 0.2890 - val_accuracy: 0.9736\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1118 - accuracy: 0.9744 - val_loss: 0.3123 - val_accuracy: 0.9646\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1147 - accuracy: 0.9727 - val_loss: 0.3129 - val_accuracy: 0.9635\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1137 - accuracy: 0.9749 - val_loss: 0.2817 - val_accuracy: 0.9732\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1158 - accuracy: 0.9737 - val_loss: 0.2941 - val_accuracy: 0.9672\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1155 - accuracy: 0.9736 - val_loss: 0.2990 - val_accuracy: 0.9584\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1169 - accuracy: 0.9724 - val_loss: 0.3023 - val_accuracy: 0.9683\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1069 - accuracy: 0.9771 - val_loss: 0.3097 - val_accuracy: 0.9663\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1137 - accuracy: 0.9734 - val_loss: 0.2876 - val_accuracy: 0.9725\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1129 - accuracy: 0.9750 - val_loss: 0.3069 - val_accuracy: 0.9633\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1105 - accuracy: 0.9753 - val_loss: 0.4191 - val_accuracy: 0.9314\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1174 - accuracy: 0.9739 - val_loss: 0.2902 - val_accuracy: 0.9699\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1017 - accuracy: 0.9779 - val_loss: 0.2950 - val_accuracy: 0.9677\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1127 - accuracy: 0.9739 - val_loss: 0.3249 - val_accuracy: 0.9597\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1103 - accuracy: 0.9758 - val_loss: 0.2866 - val_accuracy: 0.9732\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1095 - accuracy: 0.9757 - val_loss: 0.2718 - val_accuracy: 0.9762\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 4.0652 - accuracy: 0.1975 - val_loss: 3.1402 - val_accuracy: 0.3947\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 2.1369 - accuracy: 0.5866 - val_loss: 1.8191 - val_accuracy: 0.6669\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 1.2280 - accuracy: 0.7519 - val_loss: 1.3456 - val_accuracy: 0.7615\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8313 - accuracy: 0.8252 - val_loss: 1.1196 - val_accuracy: 0.8108\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6224 - accuracy: 0.8615 - val_loss: 0.9102 - val_accuracy: 0.8673\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5001 - accuracy: 0.8850 - val_loss: 0.8229 - val_accuracy: 0.8799\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4235 - accuracy: 0.8992 - val_loss: 0.7648 - val_accuracy: 0.8801\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3622 - accuracy: 0.9145 - val_loss: 0.6655 - val_accuracy: 0.9069\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3286 - accuracy: 0.9177 - val_loss: 0.6148 - val_accuracy: 0.9111\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2904 - accuracy: 0.9281 - val_loss: 0.5764 - val_accuracy: 0.9078\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2664 - accuracy: 0.9293 - val_loss: 0.5133 - val_accuracy: 0.9305\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2508 - accuracy: 0.9358 - val_loss: 0.5417 - val_accuracy: 0.9162\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2271 - accuracy: 0.9390 - val_loss: 0.5059 - val_accuracy: 0.9256\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2178 - accuracy: 0.9435 - val_loss: 0.4773 - val_accuracy: 0.9318\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2117 - accuracy: 0.9444 - val_loss: 0.4628 - val_accuracy: 0.9333\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2007 - accuracy: 0.9478 - val_loss: 0.5032 - val_accuracy: 0.9287\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1865 - accuracy: 0.9506 - val_loss: 0.4633 - val_accuracy: 0.9307\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1792 - accuracy: 0.9533 - val_loss: 0.4380 - val_accuracy: 0.9448\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1713 - accuracy: 0.9551 - val_loss: 0.4367 - val_accuracy: 0.9424\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1716 - accuracy: 0.9571 - val_loss: 0.4309 - val_accuracy: 0.9454\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1666 - accuracy: 0.9568 - val_loss: 0.4275 - val_accuracy: 0.9529\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1651 - accuracy: 0.9581 - val_loss: 0.4232 - val_accuracy: 0.9509\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1615 - accuracy: 0.9622 - val_loss: 0.4274 - val_accuracy: 0.9490\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1488 - accuracy: 0.9640 - val_loss: 0.3903 - val_accuracy: 0.9626\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1563 - accuracy: 0.9591 - val_loss: 0.4015 - val_accuracy: 0.9481\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1503 - accuracy: 0.9634 - val_loss: 0.4016 - val_accuracy: 0.9538\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1497 - accuracy: 0.9630 - val_loss: 0.4507 - val_accuracy: 0.9450\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1522 - accuracy: 0.9626 - val_loss: 0.3892 - val_accuracy: 0.9556\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1352 - accuracy: 0.9673 - val_loss: 0.3985 - val_accuracy: 0.9523\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1389 - accuracy: 0.9663 - val_loss: 0.3802 - val_accuracy: 0.9591\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1363 - accuracy: 0.9673 - val_loss: 0.3689 - val_accuracy: 0.9611\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1353 - accuracy: 0.9690 - val_loss: 0.4016 - val_accuracy: 0.9487\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1388 - accuracy: 0.9676 - val_loss: 0.3692 - val_accuracy: 0.9560\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1250 - accuracy: 0.9711 - val_loss: 0.3847 - val_accuracy: 0.9602\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1294 - accuracy: 0.9700 - val_loss: 0.4363 - val_accuracy: 0.9355\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1349 - accuracy: 0.9684 - val_loss: 0.3759 - val_accuracy: 0.9602\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1257 - accuracy: 0.9690 - val_loss: 0.4369 - val_accuracy: 0.9344\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1212 - accuracy: 0.9724 - val_loss: 0.3610 - val_accuracy: 0.9644\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1279 - accuracy: 0.9712 - val_loss: 0.3486 - val_accuracy: 0.9655\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1268 - accuracy: 0.9707 - val_loss: 0.3356 - val_accuracy: 0.9659\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1220 - accuracy: 0.9713 - val_loss: 0.3530 - val_accuracy: 0.9703\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1227 - accuracy: 0.9728 - val_loss: 0.3633 - val_accuracy: 0.9608\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1165 - accuracy: 0.9736 - val_loss: 0.3481 - val_accuracy: 0.9593\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1244 - accuracy: 0.9711 - val_loss: 0.3651 - val_accuracy: 0.9571\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1225 - accuracy: 0.9716 - val_loss: 0.3393 - val_accuracy: 0.9672\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1099 - accuracy: 0.9773 - val_loss: 0.3886 - val_accuracy: 0.9457\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1201 - accuracy: 0.9700 - val_loss: 0.3553 - val_accuracy: 0.9644\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1206 - accuracy: 0.9715 - val_loss: 0.3727 - val_accuracy: 0.9536\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1065 - accuracy: 0.9760 - val_loss: 0.3252 - val_accuracy: 0.9679\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1136 - accuracy: 0.9726 - val_loss: 0.4299 - val_accuracy: 0.9391\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1104 - accuracy: 0.9732 - val_loss: 0.3499 - val_accuracy: 0.9628\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1166 - accuracy: 0.9724 - val_loss: 0.4417 - val_accuracy: 0.9340\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1048 - accuracy: 0.9760 - val_loss: 0.3338 - val_accuracy: 0.9628\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1184 - accuracy: 0.9736 - val_loss: 0.3343 - val_accuracy: 0.9644\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1040 - accuracy: 0.9760 - val_loss: 0.3691 - val_accuracy: 0.9578\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1198 - accuracy: 0.9716 - val_loss: 0.3490 - val_accuracy: 0.9644\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0992 - accuracy: 0.9788 - val_loss: 0.5516 - val_accuracy: 0.9197\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1115 - accuracy: 0.9763 - val_loss: 0.3215 - val_accuracy: 0.9729\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1026 - accuracy: 0.9771 - val_loss: 0.4032 - val_accuracy: 0.9492\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1157 - accuracy: 0.9730 - val_loss: 0.3635 - val_accuracy: 0.9617\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1002 - accuracy: 0.9776 - val_loss: 0.3295 - val_accuracy: 0.9683\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1015 - accuracy: 0.9781 - val_loss: 0.3377 - val_accuracy: 0.9646\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1010 - accuracy: 0.9785 - val_loss: 0.3317 - val_accuracy: 0.9705\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1057 - accuracy: 0.9744 - val_loss: 0.3794 - val_accuracy: 0.9531\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0996 - accuracy: 0.9777 - val_loss: 0.3289 - val_accuracy: 0.9690\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1037 - accuracy: 0.9770 - val_loss: 0.3758 - val_accuracy: 0.9534\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0990 - accuracy: 0.9789 - val_loss: 0.3718 - val_accuracy: 0.9575\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1016 - accuracy: 0.9770 - val_loss: 0.3247 - val_accuracy: 0.9668\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1059 - accuracy: 0.9772 - val_loss: 0.3429 - val_accuracy: 0.9659\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1035 - accuracy: 0.9753 - val_loss: 0.3584 - val_accuracy: 0.9617\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0962 - accuracy: 0.9790 - val_loss: 0.3497 - val_accuracy: 0.9679\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0992 - accuracy: 0.9766 - val_loss: 0.3352 - val_accuracy: 0.9699\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0984 - accuracy: 0.9782 - val_loss: 0.3356 - val_accuracy: 0.9685\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1031 - accuracy: 0.9771 - val_loss: 0.3279 - val_accuracy: 0.9718\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1021 - accuracy: 0.9764 - val_loss: 0.3343 - val_accuracy: 0.9677\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0900 - accuracy: 0.9803 - val_loss: 0.3254 - val_accuracy: 0.9694\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0996 - accuracy: 0.9770 - val_loss: 0.3258 - val_accuracy: 0.9699\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0880 - accuracy: 0.9819 - val_loss: 0.3478 - val_accuracy: 0.9679\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0996 - accuracy: 0.9769 - val_loss: 0.3640 - val_accuracy: 0.9611\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0961 - accuracy: 0.9782 - val_loss: 0.3403 - val_accuracy: 0.9674\n",
      "Average Validation Accuracy: 0.9789418876171112\n",
      "Average Validation Loss: 0.16024383157491684\n",
      "Average Test Accuracy: 0.9791037142276764\n",
      "Final Test Accuracy for each fold: 0.9815729260444641\n",
      "Number of input features: 11\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.7906 - accuracy: 0.2667 - val_loss: 2.6530 - val_accuracy: 0.5254\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.8175 - accuracy: 0.6632 - val_loss: 1.5045 - val_accuracy: 0.7454\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.0436 - accuracy: 0.7970 - val_loss: 1.0273 - val_accuracy: 0.8244\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6831 - accuracy: 0.8622 - val_loss: 0.7663 - val_accuracy: 0.8625\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4872 - accuracy: 0.8941 - val_loss: 0.6261 - val_accuracy: 0.8970\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3737 - accuracy: 0.9136 - val_loss: 0.6633 - val_accuracy: 0.8805\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3171 - accuracy: 0.9216 - val_loss: 0.5921 - val_accuracy: 0.8972\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2786 - accuracy: 0.9303 - val_loss: 0.4430 - val_accuracy: 0.9254\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2434 - accuracy: 0.9374 - val_loss: 0.4198 - val_accuracy: 0.9402\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2252 - accuracy: 0.9457 - val_loss: 0.4624 - val_accuracy: 0.9263\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.2089 - accuracy: 0.9492 - val_loss: 0.4348 - val_accuracy: 0.9278\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.1978 - accuracy: 0.9489 - val_loss: 0.3662 - val_accuracy: 0.9481\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1862 - accuracy: 0.9509 - val_loss: 0.3925 - val_accuracy: 0.9391\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1789 - accuracy: 0.9540 - val_loss: 0.3461 - val_accuracy: 0.9540\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1660 - accuracy: 0.9589 - val_loss: 0.3888 - val_accuracy: 0.9465\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1669 - accuracy: 0.9583 - val_loss: 0.3822 - val_accuracy: 0.9457\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1553 - accuracy: 0.9634 - val_loss: 0.3824 - val_accuracy: 0.9421\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1499 - accuracy: 0.9639 - val_loss: 0.3433 - val_accuracy: 0.9545\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1521 - accuracy: 0.9634 - val_loss: 0.3324 - val_accuracy: 0.9569\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1393 - accuracy: 0.9678 - val_loss: 0.3396 - val_accuracy: 0.9494\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1369 - accuracy: 0.9688 - val_loss: 0.3333 - val_accuracy: 0.9633\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1419 - accuracy: 0.9682 - val_loss: 0.3430 - val_accuracy: 0.9611\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1389 - accuracy: 0.9687 - val_loss: 0.3095 - val_accuracy: 0.9602\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1296 - accuracy: 0.9707 - val_loss: 0.3197 - val_accuracy: 0.9575\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1333 - accuracy: 0.9718 - val_loss: 0.3253 - val_accuracy: 0.9608\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1278 - accuracy: 0.9705 - val_loss: 0.3206 - val_accuracy: 0.9646\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1172 - accuracy: 0.9750 - val_loss: 0.3054 - val_accuracy: 0.9701\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1250 - accuracy: 0.9714 - val_loss: 0.2853 - val_accuracy: 0.9710\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1213 - accuracy: 0.9732 - val_loss: 0.2724 - val_accuracy: 0.9784\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1185 - accuracy: 0.9742 - val_loss: 0.2803 - val_accuracy: 0.9749\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1127 - accuracy: 0.9754 - val_loss: 0.2936 - val_accuracy: 0.9677\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1185 - accuracy: 0.9754 - val_loss: 0.3137 - val_accuracy: 0.9624\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1158 - accuracy: 0.9773 - val_loss: 0.3328 - val_accuracy: 0.9560\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1154 - accuracy: 0.9755 - val_loss: 0.2976 - val_accuracy: 0.9644\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1082 - accuracy: 0.9782 - val_loss: 0.2818 - val_accuracy: 0.9725\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1074 - accuracy: 0.9771 - val_loss: 0.2933 - val_accuracy: 0.9644\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1049 - accuracy: 0.9786 - val_loss: 0.2873 - val_accuracy: 0.9685\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1048 - accuracy: 0.9790 - val_loss: 0.2655 - val_accuracy: 0.9714\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1071 - accuracy: 0.9777 - val_loss: 0.3005 - val_accuracy: 0.9679\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1087 - accuracy: 0.9776 - val_loss: 0.2940 - val_accuracy: 0.9571\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0996 - accuracy: 0.9786 - val_loss: 0.2549 - val_accuracy: 0.9773\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1092 - accuracy: 0.9770 - val_loss: 0.3235 - val_accuracy: 0.9507\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1041 - accuracy: 0.9773 - val_loss: 0.2613 - val_accuracy: 0.9769\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1066 - accuracy: 0.9778 - val_loss: 0.2798 - val_accuracy: 0.9674\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0935 - accuracy: 0.9797 - val_loss: 0.2961 - val_accuracy: 0.9536\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0981 - accuracy: 0.9794 - val_loss: 0.3024 - val_accuracy: 0.9571\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1053 - accuracy: 0.9773 - val_loss: 0.2744 - val_accuracy: 0.9738\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1017 - accuracy: 0.9796 - val_loss: 0.2773 - val_accuracy: 0.9701\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0957 - accuracy: 0.9797 - val_loss: 0.2493 - val_accuracy: 0.9795\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0973 - accuracy: 0.9805 - val_loss: 0.2579 - val_accuracy: 0.9767\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0952 - accuracy: 0.9807 - val_loss: 0.2853 - val_accuracy: 0.9692\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0953 - accuracy: 0.9811 - val_loss: 0.2540 - val_accuracy: 0.9773\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0946 - accuracy: 0.9802 - val_loss: 0.2599 - val_accuracy: 0.9749\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0933 - accuracy: 0.9808 - val_loss: 0.2491 - val_accuracy: 0.9762\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0895 - accuracy: 0.9823 - val_loss: 0.2647 - val_accuracy: 0.9701\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0954 - accuracy: 0.9806 - val_loss: 0.2684 - val_accuracy: 0.9688\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0919 - accuracy: 0.9822 - val_loss: 0.2765 - val_accuracy: 0.9714\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0967 - accuracy: 0.9801 - val_loss: 0.2713 - val_accuracy: 0.9723\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0882 - accuracy: 0.9837 - val_loss: 0.2451 - val_accuracy: 0.9809\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0977 - accuracy: 0.9791 - val_loss: 0.2593 - val_accuracy: 0.9754\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0877 - accuracy: 0.9834 - val_loss: 0.2551 - val_accuracy: 0.9795\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0866 - accuracy: 0.9830 - val_loss: 0.2982 - val_accuracy: 0.9666\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0910 - accuracy: 0.9820 - val_loss: 0.2651 - val_accuracy: 0.9760\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0909 - accuracy: 0.9812 - val_loss: 0.2505 - val_accuracy: 0.9811\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9819 - val_loss: 0.2535 - val_accuracy: 0.9793\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9831 - val_loss: 0.2607 - val_accuracy: 0.9760\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0893 - accuracy: 0.9815 - val_loss: 0.2738 - val_accuracy: 0.9762\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0850 - accuracy: 0.9836 - val_loss: 0.2598 - val_accuracy: 0.9765\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0848 - accuracy: 0.9819 - val_loss: 0.2573 - val_accuracy: 0.9791\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0887 - accuracy: 0.9818 - val_loss: 0.2599 - val_accuracy: 0.9798\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0840 - accuracy: 0.9846 - val_loss: 0.2573 - val_accuracy: 0.9795\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0885 - accuracy: 0.9821 - val_loss: 0.2593 - val_accuracy: 0.9780\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0767 - accuracy: 0.9852 - val_loss: 0.2672 - val_accuracy: 0.9791\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0909 - accuracy: 0.9793 - val_loss: 0.2621 - val_accuracy: 0.9802\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9856 - val_loss: 0.3750 - val_accuracy: 0.9485\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0869 - accuracy: 0.9831 - val_loss: 0.2683 - val_accuracy: 0.9806\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0830 - accuracy: 0.9836 - val_loss: 0.2817 - val_accuracy: 0.9725\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0798 - accuracy: 0.9852 - val_loss: 0.2833 - val_accuracy: 0.9703\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0855 - accuracy: 0.9824 - val_loss: 0.2762 - val_accuracy: 0.9762\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0839 - accuracy: 0.9834 - val_loss: 0.2623 - val_accuracy: 0.9784\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 10s 5ms/step - loss: 3.4720 - accuracy: 0.3479 - val_loss: 2.2651 - val_accuracy: 0.5991\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 1.4580 - accuracy: 0.7149 - val_loss: 1.2957 - val_accuracy: 0.7868\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8027 - accuracy: 0.8216 - val_loss: 0.9134 - val_accuracy: 0.8185\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5471 - accuracy: 0.8696 - val_loss: 0.6958 - val_accuracy: 0.8779\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4266 - accuracy: 0.8911 - val_loss: 0.5897 - val_accuracy: 0.8860\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3496 - accuracy: 0.9128 - val_loss: 0.4900 - val_accuracy: 0.9151\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3064 - accuracy: 0.9207 - val_loss: 0.4508 - val_accuracy: 0.9166\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2763 - accuracy: 0.9247 - val_loss: 0.4376 - val_accuracy: 0.9135\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2398 - accuracy: 0.9353 - val_loss: 0.4190 - val_accuracy: 0.9171\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2223 - accuracy: 0.9435 - val_loss: 0.3812 - val_accuracy: 0.9281\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2216 - accuracy: 0.9418 - val_loss: 0.3286 - val_accuracy: 0.9382\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2052 - accuracy: 0.9455 - val_loss: 0.3268 - val_accuracy: 0.9397\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1879 - accuracy: 0.9507 - val_loss: 0.3402 - val_accuracy: 0.9410\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1924 - accuracy: 0.9510 - val_loss: 0.3167 - val_accuracy: 0.9417\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1738 - accuracy: 0.9549 - val_loss: 0.3174 - val_accuracy: 0.9441\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1735 - accuracy: 0.9568 - val_loss: 0.2963 - val_accuracy: 0.9527\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1661 - accuracy: 0.9564 - val_loss: 0.3916 - val_accuracy: 0.9292\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1555 - accuracy: 0.9611 - val_loss: 0.3495 - val_accuracy: 0.9375\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1585 - accuracy: 0.9588 - val_loss: 0.3207 - val_accuracy: 0.9457\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1525 - accuracy: 0.9621 - val_loss: 0.2895 - val_accuracy: 0.9496\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1463 - accuracy: 0.9630 - val_loss: 0.2972 - val_accuracy: 0.9496\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1371 - accuracy: 0.9661 - val_loss: 0.2745 - val_accuracy: 0.9547\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1419 - accuracy: 0.9649 - val_loss: 0.2887 - val_accuracy: 0.9549\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1310 - accuracy: 0.9680 - val_loss: 0.2636 - val_accuracy: 0.9633\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1328 - accuracy: 0.9673 - val_loss: 0.3053 - val_accuracy: 0.9446\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1298 - accuracy: 0.9672 - val_loss: 0.2651 - val_accuracy: 0.9569\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1265 - accuracy: 0.9706 - val_loss: 0.2651 - val_accuracy: 0.9558\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1197 - accuracy: 0.9714 - val_loss: 0.2577 - val_accuracy: 0.9639\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1292 - accuracy: 0.9681 - val_loss: 0.2522 - val_accuracy: 0.9677\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1193 - accuracy: 0.9702 - val_loss: 0.2553 - val_accuracy: 0.9646\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1118 - accuracy: 0.9752 - val_loss: 0.2725 - val_accuracy: 0.9624\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1206 - accuracy: 0.9718 - val_loss: 0.2668 - val_accuracy: 0.9547\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1207 - accuracy: 0.9701 - val_loss: 0.2826 - val_accuracy: 0.9564\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1143 - accuracy: 0.9732 - val_loss: 0.2587 - val_accuracy: 0.9619\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1104 - accuracy: 0.9750 - val_loss: 0.2392 - val_accuracy: 0.9710\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1091 - accuracy: 0.9741 - val_loss: 0.2497 - val_accuracy: 0.9721\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1109 - accuracy: 0.9753 - val_loss: 0.2541 - val_accuracy: 0.9714\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0985 - accuracy: 0.9795 - val_loss: 0.3185 - val_accuracy: 0.9518\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1125 - accuracy: 0.9739 - val_loss: 0.2461 - val_accuracy: 0.9694\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1043 - accuracy: 0.9758 - val_loss: 0.2480 - val_accuracy: 0.9701\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1042 - accuracy: 0.9762 - val_loss: 0.2684 - val_accuracy: 0.9633\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1002 - accuracy: 0.9793 - val_loss: 0.3021 - val_accuracy: 0.9450\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1093 - accuracy: 0.9742 - val_loss: 0.2309 - val_accuracy: 0.9740\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0987 - accuracy: 0.9784 - val_loss: 0.2487 - val_accuracy: 0.9644\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1046 - accuracy: 0.9770 - val_loss: 0.2573 - val_accuracy: 0.9633\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0931 - accuracy: 0.9802 - val_loss: 0.2606 - val_accuracy: 0.9639\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1004 - accuracy: 0.9778 - val_loss: 0.2850 - val_accuracy: 0.9584\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1022 - accuracy: 0.9769 - val_loss: 0.2395 - val_accuracy: 0.9703\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0933 - accuracy: 0.9796 - val_loss: 0.2452 - val_accuracy: 0.9668\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9785 - val_loss: 0.2404 - val_accuracy: 0.9723\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0924 - accuracy: 0.9806 - val_loss: 0.2244 - val_accuracy: 0.9740\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0917 - accuracy: 0.9814 - val_loss: 0.2525 - val_accuracy: 0.9718\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0922 - accuracy: 0.9800 - val_loss: 0.2607 - val_accuracy: 0.9619\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0935 - accuracy: 0.9780 - val_loss: 0.2242 - val_accuracy: 0.9760\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0911 - accuracy: 0.9806 - val_loss: 0.2396 - val_accuracy: 0.9699\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0893 - accuracy: 0.9807 - val_loss: 0.2232 - val_accuracy: 0.9745\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.9811 - val_loss: 0.2561 - val_accuracy: 0.9683\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0906 - accuracy: 0.9808 - val_loss: 0.2310 - val_accuracy: 0.9740\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0868 - accuracy: 0.9800 - val_loss: 0.2596 - val_accuracy: 0.9650\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0829 - accuracy: 0.9811 - val_loss: 0.2231 - val_accuracy: 0.9800\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9824 - val_loss: 0.2316 - val_accuracy: 0.9749\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0888 - accuracy: 0.9809 - val_loss: 0.2491 - val_accuracy: 0.9749\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9833 - val_loss: 0.2299 - val_accuracy: 0.9778\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0917 - accuracy: 0.9802 - val_loss: 0.2476 - val_accuracy: 0.9727\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0863 - accuracy: 0.9796 - val_loss: 0.2556 - val_accuracy: 0.9694\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.9809 - val_loss: 0.2688 - val_accuracy: 0.9628\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0811 - accuracy: 0.9820 - val_loss: 0.2366 - val_accuracy: 0.9760\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0878 - accuracy: 0.9809 - val_loss: 0.2273 - val_accuracy: 0.9780\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9823 - val_loss: 0.2380 - val_accuracy: 0.9740\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0814 - accuracy: 0.9832 - val_loss: 0.2532 - val_accuracy: 0.9692\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0819 - accuracy: 0.9828 - val_loss: 0.3574 - val_accuracy: 0.9316\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0812 - accuracy: 0.9834 - val_loss: 0.2665 - val_accuracy: 0.9608\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9801 - val_loss: 0.2570 - val_accuracy: 0.9694\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0781 - accuracy: 0.9843 - val_loss: 0.2380 - val_accuracy: 0.9762\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0832 - accuracy: 0.9833 - val_loss: 0.2317 - val_accuracy: 0.9789\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0764 - accuracy: 0.9842 - val_loss: 0.2521 - val_accuracy: 0.9703\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9826 - val_loss: 0.2544 - val_accuracy: 0.9692\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0784 - accuracy: 0.9842 - val_loss: 0.2446 - val_accuracy: 0.9734\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0790 - accuracy: 0.9840 - val_loss: 0.3688 - val_accuracy: 0.9428\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0764 - accuracy: 0.9845 - val_loss: 0.2290 - val_accuracy: 0.9782\n",
      "Average Validation Accuracy: 0.9843153953552246\n",
      "Average Validation Loss: 0.13172321766614914\n",
      "Average Test Accuracy: 0.9836367666721344\n",
      "Final Test Accuracy for each fold: 0.9843001365661621\n",
      "Number of input features: 12\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.5792 - accuracy: 0.3112 - val_loss: 2.3980 - val_accuracy: 0.5635\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.6140 - accuracy: 0.6954 - val_loss: 1.4032 - val_accuracy: 0.7597\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9022 - accuracy: 0.8175 - val_loss: 0.9536 - val_accuracy: 0.8400\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5867 - accuracy: 0.8719 - val_loss: 0.7681 - val_accuracy: 0.8737\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4372 - accuracy: 0.8984 - val_loss: 0.6180 - val_accuracy: 0.8873\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3471 - accuracy: 0.9142 - val_loss: 0.5315 - val_accuracy: 0.9045\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2963 - accuracy: 0.9223 - val_loss: 0.4683 - val_accuracy: 0.9153\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2580 - accuracy: 0.9338 - val_loss: 0.4454 - val_accuracy: 0.9221\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2358 - accuracy: 0.9411 - val_loss: 0.4236 - val_accuracy: 0.9261\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2108 - accuracy: 0.9456 - val_loss: 0.4201 - val_accuracy: 0.9179\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1975 - accuracy: 0.9499 - val_loss: 0.4171 - val_accuracy: 0.9285\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1853 - accuracy: 0.9523 - val_loss: 0.3526 - val_accuracy: 0.9424\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1715 - accuracy: 0.9548 - val_loss: 0.3651 - val_accuracy: 0.9441\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1665 - accuracy: 0.9577 - val_loss: 0.3311 - val_accuracy: 0.9494\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1545 - accuracy: 0.9610 - val_loss: 0.3603 - val_accuracy: 0.9421\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1524 - accuracy: 0.9621 - val_loss: 0.3129 - val_accuracy: 0.9564\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1470 - accuracy: 0.9628 - val_loss: 0.3361 - val_accuracy: 0.9399\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1415 - accuracy: 0.9654 - val_loss: 0.2966 - val_accuracy: 0.9635\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1337 - accuracy: 0.9678 - val_loss: 0.3257 - val_accuracy: 0.9501\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1348 - accuracy: 0.9678 - val_loss: 0.3191 - val_accuracy: 0.9518\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1277 - accuracy: 0.9691 - val_loss: 0.2853 - val_accuracy: 0.9626\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1218 - accuracy: 0.9713 - val_loss: 0.3316 - val_accuracy: 0.9459\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1222 - accuracy: 0.9708 - val_loss: 0.2904 - val_accuracy: 0.9633\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1198 - accuracy: 0.9729 - val_loss: 0.2823 - val_accuracy: 0.9661\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1191 - accuracy: 0.9715 - val_loss: 0.2824 - val_accuracy: 0.9670\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1154 - accuracy: 0.9727 - val_loss: 0.3005 - val_accuracy: 0.9518\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1109 - accuracy: 0.9744 - val_loss: 0.2849 - val_accuracy: 0.9600\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1084 - accuracy: 0.9763 - val_loss: 0.2767 - val_accuracy: 0.9681\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1152 - accuracy: 0.9728 - val_loss: 0.2921 - val_accuracy: 0.9635\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1096 - accuracy: 0.9742 - val_loss: 0.2592 - val_accuracy: 0.9685\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.1077 - accuracy: 0.9744 - val_loss: 0.2978 - val_accuracy: 0.9635\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1079 - accuracy: 0.9746 - val_loss: 0.3091 - val_accuracy: 0.9553\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1059 - accuracy: 0.9757 - val_loss: 0.2406 - val_accuracy: 0.9747\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0989 - accuracy: 0.9782 - val_loss: 0.3029 - val_accuracy: 0.9617\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1068 - accuracy: 0.9765 - val_loss: 0.2864 - val_accuracy: 0.9606\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0997 - accuracy: 0.9791 - val_loss: 0.2751 - val_accuracy: 0.9630\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1005 - accuracy: 0.9759 - val_loss: 0.2592 - val_accuracy: 0.9688\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0979 - accuracy: 0.9782 - val_loss: 0.2563 - val_accuracy: 0.9703\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0967 - accuracy: 0.9795 - val_loss: 0.2731 - val_accuracy: 0.9745\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0994 - accuracy: 0.9767 - val_loss: 0.2439 - val_accuracy: 0.9789\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0960 - accuracy: 0.9798 - val_loss: 0.2824 - val_accuracy: 0.9635\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0984 - accuracy: 0.9790 - val_loss: 0.2696 - val_accuracy: 0.9703\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0956 - accuracy: 0.9794 - val_loss: 0.2525 - val_accuracy: 0.9714\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0936 - accuracy: 0.9819 - val_loss: 0.2673 - val_accuracy: 0.9734\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0924 - accuracy: 0.9806 - val_loss: 0.2364 - val_accuracy: 0.9809\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0896 - accuracy: 0.9822 - val_loss: 0.2574 - val_accuracy: 0.9769\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0940 - accuracy: 0.9797 - val_loss: 0.3050 - val_accuracy: 0.9538\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0913 - accuracy: 0.9827 - val_loss: 0.2637 - val_accuracy: 0.9729\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0916 - accuracy: 0.9817 - val_loss: 0.2758 - val_accuracy: 0.9683\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0902 - accuracy: 0.9815 - val_loss: 0.2440 - val_accuracy: 0.9784\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0888 - accuracy: 0.9812 - val_loss: 0.2920 - val_accuracy: 0.9650\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0906 - accuracy: 0.9807 - val_loss: 0.2811 - val_accuracy: 0.9663\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0936 - accuracy: 0.9794 - val_loss: 0.2541 - val_accuracy: 0.9773\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9814 - val_loss: 0.2474 - val_accuracy: 0.9784\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0841 - accuracy: 0.9827 - val_loss: 0.2649 - val_accuracy: 0.9749\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0903 - accuracy: 0.9805 - val_loss: 0.2773 - val_accuracy: 0.9701\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0914 - accuracy: 0.9805 - val_loss: 0.2493 - val_accuracy: 0.9815\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9840 - val_loss: 0.2820 - val_accuracy: 0.9714\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0866 - accuracy: 0.9804 - val_loss: 0.2802 - val_accuracy: 0.9683\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0858 - accuracy: 0.9815 - val_loss: 0.2556 - val_accuracy: 0.9791\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0845 - accuracy: 0.9829 - val_loss: 0.2516 - val_accuracy: 0.9749\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0809 - accuracy: 0.9839 - val_loss: 0.2881 - val_accuracy: 0.9705\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0874 - accuracy: 0.9814 - val_loss: 0.2693 - val_accuracy: 0.9765\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0775 - accuracy: 0.9848 - val_loss: 0.2555 - val_accuracy: 0.9791\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0849 - accuracy: 0.9814 - val_loss: 0.2535 - val_accuracy: 0.9769\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9834 - val_loss: 0.3032 - val_accuracy: 0.9672\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0830 - accuracy: 0.9825 - val_loss: 0.2584 - val_accuracy: 0.9747\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0832 - accuracy: 0.9835 - val_loss: 0.2506 - val_accuracy: 0.9824\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0770 - accuracy: 0.9848 - val_loss: 0.2905 - val_accuracy: 0.9652\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9828 - val_loss: 0.3258 - val_accuracy: 0.9597\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0874 - accuracy: 0.9822 - val_loss: 0.2796 - val_accuracy: 0.9690\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0709 - accuracy: 0.9865 - val_loss: 0.2475 - val_accuracy: 0.9795\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9821 - val_loss: 0.2830 - val_accuracy: 0.9751\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0765 - accuracy: 0.9835 - val_loss: 0.2533 - val_accuracy: 0.9773\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0804 - accuracy: 0.9840 - val_loss: 0.2883 - val_accuracy: 0.9705\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0790 - accuracy: 0.9840 - val_loss: 0.2739 - val_accuracy: 0.9791\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0808 - accuracy: 0.9848 - val_loss: 0.2600 - val_accuracy: 0.9813\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9825 - val_loss: 0.2792 - val_accuracy: 0.9716\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9835 - val_loss: 0.2599 - val_accuracy: 0.9747\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0761 - accuracy: 0.9835 - val_loss: 0.2552 - val_accuracy: 0.9809\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.5265 - accuracy: 0.3330 - val_loss: 2.2034 - val_accuracy: 0.6348\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.3822 - accuracy: 0.7441 - val_loss: 1.2395 - val_accuracy: 0.7927\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7447 - accuracy: 0.8421 - val_loss: 0.8706 - val_accuracy: 0.8680\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5000 - accuracy: 0.8875 - val_loss: 0.6506 - val_accuracy: 0.8946\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3785 - accuracy: 0.9068 - val_loss: 0.5575 - val_accuracy: 0.9120\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3096 - accuracy: 0.9228 - val_loss: 0.4878 - val_accuracy: 0.9091\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2805 - accuracy: 0.9275 - val_loss: 0.4593 - val_accuracy: 0.9230\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2419 - accuracy: 0.9380 - val_loss: 0.4019 - val_accuracy: 0.9270\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2214 - accuracy: 0.9394 - val_loss: 0.3849 - val_accuracy: 0.9369\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2043 - accuracy: 0.9462 - val_loss: 0.3478 - val_accuracy: 0.9426\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1920 - accuracy: 0.9492 - val_loss: 0.3643 - val_accuracy: 0.9377\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1815 - accuracy: 0.9533 - val_loss: 0.3007 - val_accuracy: 0.9534\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1771 - accuracy: 0.9543 - val_loss: 0.3298 - val_accuracy: 0.9415\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1684 - accuracy: 0.9591 - val_loss: 0.3049 - val_accuracy: 0.9564\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1629 - accuracy: 0.9601 - val_loss: 0.2895 - val_accuracy: 0.9591\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1543 - accuracy: 0.9616 - val_loss: 0.2872 - val_accuracy: 0.9485\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1448 - accuracy: 0.9659 - val_loss: 0.3441 - val_accuracy: 0.9419\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1436 - accuracy: 0.9656 - val_loss: 0.2657 - val_accuracy: 0.9606\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1439 - accuracy: 0.9645 - val_loss: 0.2900 - val_accuracy: 0.9600\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1350 - accuracy: 0.9664 - val_loss: 0.2894 - val_accuracy: 0.9534\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1382 - accuracy: 0.9649 - val_loss: 0.2750 - val_accuracy: 0.9562\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1343 - accuracy: 0.9664 - val_loss: 0.2749 - val_accuracy: 0.9547\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1238 - accuracy: 0.9705 - val_loss: 0.2559 - val_accuracy: 0.9593\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1234 - accuracy: 0.9705 - val_loss: 0.2484 - val_accuracy: 0.9655\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1226 - accuracy: 0.9712 - val_loss: 0.2541 - val_accuracy: 0.9628\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1198 - accuracy: 0.9711 - val_loss: 0.2872 - val_accuracy: 0.9593\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1189 - accuracy: 0.9716 - val_loss: 0.2744 - val_accuracy: 0.9626\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1201 - accuracy: 0.9717 - val_loss: 0.2521 - val_accuracy: 0.9681\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1138 - accuracy: 0.9739 - val_loss: 0.2472 - val_accuracy: 0.9677\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1093 - accuracy: 0.9747 - val_loss: 0.3022 - val_accuracy: 0.9496\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1154 - accuracy: 0.9732 - val_loss: 0.2493 - val_accuracy: 0.9670\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1058 - accuracy: 0.9770 - val_loss: 0.2478 - val_accuracy: 0.9703\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1082 - accuracy: 0.9746 - val_loss: 0.2835 - val_accuracy: 0.9628\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1084 - accuracy: 0.9739 - val_loss: 0.2849 - val_accuracy: 0.9527\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1076 - accuracy: 0.9758 - val_loss: 0.2615 - val_accuracy: 0.9657\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1074 - accuracy: 0.9762 - val_loss: 0.2470 - val_accuracy: 0.9683\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1058 - accuracy: 0.9763 - val_loss: 0.2677 - val_accuracy: 0.9652\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0979 - accuracy: 0.9786 - val_loss: 0.2390 - val_accuracy: 0.9729\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1036 - accuracy: 0.9772 - val_loss: 0.2693 - val_accuracy: 0.9602\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1028 - accuracy: 0.9780 - val_loss: 0.2482 - val_accuracy: 0.9721\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1000 - accuracy: 0.9777 - val_loss: 0.2667 - val_accuracy: 0.9611\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0987 - accuracy: 0.9773 - val_loss: 0.2416 - val_accuracy: 0.9699\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0967 - accuracy: 0.9784 - val_loss: 0.2457 - val_accuracy: 0.9685\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0977 - accuracy: 0.9780 - val_loss: 0.2400 - val_accuracy: 0.9683\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9778 - val_loss: 0.2442 - val_accuracy: 0.9663\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0984 - accuracy: 0.9783 - val_loss: 0.2419 - val_accuracy: 0.9703\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9817 - val_loss: 0.2433 - val_accuracy: 0.9740\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0898 - accuracy: 0.9819 - val_loss: 0.2732 - val_accuracy: 0.9630\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0951 - accuracy: 0.9793 - val_loss: 0.2661 - val_accuracy: 0.9690\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0943 - accuracy: 0.9797 - val_loss: 0.2514 - val_accuracy: 0.9727\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0909 - accuracy: 0.9806 - val_loss: 0.2339 - val_accuracy: 0.9751\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0913 - accuracy: 0.9788 - val_loss: 0.2424 - val_accuracy: 0.9707\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0934 - accuracy: 0.9803 - val_loss: 0.2674 - val_accuracy: 0.9641\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0827 - accuracy: 0.9830 - val_loss: 0.2300 - val_accuracy: 0.9738\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0867 - accuracy: 0.9814 - val_loss: 0.2374 - val_accuracy: 0.9767\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9814 - val_loss: 0.2303 - val_accuracy: 0.9765\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9804 - val_loss: 0.2666 - val_accuracy: 0.9650\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0840 - accuracy: 0.9820 - val_loss: 0.2650 - val_accuracy: 0.9672\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0845 - accuracy: 0.9815 - val_loss: 0.2197 - val_accuracy: 0.9802\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0811 - accuracy: 0.9827 - val_loss: 0.2607 - val_accuracy: 0.9712\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0903 - accuracy: 0.9808 - val_loss: 0.2834 - val_accuracy: 0.9604\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0865 - accuracy: 0.9819 - val_loss: 0.2684 - val_accuracy: 0.9690\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0824 - accuracy: 0.9821 - val_loss: 0.2298 - val_accuracy: 0.9769\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0802 - accuracy: 0.9828 - val_loss: 0.2202 - val_accuracy: 0.9787\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0828 - accuracy: 0.9819 - val_loss: 0.2327 - val_accuracy: 0.9745\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9831 - val_loss: 0.2279 - val_accuracy: 0.9732\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0834 - accuracy: 0.9815 - val_loss: 0.2428 - val_accuracy: 0.9718\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0809 - accuracy: 0.9817 - val_loss: 0.2389 - val_accuracy: 0.9740\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9827 - val_loss: 0.2381 - val_accuracy: 0.9782\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0835 - accuracy: 0.9813 - val_loss: 0.2372 - val_accuracy: 0.9745\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9849 - val_loss: 0.2388 - val_accuracy: 0.9767\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0776 - accuracy: 0.9836 - val_loss: 0.2254 - val_accuracy: 0.9787\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0754 - accuracy: 0.9854 - val_loss: 0.2278 - val_accuracy: 0.9736\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0824 - accuracy: 0.9827 - val_loss: 0.2244 - val_accuracy: 0.9784\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0777 - accuracy: 0.9834 - val_loss: 0.2241 - val_accuracy: 0.9798\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0841 - accuracy: 0.9829 - val_loss: 0.2477 - val_accuracy: 0.9707\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0772 - accuracy: 0.9837 - val_loss: 0.2512 - val_accuracy: 0.9661\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0737 - accuracy: 0.9841 - val_loss: 0.2364 - val_accuracy: 0.9747\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0810 - accuracy: 0.9832 - val_loss: 0.2619 - val_accuracy: 0.9670\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0765 - accuracy: 0.9831 - val_loss: 0.2050 - val_accuracy: 0.9824\n",
      "Average Validation Accuracy: 0.9865301847457886\n",
      "Average Validation Loss: 0.12170714884996414\n",
      "Average Test Accuracy: 0.9866219758987427\n",
      "Final Test Accuracy for each fold: 0.986732542514801\n",
      "Number of input features: 13\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.4842 - accuracy: 0.3530 - val_loss: 2.2422 - val_accuracy: 0.6438\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.4622 - accuracy: 0.7427 - val_loss: 1.2967 - val_accuracy: 0.7919\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8291 - accuracy: 0.8372 - val_loss: 0.8894 - val_accuracy: 0.8568\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5389 - accuracy: 0.8801 - val_loss: 0.6804 - val_accuracy: 0.8904\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3967 - accuracy: 0.9074 - val_loss: 0.5874 - val_accuracy: 0.8898\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3261 - accuracy: 0.9184 - val_loss: 0.5111 - val_accuracy: 0.9122\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2802 - accuracy: 0.9308 - val_loss: 0.4600 - val_accuracy: 0.9210\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2482 - accuracy: 0.9367 - val_loss: 0.4375 - val_accuracy: 0.9272\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2225 - accuracy: 0.9403 - val_loss: 0.4193 - val_accuracy: 0.9276\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2045 - accuracy: 0.9461 - val_loss: 0.3523 - val_accuracy: 0.9481\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1919 - accuracy: 0.9466 - val_loss: 0.4102 - val_accuracy: 0.9296\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1773 - accuracy: 0.9520 - val_loss: 0.3287 - val_accuracy: 0.9558\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1669 - accuracy: 0.9565 - val_loss: 0.3445 - val_accuracy: 0.9461\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1619 - accuracy: 0.9581 - val_loss: 0.3441 - val_accuracy: 0.9549\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1478 - accuracy: 0.9609 - val_loss: 0.3369 - val_accuracy: 0.9435\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1483 - accuracy: 0.9614 - val_loss: 0.2953 - val_accuracy: 0.9639\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1377 - accuracy: 0.9641 - val_loss: 0.3224 - val_accuracy: 0.9562\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1406 - accuracy: 0.9627 - val_loss: 0.3054 - val_accuracy: 0.9628\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1299 - accuracy: 0.9674 - val_loss: 0.2843 - val_accuracy: 0.9712\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1310 - accuracy: 0.9660 - val_loss: 0.2866 - val_accuracy: 0.9692\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1268 - accuracy: 0.9687 - val_loss: 0.2843 - val_accuracy: 0.9699\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1207 - accuracy: 0.9699 - val_loss: 0.3071 - val_accuracy: 0.9586\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1226 - accuracy: 0.9702 - val_loss: 0.3046 - val_accuracy: 0.9578\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1156 - accuracy: 0.9714 - val_loss: 0.2985 - val_accuracy: 0.9613\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1175 - accuracy: 0.9701 - val_loss: 0.2675 - val_accuracy: 0.9738\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1125 - accuracy: 0.9738 - val_loss: 0.3365 - val_accuracy: 0.9501\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1153 - accuracy: 0.9713 - val_loss: 0.2602 - val_accuracy: 0.9721\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1087 - accuracy: 0.9747 - val_loss: 0.2543 - val_accuracy: 0.9793\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1136 - accuracy: 0.9707 - val_loss: 0.2777 - val_accuracy: 0.9674\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1101 - accuracy: 0.9723 - val_loss: 0.2687 - val_accuracy: 0.9699\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1049 - accuracy: 0.9750 - val_loss: 0.2545 - val_accuracy: 0.9749\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1089 - accuracy: 0.9732 - val_loss: 0.2514 - val_accuracy: 0.9762\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1020 - accuracy: 0.9773 - val_loss: 0.2565 - val_accuracy: 0.9745\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0950 - accuracy: 0.9790 - val_loss: 0.2678 - val_accuracy: 0.9690\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0953 - accuracy: 0.9785 - val_loss: 0.2689 - val_accuracy: 0.9657\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1026 - accuracy: 0.9779 - val_loss: 0.2765 - val_accuracy: 0.9606\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0981 - accuracy: 0.9765 - val_loss: 0.2588 - val_accuracy: 0.9633\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0921 - accuracy: 0.9795 - val_loss: 0.2591 - val_accuracy: 0.9710\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0939 - accuracy: 0.9789 - val_loss: 0.2873 - val_accuracy: 0.9624\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0961 - accuracy: 0.9795 - val_loss: 0.2328 - val_accuracy: 0.9740\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0908 - accuracy: 0.9794 - val_loss: 0.2423 - val_accuracy: 0.9760\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0915 - accuracy: 0.9804 - val_loss: 0.2373 - val_accuracy: 0.9773\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9802 - val_loss: 0.2408 - val_accuracy: 0.9756\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0896 - accuracy: 0.9811 - val_loss: 0.2526 - val_accuracy: 0.9747\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0883 - accuracy: 0.9804 - val_loss: 0.2466 - val_accuracy: 0.9738\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0888 - accuracy: 0.9797 - val_loss: 0.2562 - val_accuracy: 0.9688\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0870 - accuracy: 0.9799 - val_loss: 0.2338 - val_accuracy: 0.9769\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0885 - accuracy: 0.9799 - val_loss: 0.2387 - val_accuracy: 0.9773\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0841 - accuracy: 0.9840 - val_loss: 0.2716 - val_accuracy: 0.9685\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9790 - val_loss: 0.2294 - val_accuracy: 0.9817\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0846 - accuracy: 0.9824 - val_loss: 0.2338 - val_accuracy: 0.9780\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0933 - accuracy: 0.9794 - val_loss: 0.2624 - val_accuracy: 0.9716\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0791 - accuracy: 0.9839 - val_loss: 0.2747 - val_accuracy: 0.9661\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0856 - accuracy: 0.9821 - val_loss: 0.2295 - val_accuracy: 0.9776\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0920 - accuracy: 0.9804 - val_loss: 0.2336 - val_accuracy: 0.9760\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9821 - val_loss: 0.2553 - val_accuracy: 0.9707\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0838 - accuracy: 0.9819 - val_loss: 0.2448 - val_accuracy: 0.9754\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9822 - val_loss: 0.2564 - val_accuracy: 0.9655\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9811 - val_loss: 0.2446 - val_accuracy: 0.9754\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0816 - accuracy: 0.9823 - val_loss: 0.2402 - val_accuracy: 0.9795\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0832 - accuracy: 0.9807 - val_loss: 0.2724 - val_accuracy: 0.9659\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0778 - accuracy: 0.9824 - val_loss: 0.2427 - val_accuracy: 0.9784\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9848 - val_loss: 0.2329 - val_accuracy: 0.9802\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0789 - accuracy: 0.9841 - val_loss: 0.2241 - val_accuracy: 0.9831\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0808 - accuracy: 0.9821 - val_loss: 0.2449 - val_accuracy: 0.9758\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0824 - accuracy: 0.9819 - val_loss: 0.2577 - val_accuracy: 0.9716\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9852 - val_loss: 0.2254 - val_accuracy: 0.9835\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9841 - val_loss: 0.2466 - val_accuracy: 0.9789\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0751 - accuracy: 0.9839 - val_loss: 0.2747 - val_accuracy: 0.9727\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9856 - val_loss: 0.2375 - val_accuracy: 0.9771\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0800 - accuracy: 0.9832 - val_loss: 0.2390 - val_accuracy: 0.9811\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0783 - accuracy: 0.9841 - val_loss: 0.2372 - val_accuracy: 0.9828\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0715 - accuracy: 0.9853 - val_loss: 0.2364 - val_accuracy: 0.9798\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0739 - accuracy: 0.9850 - val_loss: 0.2479 - val_accuracy: 0.9743\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9842 - val_loss: 0.2584 - val_accuracy: 0.9710\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0722 - accuracy: 0.9855 - val_loss: 0.2500 - val_accuracy: 0.9771\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0778 - accuracy: 0.9835 - val_loss: 0.2463 - val_accuracy: 0.9729\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0725 - accuracy: 0.9858 - val_loss: 0.2288 - val_accuracy: 0.9831\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9837 - val_loss: 0.2831 - val_accuracy: 0.9707\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0708 - accuracy: 0.9852 - val_loss: 0.2404 - val_accuracy: 0.9791\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.4506 - accuracy: 0.3459 - val_loss: 2.3018 - val_accuracy: 0.5866\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.4797 - accuracy: 0.7239 - val_loss: 1.3701 - val_accuracy: 0.7795\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8171 - accuracy: 0.8459 - val_loss: 0.9653 - val_accuracy: 0.8620\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5220 - accuracy: 0.8922 - val_loss: 0.7464 - val_accuracy: 0.8832\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3748 - accuracy: 0.9175 - val_loss: 0.6096 - val_accuracy: 0.9201\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2955 - accuracy: 0.9301 - val_loss: 0.5276 - val_accuracy: 0.9195\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2499 - accuracy: 0.9402 - val_loss: 0.4568 - val_accuracy: 0.9303\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2205 - accuracy: 0.9466 - val_loss: 0.3772 - val_accuracy: 0.9465\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1918 - accuracy: 0.9533 - val_loss: 0.3943 - val_accuracy: 0.9261\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1761 - accuracy: 0.9557 - val_loss: 0.3832 - val_accuracy: 0.9448\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1648 - accuracy: 0.9596 - val_loss: 0.3505 - val_accuracy: 0.9512\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1625 - accuracy: 0.9587 - val_loss: 0.3455 - val_accuracy: 0.9490\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1461 - accuracy: 0.9636 - val_loss: 0.3361 - val_accuracy: 0.9505\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1425 - accuracy: 0.9650 - val_loss: 0.3312 - val_accuracy: 0.9490\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1338 - accuracy: 0.9676 - val_loss: 0.2914 - val_accuracy: 0.9635\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1332 - accuracy: 0.9680 - val_loss: 0.3030 - val_accuracy: 0.9564\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1259 - accuracy: 0.9714 - val_loss: 0.3051 - val_accuracy: 0.9604\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1293 - accuracy: 0.9707 - val_loss: 0.2751 - val_accuracy: 0.9683\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1133 - accuracy: 0.9741 - val_loss: 0.2950 - val_accuracy: 0.9580\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1188 - accuracy: 0.9727 - val_loss: 0.2706 - val_accuracy: 0.9637\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1164 - accuracy: 0.9734 - val_loss: 0.2701 - val_accuracy: 0.9615\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1112 - accuracy: 0.9763 - val_loss: 0.3114 - val_accuracy: 0.9562\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1103 - accuracy: 0.9742 - val_loss: 0.3834 - val_accuracy: 0.9338\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1145 - accuracy: 0.9741 - val_loss: 0.2855 - val_accuracy: 0.9549\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1034 - accuracy: 0.9790 - val_loss: 0.2633 - val_accuracy: 0.9677\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1068 - accuracy: 0.9766 - val_loss: 0.2666 - val_accuracy: 0.9626\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1067 - accuracy: 0.9759 - val_loss: 0.2490 - val_accuracy: 0.9707\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0984 - accuracy: 0.9779 - val_loss: 0.2534 - val_accuracy: 0.9696\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0985 - accuracy: 0.9802 - val_loss: 0.4222 - val_accuracy: 0.9470\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0977 - accuracy: 0.9800 - val_loss: 0.2485 - val_accuracy: 0.9701\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1066 - accuracy: 0.9765 - val_loss: 0.2425 - val_accuracy: 0.9734\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0938 - accuracy: 0.9795 - val_loss: 0.2639 - val_accuracy: 0.9701\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0978 - accuracy: 0.9777 - val_loss: 0.2623 - val_accuracy: 0.9672\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0987 - accuracy: 0.9781 - val_loss: 0.2862 - val_accuracy: 0.9646\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0947 - accuracy: 0.9794 - val_loss: 0.3033 - val_accuracy: 0.9514\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0925 - accuracy: 0.9805 - val_loss: 0.2452 - val_accuracy: 0.9743\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0975 - accuracy: 0.9791 - val_loss: 0.2471 - val_accuracy: 0.9725\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0930 - accuracy: 0.9797 - val_loss: 0.2260 - val_accuracy: 0.9806\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0888 - accuracy: 0.9805 - val_loss: 0.2537 - val_accuracy: 0.9694\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0956 - accuracy: 0.9810 - val_loss: 0.2491 - val_accuracy: 0.9756\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0830 - accuracy: 0.9829 - val_loss: 0.2653 - val_accuracy: 0.9657\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0877 - accuracy: 0.9818 - val_loss: 0.2463 - val_accuracy: 0.9732\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0859 - accuracy: 0.9834 - val_loss: 0.2731 - val_accuracy: 0.9663\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9826 - val_loss: 0.2377 - val_accuracy: 0.9806\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0886 - accuracy: 0.9810 - val_loss: 0.2499 - val_accuracy: 0.9734\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0857 - accuracy: 0.9823 - val_loss: 0.2635 - val_accuracy: 0.9723\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9800 - val_loss: 0.2511 - val_accuracy: 0.9782\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0838 - accuracy: 0.9815 - val_loss: 0.2558 - val_accuracy: 0.9729\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0820 - accuracy: 0.9833 - val_loss: 0.2964 - val_accuracy: 0.9644\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0845 - accuracy: 0.9824 - val_loss: 0.2431 - val_accuracy: 0.9740\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0820 - accuracy: 0.9828 - val_loss: 0.2440 - val_accuracy: 0.9789\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0810 - accuracy: 0.9839 - val_loss: 0.2723 - val_accuracy: 0.9659\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0826 - accuracy: 0.9842 - val_loss: 0.2764 - val_accuracy: 0.9668\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9809 - val_loss: 0.2406 - val_accuracy: 0.9787\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0780 - accuracy: 0.9842 - val_loss: 0.2434 - val_accuracy: 0.9727\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0870 - accuracy: 0.9827 - val_loss: 0.2394 - val_accuracy: 0.9782\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9858 - val_loss: 0.2630 - val_accuracy: 0.9756\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0847 - accuracy: 0.9826 - val_loss: 0.2621 - val_accuracy: 0.9751\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9833 - val_loss: 0.2489 - val_accuracy: 0.9703\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9845 - val_loss: 0.2364 - val_accuracy: 0.9784\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0800 - accuracy: 0.9835 - val_loss: 0.2471 - val_accuracy: 0.9769\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0806 - accuracy: 0.9847 - val_loss: 0.2617 - val_accuracy: 0.9718\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0734 - accuracy: 0.9850 - val_loss: 0.2639 - val_accuracy: 0.9694\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9831 - val_loss: 0.2418 - val_accuracy: 0.9780\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0709 - accuracy: 0.9869 - val_loss: 0.2521 - val_accuracy: 0.9721\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0782 - accuracy: 0.9834 - val_loss: 0.2400 - val_accuracy: 0.9824\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0759 - accuracy: 0.9850 - val_loss: 0.2369 - val_accuracy: 0.9806\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0774 - accuracy: 0.9841 - val_loss: 0.2549 - val_accuracy: 0.9718\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0680 - accuracy: 0.9883 - val_loss: 0.3161 - val_accuracy: 0.9542\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0764 - accuracy: 0.9856 - val_loss: 0.2586 - val_accuracy: 0.9716\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0794 - accuracy: 0.9843 - val_loss: 0.2285 - val_accuracy: 0.9837\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0754 - accuracy: 0.9852 - val_loss: 0.2362 - val_accuracy: 0.9778\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0702 - accuracy: 0.9860 - val_loss: 0.2537 - val_accuracy: 0.9732\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9846 - val_loss: 0.2279 - val_accuracy: 0.9824\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0745 - accuracy: 0.9860 - val_loss: 0.2224 - val_accuracy: 0.9824\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0699 - accuracy: 0.9867 - val_loss: 0.2526 - val_accuracy: 0.9743\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0727 - accuracy: 0.9853 - val_loss: 0.2350 - val_accuracy: 0.9771\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0715 - accuracy: 0.9849 - val_loss: 0.2266 - val_accuracy: 0.9828\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0764 - accuracy: 0.9837 - val_loss: 0.2299 - val_accuracy: 0.9831\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0714 - accuracy: 0.9849 - val_loss: 0.4884 - val_accuracy: 0.9116\n",
      "Average Validation Accuracy: 0.9534535109996796\n",
      "Average Validation Loss: 0.24053094163537025\n",
      "Average Test Accuracy: 0.9522370398044586\n",
      "Final Test Accuracy for each fold: 0.9835630655288696\n",
      "Number of input features: 14\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.4079 - accuracy: 0.3693 - val_loss: 2.1367 - val_accuracy: 0.6572\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.4201 - accuracy: 0.7336 - val_loss: 1.2512 - val_accuracy: 0.7848\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8242 - accuracy: 0.8374 - val_loss: 0.8680 - val_accuracy: 0.8453\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5398 - accuracy: 0.8837 - val_loss: 0.6958 - val_accuracy: 0.8814\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4041 - accuracy: 0.9042 - val_loss: 0.6490 - val_accuracy: 0.8895\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3200 - accuracy: 0.9248 - val_loss: 0.5074 - val_accuracy: 0.9129\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2720 - accuracy: 0.9333 - val_loss: 0.5298 - val_accuracy: 0.8983\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2336 - accuracy: 0.9417 - val_loss: 0.4654 - val_accuracy: 0.9076\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2037 - accuracy: 0.9494 - val_loss: 0.4108 - val_accuracy: 0.9287\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1919 - accuracy: 0.9520 - val_loss: 0.3549 - val_accuracy: 0.9468\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1770 - accuracy: 0.9566 - val_loss: 0.3184 - val_accuracy: 0.9479\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1603 - accuracy: 0.9598 - val_loss: 0.3139 - val_accuracy: 0.9538\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1583 - accuracy: 0.9585 - val_loss: 0.3452 - val_accuracy: 0.9450\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1409 - accuracy: 0.9647 - val_loss: 0.2984 - val_accuracy: 0.9575\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1445 - accuracy: 0.9630 - val_loss: 0.2764 - val_accuracy: 0.9672\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1346 - accuracy: 0.9673 - val_loss: 0.2801 - val_accuracy: 0.9619\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1330 - accuracy: 0.9691 - val_loss: 0.3344 - val_accuracy: 0.9448\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1274 - accuracy: 0.9687 - val_loss: 0.3701 - val_accuracy: 0.9219\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1247 - accuracy: 0.9701 - val_loss: 0.2621 - val_accuracy: 0.9683\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1163 - accuracy: 0.9711 - val_loss: 0.2824 - val_accuracy: 0.9630\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1174 - accuracy: 0.9738 - val_loss: 0.2632 - val_accuracy: 0.9635\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1191 - accuracy: 0.9698 - val_loss: 0.2717 - val_accuracy: 0.9604\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1111 - accuracy: 0.9749 - val_loss: 0.2612 - val_accuracy: 0.9652\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1106 - accuracy: 0.9727 - val_loss: 0.2728 - val_accuracy: 0.9650\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1118 - accuracy: 0.9740 - val_loss: 0.2539 - val_accuracy: 0.9652\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1119 - accuracy: 0.9752 - val_loss: 0.2396 - val_accuracy: 0.9718\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0996 - accuracy: 0.9771 - val_loss: 0.2634 - val_accuracy: 0.9674\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1112 - accuracy: 0.9743 - val_loss: 0.2246 - val_accuracy: 0.9756\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1021 - accuracy: 0.9768 - val_loss: 0.2423 - val_accuracy: 0.9747\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1003 - accuracy: 0.9777 - val_loss: 0.2562 - val_accuracy: 0.9617\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0943 - accuracy: 0.9802 - val_loss: 0.2270 - val_accuracy: 0.9734\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1069 - accuracy: 0.9753 - val_loss: 0.2188 - val_accuracy: 0.9732\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0952 - accuracy: 0.9804 - val_loss: 0.2461 - val_accuracy: 0.9622\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1011 - accuracy: 0.9770 - val_loss: 0.2238 - val_accuracy: 0.9727\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0961 - accuracy: 0.9794 - val_loss: 0.3121 - val_accuracy: 0.9461\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1039 - accuracy: 0.9763 - val_loss: 0.2070 - val_accuracy: 0.9780\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9812 - val_loss: 0.2394 - val_accuracy: 0.9622\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0973 - accuracy: 0.9792 - val_loss: 0.2305 - val_accuracy: 0.9639\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0905 - accuracy: 0.9804 - val_loss: 0.2002 - val_accuracy: 0.9758\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0887 - accuracy: 0.9814 - val_loss: 0.2004 - val_accuracy: 0.9767\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0944 - accuracy: 0.9807 - val_loss: 0.1952 - val_accuracy: 0.9749\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0916 - accuracy: 0.9797 - val_loss: 0.1901 - val_accuracy: 0.9771\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0869 - accuracy: 0.9811 - val_loss: 0.2234 - val_accuracy: 0.9692\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0853 - accuracy: 0.9830 - val_loss: 0.1911 - val_accuracy: 0.9765\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0894 - accuracy: 0.9810 - val_loss: 0.2201 - val_accuracy: 0.9692\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0830 - accuracy: 0.9841 - val_loss: 0.2178 - val_accuracy: 0.9701\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0905 - accuracy: 0.9815 - val_loss: 0.1926 - val_accuracy: 0.9749\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.9815 - val_loss: 0.1884 - val_accuracy: 0.9767\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0820 - accuracy: 0.9835 - val_loss: 0.1894 - val_accuracy: 0.9747\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0831 - accuracy: 0.9831 - val_loss: 0.2173 - val_accuracy: 0.9661\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0897 - accuracy: 0.9808 - val_loss: 0.1811 - val_accuracy: 0.9809\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0841 - accuracy: 0.9828 - val_loss: 0.2077 - val_accuracy: 0.9668\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9833 - val_loss: 0.2105 - val_accuracy: 0.9696\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0806 - accuracy: 0.9840 - val_loss: 0.1935 - val_accuracy: 0.9740\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0886 - accuracy: 0.9832 - val_loss: 0.1952 - val_accuracy: 0.9734\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9840 - val_loss: 0.1870 - val_accuracy: 0.9769\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9834 - val_loss: 0.2116 - val_accuracy: 0.9663\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0798 - accuracy: 0.9835 - val_loss: 0.2104 - val_accuracy: 0.9699\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0770 - accuracy: 0.9856 - val_loss: 0.2093 - val_accuracy: 0.9710\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0849 - accuracy: 0.9805 - val_loss: 0.1785 - val_accuracy: 0.9791\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0772 - accuracy: 0.9843 - val_loss: 0.1931 - val_accuracy: 0.9762\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0798 - accuracy: 0.9818 - val_loss: 0.2293 - val_accuracy: 0.9659\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9856 - val_loss: 0.1930 - val_accuracy: 0.9778\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0754 - accuracy: 0.9839 - val_loss: 0.1934 - val_accuracy: 0.9780\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0825 - accuracy: 0.9830 - val_loss: 0.2158 - val_accuracy: 0.9677\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0729 - accuracy: 0.9858 - val_loss: 0.1997 - val_accuracy: 0.9738\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9841 - val_loss: 0.1784 - val_accuracy: 0.9811\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0744 - accuracy: 0.9857 - val_loss: 0.2029 - val_accuracy: 0.9776\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9853 - val_loss: 0.2153 - val_accuracy: 0.9677\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0713 - accuracy: 0.9865 - val_loss: 0.1785 - val_accuracy: 0.9804\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0788 - accuracy: 0.9840 - val_loss: 0.1770 - val_accuracy: 0.9798\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0811 - accuracy: 0.9834 - val_loss: 0.1735 - val_accuracy: 0.9837\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0694 - accuracy: 0.9857 - val_loss: 0.1899 - val_accuracy: 0.9776\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0751 - accuracy: 0.9839 - val_loss: 0.2107 - val_accuracy: 0.9714\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9854 - val_loss: 0.1988 - val_accuracy: 0.9714\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0808 - accuracy: 0.9835 - val_loss: 0.1741 - val_accuracy: 0.9824\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0736 - accuracy: 0.9843 - val_loss: 0.1960 - val_accuracy: 0.9758\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0692 - accuracy: 0.9859 - val_loss: 0.1796 - val_accuracy: 0.9844\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0714 - accuracy: 0.9854 - val_loss: 0.1892 - val_accuracy: 0.9806\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0719 - accuracy: 0.9859 - val_loss: 0.1876 - val_accuracy: 0.9787\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.7672 - accuracy: 0.2781 - val_loss: 2.5507 - val_accuracy: 0.5556\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.6831 - accuracy: 0.6912 - val_loss: 1.4543 - val_accuracy: 0.7520\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9702 - accuracy: 0.8101 - val_loss: 1.0776 - val_accuracy: 0.8255\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6477 - accuracy: 0.8665 - val_loss: 0.8592 - val_accuracy: 0.8726\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4663 - accuracy: 0.8989 - val_loss: 0.6747 - val_accuracy: 0.9023\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3604 - accuracy: 0.9189 - val_loss: 0.6447 - val_accuracy: 0.8942\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2940 - accuracy: 0.9344 - val_loss: 0.5403 - val_accuracy: 0.9287\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2494 - accuracy: 0.9434 - val_loss: 0.4895 - val_accuracy: 0.9318\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2167 - accuracy: 0.9485 - val_loss: 0.4361 - val_accuracy: 0.9388\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1989 - accuracy: 0.9526 - val_loss: 0.4234 - val_accuracy: 0.9358\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1759 - accuracy: 0.9591 - val_loss: 0.4361 - val_accuracy: 0.9439\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1695 - accuracy: 0.9602 - val_loss: 0.3899 - val_accuracy: 0.9465\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1538 - accuracy: 0.9625 - val_loss: 0.3595 - val_accuracy: 0.9501\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1547 - accuracy: 0.9627 - val_loss: 0.3450 - val_accuracy: 0.9573\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1411 - accuracy: 0.9662 - val_loss: 0.3802 - val_accuracy: 0.9476\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1404 - accuracy: 0.9652 - val_loss: 0.3494 - val_accuracy: 0.9549\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1321 - accuracy: 0.9694 - val_loss: 0.3295 - val_accuracy: 0.9611\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1278 - accuracy: 0.9710 - val_loss: 0.3899 - val_accuracy: 0.9459\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1175 - accuracy: 0.9742 - val_loss: 0.3728 - val_accuracy: 0.9509\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1231 - accuracy: 0.9737 - val_loss: 0.3419 - val_accuracy: 0.9580\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1195 - accuracy: 0.9732 - val_loss: 0.3029 - val_accuracy: 0.9732\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1171 - accuracy: 0.9759 - val_loss: 0.3222 - val_accuracy: 0.9652\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1180 - accuracy: 0.9743 - val_loss: 0.2959 - val_accuracy: 0.9716\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1108 - accuracy: 0.9754 - val_loss: 0.3334 - val_accuracy: 0.9615\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1067 - accuracy: 0.9764 - val_loss: 0.3163 - val_accuracy: 0.9595\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.1171 - accuracy: 0.9751 - val_loss: 0.2970 - val_accuracy: 0.9668\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1081 - accuracy: 0.9762 - val_loss: 0.3385 - val_accuracy: 0.9564\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1069 - accuracy: 0.9759 - val_loss: 0.2960 - val_accuracy: 0.9679\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1034 - accuracy: 0.9765 - val_loss: 0.3060 - val_accuracy: 0.9703\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1051 - accuracy: 0.9769 - val_loss: 0.3951 - val_accuracy: 0.9454\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0964 - accuracy: 0.9803 - val_loss: 0.2795 - val_accuracy: 0.9723\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1025 - accuracy: 0.9785 - val_loss: 0.2784 - val_accuracy: 0.9729\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0965 - accuracy: 0.9794 - val_loss: 0.2844 - val_accuracy: 0.9743\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9801 - val_loss: 0.2774 - val_accuracy: 0.9721\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0969 - accuracy: 0.9778 - val_loss: 0.2802 - val_accuracy: 0.9734\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0962 - accuracy: 0.9788 - val_loss: 0.2970 - val_accuracy: 0.9663\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0988 - accuracy: 0.9791 - val_loss: 0.2672 - val_accuracy: 0.9738\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0931 - accuracy: 0.9803 - val_loss: 0.2842 - val_accuracy: 0.9681\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0918 - accuracy: 0.9815 - val_loss: 0.3120 - val_accuracy: 0.9626\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9793 - val_loss: 0.2657 - val_accuracy: 0.9747\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0963 - accuracy: 0.9798 - val_loss: 0.2792 - val_accuracy: 0.9705\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0926 - accuracy: 0.9805 - val_loss: 0.2583 - val_accuracy: 0.9729\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0907 - accuracy: 0.9805 - val_loss: 0.2602 - val_accuracy: 0.9714\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9823 - val_loss: 0.2514 - val_accuracy: 0.9795\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.2554 - val_accuracy: 0.9712\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0831 - accuracy: 0.9839 - val_loss: 0.2683 - val_accuracy: 0.9749\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0876 - accuracy: 0.9814 - val_loss: 0.2588 - val_accuracy: 0.9732\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.9828 - val_loss: 0.2457 - val_accuracy: 0.9776\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0909 - accuracy: 0.9819 - val_loss: 0.2513 - val_accuracy: 0.9771\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0939 - accuracy: 0.9809 - val_loss: 0.2704 - val_accuracy: 0.9716\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0828 - accuracy: 0.9827 - val_loss: 0.2363 - val_accuracy: 0.9802\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0858 - accuracy: 0.9816 - val_loss: 0.2501 - val_accuracy: 0.9747\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0839 - accuracy: 0.9830 - val_loss: 0.2441 - val_accuracy: 0.9765\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0827 - accuracy: 0.9824 - val_loss: 0.2566 - val_accuracy: 0.9745\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.9815 - val_loss: 0.2561 - val_accuracy: 0.9740\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0844 - accuracy: 0.9826 - val_loss: 0.2645 - val_accuracy: 0.9692\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0799 - accuracy: 0.9852 - val_loss: 0.2409 - val_accuracy: 0.9769\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0858 - accuracy: 0.9819 - val_loss: 0.2699 - val_accuracy: 0.9749\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9829 - val_loss: 0.2433 - val_accuracy: 0.9767\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0800 - accuracy: 0.9837 - val_loss: 0.2651 - val_accuracy: 0.9721\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9846 - val_loss: 0.2541 - val_accuracy: 0.9760\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0774 - accuracy: 0.9846 - val_loss: 0.2868 - val_accuracy: 0.9641\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0843 - accuracy: 0.9831 - val_loss: 0.2588 - val_accuracy: 0.9740\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0806 - accuracy: 0.9846 - val_loss: 0.2419 - val_accuracy: 0.9795\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9843 - val_loss: 0.2669 - val_accuracy: 0.9685\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0758 - accuracy: 0.9847 - val_loss: 0.2544 - val_accuracy: 0.9710\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9837 - val_loss: 0.2681 - val_accuracy: 0.9639\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9844 - val_loss: 0.2632 - val_accuracy: 0.9758\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9840 - val_loss: 0.2458 - val_accuracy: 0.9776\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0744 - accuracy: 0.9854 - val_loss: 0.2564 - val_accuracy: 0.9729\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0795 - accuracy: 0.9842 - val_loss: 0.2595 - val_accuracy: 0.9773\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0806 - accuracy: 0.9843 - val_loss: 0.2585 - val_accuracy: 0.9760\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0746 - accuracy: 0.9850 - val_loss: 0.2489 - val_accuracy: 0.9738\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0764 - accuracy: 0.9856 - val_loss: 0.2456 - val_accuracy: 0.9769\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0755 - accuracy: 0.9860 - val_loss: 0.2938 - val_accuracy: 0.9637\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0770 - accuracy: 0.9852 - val_loss: 0.2490 - val_accuracy: 0.9798\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0752 - accuracy: 0.9855 - val_loss: 0.2511 - val_accuracy: 0.9734\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0729 - accuracy: 0.9853 - val_loss: 0.2376 - val_accuracy: 0.9831\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9841 - val_loss: 0.2489 - val_accuracy: 0.9782\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0717 - accuracy: 0.9861 - val_loss: 0.2880 - val_accuracy: 0.9657\n",
      "Average Validation Accuracy: 0.9786150455474854\n",
      "Average Validation Loss: 0.13588166236877441\n",
      "Average Test Accuracy: 0.979582816362381\n",
      "Final Test Accuracy for each fold: 0.9860691428184509\n",
      "Number of input features: 15\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 3.5624 - accuracy: 0.3260 - val_loss: 2.3627 - val_accuracy: 0.6128\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.6237 - accuracy: 0.7017 - val_loss: 1.3948 - val_accuracy: 0.7727\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9653 - accuracy: 0.8103 - val_loss: 1.0078 - val_accuracy: 0.8420\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6547 - accuracy: 0.8669 - val_loss: 0.7782 - val_accuracy: 0.8880\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4781 - accuracy: 0.8980 - val_loss: 0.7187 - val_accuracy: 0.8737\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3660 - accuracy: 0.9159 - val_loss: 0.5673 - val_accuracy: 0.9171\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2964 - accuracy: 0.9276 - val_loss: 0.5037 - val_accuracy: 0.9309\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2578 - accuracy: 0.9365 - val_loss: 0.5098 - val_accuracy: 0.9142\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2258 - accuracy: 0.9453 - val_loss: 0.4430 - val_accuracy: 0.9397\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2099 - accuracy: 0.9483 - val_loss: 0.4671 - val_accuracy: 0.9349\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1877 - accuracy: 0.9515 - val_loss: 0.4043 - val_accuracy: 0.9501\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1792 - accuracy: 0.9548 - val_loss: 0.3727 - val_accuracy: 0.9556\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1694 - accuracy: 0.9574 - val_loss: 0.3837 - val_accuracy: 0.9514\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1629 - accuracy: 0.9612 - val_loss: 0.3923 - val_accuracy: 0.9450\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1538 - accuracy: 0.9626 - val_loss: 0.3539 - val_accuracy: 0.9580\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1462 - accuracy: 0.9650 - val_loss: 0.3600 - val_accuracy: 0.9582\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1502 - accuracy: 0.9625 - val_loss: 0.3852 - val_accuracy: 0.9476\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1355 - accuracy: 0.9688 - val_loss: 0.3429 - val_accuracy: 0.9613\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1354 - accuracy: 0.9692 - val_loss: 0.3606 - val_accuracy: 0.9536\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1325 - accuracy: 0.9690 - val_loss: 0.3163 - val_accuracy: 0.9714\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1198 - accuracy: 0.9738 - val_loss: 0.3091 - val_accuracy: 0.9690\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1257 - accuracy: 0.9693 - val_loss: 0.3323 - val_accuracy: 0.9582\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1176 - accuracy: 0.9710 - val_loss: 0.3117 - val_accuracy: 0.9692\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1201 - accuracy: 0.9712 - val_loss: 0.3777 - val_accuracy: 0.9437\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1161 - accuracy: 0.9743 - val_loss: 0.2993 - val_accuracy: 0.9740\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1167 - accuracy: 0.9746 - val_loss: 0.3053 - val_accuracy: 0.9666\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1100 - accuracy: 0.9751 - val_loss: 0.3192 - val_accuracy: 0.9666\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1146 - accuracy: 0.9730 - val_loss: 0.3886 - val_accuracy: 0.9494\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1047 - accuracy: 0.9780 - val_loss: 0.3029 - val_accuracy: 0.9641\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1147 - accuracy: 0.9741 - val_loss: 0.2879 - val_accuracy: 0.9729\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1034 - accuracy: 0.9777 - val_loss: 0.2840 - val_accuracy: 0.9736\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1078 - accuracy: 0.9759 - val_loss: 0.3379 - val_accuracy: 0.9558\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1053 - accuracy: 0.9766 - val_loss: 0.2944 - val_accuracy: 0.9701\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0999 - accuracy: 0.9791 - val_loss: 0.3048 - val_accuracy: 0.9624\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1019 - accuracy: 0.9775 - val_loss: 0.2701 - val_accuracy: 0.9754\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1026 - accuracy: 0.9772 - val_loss: 0.2927 - val_accuracy: 0.9670\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1017 - accuracy: 0.9778 - val_loss: 0.2732 - val_accuracy: 0.9756\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0965 - accuracy: 0.9791 - val_loss: 0.2728 - val_accuracy: 0.9751\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9803 - val_loss: 0.2752 - val_accuracy: 0.9707\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0972 - accuracy: 0.9783 - val_loss: 0.2602 - val_accuracy: 0.9751\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0947 - accuracy: 0.9794 - val_loss: 0.2713 - val_accuracy: 0.9747\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0900 - accuracy: 0.9822 - val_loss: 0.2607 - val_accuracy: 0.9714\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0921 - accuracy: 0.9810 - val_loss: 0.2653 - val_accuracy: 0.9745\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1001 - accuracy: 0.9793 - val_loss: 0.2556 - val_accuracy: 0.9769\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0906 - accuracy: 0.9825 - val_loss: 0.2563 - val_accuracy: 0.9758\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0930 - accuracy: 0.9798 - val_loss: 0.2890 - val_accuracy: 0.9699\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0957 - accuracy: 0.9811 - val_loss: 0.2595 - val_accuracy: 0.9703\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0850 - accuracy: 0.9833 - val_loss: 0.2707 - val_accuracy: 0.9659\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0895 - accuracy: 0.9814 - val_loss: 0.2672 - val_accuracy: 0.9780\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0927 - accuracy: 0.9801 - val_loss: 0.3231 - val_accuracy: 0.9600\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0886 - accuracy: 0.9823 - val_loss: 0.2515 - val_accuracy: 0.9791\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0853 - accuracy: 0.9827 - val_loss: 0.2814 - val_accuracy: 0.9685\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9837 - val_loss: 0.3016 - val_accuracy: 0.9650\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0910 - accuracy: 0.9807 - val_loss: 0.2806 - val_accuracy: 0.9652\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0855 - accuracy: 0.9821 - val_loss: 0.2650 - val_accuracy: 0.9734\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0793 - accuracy: 0.9854 - val_loss: 0.2755 - val_accuracy: 0.9710\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0886 - accuracy: 0.9821 - val_loss: 0.2543 - val_accuracy: 0.9789\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0852 - accuracy: 0.9824 - val_loss: 0.2499 - val_accuracy: 0.9800\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0789 - accuracy: 0.9843 - val_loss: 0.2703 - val_accuracy: 0.9732\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0863 - accuracy: 0.9822 - val_loss: 0.2550 - val_accuracy: 0.9769\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9840 - val_loss: 0.2479 - val_accuracy: 0.9802\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0894 - accuracy: 0.9812 - val_loss: 0.2594 - val_accuracy: 0.9771\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0833 - accuracy: 0.9829 - val_loss: 0.3266 - val_accuracy: 0.9470\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9839 - val_loss: 0.2461 - val_accuracy: 0.9780\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0774 - accuracy: 0.9840 - val_loss: 0.2835 - val_accuracy: 0.9692\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9836 - val_loss: 0.2771 - val_accuracy: 0.9699\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9844 - val_loss: 0.2745 - val_accuracy: 0.9718\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9825 - val_loss: 0.2851 - val_accuracy: 0.9690\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0747 - accuracy: 0.9846 - val_loss: 0.2676 - val_accuracy: 0.9736\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9832 - val_loss: 0.2724 - val_accuracy: 0.9707\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0787 - accuracy: 0.9842 - val_loss: 0.2577 - val_accuracy: 0.9782\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0831 - accuracy: 0.9834 - val_loss: 0.2565 - val_accuracy: 0.9813\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0743 - accuracy: 0.9855 - val_loss: 0.2730 - val_accuracy: 0.9754\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0788 - accuracy: 0.9829 - val_loss: 0.2524 - val_accuracy: 0.9769\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0717 - accuracy: 0.9856 - val_loss: 0.2807 - val_accuracy: 0.9732\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0785 - accuracy: 0.9830 - val_loss: 0.2788 - val_accuracy: 0.9758\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0795 - accuracy: 0.9824 - val_loss: 0.2452 - val_accuracy: 0.9815\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0781 - accuracy: 0.9843 - val_loss: 0.2857 - val_accuracy: 0.9718\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9848 - val_loss: 0.2533 - val_accuracy: 0.9804\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0765 - accuracy: 0.9841 - val_loss: 0.2530 - val_accuracy: 0.9844\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.5217 - accuracy: 0.3199 - val_loss: 2.3632 - val_accuracy: 0.5848\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.4821 - accuracy: 0.7286 - val_loss: 1.4012 - val_accuracy: 0.7795\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8655 - accuracy: 0.8334 - val_loss: 1.0328 - val_accuracy: 0.8323\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5739 - accuracy: 0.8786 - val_loss: 0.7796 - val_accuracy: 0.8818\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4103 - accuracy: 0.9066 - val_loss: 0.6353 - val_accuracy: 0.8957\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3232 - accuracy: 0.9251 - val_loss: 0.5531 - val_accuracy: 0.9043\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2703 - accuracy: 0.9338 - val_loss: 0.4548 - val_accuracy: 0.9217\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2369 - accuracy: 0.9408 - val_loss: 0.3955 - val_accuracy: 0.9402\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2093 - accuracy: 0.9471 - val_loss: 0.5736 - val_accuracy: 0.8880\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1916 - accuracy: 0.9556 - val_loss: 0.3504 - val_accuracy: 0.9424\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1833 - accuracy: 0.9545 - val_loss: 0.3236 - val_accuracy: 0.9454\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1667 - accuracy: 0.9579 - val_loss: 0.3893 - val_accuracy: 0.9309\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1587 - accuracy: 0.9615 - val_loss: 0.3460 - val_accuracy: 0.9388\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1544 - accuracy: 0.9622 - val_loss: 0.3082 - val_accuracy: 0.9509\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1538 - accuracy: 0.9619 - val_loss: 0.2739 - val_accuracy: 0.9600\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1389 - accuracy: 0.9655 - val_loss: 0.3100 - val_accuracy: 0.9523\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1366 - accuracy: 0.9677 - val_loss: 0.2825 - val_accuracy: 0.9538\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1316 - accuracy: 0.9691 - val_loss: 0.3082 - val_accuracy: 0.9507\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1317 - accuracy: 0.9671 - val_loss: 0.2636 - val_accuracy: 0.9582\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1285 - accuracy: 0.9673 - val_loss: 0.2520 - val_accuracy: 0.9650\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1247 - accuracy: 0.9703 - val_loss: 0.2486 - val_accuracy: 0.9650\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1272 - accuracy: 0.9699 - val_loss: 0.2715 - val_accuracy: 0.9602\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1150 - accuracy: 0.9718 - val_loss: 0.2409 - val_accuracy: 0.9679\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1259 - accuracy: 0.9685 - val_loss: 0.2554 - val_accuracy: 0.9637\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1122 - accuracy: 0.9733 - val_loss: 0.2603 - val_accuracy: 0.9595\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1094 - accuracy: 0.9745 - val_loss: 0.2553 - val_accuracy: 0.9666\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1112 - accuracy: 0.9752 - val_loss: 0.2763 - val_accuracy: 0.9648\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1114 - accuracy: 0.9751 - val_loss: 0.2371 - val_accuracy: 0.9677\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1032 - accuracy: 0.9765 - val_loss: 0.2354 - val_accuracy: 0.9714\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1136 - accuracy: 0.9750 - val_loss: 0.2417 - val_accuracy: 0.9666\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1002 - accuracy: 0.9776 - val_loss: 0.2442 - val_accuracy: 0.9679\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1076 - accuracy: 0.9753 - val_loss: 0.2375 - val_accuracy: 0.9721\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0989 - accuracy: 0.9793 - val_loss: 0.2465 - val_accuracy: 0.9641\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1067 - accuracy: 0.9754 - val_loss: 0.2329 - val_accuracy: 0.9712\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0934 - accuracy: 0.9808 - val_loss: 0.2350 - val_accuracy: 0.9732\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1029 - accuracy: 0.9757 - val_loss: 0.2529 - val_accuracy: 0.9677\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0995 - accuracy: 0.9773 - val_loss: 0.2540 - val_accuracy: 0.9668\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0979 - accuracy: 0.9801 - val_loss: 0.2381 - val_accuracy: 0.9703\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0949 - accuracy: 0.9798 - val_loss: 0.2394 - val_accuracy: 0.9727\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0922 - accuracy: 0.9800 - val_loss: 0.2289 - val_accuracy: 0.9714\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1017 - accuracy: 0.9776 - val_loss: 0.2393 - val_accuracy: 0.9721\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0892 - accuracy: 0.9804 - val_loss: 0.2414 - val_accuracy: 0.9699\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0911 - accuracy: 0.9800 - val_loss: 0.2158 - val_accuracy: 0.9800\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0870 - accuracy: 0.9827 - val_loss: 0.2343 - val_accuracy: 0.9732\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0996 - accuracy: 0.9775 - val_loss: 0.2757 - val_accuracy: 0.9584\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0854 - accuracy: 0.9829 - val_loss: 0.2096 - val_accuracy: 0.9813\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0924 - accuracy: 0.9803 - val_loss: 0.2336 - val_accuracy: 0.9729\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0859 - accuracy: 0.9822 - val_loss: 0.2366 - val_accuracy: 0.9732\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0885 - accuracy: 0.9824 - val_loss: 0.2447 - val_accuracy: 0.9690\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0837 - accuracy: 0.9815 - val_loss: 0.2263 - val_accuracy: 0.9751\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0882 - accuracy: 0.9809 - val_loss: 0.2545 - val_accuracy: 0.9683\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0882 - accuracy: 0.9804 - val_loss: 0.2244 - val_accuracy: 0.9758\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9845 - val_loss: 0.2756 - val_accuracy: 0.9608\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9798 - val_loss: 0.2699 - val_accuracy: 0.9670\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0847 - accuracy: 0.9830 - val_loss: 0.2306 - val_accuracy: 0.9784\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9804 - val_loss: 0.2356 - val_accuracy: 0.9718\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0811 - accuracy: 0.9834 - val_loss: 0.2463 - val_accuracy: 0.9663\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0842 - accuracy: 0.9835 - val_loss: 0.2309 - val_accuracy: 0.9767\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0818 - accuracy: 0.9844 - val_loss: 0.2336 - val_accuracy: 0.9798\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9833 - val_loss: 0.2213 - val_accuracy: 0.9773\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0827 - accuracy: 0.9828 - val_loss: 0.2742 - val_accuracy: 0.9646\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0827 - accuracy: 0.9821 - val_loss: 0.2270 - val_accuracy: 0.9736\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0781 - accuracy: 0.9842 - val_loss: 0.2475 - val_accuracy: 0.9727\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0860 - accuracy: 0.9824 - val_loss: 0.2312 - val_accuracy: 0.9732\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0764 - accuracy: 0.9840 - val_loss: 0.2212 - val_accuracy: 0.9751\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9823 - val_loss: 0.2358 - val_accuracy: 0.9723\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0768 - accuracy: 0.9848 - val_loss: 0.2227 - val_accuracy: 0.9760\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9827 - val_loss: 0.2317 - val_accuracy: 0.9747\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9836 - val_loss: 0.2664 - val_accuracy: 0.9575\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0724 - accuracy: 0.9855 - val_loss: 0.3570 - val_accuracy: 0.9468\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9821 - val_loss: 0.2235 - val_accuracy: 0.9789\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0754 - accuracy: 0.9845 - val_loss: 0.2579 - val_accuracy: 0.9681\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0798 - accuracy: 0.9835 - val_loss: 0.2305 - val_accuracy: 0.9762\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0736 - accuracy: 0.9854 - val_loss: 0.2148 - val_accuracy: 0.9795\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0750 - accuracy: 0.9849 - val_loss: 0.2414 - val_accuracy: 0.9705\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0808 - accuracy: 0.9821 - val_loss: 0.2191 - val_accuracy: 0.9767\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0723 - accuracy: 0.9845 - val_loss: 0.2167 - val_accuracy: 0.9806\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0807 - accuracy: 0.9823 - val_loss: 0.2213 - val_accuracy: 0.9787\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0729 - accuracy: 0.9850 - val_loss: 0.2535 - val_accuracy: 0.9699\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0772 - accuracy: 0.9847 - val_loss: 0.2277 - val_accuracy: 0.9745\n",
      "Average Validation Accuracy: 0.9856224060058594\n",
      "Average Validation Loss: 0.12626541405916214\n",
      "Average Test Accuracy: 0.986253410577774\n",
      "Final Test Accuracy for each fold: 0.9885752201080322\n",
      "Number of input features: 16\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.4816 - accuracy: 0.3398 - val_loss: 2.2153 - val_accuracy: 0.6299\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.4663 - accuracy: 0.7326 - val_loss: 1.2778 - val_accuracy: 0.7930\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8141 - accuracy: 0.8452 - val_loss: 0.9097 - val_accuracy: 0.8612\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5193 - accuracy: 0.8938 - val_loss: 0.7052 - val_accuracy: 0.8983\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3780 - accuracy: 0.9158 - val_loss: 0.5672 - val_accuracy: 0.9219\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2962 - accuracy: 0.9344 - val_loss: 0.4987 - val_accuracy: 0.9265\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2496 - accuracy: 0.9398 - val_loss: 0.4201 - val_accuracy: 0.9402\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2145 - accuracy: 0.9484 - val_loss: 0.4314 - val_accuracy: 0.9300\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1977 - accuracy: 0.9496 - val_loss: 0.3781 - val_accuracy: 0.9360\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1800 - accuracy: 0.9555 - val_loss: 0.3571 - val_accuracy: 0.9408\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1644 - accuracy: 0.9590 - val_loss: 0.3207 - val_accuracy: 0.9527\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1635 - accuracy: 0.9564 - val_loss: 0.3080 - val_accuracy: 0.9635\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1507 - accuracy: 0.9611 - val_loss: 0.3784 - val_accuracy: 0.9248\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1467 - accuracy: 0.9627 - val_loss: 0.3208 - val_accuracy: 0.9470\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1393 - accuracy: 0.9660 - val_loss: 0.2973 - val_accuracy: 0.9639\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1369 - accuracy: 0.9667 - val_loss: 0.2716 - val_accuracy: 0.9611\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1283 - accuracy: 0.9699 - val_loss: 0.3117 - val_accuracy: 0.9536\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1276 - accuracy: 0.9712 - val_loss: 0.2950 - val_accuracy: 0.9600\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1208 - accuracy: 0.9730 - val_loss: 0.3361 - val_accuracy: 0.9419\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1228 - accuracy: 0.9708 - val_loss: 0.3790 - val_accuracy: 0.9369\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1214 - accuracy: 0.9727 - val_loss: 0.2721 - val_accuracy: 0.9608\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1092 - accuracy: 0.9756 - val_loss: 0.2681 - val_accuracy: 0.9619\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1148 - accuracy: 0.9716 - val_loss: 0.2855 - val_accuracy: 0.9556\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1142 - accuracy: 0.9753 - val_loss: 0.2477 - val_accuracy: 0.9747\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1151 - accuracy: 0.9724 - val_loss: 0.2560 - val_accuracy: 0.9677\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1058 - accuracy: 0.9754 - val_loss: 0.2509 - val_accuracy: 0.9701\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1047 - accuracy: 0.9784 - val_loss: 0.3374 - val_accuracy: 0.9483\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1031 - accuracy: 0.9784 - val_loss: 0.3147 - val_accuracy: 0.9520\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1124 - accuracy: 0.9746 - val_loss: 0.2304 - val_accuracy: 0.9751\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0993 - accuracy: 0.9803 - val_loss: 0.2382 - val_accuracy: 0.9740\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0990 - accuracy: 0.9797 - val_loss: 0.2662 - val_accuracy: 0.9716\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1107 - accuracy: 0.9744 - val_loss: 0.2405 - val_accuracy: 0.9749\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0943 - accuracy: 0.9803 - val_loss: 0.2514 - val_accuracy: 0.9690\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0904 - accuracy: 0.9819 - val_loss: 0.2298 - val_accuracy: 0.9773\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1055 - accuracy: 0.9765 - val_loss: 0.2395 - val_accuracy: 0.9707\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0930 - accuracy: 0.9809 - val_loss: 0.2522 - val_accuracy: 0.9703\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0930 - accuracy: 0.9806 - val_loss: 0.2552 - val_accuracy: 0.9672\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0946 - accuracy: 0.9806 - val_loss: 0.2453 - val_accuracy: 0.9718\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0948 - accuracy: 0.9812 - val_loss: 0.2592 - val_accuracy: 0.9659\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0921 - accuracy: 0.9804 - val_loss: 0.3363 - val_accuracy: 0.9397\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0884 - accuracy: 0.9810 - val_loss: 0.2282 - val_accuracy: 0.9773\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0896 - accuracy: 0.9820 - val_loss: 0.2320 - val_accuracy: 0.9758\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0893 - accuracy: 0.9809 - val_loss: 0.2593 - val_accuracy: 0.9707\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0951 - accuracy: 0.9805 - val_loss: 0.2359 - val_accuracy: 0.9747\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0860 - accuracy: 0.9825 - val_loss: 0.2594 - val_accuracy: 0.9611\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0928 - accuracy: 0.9815 - val_loss: 0.2786 - val_accuracy: 0.9604\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0866 - accuracy: 0.9822 - val_loss: 0.2323 - val_accuracy: 0.9787\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0893 - accuracy: 0.9827 - val_loss: 0.2701 - val_accuracy: 0.9593\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0812 - accuracy: 0.9848 - val_loss: 0.2324 - val_accuracy: 0.9743\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0963 - accuracy: 0.9789 - val_loss: 0.2515 - val_accuracy: 0.9677\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9848 - val_loss: 0.2577 - val_accuracy: 0.9670\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9840 - val_loss: 0.2311 - val_accuracy: 0.9738\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0800 - accuracy: 0.9841 - val_loss: 0.2358 - val_accuracy: 0.9696\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0841 - accuracy: 0.9835 - val_loss: 0.2113 - val_accuracy: 0.9820\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0815 - accuracy: 0.9846 - val_loss: 0.2175 - val_accuracy: 0.9804\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9828 - val_loss: 0.2103 - val_accuracy: 0.9802\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0811 - accuracy: 0.9844 - val_loss: 0.2309 - val_accuracy: 0.9749\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0772 - accuracy: 0.9849 - val_loss: 0.2916 - val_accuracy: 0.9668\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0852 - accuracy: 0.9836 - val_loss: 0.2613 - val_accuracy: 0.9679\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0799 - accuracy: 0.9830 - val_loss: 0.2189 - val_accuracy: 0.9771\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9823 - val_loss: 0.2271 - val_accuracy: 0.9780\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0715 - accuracy: 0.9871 - val_loss: 0.2139 - val_accuracy: 0.9844\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0794 - accuracy: 0.9836 - val_loss: 0.2415 - val_accuracy: 0.9677\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9855 - val_loss: 0.2234 - val_accuracy: 0.9756\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0789 - accuracy: 0.9839 - val_loss: 0.2295 - val_accuracy: 0.9745\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0761 - accuracy: 0.9848 - val_loss: 0.2459 - val_accuracy: 0.9705\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0806 - accuracy: 0.9841 - val_loss: 0.2283 - val_accuracy: 0.9798\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0727 - accuracy: 0.9870 - val_loss: 0.2193 - val_accuracy: 0.9798\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0784 - accuracy: 0.9846 - val_loss: 0.2525 - val_accuracy: 0.9710\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0776 - accuracy: 0.9865 - val_loss: 0.2254 - val_accuracy: 0.9798\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0718 - accuracy: 0.9858 - val_loss: 0.2335 - val_accuracy: 0.9762\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0751 - accuracy: 0.9856 - val_loss: 0.2384 - val_accuracy: 0.9754\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0774 - accuracy: 0.9847 - val_loss: 0.2198 - val_accuracy: 0.9802\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0726 - accuracy: 0.9867 - val_loss: 0.2237 - val_accuracy: 0.9773\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0757 - accuracy: 0.9857 - val_loss: 0.2224 - val_accuracy: 0.9809\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0700 - accuracy: 0.9863 - val_loss: 0.2280 - val_accuracy: 0.9771\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0746 - accuracy: 0.9852 - val_loss: 0.2314 - val_accuracy: 0.9773\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9844 - val_loss: 0.2166 - val_accuracy: 0.9839\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0719 - accuracy: 0.9862 - val_loss: 0.3415 - val_accuracy: 0.9468\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0744 - accuracy: 0.9856 - val_loss: 0.2417 - val_accuracy: 0.9696\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 15s 3ms/step - loss: 3.6813 - accuracy: 0.2962 - val_loss: 2.5479 - val_accuracy: 0.5193\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.6651 - accuracy: 0.6996 - val_loss: 1.5237 - val_accuracy: 0.7723\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.9469 - accuracy: 0.8254 - val_loss: 1.0915 - val_accuracy: 0.8372\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6308 - accuracy: 0.8704 - val_loss: 0.8513 - val_accuracy: 0.8796\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4474 - accuracy: 0.9038 - val_loss: 0.7060 - val_accuracy: 0.9087\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3483 - accuracy: 0.9233 - val_loss: 0.5949 - val_accuracy: 0.9267\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2878 - accuracy: 0.9348 - val_loss: 0.5332 - val_accuracy: 0.9395\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2439 - accuracy: 0.9415 - val_loss: 0.5048 - val_accuracy: 0.9274\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2179 - accuracy: 0.9475 - val_loss: 0.4693 - val_accuracy: 0.9234\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1939 - accuracy: 0.9522 - val_loss: 0.4219 - val_accuracy: 0.9426\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1820 - accuracy: 0.9548 - val_loss: 0.3911 - val_accuracy: 0.9485\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1667 - accuracy: 0.9591 - val_loss: 0.3963 - val_accuracy: 0.9465\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1639 - accuracy: 0.9606 - val_loss: 0.4508 - val_accuracy: 0.9292\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1498 - accuracy: 0.9628 - val_loss: 0.4214 - val_accuracy: 0.9450\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1519 - accuracy: 0.9645 - val_loss: 0.3760 - val_accuracy: 0.9481\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1348 - accuracy: 0.9680 - val_loss: 0.3732 - val_accuracy: 0.9536\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1383 - accuracy: 0.9686 - val_loss: 0.4071 - val_accuracy: 0.9481\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1328 - accuracy: 0.9710 - val_loss: 0.3155 - val_accuracy: 0.9659\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1193 - accuracy: 0.9733 - val_loss: 0.3451 - val_accuracy: 0.9573\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1295 - accuracy: 0.9702 - val_loss: 0.3402 - val_accuracy: 0.9608\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1220 - accuracy: 0.9719 - val_loss: 0.3341 - val_accuracy: 0.9600\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1167 - accuracy: 0.9743 - val_loss: 0.3270 - val_accuracy: 0.9644\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1174 - accuracy: 0.9753 - val_loss: 0.3252 - val_accuracy: 0.9593\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1141 - accuracy: 0.9743 - val_loss: 0.3493 - val_accuracy: 0.9553\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1130 - accuracy: 0.9757 - val_loss: 0.3099 - val_accuracy: 0.9681\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1175 - accuracy: 0.9739 - val_loss: 0.3481 - val_accuracy: 0.9584\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1103 - accuracy: 0.9755 - val_loss: 0.3064 - val_accuracy: 0.9637\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1127 - accuracy: 0.9756 - val_loss: 0.2795 - val_accuracy: 0.9707\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1084 - accuracy: 0.9752 - val_loss: 0.3088 - val_accuracy: 0.9635\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1066 - accuracy: 0.9776 - val_loss: 0.2746 - val_accuracy: 0.9751\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0970 - accuracy: 0.9800 - val_loss: 0.3023 - val_accuracy: 0.9622\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1038 - accuracy: 0.9790 - val_loss: 0.2957 - val_accuracy: 0.9670\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0999 - accuracy: 0.9783 - val_loss: 0.2916 - val_accuracy: 0.9703\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1058 - accuracy: 0.9771 - val_loss: 0.2808 - val_accuracy: 0.9677\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1015 - accuracy: 0.9794 - val_loss: 0.2700 - val_accuracy: 0.9701\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0883 - accuracy: 0.9835 - val_loss: 0.2566 - val_accuracy: 0.9762\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1020 - accuracy: 0.9795 - val_loss: 0.3138 - val_accuracy: 0.9556\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0952 - accuracy: 0.9797 - val_loss: 0.2717 - val_accuracy: 0.9712\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0984 - accuracy: 0.9794 - val_loss: 0.2654 - val_accuracy: 0.9716\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0952 - accuracy: 0.9806 - val_loss: 0.2552 - val_accuracy: 0.9760\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0897 - accuracy: 0.9823 - val_loss: 0.2723 - val_accuracy: 0.9677\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0985 - accuracy: 0.9802 - val_loss: 0.2549 - val_accuracy: 0.9765\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0861 - accuracy: 0.9830 - val_loss: 0.2536 - val_accuracy: 0.9758\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0946 - accuracy: 0.9806 - val_loss: 0.2872 - val_accuracy: 0.9635\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0867 - accuracy: 0.9826 - val_loss: 0.2651 - val_accuracy: 0.9690\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0932 - accuracy: 0.9806 - val_loss: 0.2653 - val_accuracy: 0.9659\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0882 - accuracy: 0.9815 - val_loss: 0.2893 - val_accuracy: 0.9624\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0889 - accuracy: 0.9806 - val_loss: 0.2473 - val_accuracy: 0.9791\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0862 - accuracy: 0.9831 - val_loss: 0.2605 - val_accuracy: 0.9677\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0903 - accuracy: 0.9813 - val_loss: 0.2775 - val_accuracy: 0.9670\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0879 - accuracy: 0.9820 - val_loss: 0.2880 - val_accuracy: 0.9606\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0833 - accuracy: 0.9837 - val_loss: 0.2657 - val_accuracy: 0.9738\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0859 - accuracy: 0.9819 - val_loss: 0.2443 - val_accuracy: 0.9804\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9828 - val_loss: 0.2495 - val_accuracy: 0.9767\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0857 - accuracy: 0.9831 - val_loss: 0.2496 - val_accuracy: 0.9765\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0856 - accuracy: 0.9826 - val_loss: 0.2476 - val_accuracy: 0.9751\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9847 - val_loss: 0.2533 - val_accuracy: 0.9780\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0859 - accuracy: 0.9827 - val_loss: 0.2691 - val_accuracy: 0.9699\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0795 - accuracy: 0.9848 - val_loss: 0.2589 - val_accuracy: 0.9749\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0879 - accuracy: 0.9805 - val_loss: 0.2540 - val_accuracy: 0.9749\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0850 - accuracy: 0.9818 - val_loss: 0.2543 - val_accuracy: 0.9767\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0793 - accuracy: 0.9847 - val_loss: 0.2760 - val_accuracy: 0.9716\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0834 - accuracy: 0.9831 - val_loss: 0.2732 - val_accuracy: 0.9692\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0819 - accuracy: 0.9844 - val_loss: 0.2750 - val_accuracy: 0.9694\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0838 - accuracy: 0.9833 - val_loss: 0.2667 - val_accuracy: 0.9707\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0804 - accuracy: 0.9842 - val_loss: 0.2492 - val_accuracy: 0.9787\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0809 - accuracy: 0.9830 - val_loss: 0.2614 - val_accuracy: 0.9696\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0853 - accuracy: 0.9810 - val_loss: 0.2759 - val_accuracy: 0.9710\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0799 - accuracy: 0.9833 - val_loss: 0.2546 - val_accuracy: 0.9747\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9843 - val_loss: 0.2508 - val_accuracy: 0.9787\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0839 - accuracy: 0.9831 - val_loss: 0.2516 - val_accuracy: 0.9773\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0717 - accuracy: 0.9855 - val_loss: 0.3012 - val_accuracy: 0.9740\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0798 - accuracy: 0.9830 - val_loss: 0.2602 - val_accuracy: 0.9771\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0862 - accuracy: 0.9829 - val_loss: 0.2666 - val_accuracy: 0.9707\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0720 - accuracy: 0.9869 - val_loss: 0.2440 - val_accuracy: 0.9815\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0815 - accuracy: 0.9850 - val_loss: 0.2432 - val_accuracy: 0.9767\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0755 - accuracy: 0.9855 - val_loss: 0.2527 - val_accuracy: 0.9758\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0721 - accuracy: 0.9855 - val_loss: 0.2615 - val_accuracy: 0.9760\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0758 - accuracy: 0.9844 - val_loss: 0.2566 - val_accuracy: 0.9804\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0756 - accuracy: 0.9852 - val_loss: 0.2499 - val_accuracy: 0.9760\n",
      "Average Validation Accuracy: 0.9803217351436615\n",
      "Average Validation Loss: 0.1303471028804779\n",
      "Average Test Accuracy: 0.9800987839698792\n",
      "Final Test Accuracy for each fold: 0.9816466569900513\n",
      "Number of input features: 17\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.1601 - accuracy: 0.4189 - val_loss: 1.7033 - val_accuracy: 0.7041\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 1.0878 - accuracy: 0.7859 - val_loss: 0.9633 - val_accuracy: 0.8180\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.6241 - accuracy: 0.8607 - val_loss: 0.6875 - val_accuracy: 0.8724\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4413 - accuracy: 0.8900 - val_loss: 0.5956 - val_accuracy: 0.8895\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3547 - accuracy: 0.9087 - val_loss: 0.5514 - val_accuracy: 0.8939\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2916 - accuracy: 0.9237 - val_loss: 0.4259 - val_accuracy: 0.9237\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2605 - accuracy: 0.9299 - val_loss: 0.3996 - val_accuracy: 0.9190\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2325 - accuracy: 0.9350 - val_loss: 0.3862 - val_accuracy: 0.9212\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2206 - accuracy: 0.9406 - val_loss: 0.3560 - val_accuracy: 0.9283\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1970 - accuracy: 0.9484 - val_loss: 0.3319 - val_accuracy: 0.9435\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1828 - accuracy: 0.9515 - val_loss: 0.3272 - val_accuracy: 0.9364\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1684 - accuracy: 0.9542 - val_loss: 0.3152 - val_accuracy: 0.9479\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1733 - accuracy: 0.9533 - val_loss: 0.3072 - val_accuracy: 0.9503\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1568 - accuracy: 0.9585 - val_loss: 0.3987 - val_accuracy: 0.9199\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1468 - accuracy: 0.9618 - val_loss: 0.3668 - val_accuracy: 0.9270\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1494 - accuracy: 0.9611 - val_loss: 0.3375 - val_accuracy: 0.9373\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1327 - accuracy: 0.9662 - val_loss: 0.2907 - val_accuracy: 0.9509\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1368 - accuracy: 0.9664 - val_loss: 0.3393 - val_accuracy: 0.9437\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1393 - accuracy: 0.9651 - val_loss: 0.2722 - val_accuracy: 0.9655\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1263 - accuracy: 0.9686 - val_loss: 0.2488 - val_accuracy: 0.9661\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1216 - accuracy: 0.9717 - val_loss: 0.2702 - val_accuracy: 0.9611\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1193 - accuracy: 0.9721 - val_loss: 0.2888 - val_accuracy: 0.9582\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1260 - accuracy: 0.9689 - val_loss: 0.3305 - val_accuracy: 0.9450\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1099 - accuracy: 0.9750 - val_loss: 0.2833 - val_accuracy: 0.9615\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1128 - accuracy: 0.9770 - val_loss: 0.2790 - val_accuracy: 0.9606\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1122 - accuracy: 0.9733 - val_loss: 0.2458 - val_accuracy: 0.9705\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1066 - accuracy: 0.9747 - val_loss: 0.2857 - val_accuracy: 0.9591\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1072 - accuracy: 0.9749 - val_loss: 0.3047 - val_accuracy: 0.9622\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1105 - accuracy: 0.9745 - val_loss: 0.2529 - val_accuracy: 0.9714\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0999 - accuracy: 0.9786 - val_loss: 0.2614 - val_accuracy: 0.9655\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1076 - accuracy: 0.9759 - val_loss: 0.2859 - val_accuracy: 0.9622\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1044 - accuracy: 0.9756 - val_loss: 0.2475 - val_accuracy: 0.9707\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0969 - accuracy: 0.9786 - val_loss: 0.2436 - val_accuracy: 0.9745\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1077 - accuracy: 0.9760 - val_loss: 0.2302 - val_accuracy: 0.9791\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0953 - accuracy: 0.9785 - val_loss: 0.2365 - val_accuracy: 0.9817\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0953 - accuracy: 0.9789 - val_loss: 0.2443 - val_accuracy: 0.9760\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0995 - accuracy: 0.9783 - val_loss: 0.2379 - val_accuracy: 0.9773\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9815 - val_loss: 0.2360 - val_accuracy: 0.9756\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0992 - accuracy: 0.9765 - val_loss: 0.3215 - val_accuracy: 0.9542\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0962 - accuracy: 0.9794 - val_loss: 0.2570 - val_accuracy: 0.9740\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0891 - accuracy: 0.9814 - val_loss: 0.2909 - val_accuracy: 0.9635\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9802 - val_loss: 0.2827 - val_accuracy: 0.9710\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9817 - val_loss: 0.2606 - val_accuracy: 0.9714\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0894 - accuracy: 0.9821 - val_loss: 0.2655 - val_accuracy: 0.9670\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9816 - val_loss: 0.2715 - val_accuracy: 0.9701\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0832 - accuracy: 0.9845 - val_loss: 0.3198 - val_accuracy: 0.9562\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0900 - accuracy: 0.9809 - val_loss: 0.2665 - val_accuracy: 0.9745\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0885 - accuracy: 0.9816 - val_loss: 0.2783 - val_accuracy: 0.9606\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0795 - accuracy: 0.9844 - val_loss: 0.2666 - val_accuracy: 0.9683\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9820 - val_loss: 0.2665 - val_accuracy: 0.9710\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0919 - accuracy: 0.9804 - val_loss: 0.2617 - val_accuracy: 0.9747\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0795 - accuracy: 0.9834 - val_loss: 0.2397 - val_accuracy: 0.9804\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0877 - accuracy: 0.9807 - val_loss: 0.2578 - val_accuracy: 0.9721\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0840 - accuracy: 0.9834 - val_loss: 0.2501 - val_accuracy: 0.9800\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0842 - accuracy: 0.9824 - val_loss: 0.2926 - val_accuracy: 0.9679\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0833 - accuracy: 0.9815 - val_loss: 0.2503 - val_accuracy: 0.9791\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0835 - accuracy: 0.9831 - val_loss: 0.3316 - val_accuracy: 0.9549\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0799 - accuracy: 0.9828 - val_loss: 0.2391 - val_accuracy: 0.9798\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0771 - accuracy: 0.9848 - val_loss: 0.2441 - val_accuracy: 0.9789\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9850 - val_loss: 0.2541 - val_accuracy: 0.9787\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0866 - accuracy: 0.9812 - val_loss: 0.2409 - val_accuracy: 0.9815\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0808 - accuracy: 0.9835 - val_loss: 0.2871 - val_accuracy: 0.9670\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0807 - accuracy: 0.9836 - val_loss: 0.2500 - val_accuracy: 0.9765\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0792 - accuracy: 0.9840 - val_loss: 0.2806 - val_accuracy: 0.9707\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0780 - accuracy: 0.9840 - val_loss: 0.2538 - val_accuracy: 0.9780\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0767 - accuracy: 0.9846 - val_loss: 0.2842 - val_accuracy: 0.9696\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9842 - val_loss: 0.2472 - val_accuracy: 0.9778\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9845 - val_loss: 0.2564 - val_accuracy: 0.9758\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0795 - accuracy: 0.9830 - val_loss: 0.2954 - val_accuracy: 0.9670\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9847 - val_loss: 0.2753 - val_accuracy: 0.9661\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9844 - val_loss: 0.2481 - val_accuracy: 0.9787\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0724 - accuracy: 0.9865 - val_loss: 0.2496 - val_accuracy: 0.9773\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0789 - accuracy: 0.9849 - val_loss: 0.2464 - val_accuracy: 0.9791\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0767 - accuracy: 0.9836 - val_loss: 0.2648 - val_accuracy: 0.9716\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0761 - accuracy: 0.9848 - val_loss: 0.2691 - val_accuracy: 0.9725\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0750 - accuracy: 0.9834 - val_loss: 0.2440 - val_accuracy: 0.9815\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0679 - accuracy: 0.9871 - val_loss: 0.2670 - val_accuracy: 0.9712\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0778 - accuracy: 0.9833 - val_loss: 0.2970 - val_accuracy: 0.9597\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0738 - accuracy: 0.9846 - val_loss: 0.3074 - val_accuracy: 0.9633\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0761 - accuracy: 0.9848 - val_loss: 0.2473 - val_accuracy: 0.9824\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.4004 - accuracy: 0.3500 - val_loss: 2.1507 - val_accuracy: 0.6112\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.3631 - accuracy: 0.7414 - val_loss: 1.3055 - val_accuracy: 0.7756\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8105 - accuracy: 0.8319 - val_loss: 0.9948 - val_accuracy: 0.8345\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5661 - accuracy: 0.8758 - val_loss: 0.8892 - val_accuracy: 0.8541\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4253 - accuracy: 0.9018 - val_loss: 0.7156 - val_accuracy: 0.8821\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3530 - accuracy: 0.9132 - val_loss: 0.5694 - val_accuracy: 0.9116\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2940 - accuracy: 0.9252 - val_loss: 0.5138 - val_accuracy: 0.9195\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2678 - accuracy: 0.9303 - val_loss: 0.4531 - val_accuracy: 0.9344\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2332 - accuracy: 0.9402 - val_loss: 0.4514 - val_accuracy: 0.9399\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2198 - accuracy: 0.9418 - val_loss: 0.4336 - val_accuracy: 0.9311\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2035 - accuracy: 0.9469 - val_loss: 0.4162 - val_accuracy: 0.9349\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1870 - accuracy: 0.9497 - val_loss: 0.4278 - val_accuracy: 0.9413\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1823 - accuracy: 0.9538 - val_loss: 0.3768 - val_accuracy: 0.9516\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1745 - accuracy: 0.9545 - val_loss: 0.4772 - val_accuracy: 0.9133\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1638 - accuracy: 0.9587 - val_loss: 0.3456 - val_accuracy: 0.9520\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1598 - accuracy: 0.9585 - val_loss: 0.3577 - val_accuracy: 0.9602\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1616 - accuracy: 0.9611 - val_loss: 0.3555 - val_accuracy: 0.9580\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1548 - accuracy: 0.9619 - val_loss: 0.3497 - val_accuracy: 0.9531\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1476 - accuracy: 0.9653 - val_loss: 0.3658 - val_accuracy: 0.9567\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1310 - accuracy: 0.9712 - val_loss: 0.4000 - val_accuracy: 0.9360\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1412 - accuracy: 0.9661 - val_loss: 0.3730 - val_accuracy: 0.9549\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1353 - accuracy: 0.9688 - val_loss: 0.5080 - val_accuracy: 0.9404\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1275 - accuracy: 0.9694 - val_loss: 0.3932 - val_accuracy: 0.9419\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1342 - accuracy: 0.9690 - val_loss: 0.3388 - val_accuracy: 0.9567\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1293 - accuracy: 0.9708 - val_loss: 0.3139 - val_accuracy: 0.9644\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1213 - accuracy: 0.9732 - val_loss: 0.4372 - val_accuracy: 0.9415\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1248 - accuracy: 0.9704 - val_loss: 0.3432 - val_accuracy: 0.9525\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1144 - accuracy: 0.9739 - val_loss: 0.3371 - val_accuracy: 0.9553\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1193 - accuracy: 0.9720 - val_loss: 0.3017 - val_accuracy: 0.9637\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1183 - accuracy: 0.9746 - val_loss: 0.3124 - val_accuracy: 0.9637\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1148 - accuracy: 0.9739 - val_loss: 0.2821 - val_accuracy: 0.9732\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1188 - accuracy: 0.9746 - val_loss: 0.3218 - val_accuracy: 0.9655\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1121 - accuracy: 0.9755 - val_loss: 0.3150 - val_accuracy: 0.9633\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1082 - accuracy: 0.9754 - val_loss: 0.2948 - val_accuracy: 0.9670\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1094 - accuracy: 0.9751 - val_loss: 0.3635 - val_accuracy: 0.9461\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1093 - accuracy: 0.9755 - val_loss: 0.2874 - val_accuracy: 0.9677\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1085 - accuracy: 0.9776 - val_loss: 0.2986 - val_accuracy: 0.9652\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1043 - accuracy: 0.9771 - val_loss: 0.2882 - val_accuracy: 0.9648\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1071 - accuracy: 0.9759 - val_loss: 0.2729 - val_accuracy: 0.9754\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1053 - accuracy: 0.9780 - val_loss: 0.3923 - val_accuracy: 0.9217\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1031 - accuracy: 0.9765 - val_loss: 0.2626 - val_accuracy: 0.9729\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0960 - accuracy: 0.9800 - val_loss: 0.2740 - val_accuracy: 0.9679\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1028 - accuracy: 0.9786 - val_loss: 0.3403 - val_accuracy: 0.9527\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0968 - accuracy: 0.9789 - val_loss: 0.2500 - val_accuracy: 0.9791\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0937 - accuracy: 0.9793 - val_loss: 0.2947 - val_accuracy: 0.9586\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0956 - accuracy: 0.9793 - val_loss: 0.2799 - val_accuracy: 0.9608\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0997 - accuracy: 0.9788 - val_loss: 0.2563 - val_accuracy: 0.9714\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0960 - accuracy: 0.9807 - val_loss: 0.2804 - val_accuracy: 0.9699\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0924 - accuracy: 0.9816 - val_loss: 0.2988 - val_accuracy: 0.9602\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0927 - accuracy: 0.9805 - val_loss: 0.2640 - val_accuracy: 0.9707\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0936 - accuracy: 0.9801 - val_loss: 0.2544 - val_accuracy: 0.9745\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0917 - accuracy: 0.9810 - val_loss: 0.2853 - val_accuracy: 0.9641\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0923 - accuracy: 0.9816 - val_loss: 0.3565 - val_accuracy: 0.9468\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0910 - accuracy: 0.9808 - val_loss: 0.2745 - val_accuracy: 0.9661\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0921 - accuracy: 0.9810 - val_loss: 0.2464 - val_accuracy: 0.9791\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0918 - accuracy: 0.9805 - val_loss: 0.2608 - val_accuracy: 0.9749\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0902 - accuracy: 0.9807 - val_loss: 0.2584 - val_accuracy: 0.9754\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0902 - accuracy: 0.9818 - val_loss: 0.2673 - val_accuracy: 0.9714\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9808 - val_loss: 0.2763 - val_accuracy: 0.9681\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0917 - accuracy: 0.9806 - val_loss: 0.2479 - val_accuracy: 0.9756\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0921 - accuracy: 0.9808 - val_loss: 0.2639 - val_accuracy: 0.9732\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0930 - accuracy: 0.9809 - val_loss: 0.2514 - val_accuracy: 0.9743\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0824 - accuracy: 0.9842 - val_loss: 0.2607 - val_accuracy: 0.9767\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0846 - accuracy: 0.9833 - val_loss: 0.2696 - val_accuracy: 0.9714\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0920 - accuracy: 0.9798 - val_loss: 0.2860 - val_accuracy: 0.9690\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0819 - accuracy: 0.9842 - val_loss: 0.2477 - val_accuracy: 0.9754\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9829 - val_loss: 0.2532 - val_accuracy: 0.9758\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9816 - val_loss: 0.2826 - val_accuracy: 0.9674\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0850 - accuracy: 0.9826 - val_loss: 0.2388 - val_accuracy: 0.9815\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0822 - accuracy: 0.9828 - val_loss: 0.2681 - val_accuracy: 0.9707\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0867 - accuracy: 0.9835 - val_loss: 0.2684 - val_accuracy: 0.9754\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0859 - accuracy: 0.9821 - val_loss: 0.2577 - val_accuracy: 0.9762\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0799 - accuracy: 0.9833 - val_loss: 0.2471 - val_accuracy: 0.9791\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0816 - accuracy: 0.9827 - val_loss: 0.2447 - val_accuracy: 0.9820\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0836 - accuracy: 0.9824 - val_loss: 0.2907 - val_accuracy: 0.9663\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9829 - val_loss: 0.2735 - val_accuracy: 0.9705\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0799 - accuracy: 0.9840 - val_loss: 0.2400 - val_accuracy: 0.9806\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0824 - accuracy: 0.9839 - val_loss: 0.3483 - val_accuracy: 0.9509\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0785 - accuracy: 0.9846 - val_loss: 0.2759 - val_accuracy: 0.9668\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0788 - accuracy: 0.9847 - val_loss: 0.2312 - val_accuracy: 0.9826\n",
      "Average Validation Accuracy: 0.9866753816604614\n",
      "Average Validation Loss: 0.12367894127964973\n",
      "Average Test Accuracy: 0.9877275824546814\n",
      "Final Test Accuracy for each fold: 0.9879855513572693\n",
      "Number of input features: 18\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.3105 - accuracy: 0.3837 - val_loss: 2.0228 - val_accuracy: 0.6480\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.2917 - accuracy: 0.7600 - val_loss: 1.1170 - val_accuracy: 0.8145\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7138 - accuracy: 0.8613 - val_loss: 0.7907 - val_accuracy: 0.8561\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4679 - accuracy: 0.8968 - val_loss: 0.6156 - val_accuracy: 0.8873\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3476 - accuracy: 0.9170 - val_loss: 0.5532 - val_accuracy: 0.9129\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2841 - accuracy: 0.9306 - val_loss: 0.4985 - val_accuracy: 0.9096\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2470 - accuracy: 0.9366 - val_loss: 0.4474 - val_accuracy: 0.9298\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2155 - accuracy: 0.9472 - val_loss: 0.3887 - val_accuracy: 0.9391\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1960 - accuracy: 0.9509 - val_loss: 0.3651 - val_accuracy: 0.9454\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1844 - accuracy: 0.9529 - val_loss: 0.3544 - val_accuracy: 0.9454\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1663 - accuracy: 0.9587 - val_loss: 0.3497 - val_accuracy: 0.9443\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1587 - accuracy: 0.9597 - val_loss: 0.3669 - val_accuracy: 0.9437\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1583 - accuracy: 0.9597 - val_loss: 0.3575 - val_accuracy: 0.9481\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1479 - accuracy: 0.9627 - val_loss: 0.3196 - val_accuracy: 0.9639\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1390 - accuracy: 0.9667 - val_loss: 0.3285 - val_accuracy: 0.9582\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1393 - accuracy: 0.9648 - val_loss: 0.3352 - val_accuracy: 0.9558\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1339 - accuracy: 0.9680 - val_loss: 0.2879 - val_accuracy: 0.9694\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1307 - accuracy: 0.9664 - val_loss: 0.3215 - val_accuracy: 0.9584\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1226 - accuracy: 0.9700 - val_loss: 0.3578 - val_accuracy: 0.9404\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1228 - accuracy: 0.9708 - val_loss: 0.2872 - val_accuracy: 0.9659\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1148 - accuracy: 0.9728 - val_loss: 0.3199 - val_accuracy: 0.9551\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1233 - accuracy: 0.9681 - val_loss: 0.2824 - val_accuracy: 0.9696\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1089 - accuracy: 0.9759 - val_loss: 0.2804 - val_accuracy: 0.9699\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1114 - accuracy: 0.9742 - val_loss: 0.2767 - val_accuracy: 0.9685\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1108 - accuracy: 0.9756 - val_loss: 0.3019 - val_accuracy: 0.9613\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1071 - accuracy: 0.9746 - val_loss: 0.2855 - val_accuracy: 0.9683\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1112 - accuracy: 0.9762 - val_loss: 0.2587 - val_accuracy: 0.9769\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1057 - accuracy: 0.9773 - val_loss: 0.2921 - val_accuracy: 0.9589\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0990 - accuracy: 0.9778 - val_loss: 0.2686 - val_accuracy: 0.9696\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0998 - accuracy: 0.9781 - val_loss: 0.2572 - val_accuracy: 0.9690\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0990 - accuracy: 0.9782 - val_loss: 0.4602 - val_accuracy: 0.9173\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0961 - accuracy: 0.9789 - val_loss: 0.2589 - val_accuracy: 0.9694\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0989 - accuracy: 0.9793 - val_loss: 0.2590 - val_accuracy: 0.9716\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0941 - accuracy: 0.9808 - val_loss: 0.2601 - val_accuracy: 0.9732\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0977 - accuracy: 0.9797 - val_loss: 0.2515 - val_accuracy: 0.9734\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0946 - accuracy: 0.9806 - val_loss: 0.2446 - val_accuracy: 0.9747\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0929 - accuracy: 0.9804 - val_loss: 0.2500 - val_accuracy: 0.9694\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0923 - accuracy: 0.9801 - val_loss: 0.2363 - val_accuracy: 0.9793\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0962 - accuracy: 0.9791 - val_loss: 0.2322 - val_accuracy: 0.9745\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0890 - accuracy: 0.9806 - val_loss: 0.2663 - val_accuracy: 0.9655\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0899 - accuracy: 0.9823 - val_loss: 0.2462 - val_accuracy: 0.9749\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0944 - accuracy: 0.9809 - val_loss: 0.2373 - val_accuracy: 0.9765\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0856 - accuracy: 0.9815 - val_loss: 0.2301 - val_accuracy: 0.9773\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0874 - accuracy: 0.9819 - val_loss: 0.2689 - val_accuracy: 0.9677\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0879 - accuracy: 0.9821 - val_loss: 0.2398 - val_accuracy: 0.9747\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0864 - accuracy: 0.9830 - val_loss: 0.2403 - val_accuracy: 0.9729\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0806 - accuracy: 0.9837 - val_loss: 0.2559 - val_accuracy: 0.9705\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0901 - accuracy: 0.9824 - val_loss: 0.2263 - val_accuracy: 0.9765\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0857 - accuracy: 0.9823 - val_loss: 0.2403 - val_accuracy: 0.9736\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0858 - accuracy: 0.9840 - val_loss: 0.2382 - val_accuracy: 0.9769\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9841 - val_loss: 0.2670 - val_accuracy: 0.9666\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0907 - accuracy: 0.9807 - val_loss: 0.2194 - val_accuracy: 0.9835\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0905 - accuracy: 0.9807 - val_loss: 0.2421 - val_accuracy: 0.9756\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0799 - accuracy: 0.9842 - val_loss: 0.2441 - val_accuracy: 0.9762\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0798 - accuracy: 0.9831 - val_loss: 0.2339 - val_accuracy: 0.9798\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0800 - accuracy: 0.9832 - val_loss: 0.2302 - val_accuracy: 0.9782\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0800 - accuracy: 0.9841 - val_loss: 0.2476 - val_accuracy: 0.9758\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0811 - accuracy: 0.9815 - val_loss: 0.2442 - val_accuracy: 0.9771\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0826 - accuracy: 0.9827 - val_loss: 0.2281 - val_accuracy: 0.9791\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0776 - accuracy: 0.9833 - val_loss: 0.2615 - val_accuracy: 0.9734\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9825 - val_loss: 0.2339 - val_accuracy: 0.9767\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9846 - val_loss: 0.2964 - val_accuracy: 0.9637\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0801 - accuracy: 0.9819 - val_loss: 0.2296 - val_accuracy: 0.9820\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9832 - val_loss: 0.2545 - val_accuracy: 0.9787\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9827 - val_loss: 0.2458 - val_accuracy: 0.9729\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0725 - accuracy: 0.9862 - val_loss: 0.2294 - val_accuracy: 0.9806\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0783 - accuracy: 0.9844 - val_loss: 0.2755 - val_accuracy: 0.9648\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0705 - accuracy: 0.9858 - val_loss: 0.2403 - val_accuracy: 0.9787\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0812 - accuracy: 0.9839 - val_loss: 0.2465 - val_accuracy: 0.9727\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0692 - accuracy: 0.9876 - val_loss: 0.2427 - val_accuracy: 0.9749\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0773 - accuracy: 0.9853 - val_loss: 0.2915 - val_accuracy: 0.9655\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0738 - accuracy: 0.9854 - val_loss: 0.2402 - val_accuracy: 0.9756\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0720 - accuracy: 0.9858 - val_loss: 0.2415 - val_accuracy: 0.9778\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0756 - accuracy: 0.9846 - val_loss: 0.2380 - val_accuracy: 0.9756\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9846 - val_loss: 0.2269 - val_accuracy: 0.9809\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0734 - accuracy: 0.9853 - val_loss: 0.2308 - val_accuracy: 0.9811\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0718 - accuracy: 0.9850 - val_loss: 0.2515 - val_accuracy: 0.9751\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9832 - val_loss: 0.2312 - val_accuracy: 0.9769\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0723 - accuracy: 0.9853 - val_loss: 0.2198 - val_accuracy: 0.9842\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0717 - accuracy: 0.9870 - val_loss: 0.2753 - val_accuracy: 0.9657\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.4871 - accuracy: 0.3248 - val_loss: 2.3135 - val_accuracy: 0.5883\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.5205 - accuracy: 0.7112 - val_loss: 1.3898 - val_accuracy: 0.7672\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.8690 - accuracy: 0.8246 - val_loss: 0.9638 - val_accuracy: 0.8383\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5646 - accuracy: 0.8791 - val_loss: 0.7958 - val_accuracy: 0.8695\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4070 - accuracy: 0.9083 - val_loss: 0.6387 - val_accuracy: 0.9133\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3209 - accuracy: 0.9223 - val_loss: 0.5204 - val_accuracy: 0.9259\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2633 - accuracy: 0.9379 - val_loss: 0.4665 - val_accuracy: 0.9243\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9427 - val_loss: 0.4146 - val_accuracy: 0.9300\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2036 - accuracy: 0.9514 - val_loss: 0.4042 - val_accuracy: 0.9353\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1929 - accuracy: 0.9509 - val_loss: 0.4101 - val_accuracy: 0.9278\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1801 - accuracy: 0.9525 - val_loss: 0.3225 - val_accuracy: 0.9580\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1673 - accuracy: 0.9585 - val_loss: 0.3242 - val_accuracy: 0.9562\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1525 - accuracy: 0.9621 - val_loss: 0.3518 - val_accuracy: 0.9386\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1472 - accuracy: 0.9646 - val_loss: 0.2844 - val_accuracy: 0.9597\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1429 - accuracy: 0.9673 - val_loss: 0.3517 - val_accuracy: 0.9437\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1396 - accuracy: 0.9665 - val_loss: 0.2969 - val_accuracy: 0.9637\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1374 - accuracy: 0.9669 - val_loss: 0.2902 - val_accuracy: 0.9584\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1269 - accuracy: 0.9705 - val_loss: 0.2776 - val_accuracy: 0.9657\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1354 - accuracy: 0.9686 - val_loss: 0.2759 - val_accuracy: 0.9611\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1173 - accuracy: 0.9732 - val_loss: 0.2888 - val_accuracy: 0.9622\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1186 - accuracy: 0.9743 - val_loss: 0.2764 - val_accuracy: 0.9582\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1188 - accuracy: 0.9719 - val_loss: 0.2814 - val_accuracy: 0.9593\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1164 - accuracy: 0.9731 - val_loss: 0.3456 - val_accuracy: 0.9413\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1081 - accuracy: 0.9770 - val_loss: 0.2607 - val_accuracy: 0.9578\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1079 - accuracy: 0.9762 - val_loss: 0.2622 - val_accuracy: 0.9628\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1108 - accuracy: 0.9756 - val_loss: 0.2301 - val_accuracy: 0.9663\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1079 - accuracy: 0.9753 - val_loss: 0.2600 - val_accuracy: 0.9523\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1015 - accuracy: 0.9791 - val_loss: 0.2251 - val_accuracy: 0.9685\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1050 - accuracy: 0.9767 - val_loss: 0.2299 - val_accuracy: 0.9710\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1077 - accuracy: 0.9769 - val_loss: 0.2576 - val_accuracy: 0.9600\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1020 - accuracy: 0.9782 - val_loss: 0.2187 - val_accuracy: 0.9718\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0962 - accuracy: 0.9788 - val_loss: 0.2587 - val_accuracy: 0.9536\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1021 - accuracy: 0.9785 - val_loss: 0.2421 - val_accuracy: 0.9644\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0951 - accuracy: 0.9792 - val_loss: 0.2107 - val_accuracy: 0.9738\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1002 - accuracy: 0.9786 - val_loss: 0.2046 - val_accuracy: 0.9732\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0985 - accuracy: 0.9792 - val_loss: 0.2470 - val_accuracy: 0.9637\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0908 - accuracy: 0.9807 - val_loss: 0.2281 - val_accuracy: 0.9723\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0966 - accuracy: 0.9802 - val_loss: 0.2289 - val_accuracy: 0.9626\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0938 - accuracy: 0.9792 - val_loss: 0.2253 - val_accuracy: 0.9681\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0913 - accuracy: 0.9801 - val_loss: 0.2233 - val_accuracy: 0.9734\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0934 - accuracy: 0.9798 - val_loss: 0.2028 - val_accuracy: 0.9778\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0891 - accuracy: 0.9814 - val_loss: 0.2130 - val_accuracy: 0.9743\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0896 - accuracy: 0.9829 - val_loss: 0.2921 - val_accuracy: 0.9600\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0916 - accuracy: 0.9811 - val_loss: 0.2200 - val_accuracy: 0.9714\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0863 - accuracy: 0.9829 - val_loss: 0.2068 - val_accuracy: 0.9782\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0871 - accuracy: 0.9815 - val_loss: 0.2387 - val_accuracy: 0.9648\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0850 - accuracy: 0.9836 - val_loss: 0.2052 - val_accuracy: 0.9811\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0916 - accuracy: 0.9811 - val_loss: 0.2045 - val_accuracy: 0.9760\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9844 - val_loss: 0.2120 - val_accuracy: 0.9738\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0867 - accuracy: 0.9822 - val_loss: 0.2239 - val_accuracy: 0.9723\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9841 - val_loss: 0.2064 - val_accuracy: 0.9793\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0851 - accuracy: 0.9843 - val_loss: 0.2330 - val_accuracy: 0.9747\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0835 - accuracy: 0.9832 - val_loss: 0.2045 - val_accuracy: 0.9771\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0774 - accuracy: 0.9843 - val_loss: 0.2493 - val_accuracy: 0.9701\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0864 - accuracy: 0.9828 - val_loss: 0.2016 - val_accuracy: 0.9784\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0849 - accuracy: 0.9831 - val_loss: 0.1982 - val_accuracy: 0.9850\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0785 - accuracy: 0.9835 - val_loss: 0.2192 - val_accuracy: 0.9727\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9834 - val_loss: 0.2119 - val_accuracy: 0.9760\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0765 - accuracy: 0.9849 - val_loss: 0.1964 - val_accuracy: 0.9826\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0813 - accuracy: 0.9832 - val_loss: 0.2093 - val_accuracy: 0.9729\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0737 - accuracy: 0.9855 - val_loss: 0.1987 - val_accuracy: 0.9789\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0820 - accuracy: 0.9836 - val_loss: 0.1904 - val_accuracy: 0.9815\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9826 - val_loss: 0.2448 - val_accuracy: 0.9626\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0776 - accuracy: 0.9837 - val_loss: 0.2223 - val_accuracy: 0.9734\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9833 - val_loss: 0.2220 - val_accuracy: 0.9685\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0703 - accuracy: 0.9866 - val_loss: 0.2561 - val_accuracy: 0.9560\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0800 - accuracy: 0.9827 - val_loss: 0.2524 - val_accuracy: 0.9663\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9841 - val_loss: 0.2058 - val_accuracy: 0.9806\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0779 - accuracy: 0.9832 - val_loss: 0.2173 - val_accuracy: 0.9760\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0706 - accuracy: 0.9873 - val_loss: 0.2023 - val_accuracy: 0.9756\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0746 - accuracy: 0.9836 - val_loss: 0.2089 - val_accuracy: 0.9800\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0755 - accuracy: 0.9837 - val_loss: 0.1915 - val_accuracy: 0.9831\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0714 - accuracy: 0.9863 - val_loss: 0.2379 - val_accuracy: 0.9725\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0783 - accuracy: 0.9831 - val_loss: 0.1996 - val_accuracy: 0.9798\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0695 - accuracy: 0.9858 - val_loss: 0.2071 - val_accuracy: 0.9780\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0783 - accuracy: 0.9833 - val_loss: 0.1955 - val_accuracy: 0.9828\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0655 - accuracy: 0.9875 - val_loss: 0.1927 - val_accuracy: 0.9787\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0705 - accuracy: 0.9860 - val_loss: 0.2075 - val_accuracy: 0.9765\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9826 - val_loss: 0.1937 - val_accuracy: 0.9789\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0678 - accuracy: 0.9870 - val_loss: 0.2214 - val_accuracy: 0.9716\n",
      "Average Validation Accuracy: 0.9756745398044586\n",
      "Average Validation Loss: 0.1425677016377449\n",
      "Average Test Accuracy: 0.9768924713134766\n",
      "Final Test Accuracy for each fold: 0.9786983132362366\n",
      "Number of input features: 19\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.3210 - accuracy: 0.3845 - val_loss: 2.0549 - val_accuracy: 0.6574\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 1.3258 - accuracy: 0.7600 - val_loss: 1.1775 - val_accuracy: 0.8134\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7230 - accuracy: 0.8571 - val_loss: 0.7904 - val_accuracy: 0.8717\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4736 - accuracy: 0.8952 - val_loss: 0.6453 - val_accuracy: 0.8849\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3534 - accuracy: 0.9164 - val_loss: 0.5335 - val_accuracy: 0.9025\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2974 - accuracy: 0.9223 - val_loss: 0.5037 - val_accuracy: 0.9091\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2541 - accuracy: 0.9354 - val_loss: 0.4366 - val_accuracy: 0.9314\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2181 - accuracy: 0.9445 - val_loss: 0.4484 - val_accuracy: 0.9168\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1999 - accuracy: 0.9484 - val_loss: 0.4808 - val_accuracy: 0.8966\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1852 - accuracy: 0.9533 - val_loss: 0.3735 - val_accuracy: 0.9395\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1781 - accuracy: 0.9540 - val_loss: 0.3464 - val_accuracy: 0.9397\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1630 - accuracy: 0.9583 - val_loss: 0.3563 - val_accuracy: 0.9446\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1605 - accuracy: 0.9589 - val_loss: 0.3359 - val_accuracy: 0.9562\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1420 - accuracy: 0.9642 - val_loss: 0.3185 - val_accuracy: 0.9523\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1469 - accuracy: 0.9633 - val_loss: 0.3230 - val_accuracy: 0.9575\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1449 - accuracy: 0.9649 - val_loss: 0.3535 - val_accuracy: 0.9446\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1314 - accuracy: 0.9704 - val_loss: 0.3146 - val_accuracy: 0.9567\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1369 - accuracy: 0.9695 - val_loss: 0.3260 - val_accuracy: 0.9549\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1260 - accuracy: 0.9718 - val_loss: 0.3190 - val_accuracy: 0.9619\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1255 - accuracy: 0.9724 - val_loss: 0.2953 - val_accuracy: 0.9624\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1218 - accuracy: 0.9719 - val_loss: 0.2865 - val_accuracy: 0.9666\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1276 - accuracy: 0.9689 - val_loss: 0.2744 - val_accuracy: 0.9734\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1130 - accuracy: 0.9742 - val_loss: 0.2763 - val_accuracy: 0.9674\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1142 - accuracy: 0.9741 - val_loss: 0.2692 - val_accuracy: 0.9674\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1165 - accuracy: 0.9719 - val_loss: 0.2681 - val_accuracy: 0.9690\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1076 - accuracy: 0.9765 - val_loss: 0.2904 - val_accuracy: 0.9582\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1119 - accuracy: 0.9753 - val_loss: 0.2677 - val_accuracy: 0.9668\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.1089 - accuracy: 0.9764 - val_loss: 0.3239 - val_accuracy: 0.9452\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 0.1008 - accuracy: 0.9788 - val_loss: 0.2571 - val_accuracy: 0.9743\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1070 - accuracy: 0.9768 - val_loss: 0.2663 - val_accuracy: 0.9721\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1013 - accuracy: 0.9796 - val_loss: 0.2993 - val_accuracy: 0.9652\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1048 - accuracy: 0.9754 - val_loss: 0.3068 - val_accuracy: 0.9593\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0963 - accuracy: 0.9793 - val_loss: 0.2544 - val_accuracy: 0.9743\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1030 - accuracy: 0.9777 - val_loss: 0.2558 - val_accuracy: 0.9756\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1021 - accuracy: 0.9785 - val_loss: 0.3216 - val_accuracy: 0.9545\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0994 - accuracy: 0.9791 - val_loss: 0.2622 - val_accuracy: 0.9732\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1009 - accuracy: 0.9797 - val_loss: 0.3149 - val_accuracy: 0.9529\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1003 - accuracy: 0.9794 - val_loss: 0.2726 - val_accuracy: 0.9762\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1009 - accuracy: 0.9782 - val_loss: 0.2749 - val_accuracy: 0.9723\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0889 - accuracy: 0.9827 - val_loss: 0.2495 - val_accuracy: 0.9784\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0973 - accuracy: 0.9794 - val_loss: 0.2626 - val_accuracy: 0.9692\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0918 - accuracy: 0.9812 - val_loss: 0.3043 - val_accuracy: 0.9608\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0861 - accuracy: 0.9822 - val_loss: 0.2550 - val_accuracy: 0.9776\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0999 - accuracy: 0.9783 - val_loss: 0.2500 - val_accuracy: 0.9765\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0887 - accuracy: 0.9810 - val_loss: 0.3127 - val_accuracy: 0.9595\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0893 - accuracy: 0.9823 - val_loss: 0.2503 - val_accuracy: 0.9811\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0937 - accuracy: 0.9794 - val_loss: 0.2596 - val_accuracy: 0.9749\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0909 - accuracy: 0.9803 - val_loss: 0.2703 - val_accuracy: 0.9705\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0849 - accuracy: 0.9820 - val_loss: 0.2618 - val_accuracy: 0.9727\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0883 - accuracy: 0.9825 - val_loss: 0.2574 - val_accuracy: 0.9815\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0852 - accuracy: 0.9832 - val_loss: 0.2560 - val_accuracy: 0.9769\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0841 - accuracy: 0.9837 - val_loss: 0.2550 - val_accuracy: 0.9767\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0848 - accuracy: 0.9830 - val_loss: 0.2555 - val_accuracy: 0.9771\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9831 - val_loss: 0.2624 - val_accuracy: 0.9767\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0833 - accuracy: 0.9835 - val_loss: 0.2752 - val_accuracy: 0.9718\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0885 - accuracy: 0.9802 - val_loss: 0.2540 - val_accuracy: 0.9782\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0867 - accuracy: 0.9832 - val_loss: 0.2509 - val_accuracy: 0.9804\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0772 - accuracy: 0.9835 - val_loss: 0.2509 - val_accuracy: 0.9822\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0878 - accuracy: 0.9815 - val_loss: 0.2522 - val_accuracy: 0.9809\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0835 - accuracy: 0.9828 - val_loss: 0.2477 - val_accuracy: 0.9802\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0787 - accuracy: 0.9828 - val_loss: 0.4067 - val_accuracy: 0.9259\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0816 - accuracy: 0.9830 - val_loss: 0.2701 - val_accuracy: 0.9703\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0805 - accuracy: 0.9824 - val_loss: 0.2848 - val_accuracy: 0.9710\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0794 - accuracy: 0.9843 - val_loss: 0.2571 - val_accuracy: 0.9789\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0824 - accuracy: 0.9833 - val_loss: 0.2411 - val_accuracy: 0.9828\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0758 - accuracy: 0.9867 - val_loss: 0.2529 - val_accuracy: 0.9769\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9830 - val_loss: 0.2497 - val_accuracy: 0.9802\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0777 - accuracy: 0.9846 - val_loss: 0.2546 - val_accuracy: 0.9804\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0761 - accuracy: 0.9846 - val_loss: 0.2596 - val_accuracy: 0.9734\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0795 - accuracy: 0.9834 - val_loss: 0.2909 - val_accuracy: 0.9578\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0735 - accuracy: 0.9856 - val_loss: 0.2461 - val_accuracy: 0.9811\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0859 - accuracy: 0.9829 - val_loss: 0.2843 - val_accuracy: 0.9725\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0682 - accuracy: 0.9879 - val_loss: 0.2706 - val_accuracy: 0.9749\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0773 - accuracy: 0.9847 - val_loss: 0.2614 - val_accuracy: 0.9767\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0693 - accuracy: 0.9878 - val_loss: 0.3522 - val_accuracy: 0.9514\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0784 - accuracy: 0.9836 - val_loss: 0.2422 - val_accuracy: 0.9844\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9855 - val_loss: 0.2579 - val_accuracy: 0.9767\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0724 - accuracy: 0.9845 - val_loss: 0.2532 - val_accuracy: 0.9815\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0751 - accuracy: 0.9848 - val_loss: 0.2483 - val_accuracy: 0.9828\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0778 - accuracy: 0.9831 - val_loss: 0.2594 - val_accuracy: 0.9817\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.3439 - accuracy: 0.3717 - val_loss: 2.1499 - val_accuracy: 0.5945\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.3943 - accuracy: 0.7384 - val_loss: 1.2986 - val_accuracy: 0.7925\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7988 - accuracy: 0.8447 - val_loss: 0.9591 - val_accuracy: 0.8471\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.5380 - accuracy: 0.8878 - val_loss: 0.7420 - val_accuracy: 0.8964\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3968 - accuracy: 0.9133 - val_loss: 0.6301 - val_accuracy: 0.9069\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3235 - accuracy: 0.9261 - val_loss: 0.5188 - val_accuracy: 0.9263\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2668 - accuracy: 0.9374 - val_loss: 0.4954 - val_accuracy: 0.9149\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2360 - accuracy: 0.9453 - val_loss: 0.4075 - val_accuracy: 0.9388\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.2049 - accuracy: 0.9518 - val_loss: 0.4204 - val_accuracy: 0.9204\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1898 - accuracy: 0.9555 - val_loss: 0.3783 - val_accuracy: 0.9426\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1812 - accuracy: 0.9531 - val_loss: 0.3433 - val_accuracy: 0.9494\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1693 - accuracy: 0.9583 - val_loss: 0.3358 - val_accuracy: 0.9589\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.1577 - accuracy: 0.9627 - val_loss: 0.3042 - val_accuracy: 0.9569\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1523 - accuracy: 0.9623 - val_loss: 0.3431 - val_accuracy: 0.9468\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1386 - accuracy: 0.9685 - val_loss: 0.3001 - val_accuracy: 0.9584\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1399 - accuracy: 0.9688 - val_loss: 0.3047 - val_accuracy: 0.9558\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1431 - accuracy: 0.9645 - val_loss: 0.2979 - val_accuracy: 0.9628\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1251 - accuracy: 0.9712 - val_loss: 0.3035 - val_accuracy: 0.9586\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1260 - accuracy: 0.9710 - val_loss: 0.2839 - val_accuracy: 0.9615\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1239 - accuracy: 0.9731 - val_loss: 0.2698 - val_accuracy: 0.9624\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1271 - accuracy: 0.9719 - val_loss: 0.2716 - val_accuracy: 0.9635\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1185 - accuracy: 0.9726 - val_loss: 0.2807 - val_accuracy: 0.9619\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1196 - accuracy: 0.9719 - val_loss: 0.3040 - val_accuracy: 0.9538\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1118 - accuracy: 0.9764 - val_loss: 0.2529 - val_accuracy: 0.9617\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1144 - accuracy: 0.9751 - val_loss: 0.2468 - val_accuracy: 0.9661\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1160 - accuracy: 0.9732 - val_loss: 0.2396 - val_accuracy: 0.9650\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1036 - accuracy: 0.9778 - val_loss: 0.2653 - val_accuracy: 0.9641\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1144 - accuracy: 0.9765 - val_loss: 0.2257 - val_accuracy: 0.9696\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1036 - accuracy: 0.9782 - val_loss: 0.2295 - val_accuracy: 0.9723\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1003 - accuracy: 0.9798 - val_loss: 0.2404 - val_accuracy: 0.9670\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1051 - accuracy: 0.9754 - val_loss: 0.2366 - val_accuracy: 0.9666\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1025 - accuracy: 0.9773 - val_loss: 0.2667 - val_accuracy: 0.9505\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1012 - accuracy: 0.9777 - val_loss: 0.2280 - val_accuracy: 0.9725\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1021 - accuracy: 0.9785 - val_loss: 0.2781 - val_accuracy: 0.9560\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1026 - accuracy: 0.9792 - val_loss: 0.2402 - val_accuracy: 0.9690\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0943 - accuracy: 0.9795 - val_loss: 0.2744 - val_accuracy: 0.9580\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0986 - accuracy: 0.9803 - val_loss: 0.2557 - val_accuracy: 0.9668\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0975 - accuracy: 0.9790 - val_loss: 0.2140 - val_accuracy: 0.9718\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0965 - accuracy: 0.9788 - val_loss: 0.2542 - val_accuracy: 0.9608\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0914 - accuracy: 0.9813 - val_loss: 0.2375 - val_accuracy: 0.9685\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0941 - accuracy: 0.9801 - val_loss: 0.2279 - val_accuracy: 0.9732\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0916 - accuracy: 0.9804 - val_loss: 0.2394 - val_accuracy: 0.9644\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0900 - accuracy: 0.9826 - val_loss: 0.2272 - val_accuracy: 0.9725\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0989 - accuracy: 0.9779 - val_loss: 0.2315 - val_accuracy: 0.9712\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0852 - accuracy: 0.9829 - val_loss: 0.2218 - val_accuracy: 0.9745\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0885 - accuracy: 0.9826 - val_loss: 0.2141 - val_accuracy: 0.9767\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0924 - accuracy: 0.9801 - val_loss: 0.2266 - val_accuracy: 0.9712\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0787 - accuracy: 0.9847 - val_loss: 0.2393 - val_accuracy: 0.9685\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0935 - accuracy: 0.9806 - val_loss: 0.2258 - val_accuracy: 0.9740\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0820 - accuracy: 0.9837 - val_loss: 0.2202 - val_accuracy: 0.9756\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0875 - accuracy: 0.9809 - val_loss: 0.2118 - val_accuracy: 0.9736\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0802 - accuracy: 0.9854 - val_loss: 0.2232 - val_accuracy: 0.9712\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0902 - accuracy: 0.9802 - val_loss: 0.2293 - val_accuracy: 0.9703\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0906 - accuracy: 0.9815 - val_loss: 0.2224 - val_accuracy: 0.9771\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9824 - val_loss: 0.2121 - val_accuracy: 0.9804\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0867 - accuracy: 0.9824 - val_loss: 0.2231 - val_accuracy: 0.9683\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0813 - accuracy: 0.9833 - val_loss: 0.2799 - val_accuracy: 0.9624\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0786 - accuracy: 0.9847 - val_loss: 0.3017 - val_accuracy: 0.9562\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0839 - accuracy: 0.9822 - val_loss: 0.2308 - val_accuracy: 0.9738\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9824 - val_loss: 0.2306 - val_accuracy: 0.9756\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0868 - accuracy: 0.9840 - val_loss: 0.2458 - val_accuracy: 0.9672\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0728 - accuracy: 0.9871 - val_loss: 0.2448 - val_accuracy: 0.9718\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0850 - accuracy: 0.9806 - val_loss: 0.2343 - val_accuracy: 0.9703\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0818 - accuracy: 0.9836 - val_loss: 0.2523 - val_accuracy: 0.9639\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9841 - val_loss: 0.2118 - val_accuracy: 0.9767\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9836 - val_loss: 0.2482 - val_accuracy: 0.9712\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0732 - accuracy: 0.9856 - val_loss: 0.2353 - val_accuracy: 0.9747\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0795 - accuracy: 0.9836 - val_loss: 0.2035 - val_accuracy: 0.9817\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9840 - val_loss: 0.2090 - val_accuracy: 0.9800\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0752 - accuracy: 0.9855 - val_loss: 0.2362 - val_accuracy: 0.9725\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0808 - accuracy: 0.9831 - val_loss: 0.2169 - val_accuracy: 0.9787\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0769 - accuracy: 0.9836 - val_loss: 0.2283 - val_accuracy: 0.9736\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0709 - accuracy: 0.9873 - val_loss: 0.2484 - val_accuracy: 0.9718\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0723 - accuracy: 0.9841 - val_loss: 0.2181 - val_accuracy: 0.9773\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0802 - accuracy: 0.9832 - val_loss: 0.2495 - val_accuracy: 0.9648\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0736 - accuracy: 0.9859 - val_loss: 0.2057 - val_accuracy: 0.9817\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0742 - accuracy: 0.9858 - val_loss: 0.2601 - val_accuracy: 0.9663\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0765 - accuracy: 0.9848 - val_loss: 0.2120 - val_accuracy: 0.9817\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0751 - accuracy: 0.9852 - val_loss: 0.2226 - val_accuracy: 0.9773\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0753 - accuracy: 0.9837 - val_loss: 0.2222 - val_accuracy: 0.9769\n",
      "Average Validation Accuracy: 0.9835166335105896\n",
      "Average Validation Loss: 0.1284957267343998\n",
      "Average Test Accuracy: 0.9842264354228973\n",
      "Final Test Accuracy for each fold: 0.9858480095863342\n",
      "Number of input features: 20\n",
      "Fold: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 7s 3ms/step - loss: 3.2953 - accuracy: 0.3775 - val_loss: 2.0482 - val_accuracy: 0.6484\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 1.3424 - accuracy: 0.7517 - val_loss: 1.1386 - val_accuracy: 0.8062\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.7164 - accuracy: 0.8550 - val_loss: 0.7431 - val_accuracy: 0.8746\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.4492 - accuracy: 0.8993 - val_loss: 0.5957 - val_accuracy: 0.8959\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.3304 - accuracy: 0.9228 - val_loss: 0.4967 - val_accuracy: 0.9160\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2746 - accuracy: 0.9329 - val_loss: 0.4557 - val_accuracy: 0.9107\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2363 - accuracy: 0.9421 - val_loss: 0.3760 - val_accuracy: 0.9294\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2146 - accuracy: 0.9457 - val_loss: 0.3615 - val_accuracy: 0.9446\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2004 - accuracy: 0.9487 - val_loss: 0.3621 - val_accuracy: 0.9307\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1836 - accuracy: 0.9532 - val_loss: 0.3099 - val_accuracy: 0.9483\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1729 - accuracy: 0.9549 - val_loss: 0.2866 - val_accuracy: 0.9604\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1634 - accuracy: 0.9590 - val_loss: 0.3656 - val_accuracy: 0.9410\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1609 - accuracy: 0.9577 - val_loss: 0.3210 - val_accuracy: 0.9483\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1482 - accuracy: 0.9634 - val_loss: 0.3297 - val_accuracy: 0.9402\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1484 - accuracy: 0.9620 - val_loss: 0.2761 - val_accuracy: 0.9593\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1364 - accuracy: 0.9681 - val_loss: 0.2992 - val_accuracy: 0.9483\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1381 - accuracy: 0.9644 - val_loss: 0.2495 - val_accuracy: 0.9639\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1341 - accuracy: 0.9695 - val_loss: 0.2532 - val_accuracy: 0.9619\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1299 - accuracy: 0.9686 - val_loss: 0.3181 - val_accuracy: 0.9481\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1271 - accuracy: 0.9715 - val_loss: 0.2643 - val_accuracy: 0.9650\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1311 - accuracy: 0.9682 - val_loss: 0.2890 - val_accuracy: 0.9549\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1193 - accuracy: 0.9730 - val_loss: 0.2927 - val_accuracy: 0.9595\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1196 - accuracy: 0.9733 - val_loss: 0.2452 - val_accuracy: 0.9694\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1135 - accuracy: 0.9732 - val_loss: 0.2306 - val_accuracy: 0.9701\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1185 - accuracy: 0.9733 - val_loss: 0.2307 - val_accuracy: 0.9725\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1187 - accuracy: 0.9721 - val_loss: 0.2344 - val_accuracy: 0.9762\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1035 - accuracy: 0.9771 - val_loss: 0.2581 - val_accuracy: 0.9666\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1098 - accuracy: 0.9758 - val_loss: 0.2359 - val_accuracy: 0.9749\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1107 - accuracy: 0.9756 - val_loss: 0.2423 - val_accuracy: 0.9703\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1064 - accuracy: 0.9766 - val_loss: 0.2333 - val_accuracy: 0.9745\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1050 - accuracy: 0.9766 - val_loss: 0.2401 - val_accuracy: 0.9738\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0994 - accuracy: 0.9781 - val_loss: 0.2427 - val_accuracy: 0.9696\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1080 - accuracy: 0.9760 - val_loss: 0.2668 - val_accuracy: 0.9613\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0993 - accuracy: 0.9788 - val_loss: 0.4147 - val_accuracy: 0.9300\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0993 - accuracy: 0.9785 - val_loss: 0.2640 - val_accuracy: 0.9725\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1066 - accuracy: 0.9765 - val_loss: 0.2443 - val_accuracy: 0.9714\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1040 - accuracy: 0.9779 - val_loss: 0.2732 - val_accuracy: 0.9650\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0968 - accuracy: 0.9799 - val_loss: 0.2421 - val_accuracy: 0.9732\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0981 - accuracy: 0.9781 - val_loss: 0.2336 - val_accuracy: 0.9813\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0947 - accuracy: 0.9806 - val_loss: 0.3156 - val_accuracy: 0.9558\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0931 - accuracy: 0.9799 - val_loss: 0.2349 - val_accuracy: 0.9756\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0917 - accuracy: 0.9799 - val_loss: 0.2245 - val_accuracy: 0.9809\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0947 - accuracy: 0.9811 - val_loss: 0.2604 - val_accuracy: 0.9685\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1027 - accuracy: 0.9769 - val_loss: 0.2377 - val_accuracy: 0.9749\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0936 - accuracy: 0.9804 - val_loss: 0.2757 - val_accuracy: 0.9644\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0893 - accuracy: 0.9807 - val_loss: 0.2454 - val_accuracy: 0.9791\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0925 - accuracy: 0.9816 - val_loss: 0.2587 - val_accuracy: 0.9714\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0891 - accuracy: 0.9806 - val_loss: 0.2290 - val_accuracy: 0.9747\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0921 - accuracy: 0.9809 - val_loss: 0.2337 - val_accuracy: 0.9773\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0911 - accuracy: 0.9804 - val_loss: 0.2272 - val_accuracy: 0.9791\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0934 - accuracy: 0.9803 - val_loss: 0.2500 - val_accuracy: 0.9729\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0828 - accuracy: 0.9830 - val_loss: 0.2300 - val_accuracy: 0.9813\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0879 - accuracy: 0.9810 - val_loss: 0.2394 - val_accuracy: 0.9729\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0852 - accuracy: 0.9818 - val_loss: 0.2795 - val_accuracy: 0.9613\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 0.0844 - accuracy: 0.9835 - val_loss: 0.2286 - val_accuracy: 0.9769\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0875 - accuracy: 0.9810 - val_loss: 0.2487 - val_accuracy: 0.9699\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 0.0870 - accuracy: 0.9823 - val_loss: 0.2352 - val_accuracy: 0.9769\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.0823 - accuracy: 0.9837 - val_loss: 0.2757 - val_accuracy: 0.9670\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0912 - accuracy: 0.9803 - val_loss: 0.2217 - val_accuracy: 0.9802\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0876 - accuracy: 0.9808 - val_loss: 0.2621 - val_accuracy: 0.9696\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0819 - accuracy: 0.9835 - val_loss: 0.2353 - val_accuracy: 0.9765\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0854 - accuracy: 0.9827 - val_loss: 0.2329 - val_accuracy: 0.9778\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0804 - accuracy: 0.9833 - val_loss: 0.2522 - val_accuracy: 0.9743\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0854 - accuracy: 0.9817 - val_loss: 0.2322 - val_accuracy: 0.9758\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0786 - accuracy: 0.9845 - val_loss: 0.2237 - val_accuracy: 0.9822\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0880 - accuracy: 0.9814 - val_loss: 0.2214 - val_accuracy: 0.9787\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0747 - accuracy: 0.9857 - val_loss: 0.2432 - val_accuracy: 0.9725\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0847 - accuracy: 0.9825 - val_loss: 0.2289 - val_accuracy: 0.9802\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0801 - accuracy: 0.9832 - val_loss: 0.2144 - val_accuracy: 0.9824\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0738 - accuracy: 0.9860 - val_loss: 0.2232 - val_accuracy: 0.9793\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0761 - accuracy: 0.9846 - val_loss: 0.2473 - val_accuracy: 0.9712\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0798 - accuracy: 0.9844 - val_loss: 0.2422 - val_accuracy: 0.9784\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0805 - accuracy: 0.9849 - val_loss: 0.2523 - val_accuracy: 0.9685\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0784 - accuracy: 0.9830 - val_loss: 0.2533 - val_accuracy: 0.9762\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0772 - accuracy: 0.9823 - val_loss: 0.2774 - val_accuracy: 0.9670\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0752 - accuracy: 0.9856 - val_loss: 0.2207 - val_accuracy: 0.9811\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0746 - accuracy: 0.9853 - val_loss: 0.2438 - val_accuracy: 0.9751\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0802 - accuracy: 0.9834 - val_loss: 0.2260 - val_accuracy: 0.9820\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0801 - accuracy: 0.9830 - val_loss: 0.2288 - val_accuracy: 0.9793\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0705 - accuracy: 0.9868 - val_loss: 0.2293 - val_accuracy: 0.9795\n",
      "Fold: 2\n",
      "Epoch 1/80\n",
      "1846/1846 [==============================] - 8s 3ms/step - loss: 3.3086 - accuracy: 0.3724 - val_loss: 1.9765 - val_accuracy: 0.6559\n",
      "Epoch 2/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 1.2377 - accuracy: 0.7593 - val_loss: 1.0767 - val_accuracy: 0.8194\n",
      "Epoch 3/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.6448 - accuracy: 0.8666 - val_loss: 0.8048 - val_accuracy: 0.8502\n",
      "Epoch 4/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.4045 - accuracy: 0.9096 - val_loss: 0.5446 - val_accuracy: 0.9228\n",
      "Epoch 5/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2954 - accuracy: 0.9349 - val_loss: 0.4438 - val_accuracy: 0.9296\n",
      "Epoch 6/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.2374 - accuracy: 0.9438 - val_loss: 0.3947 - val_accuracy: 0.9344\n",
      "Epoch 7/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.2118 - accuracy: 0.9472 - val_loss: 0.3524 - val_accuracy: 0.9406\n",
      "Epoch 8/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1789 - accuracy: 0.9570 - val_loss: 0.2953 - val_accuracy: 0.9542\n",
      "Epoch 9/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1719 - accuracy: 0.9570 - val_loss: 0.2833 - val_accuracy: 0.9529\n",
      "Epoch 10/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1555 - accuracy: 0.9638 - val_loss: 0.3021 - val_accuracy: 0.9529\n",
      "Epoch 11/80\n",
      "1846/1846 [==============================] - 8s 4ms/step - loss: 0.1480 - accuracy: 0.9649 - val_loss: 0.2740 - val_accuracy: 0.9542\n",
      "Epoch 12/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1491 - accuracy: 0.9635 - val_loss: 0.2583 - val_accuracy: 0.9606\n",
      "Epoch 13/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1339 - accuracy: 0.9691 - val_loss: 0.2662 - val_accuracy: 0.9597\n",
      "Epoch 14/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1374 - accuracy: 0.9693 - val_loss: 0.3068 - val_accuracy: 0.9421\n",
      "Epoch 15/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1228 - accuracy: 0.9718 - val_loss: 0.3249 - val_accuracy: 0.9311\n",
      "Epoch 16/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1327 - accuracy: 0.9689 - val_loss: 0.2702 - val_accuracy: 0.9520\n",
      "Epoch 17/80\n",
      "1846/1846 [==============================] - 7s 4ms/step - loss: 0.1240 - accuracy: 0.9720 - val_loss: 0.2327 - val_accuracy: 0.9661\n",
      "Epoch 18/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1152 - accuracy: 0.9744 - val_loss: 0.2207 - val_accuracy: 0.9718\n",
      "Epoch 19/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1197 - accuracy: 0.9731 - val_loss: 0.2166 - val_accuracy: 0.9747\n",
      "Epoch 20/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1169 - accuracy: 0.9715 - val_loss: 0.2371 - val_accuracy: 0.9668\n",
      "Epoch 21/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1106 - accuracy: 0.9754 - val_loss: 0.2087 - val_accuracy: 0.9747\n",
      "Epoch 22/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1086 - accuracy: 0.9759 - val_loss: 0.2159 - val_accuracy: 0.9732\n",
      "Epoch 23/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9754 - val_loss: 0.2392 - val_accuracy: 0.9635\n",
      "Epoch 24/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.1088 - accuracy: 0.9762 - val_loss: 0.2465 - val_accuracy: 0.9613\n",
      "Epoch 25/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1039 - accuracy: 0.9783 - val_loss: 0.2885 - val_accuracy: 0.9567\n",
      "Epoch 26/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1095 - accuracy: 0.9751 - val_loss: 0.2376 - val_accuracy: 0.9690\n",
      "Epoch 27/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1003 - accuracy: 0.9788 - val_loss: 0.2337 - val_accuracy: 0.9694\n",
      "Epoch 28/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1011 - accuracy: 0.9777 - val_loss: 0.2854 - val_accuracy: 0.9567\n",
      "Epoch 29/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.1035 - accuracy: 0.9769 - val_loss: 0.2525 - val_accuracy: 0.9655\n",
      "Epoch 30/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0948 - accuracy: 0.9803 - val_loss: 0.2219 - val_accuracy: 0.9714\n",
      "Epoch 31/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0960 - accuracy: 0.9804 - val_loss: 0.2443 - val_accuracy: 0.9727\n",
      "Epoch 32/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0941 - accuracy: 0.9788 - val_loss: 0.2352 - val_accuracy: 0.9740\n",
      "Epoch 33/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0961 - accuracy: 0.9795 - val_loss: 0.2256 - val_accuracy: 0.9754\n",
      "Epoch 34/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0941 - accuracy: 0.9805 - val_loss: 0.2150 - val_accuracy: 0.9751\n",
      "Epoch 35/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0921 - accuracy: 0.9815 - val_loss: 0.2310 - val_accuracy: 0.9701\n",
      "Epoch 36/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0945 - accuracy: 0.9809 - val_loss: 0.2858 - val_accuracy: 0.9582\n",
      "Epoch 37/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0970 - accuracy: 0.9807 - val_loss: 0.2180 - val_accuracy: 0.9773\n",
      "Epoch 38/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0857 - accuracy: 0.9830 - val_loss: 0.2271 - val_accuracy: 0.9747\n",
      "Epoch 39/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0955 - accuracy: 0.9790 - val_loss: 0.2652 - val_accuracy: 0.9637\n",
      "Epoch 40/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0867 - accuracy: 0.9823 - val_loss: 0.2245 - val_accuracy: 0.9747\n",
      "Epoch 41/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0939 - accuracy: 0.9802 - val_loss: 0.2218 - val_accuracy: 0.9813\n",
      "Epoch 42/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0882 - accuracy: 0.9827 - val_loss: 0.2397 - val_accuracy: 0.9661\n",
      "Epoch 43/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0904 - accuracy: 0.9805 - val_loss: 0.2263 - val_accuracy: 0.9655\n",
      "Epoch 44/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0862 - accuracy: 0.9833 - val_loss: 0.2160 - val_accuracy: 0.9762\n",
      "Epoch 45/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0896 - accuracy: 0.9806 - val_loss: 0.2213 - val_accuracy: 0.9806\n",
      "Epoch 46/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0861 - accuracy: 0.9826 - val_loss: 0.2470 - val_accuracy: 0.9679\n",
      "Epoch 47/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0928 - accuracy: 0.9800 - val_loss: 0.2248 - val_accuracy: 0.9734\n",
      "Epoch 48/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0796 - accuracy: 0.9827 - val_loss: 0.2675 - val_accuracy: 0.9672\n",
      "Epoch 49/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0843 - accuracy: 0.9822 - val_loss: 0.2252 - val_accuracy: 0.9771\n",
      "Epoch 50/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0810 - accuracy: 0.9822 - val_loss: 0.2089 - val_accuracy: 0.9846\n",
      "Epoch 51/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0796 - accuracy: 0.9846 - val_loss: 0.2185 - val_accuracy: 0.9787\n",
      "Epoch 52/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0779 - accuracy: 0.9846 - val_loss: 0.2373 - val_accuracy: 0.9727\n",
      "Epoch 53/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0868 - accuracy: 0.9833 - val_loss: 0.2220 - val_accuracy: 0.9745\n",
      "Epoch 54/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0896 - accuracy: 0.9809 - val_loss: 0.2017 - val_accuracy: 0.9828\n",
      "Epoch 55/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0804 - accuracy: 0.9834 - val_loss: 0.2040 - val_accuracy: 0.9769\n",
      "Epoch 56/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0763 - accuracy: 0.9847 - val_loss: 0.2056 - val_accuracy: 0.9782\n",
      "Epoch 57/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0797 - accuracy: 0.9844 - val_loss: 0.2491 - val_accuracy: 0.9644\n",
      "Epoch 58/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0819 - accuracy: 0.9834 - val_loss: 0.2127 - val_accuracy: 0.9802\n",
      "Epoch 59/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0761 - accuracy: 0.9841 - val_loss: 0.2114 - val_accuracy: 0.9800\n",
      "Epoch 60/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0801 - accuracy: 0.9824 - val_loss: 0.2221 - val_accuracy: 0.9758\n",
      "Epoch 61/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0746 - accuracy: 0.9847 - val_loss: 0.2082 - val_accuracy: 0.9787\n",
      "Epoch 62/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0813 - accuracy: 0.9839 - val_loss: 0.2173 - val_accuracy: 0.9734\n",
      "Epoch 63/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0806 - accuracy: 0.9844 - val_loss: 0.2418 - val_accuracy: 0.9723\n",
      "Epoch 64/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0734 - accuracy: 0.9858 - val_loss: 0.2122 - val_accuracy: 0.9806\n",
      "Epoch 65/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0750 - accuracy: 0.9846 - val_loss: 0.2236 - val_accuracy: 0.9747\n",
      "Epoch 66/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9828 - val_loss: 0.2183 - val_accuracy: 0.9815\n",
      "Epoch 67/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0684 - accuracy: 0.9880 - val_loss: 0.2311 - val_accuracy: 0.9736\n",
      "Epoch 68/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0752 - accuracy: 0.9849 - val_loss: 0.2698 - val_accuracy: 0.9637\n",
      "Epoch 69/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0757 - accuracy: 0.9836 - val_loss: 0.2483 - val_accuracy: 0.9683\n",
      "Epoch 70/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0782 - accuracy: 0.9842 - val_loss: 0.2292 - val_accuracy: 0.9754\n",
      "Epoch 71/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0715 - accuracy: 0.9863 - val_loss: 0.2153 - val_accuracy: 0.9784\n",
      "Epoch 72/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0744 - accuracy: 0.9845 - val_loss: 0.2669 - val_accuracy: 0.9613\n",
      "Epoch 73/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0763 - accuracy: 0.9845 - val_loss: 0.2398 - val_accuracy: 0.9782\n",
      "Epoch 74/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0753 - accuracy: 0.9842 - val_loss: 0.2046 - val_accuracy: 0.9837\n",
      "Epoch 75/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0696 - accuracy: 0.9858 - val_loss: 0.2211 - val_accuracy: 0.9793\n",
      "Epoch 76/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0743 - accuracy: 0.9847 - val_loss: 0.2188 - val_accuracy: 0.9806\n",
      "Epoch 77/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9833 - val_loss: 0.2210 - val_accuracy: 0.9771\n",
      "Epoch 78/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0678 - accuracy: 0.9871 - val_loss: 0.2313 - val_accuracy: 0.9762\n",
      "Epoch 79/80\n",
      "1846/1846 [==============================] - 5s 3ms/step - loss: 0.0703 - accuracy: 0.9853 - val_loss: 0.2268 - val_accuracy: 0.9747\n",
      "Epoch 80/80\n",
      "1846/1846 [==============================] - 6s 3ms/step - loss: 0.0691 - accuracy: 0.9848 - val_loss: 0.2308 - val_accuracy: 0.9681\n",
      "Average Validation Accuracy: 0.9788692891597748\n",
      "Average Validation Loss: 0.12906116992235184\n",
      "Average Test Accuracy: 0.9796196520328522\n",
      "Final Test Accuracy for each fold: 0.9834893345832825\n"
     ]
    }
   ],
   "source": [
    "# split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_fs, Y, test_size=0.33, random_state=1)\n",
    "\n",
    "# prepare output data\n",
    "y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n",
    "\n",
    "# Define the number of folds for k-fold cross-validation\n",
    "k = 2\n",
    "\n",
    "# Define the cross-validation method\n",
    "cv_method = StratifiedKFold(n_splits=k)\n",
    "\n",
    "# Initialize the list to store the history, train & validation(accuracy & loss) for each model\n",
    "models = []\n",
    "model_history = []\n",
    "model_accuracy = []\n",
    "model_train_acc = []\n",
    "model_train_loss = []\n",
    "model_val_acc = []\n",
    "model_val_loss = []\n",
    "\n",
    "\n",
    "for i in range(1,21):\n",
    "\n",
    "    models_fold = []\n",
    "    hist = []\n",
    "    train_accuracy = []\n",
    "    train_loss = []\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    test_accuracy = []\n",
    "\n",
    "    print(\"Number of input features:\",i)\n",
    "\n",
    "    # Select the input features from the input data\n",
    "    X_train_selected = X_train[:, :i]\n",
    "    X_test_selected = X_test[:, :i]\n",
    "\n",
    "    # Loop over the folds\n",
    "    for fold, (train_index, val_index) in enumerate(cv_method.split(X_train_selected, y_train)):\n",
    "\n",
    "        print(\"Fold:\", fold+1)\n",
    "\n",
    "        # Split the data into train and validation sets using the current fold index\n",
    "        X_train_fold  = X_train_selected[train_index]\n",
    "        y_train_fold  = y_train[train_index]\n",
    "        X_val_fold = X_train_selected[val_index]\n",
    "        y_val_fold = y_train[val_index]\n",
    "\n",
    "        # Prepare the target data\n",
    "        y_train_fold_enc, y_val_fold_enc = prepare_targets(y_train_fold, y_val_fold)\n",
    "\n",
    "        # build the model\n",
    "        model = MLP_model(i)\n",
    "\n",
    "        # Fit the model to the training data for the current fold\n",
    "        history = model.fit(X_train_fold, to_categorical(y_train_fold_enc, num_classes=373), epochs=80, batch_size=5, verbose=1, validation_split = 0.33)\n",
    "    \n",
    "        # Evaluate the model on the validation data for the current fold\n",
    "        val_scores = model.evaluate(X_val_fold, to_categorical(y_val_fold_enc, num_classes=373), verbose=0)\n",
    "        val_accuracy.append(val_scores[1])\n",
    "        val_loss.append(val_scores[0])\n",
    "\n",
    "        # Evaluate the model on the test data for the current fold\n",
    "        test_scores = model.evaluate(X_test_selected, to_categorical(y_test_enc, num_classes=373), verbose=0)\n",
    "        test_accuracy.append(test_scores[1])\n",
    "\n",
    "        # add the model to the list of models\n",
    "        models_fold.append(model)\n",
    "        hist.append(history)\n",
    "\n",
    "        # store the training accuracy and loss for each fold\n",
    "        train_accuracy.append(history.history['accuracy'])\n",
    "        train_loss.append(history.history['loss'])\n",
    "        \n",
    "    # Calculate the average test and validation accuracy and loss across all folds\n",
    "    avg_test_acc = sum(test_accuracy) / len(test_accuracy)\n",
    "    avg_val_acc = sum(val_accuracy) / len(val_accuracy)\n",
    "    avg_val_loss = sum(val_loss) / len(val_loss)\n",
    "\n",
    "    # Print the average validation and test accuracy and loss\n",
    "    print(\"Average Validation Accuracy:\", avg_val_acc)\n",
    "    print(\"Average Validation Loss:\",avg_val_loss)\n",
    "    print(\"Average Test Accuracy:\", avg_test_acc)\n",
    "\n",
    "    best_fold_index = test_accuracy.index(max(test_accuracy))\n",
    "    model_accuracy.append(test_accuracy[best_fold_index])\n",
    "    models.append(models_fold[best_fold_index])\n",
    "    model_history.append(hist[best_fold_index])\n",
    "    model_train_acc.append(train_accuracy[best_fold_index])\n",
    "    model_train_loss.append(train_loss[best_fold_index])\n",
    "    model_val_acc.append(val_accuracy[best_fold_index])\n",
    "    model_val_loss.append(val_loss[best_fold_index])\n",
    "\n",
    "\n",
    "    print(\"Final Test Accuracy for each fold:\", test_accuracy[best_fold_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to show the no of input features and its corresponding model accuracy\n",
    "model_list = []\n",
    "\n",
    "#Iterate through each model's accuracy \n",
    "for i in range (len(model_accuracy)):\n",
    "    #get the number of input features for the current model\n",
    "    no_features = i + 1\n",
    "\n",
    "    #round the model accuries to 3 d.p.\n",
    "    rounded_model_acc = round(model_accuracy[i], 3)\n",
    "    \n",
    "    model_list.append([no_features, rounded_model_acc])\n",
    "\n",
    "models_df = pd.DataFrame(model_list, columns=[\"No of input features\", \"Model accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAACJTUlEQVR4nOzdd3wUdfrA8c9sT92QQgqk0VsoAiJF5QRFUeyKnoWI5aeCghx3gor1BPuJWPDuRPTsIiCKDamKSFN67zWNkJ5s/f7+mGQhJLSQZMnyvF+vee1mdnbm+c5sdp79lhlNKaUQQgghhAgQBn8HIIQQQghRmyS5EUIIIURAkeRGCCGEEAFFkhshhBBCBBRJboQQQggRUCS5EUIIIURAkeRGCCGEEAFFkhshhBBCBBRJboQQQggRUCS5EULUml27dqFpGlOnTj3t9y5YsABN01iwYEGtxyWEOLdIciOEEEKIgCLJjRBCCCECiiQ3QghRh4qLi/0dghDnHEluhAggTz/9NJqmsWXLFm6//XbsdjsxMTGMGzcOpRR79+7lmmuuITw8nLi4OF599dUq68jKyuLuu+8mNjYWm81Gp06d+OCDD6osl5eXR3p6Ona7nYiICIYMGUJeXl61cW3atIkbb7yRyMhIbDYb3bp1Y9asWTUq4+7du3nwwQdp3bo1QUFBREVFcdNNN7Fr165qY3zkkUdISUnBarXStGlT7rzzTnJycnzLlJWV8fTTT9OqVStsNhvx8fFcf/31bN++HTh+X6Dq+help6cTGhrK9u3bGThwIGFhYdx2220A/PLLL9x0000kJSVhtVpJTEzkkUceobS0tNr9dfPNNxMTE0NQUBCtW7fm8ccfB2D+/PlomsaMGTOqvO+TTz5B0zSWLFlyurtViIBi8ncAQojaN3jwYNq2bcsLL7zA7Nmz+ec//0lkZCTvvvsul1xyCS+++CIff/wxo0ePpnv37lx00UUAlJaW0rdvX7Zt28bw4cNJTU3lyy+/JD09nby8PEaMGAGAUoprrrmGX3/9lfvvv5+2bdsyY8YMhgwZUiWW9evX07t3b5o0acKYMWMICQnhiy++4Nprr+Wrr77iuuuuO62yLV++nN9++41bbrmFpk2bsmvXLt555x369u3Lhg0bCA4OBqCoqIgLL7yQjRs3MnToUM477zxycnKYNWsW+/btIzo6Go/Hw1VXXcXcuXO55ZZbGDFiBIWFhcyZM4d169bRvHnz0973brebAQMG0KdPH1555RVfPF9++SUlJSU88MADREVFsWzZMiZNmsS+ffv48ssvfe9fs2YNF154IWazmfvuu4+UlBS2b9/ON998w/PPP0/fvn1JTEzk448/rrLvPv74Y5o3b07Pnj1PO24hAooSQgSMp556SgHqvvvu881zu92qadOmStM09cILL/jmHz58WAUFBakhQ4b45r3++usKUB999JFvntPpVD179lShoaGqoKBAKaXUzJkzFaBeeumlStu58MILFaDef/993/x+/fqptLQ0VVZW5pvn9XpVr169VMuWLX3z5s+frwA1f/78E5axpKSkyrwlS5YoQH344Ye+eU8++aQC1PTp06ss7/V6lVJKTZkyRQHqtddeO+4yx4tr586dVco6ZMgQBagxY8acUtwTJkxQmqap3bt3++ZddNFFKiwsrNK8o+NRSqmxY8cqq9Wq8vLyfPOysrKUyWRSTz31VJXtCHGukWYpIQLQPffc43tuNBrp1q0bSinuvvtu3/yIiAhat27Njh07fPO+++474uLiuPXWW33zzGYzDz/8MEVFRSxcuNC3nMlk4oEHHqi0nYceeqhSHLm5ucybN4+bb76ZwsJCcnJyyMnJ4dChQwwYMICtW7eyf//+0ypbUFCQ77nL5eLQoUO0aNGCiIgI/vjjD99rX331FZ06daq2ZkjTNN8y0dHRVeI+epmaOHq/VBd3cXExOTk59OrVC6UUf/75JwDZ2dksWrSIoUOHkpSUdNx47rzzThwOB9OmTfPN+/zzz3G73dx+++01jluIQCHJjRAB6NgTo91ux2azER0dXWX+4cOHfX/v3r2bli1bYjBU/mpo27at7/WKx/j4eEJDQyst17p160p/b9u2DaUU48aNIyYmptL01FNPAXofn9NRWlrKk08+SWJiIlarlejoaGJiYsjLyyM/P9+33Pbt2+nQocMJ17V9+3Zat26NyVR7LfQmk4mmTZtWmb9nzx7S09OJjIwkNDSUmJgYLr74YgBf3BWJ5snibtOmDd27d+fjjz/2zfv444+54IILaNGiRW0VRYgGS/rcCBGAjEbjKc0Dvf9MXfF6vQCMHj2aAQMGVLvM6Z6MH3roId5//31GjhxJz549sdvtaJrGLbfc4ttebTpeDY7H46l2vtVqrZIcejweLr30UnJzc3n00Udp06YNISEh7N+/n/T09BrFfeeddzJixAj27duHw+Hg999/58033zzt9QgRiCS5EUL4JCcns2bNGrxeb6UT9KZNm3yvVzzOnTuXoqKiSrU3mzdvrrS+Zs2aAXrTVv/+/WslxmnTpjFkyJBKI73KysqqjNRq3rw569atO+G6mjdvztKlS3G5XJjN5mqXadSoEUCV9VfUYp2KtWvXsmXLFj744APuvPNO3/w5c+ZUWq5if50sboBbbrmFUaNG8emnn1JaWorZbGbw4MGnHJMQgUyapYQQPgMHDiQjI4PPP//cN8/tdjNp0iRCQ0N9zSgDBw7E7Xbzzjvv+JbzeDxMmjSp0voaN25M3759effddzl48GCV7WVnZ592jEajsUpt06RJk6rUpNxwww2sXr262iHTFe+/4YYbyMnJqbbGo2KZ5ORkjEYjixYtqvT622+/fVoxH73OiucTJ06stFxMTAwXXXQRU6ZMYc+ePdXGUyE6OporrriCjz76iI8//pjLL7+8SrOjEOcqqbkRQvjcd999vPvuu6Snp7Ny5UpSUlKYNm0aixcv5vXXXycsLAyAQYMG0bt3b8aMGcOuXbto164d06dPr9TnpcJbb71Fnz59SEtL495776VZs2ZkZmayZMkS9u3bx+rVq08rxquuuor//e9/2O122rVrx5IlS/j555+JioqqtNzf//53pk2bxk033cTQoUPp2rUrubm5zJo1i8mTJ9OpUyfuvPNOPvzwQ0aNGsWyZcu48MILKS4u5ueff+bBBx/kmmuuwW63c9NNNzFp0iQ0TaN58+Z8++23p9VXqE2bNjRv3pzRo0ezf/9+wsPD+eqrryr1d6rwxhtv0KdPH8477zzuu+8+UlNT2bVrF7Nnz2bVqlWVlr3zzju58cYbAXjuuedOaz8KEdD8NUxLCFH7KoaCZ2dnV5o/ZMgQFRISUmX5iy++WLVv377SvMzMTHXXXXep6OhoZbFYVFpaWqXhzhUOHTqk7rjjDhUeHq7sdru644471J9//llleLRSSm3fvl3deeedKi4uTpnNZtWkSRN11VVXqWnTpvmWOdWh4IcPH/bFFxoaqgYMGKA2bdqkkpOTKw1rr4hx+PDhqkmTJspisaimTZuqIUOGqJycHN8yJSUl6vHHH1epqanKbDaruLg4deONN6rt27f7lsnOzlY33HCDCg4OVo0aNVL/93//p9atW1ftUPDq9rNSSm3YsEH1799fhYaGqujoaHXvvfeq1atXV7u/1q1bp6677joVERGhbDabat26tRo3blyVdTocDtWoUSNlt9tVaWnpCfebEOcSTak67E0ohBCizrjdbhISEhg0aBDvvfeev8MR4qwhfW6EEKKBmjlzJtnZ2ZU6KQshQGpuhBCigVm6dClr1qzhueeeIzo6utLFC4UQUnMjhBANzjvvvMMDDzxA48aN+fDDD/0djhBnHam5EUIIIURAkZobIYQQQgQUSW6EEEIIEVD8ehG/RYsW8fLLL7Ny5UoOHjzIjBkzuPbaa0/4ngULFjBq1CjWr19PYmIiTzzxBOnp6ae8Ta/Xy4EDBwgLCzuju/4KIYQQov4opSgsLCQhIaHK/duO5dfkpri4mE6dOjF06FCuv/76ky6/c+dOrrzySu6//34+/vhj5s6dyz333EN8fPxxb8p3rAMHDpCYmHimoQshhBDCD/bu3UvTpk1PuMxZ06FY07ST1tw8+uijzJ49u9JN5W655Rby8vL44YcfTmk7+fn5REREsHfvXsLDw880bCGEEELUg4KCAhITE8nLy8Nut59w2QZ1b6klS5ZUubPwgAEDGDly5Cmvo6IpKjw8XJIbIYQQooE5lS4lDSq5ycjIIDY2ttK82NhYCgoKKC0tJSgoqMp7HA4HDofD93dBQUGdxymEEEII/wn40VITJkzAbrf7JulvI4QQQgS2BlVzExcXR2ZmZqV5mZmZhIeHV1trAzB27FhGjRrl+7uizU4IcW4qc3lQCqwmAwbD6Y+YVEqRW+xEAY2CLRhPYx0uj5f8Uhd5JU7ySly4vQp7kJnwIDP2IDMhFuNpjeIsc3koLHPjVQqvUni8Cq8XPErh8ngpdXooc3koc3spc3lwur1EBJuJDbfROMyKPch83O25PF5yi51k5JdxML+MzAL9MauwjBCLiTi7jbhwm/5otxEdakXTwOtVeBV6LErhcHkpKHNRUOaisMxNYZmbglIXZqNGeJCZiGAL9vLyh9lMvjIVlrkpcujvcXkUUSEWokOtRIdZiAqxYjEZKsVa7NDfU+x0U+r04HB7cZSX2+H24nR78SoFChSKo3ubGgwaRk3DaNDQNDAaNDxehdPtxeXR96XT7cXtVYRYjYTbzIQHmQizmQm3mTEbNfJLXb4pr0R/VApCrEaCLSbfY5DZiNvr9cXnKD8+bo8Xs9GAxWjAYjLoz00G3BWfmaPWXVDmIshsJCrUQnSIlahQC1GhVsJtJvJKXeQUOsgpcnKoyEFOkYMyl5fIUAvRIfpyUaH6Pgy1mjAaNMxGDZPRgMmgYTBolDjc5cdMP1YFZW5KHG7cXn1feLwKl0fh8XoBsJgMhKgSol0HiHQeJMJxAGt4DGlXPXjKn+Xa1qCSm549e/Ldd99Vmjdnzhx69ux53PdYrVasVmtdhyaE3yilyC5ysPtQCfYgM00bBRFsOf6/dpnLw8H8MkqdHsJsJsJsJkKtJkzG41fkuj1eckuc5BY7yS1ycqhYf+5wewix6u/3TTYTVpMBTdPQAIOmYdD0k4bHq3B79ZOE26Nwl59ASspPSCVODyUuD6VON6VOL6Uu/eRcWj6/zOUhyGwkPMikJwU2/aQYbDXhLD+RVZzMSp0eCstcZBc5yC7/ss8udFDkcPvKZTMbCDIbCTIbsVmMhFn1E1aoVd8v4VYDVlXGviLFwUI3GQVlZOY7cHr0L3WDBpEhVqJDLcSEWYkMseDxKkqdHkpdenlKnR6KnW7ySlyVtl0dowE6WLMpsUSDNYxgi5Egi35StBgNFDpc5BbrydHhEifN3dtppe3jV28Hsml0eh8c9JNS4zArEcFmylxeShxuistjrijjyRjx0EnbTpphJyGUYdWcBOHEhpMgHJRiZZW3OStVK3arWOD4yVsYJcRpucRrh/RHconTcgnTStml7PyuIslUjcikEcWWaDKN8eQ5wOE+cawm3LTXdrFJJeHAcjq7qB4ommrZdNB2EaflEqsdprF2mGgOE6vl4cbABpVCpjeFtd5UNqpkiqn6Y96IBwsuSrFyon18NBNummsHaKftpp1hN+21XaQYMtjlTeEnbzfmeLqSR1iV94VTxIWGdVxsWE0bwx6StCwitOJKy2wytYVzNbkpKipi27Ztvr937tzJqlWriIyMJCkpibFjx7J//37fvVPuv/9+3nzzTf7xj38wdOhQ5s2bxxdffMHs2bP9VQTR0CkFmuZLELZlFbEjW/8nbRYdQmpMCLFhthr9wi9zecgqcJBZWEZGfhlZ+cXEb/8Ch9fItpDO5Jrj8SjwePH96q44+Xu84PF6MWia75d9RLDZ9wv3cImLbVmFbM0sYmtWEfmlrkrbjg610LRRMGlhRbRT2ykqKaGwuISikhLKHE7MuNmtYlng7UTFF2GQ2UiYTf9KcHsVLrcXl9db/gvtVAZVKvoY1nGTcSEeDPziSeMXb0dyqDqqwU4RFxnWcLFxDa21PVgxYMeAGwMejHiUgTxC2KXiOKTi2OGN158TjhUXSVoWzbSDpGgZhGsZ2LVDKLQj78eABwPFykYkkYSrSEJUJBYVSQaRWHARqx0m1nOYWG8esc7DxBQfJkorJFIrIJJCIrVC7BRj0PSyu5SRMiyUmcyUGa1k0Ih13lTWl6awrjiV3zKa4MF40r2kaRBu04+n0aBRUOqG0sMMYiG3GufRSu0nvyyYV4tu4mNP/2rXGUYJj5s+4w7rzwB4lMZS1Y7ZqjdztR4Ua2GYTQZsJgM2ixGbyYjNrNcG5JW4yCwsI6/EhdPtZd/hUvYdLq20/mDK6GXYRKRWiAqKwhAajS28McGNYmkUYSckbwsRmb+RmLec1mVrCKG0SoxHu5M5AORrdrbb2rE3pANOZSK07CB2ZwYx7gxivVmEayUn3X9H2+OK4Q7PWHYTB+jJaqjVRJDFiNVkxGoyEGZ0Mi7/Gdo7V+PQrGy0dWZNUA/WBfcg16z34fR4FR6l/1Co+D80GTXMxvIaFKNGqMGJTZVxyBPEYQe+GqjCMjdOt9f3P9rUUkJLUwYpHMCAIocIMlUEmd5wDrrCKHJCEzLpqtaR5l5He+caojzZJyxnW/Zyg/EXABQaBcFJOA02jM4izJ5irJ4SLDgBKCGIHHMcBdZ4yoITcIUnoizheIuzMRRnYy47hM2ZS6g7lwTvQay4qmwvwZjLpcY/8JgNbLR0ZE3YheSEtqZV6Z+0KVpGUsl6DFRNKIuMEeSY48k2xVHcqB1tTuto1i6/DgVfsGABf/nLX6rMHzJkCFOnTiU9PZ1du3axYMGCSu955JFH2LBhA02bNmXcuHGndRG/goIC7HY7+fn5MloqgOSVOFmzL5+1+/MpKNWr+48kCwqvV6Fpei97gwaxZTsYeOBNUgtXUqwFc0iFkuMN47AK45AKZ6tqyreeC8iiETazgZSoEFKiQgAocrgpdLhxlRbRtfQ3Uj07+NB7BVlEljcP6F+SLs+Rfy0DXl42T+YG46++eQdUJEu9bfnd244V3lYUqaq/xgoJpgTbSctv0CAhIoii0jJaOjZyifFP+hpW0daw94TvW6ra8pRzCJtUUrWv23Bwi3E+FxnWsF01Ya2lIzuDOxIU2ojIEAtBFiPu0kK6HP6B/kVfk+Spur1NKpnFdGKltzXtDLu5UPuTDmzHWM2X48m4jMGYPKVonBVXsKjEY7CSG9IclykEEx5MmhcjHox40QxGVEQyxujmWGNbYYhqAVHN4dA2WPE+asNMNHcZoJ+8KspXGNGG1R3HsT+sIw63l3CriRa582n9x7OYS7L05WPaoGVvOhKIwQwtL4VmfcGeCPam+hTUSM+sypW5PGQXOsgqLCO/uIyYwk3EZC3GfvBXbBkr0bxVT3r6+k3gPaYGyhaBJ/ECCI5EMwejmYPQLMFgskHJIdi7DA6uAo/z5DvSFgHhTSA8oXxqAtYwKM6CgoOowoN4Cw6i5e/F4C7FHRpPyS0zCIpvjfnY2kdXGXx6C+yYX/22YtpAQhfwesDrAo9Lj9HjAkchlOVBWT6U5umvVwiKhNBYCG2sPxrN+rHM2QqluSconAaWUHAWVt2ncR0hIgnC4iEs7sijqwQOrj4yFew/+T48HZYwiEvTp/iO0CgFdv8GG2dBxtrjvy+6tf45S+oJkakQkQzW0NqN7Rinc/4+a65zU18kufG/Eqeb3GInJU4PxQ53pce8iqaPEieHi13kFjspcrixB5mJDLEQGWIhKsRCZKiFUqeHNfvyWbMvj12H9F98FlwoNFzHqZQMp5gRpukMMf6ISTvxydWDgSXedsz09OYHT3eKCMaAlwsMG7je+CuXG5YRquknpAzViLudo1mvUiutw2oyEB9m5hn1NheXzcWLkczQtjQu3oRRnbiJAsBjMLO2yS3Mj00ny2mloLzdPcRqpFVsGC0ah9KycRjNnRuwrvgPbJujfxmX82IgK7glyhqG2WLDarVgtQZhNhnQtv4M7lKUZsDR+S6yu/2NfPQvJ5unkMgNH2Jf9R+MZcd8WWtGSOgMKRfqJ4E/PwJH+TYtodD5r/rj9rn6l/HxxLSFlv31L0eDqfwE4wblAY8birP1E0budji0A/L3QkVSY7VDVDOIbK4nCRFJoBn091esx+sBRwEUHDhq2q+ffDQDhDQ+chIJj4fQOAiJhuCoI4/BUXpZ3GXgKj3y6CqB3J2VTzrHnrBOV2wH6JoOHW6A9dNh7nP6yRWg4y1wwf2w8GXYXF5THdkcBr0OqRfB4V2w7itY+xVkra9+/eZgPVkwWkB5j5oUFOccOYYVIpIgspmenBQfgpKcI8mJKQiSe0LqxdDsYv3EbDhJrZXboe+nvUth3wo90YpI0hOwiGSISNSfn+oJsigLpl4FOZv1Y5g+W/8sHL29z2+HrT+BOQTumK4nSVt+1OftXaqXvy6EN4XoFmC0QlFm+ZSlf7ZBT0CbdoOUPpDcGxLPB0vIqa27KAsy1+mxW8L0/WUJ1ctmNEPBQcjbA/l79Me8PXqiFhJzzBStJzKNUuF4V/vN3QmbvoWN3+j/i4kX6P+zLfrrx66eSXJzApLc1BGvB6UZKHS4OeTryOYku7DMV+2973AJew+Xkltc9ddbFPlcZfydCIowaAoNLwYUBhQuTCz0dOQP1ZLjtSU31/bzSMhPDPAsQGlG9od2ZG9EN/ZHdCMnvB0Gg5G2Gd9wwc43CXbpJ+ttkRezLOUBEiJDSA0uI95cjMVxGIqy9RPz3qW+9XuMVg5EXkBk4SZCyo50aneGJYLBiCV/F15TELkD3sLRciAGTW/msVsNaLOGw+pP9aTgpveh3TXgLIF9y2DXYti9GA78qScKlagjv5CDo+Evj8F5Q8B4VOK2azEsegl2LDgyL6iR/uXTcgC06AfBkdUfs7w98NM42DCzfBtR0HesnkQsn3LkZB2RDF2H6CfQnb/A4Z1V1xXZDM7/Pz2xsR31f1WUrce2fS7sXwnRrfRfey3667UJp8NVpscW1EiPtaa3T3GV6icXYy22ynu9+n7JXK//wjeY9ONtMOknfY9TP1HkbodD5VPBPj3h6HA9dL0LmnStXKbiQzD3GfjjQzi6pspggj6PwIWjwVxNrV7WRlg/A7I2QP4+fSo+cbMHoCeMqRdC879As7/ox/ToeJQCZxGU5OpJoeks6MtYlAUfDILsTXqCM+RbPanwuOCLIXoiaAqC26fpicTRSg/D9nlweLee8BnN5ZNF/3xYQ8Fm12uSgiL05+YQPeEszDiSsBRl6olUVDOIaqknWNUlKl6vnliXHNKTOEtwPeygwCLJzQlIclMzFf1HDuaVkJ+xA2/GOqyHNhCev5n4sm3EeQ6Sr0LZrRqzS8WyW8Wy2xvLThXPBpVcpROfxaS3jXcx7WKw9zv+4lqEmRPXZBTaElgX2Z/fgy9hvScRo6a4PHQbF+V8TtSB41Q7g/6rJjRWP7GAfoK9/AX9xH8ih3fB2i9hzReQs+XIfJsd2l+n/5pOukCvHfgyXf+iRIP+T0Hvkfovq6+Hw+pP9BPdjVOg/bUn3ubRlIKtc+DHx+DQVn1eTFsY8Lxe87DoZT0xAv2E1/EWOO9O/RfhyX5FH23HQvj+UcjeWHl+4/b6SbT9dZUTgby9sOsXPdFxl0Ln26B5v+P/+hPVc5Xqx/FkScK+lfDdaDjwBzQ9HwZNhNh2p7mtMr3WquCA/rnUDHriohn0yRwMjdvVbsJXX45NcO78GuY/Dxu+1mtO/vq5nrCJBk+SmxOQ5Kaq7EIHGeVDPbMKHeWPZWQWOHxDQIuLi7jZuID7Td/QRDt0Wuv3YiQ3rCWlMZ0wNu1GWPPzCSvcDkvfrVQ7QsJ5enNHxRduxVSUBVt+0H81Vohpq//KylhTPkODNldCz+F68rHrF9i5CHb9eqRq3xIGfR/VaxhMpzFiQim9On37XIhqodeIHPuL2eOGH8bA8v/of3e+TX9c9XF5YvOeniTUhMcFK6bAggn6r82jGS3Q5XY9mWqUXLP1V2xj+X/1hCmqpZ7UtBpQ89oRUbu8Xj05j2wuSWR1irLLE5yNR/oEGS1wy6d6M4oICJLcnIAkN+Bwe1i2M5f5m7JZsDmLHTlFHK+5x4KLm40LGGb6mnhNb85xYyLTmszhsFaUNmoDcWkEJ7QlxlhMhGMflvzdehV97k7911RRZrXrBvTq3/bXQY//02scjsdZoic4677S28uPbvvvchtc8GDl9vYKXi9krtU7+qVcCGGxVZepTUv/DT88eqQtXzPCDf/Vmx7OVOlhWPgSLPu3/gXeNR16PQz2Jme+7grlo8eEaHCKsuHDq/XmOIMJBn8Era/wd1SiFklycwLnanJzML+U+Zuymb85i8XbcihxetDw8nfTF6Qbf6RIC+GAOZFDQSkUhTXH3agVSWofaTv/i60kAwAVloB24Sjockf1bf3VUUqvDt+/snz6Q+9fYgnR+xl0u0tvvz8dpXmwaTY4i/XOlyFRp/f+urb1Z5h2l17TdMN/9RhrU2GG/qv0eH1phDhXFefAr/86MlpMBBRJbk7gnEhu9q3E4yxhlaEd8zZnM29TNhsPVr6nVlKol7eDJtOh8NfjrOQoYQlw4Si9P0dtdCL0esvb+wO4hqAoW++QG9nM35EIIURAOJ3zdwPsPSaq5fWiNs+meN5rhGb/gRFweNqxwH0bG1UqmgadEyO4pHVjLm3qofX8e9Ay1uod7ga9rneyzd6sD6vM3qI/okGP+/Wk5lRrak7FudBnIDQGiPF3FEIIcU6SmpuGzlVG4fKP8Pz6BhEluwFwKBOgYdX0ocV7mg4ibOAzNEporjcLfXorFGXo1zq45RP9GgtCCCHEWUxqbs4R23+dRvT80dg9+giafBXMZ+oyMtrcyVXto+my7U0Ma78gad838N5PkHaT3iHXXaoP+7z1szMbYSOEEEKchaTmpgHKLnTw71nzeXhLOmFaKftVFD+EXk9477u5/LwWhNnMRxY+8Kd+obZdvxyZ1+JS/ZortoZZfiGEEOceqbkJUC6Pl/8t2c3EOZv4t3qaMEMpO4M64Lx9Fnc3Oc6IoYQuMOQbfRj14jf0i8795fGGebEuIYQQ4hTIGa6B+G17Dk/PWs+WzCLuN86ih3kTHlMIqfd+BJEnGQqtafr1HuSaD0IIIc4Bktw0AP/9ZQf/nK1fGr9H0D7+zjRQYBz4on43ViGEEEL4nANjchuYvD36vXvKffDbLl9ic0e3xnwSNUW/m3Sbq/TL7gshhBCiEqm5OZtkbYR//wXcZdDuGr6P+CtPzdNvJvlg3+b8nQ/QcjZBSGP95nmBfBE8IYQQooYkuTlbeD3w9TB9mDbAhplcwUw+MHdkd7v/446WGWj/e1t/7Zo3ISTaf7EKIYQQZzFJbs4WS97S771kDee3rq+R9cv7XGVYwsXGNbB5GGwtH97dbah+t2YhhBBCVEv63JwNcrbB/OcBWNv+H9yxIISRrmG81uZTVLe79VskeF0Q2Rwu+6efgxVCCCHOblJz429eL8waDu4yShMv4oalzfF4FTec15TRN3ZEM1wOFz8KG2dBq8v1u2kLIYQQ4rgkufG35f+BPUvAEsoL5gdxerz0bBbFSzd2xGAo7zAcFgvn3+vfOIUQQogGQpql/OnwLvj5aQAOnD+WDzZ4AXj8yrYYDTISSgghhKgJSW78RSmY9RC4SiC5D4/t7gbAoE4JdGhi93NwQgghRMMlyY2/rJwKOxeBKYg/Oz/Lgq2HMBk0/nZpK39HJoQQQjRoktz4g9sB88cDoC55gqd/KwPg1vOTSImWDsNCCCHEmZDkxh/WTYfiLAhL4KfQq1m9N48gs5GH+rXwd2RCCCFEgyfJTX1TCn7XrzTs6X4PL87ZAcA9F6bSOMzmz8iEEEKIgCDJTX3bswQy1oApiFnGS9mRXUyjYDP3XdTM35EJIYQQAcHvyc1bb71FSkoKNpuNHj16sGzZshMu//rrr9O6dWuCgoJITEzkkUceoaysrJ6irQXltTbutJt5cWE2AMP+0oIwm9mfUQkhhBABw6/Jzeeff86oUaN46qmn+OOPP+jUqRMDBgwgKyur2uU/+eQTxowZw1NPPcXGjRt57733+Pzzz3nsscfqOfIaOrwbNs0G4CvzIDIKykiw27j9gmQ/ByaEEEIEjholN/Pnz6+Vjb/22mvce++93HXXXbRr147JkycTHBzMlClTql3+t99+o3fv3vz1r38lJSWFyy67jFtvvfWktT1njWX/BuVFNb+ESWuNAIy8tBU2s9HPgQkhhBCBo0bJzeWXX07z5s355z//yd69e2u0YafTycqVK+nfv/+RYAwG+vfvz5IlS6p9T69evVi5cqUvmdmxYwffffcdAwcOPO52HA4HBQUFlSa/cBTCH/8DIKPtXew7XIrFaODKtHj/xCOEEEIEqBolN/v372f48OFMmzaNZs2aMWDAAL744gucTucpryMnJwePx0NsbGyl+bGxsWRkZFT7nr/+9a88++yz9OnTB7PZTPPmzenbt+8Jm6UmTJiA3W73TYmJiaccY61a9Sk48iGqBT+UtQegW0ojQqxyey8hhBCiNtUouYmOjuaRRx5h1apVLF26lFatWvHggw+SkJDAww8/zOrVq2s7TgAWLFjA+PHjefvtt/njjz+YPn06s2fP5rnnnjvue8aOHUt+fr5vqmlN0xnxemHpZP15j/tZtPUQABe1iqn/WIQQQogAd8bVBueddx5xcXFERUXxwgsvMGXKFN5++2169uzJ5MmTad++fbXvi46Oxmg0kpmZWWl+ZmYmcXFx1b5n3Lhx3HHHHdxzzz0ApKWlUVxczH333cfjjz+OwVA1V7NarVit1jMs5RnaNgdyt4PNTln7m/n9G73Z7WJJboQQQohaV+PRUi6Xi2nTpjFw4ECSk5P58ccfefPNN8nMzGTbtm0kJydz0003Hff9FouFrl27MnfuXN88r9fL3Llz6dmzZ7XvKSkpqZLAGI16Z1ylVE2LUvfKh39z3hBWHHBR6vLQOMxKm7gw/8YlhBBCBKAa1dw89NBDfPrppyiluOOOO3jppZfo0KGD7/WQkBBeeeUVEhISTrieUaNGMWTIELp168b555/P66+/TnFxMXfddRcAd955J02aNGHChAkADBo0iNdee40uXbrQo0cPtm3bxrhx4xg0aJAvyTnrZG6AHQtAM8D597LoN/3aNhe2jEHTNP/GJoQQQgSgGiU3GzZsYNKkSVx//fXHbfKJjo4+6ZDxwYMHk52dzZNPPklGRgadO3fmhx9+8HUy3rNnT6WamieeeAJN03jiiSfYv38/MTExDBo0iOeff74mxagfa7/UH9tcCRFJLNqyCICLWkX7MSghhBAicGnqrG7PqX0FBQXY7Xby8/MJDw+v+w3+73rYPheu+heZrf5Kj/Fz0TRY+cSlRIZY6n77QgghRAA4nfN3jfrcTJgwodoL7U2ZMoUXX3yxJqsMXBlr9ce4TizcojdJdWxil8RGCCGEqCM1Sm7effdd2rRpU2V++/btmTx58hkHFTAKM6A4S+9v07gti8qTGxkCLoQQQtSdGiU3GRkZxMdXvbJuTEwMBw8ePOOgAkZFrU10KzymIH7dlgPIEHAhhBCiLtUouUlMTGTx4sVV5i9evPikI6TOKQfLL2YYl8aafXnklbgIs5nonBjh17CEEEKIQFaj0VL33nsvI0eOxOVycckllwAwd+5c/vGPf/C3v/2tVgNs0Hz9bdJYtEWvtendPBqT0a83YxdCCCECWo2Sm7///e8cOnSIBx980Hc/KZvNxqOPPsrYsWNrNcAGLWON/hjXkUU/SX8bIYQQoj7UKLnRNI0XX3yRcePGsXHjRoKCgmjZsqX/b3NwNnEUQu4OAArsbflzz0pArm8jhBBC1LUzurdUaGgo3bt3r61YAkvmev0xvAm/HlR4FTSPCaFpo2D/xiWEEEIEuBonNytWrOCLL75gz549vqapCtOnTz/jwBq8gxVNUmkyBFwIIYSoRzXq2frZZ5/Rq1cvNm7cyIwZM3C5XKxfv5558+Zht9trO8aGqby/jYrt4EtuZAi4EEIIUfdqlNyMHz+ef/3rX3zzzTdYLBYmTpzIpk2buPnmm0lKSqrtGBum8uTmYHArDuSXYTEZ6JEa5eeghBBCiMBXo+Rm+/btXHnllQBYLBaKi4vRNI1HHnmEf//737UaYIPkcUHWRgAWF+rX/emRGkmQ5Sy9c7kQQggRQGqU3DRq1IjCwkIAmjRpwrp16wDIy8ujpKSk9qJrqLI3g8cJ1nDWlzYCoH2CNNcJIYQQ9aFGHYovuugi5syZQ1paGjfddBMjRoxg3rx5zJkzh379+tV2jA3PURfvO1zqAiBKbpQphBBC1IsaJTdvvvkmZWVlADz++OOYzWZ+++03brjhBp544olaDbBB8iU3Hck9oI8kk7uACyGEEPXjtJMbt9vNt99+y4ABAwAwGAyMGTOm1gNr0DKODAM/tKU8uQmV5EYIIYSoD6fd58ZkMnH//ff7am7EMZSqlNwcLilPboIluRFCCCHqQ406FJ9//vmsWrWqlkMJEHl7oCwfDGZUTGsOFUuzlBBCCFGfatTn5sEHH2TUqFHs3buXrl27EhISUun1jh071kpwDVJFf5vGbSjxGHG6vYAkN0IIIUR9qVFyc8sttwDw8MMP++ZpmoZSCk3T8Hg8tRNdQ+RrkupEbnmtjdVkIFiucSOEEELUixolNzt37qztOALHUcPAK5qkokIsaJrmx6CEEEKIc0eNkpvk5OTajiNwHH2Nm/LkppE0SQkhhBD1pkbJzYcffnjC1++8884aBdPgleRC/l79eVwHDq3Xr+Is/W2EEEKI+lOj5GbEiBGV/na5XJSUlGCxWAgODj53k5uKWptGKWCzc7j4ECDJjRBCCFGfajQU/PDhw5WmoqIiNm/eTJ8+ffj0009rO8aGw9eZWB8tJsPAhRBCiPpXo+SmOi1btuSFF16oUqtzTjnqtgsAucUOQO4rJYQQQtSnWktuQL968YEDB2pzlQ3LUZ2JAXKL9ZtmSodiIYQQov7UKLmZNWtWpenrr79m8uTJ3H777fTu3fu01vXWW2+RkpKCzWajR48eLFu27ITL5+XlMWzYMOLj47FarbRq1YrvvvuuJsWoXa5SyN6sP4+XmhshhBDCX2rUofjaa6+t9LemacTExHDJJZfw6quvnvJ6Pv/8c0aNGsXkyZPp0aMHr7/+OgMGDGDz5s00bty4yvJOp5NLL72Uxo0bM23aNJo0acLu3buJiIioSTFqV9ZGUB4IjoKweAAOl+g1N5EhVn9GJoQQQpxTapTceL3eWtn4a6+9xr333stdd90FwOTJk5k9ezZTpkyp9k7jU6ZMITc3l99++w2z2QxASkpKrcRyxjQDtL4SbOFQfsG+Q0V6zU1kiNmfkQkhhBDnlFrtc3M6nE4nK1eupH///keCMRjo378/S5YsqfY9s2bNomfPngwbNozY2Fg6dOjA+PHjT3i7B4fDQUFBQaWpTiR0hls/gesmA+DyeCkocwNScyOEEELUpxolNzfccAMvvvhilfkvvfQSN9100ymtIycnB4/HQ2xsbKX5sbGxZGRkVPueHTt2MG3aNDweD9999x3jxo3j1Vdf5Z///OdxtzNhwgTsdrtvSkxMPKX4ztThEn0YuKaBPUhqboQQQoj6UqPkZtGiRQwcOLDK/CuuuIJFixadcVDH4/V6ady4Mf/+97/p2rUrgwcP5vHHH2fy5MnHfc/YsWPJz8/3TXv37q2z+I5WcdPMRsEWjAa5r5QQQghRX2rU56aoqAiLpeoIILPZfMrNPtHR0RiNRjIzMyvNz8zMJC4urtr3xMfHYzabMRqP3GG7bdu2ZGRk4HQ6q43JarVitdZ/s1BukVzATwghhPCHGtXcpKWl8fnnn1eZ/9lnn9GuXbtTWofFYqFr167MnTvXN8/r9TJ37lx69uxZ7Xt69+7Ntm3bKnVo3rJlC/Hx8dUmNv6UW94sFRl8dsUlhBBCBLoa1dyMGzeO66+/nu3bt3PJJZcAMHfuXD799FO+/PLLU17PqFGjGDJkCN26deP888/n9ddfp7i42Dd66s4776RJkyZMmDABgAceeIA333yTESNG8NBDD7F161bGjx/Pww8/XJNi1KlcufWCEEKckzweDy6Xy99hNEgWiwWD4czHOtUouRk0aBAzZ85k/PjxTJs2jaCgIDp27MjPP//MxRdffMrrGTx4MNnZ2Tz55JNkZGTQuXNnfvjhB18n4z179lQqZGJiIj/++COPPPIIHTt2pEmTJowYMYJHH320JsWoU77kJlSSGyGEOBcopcjIyCAvL8/foTRYBoOB1NTUM26N0ZRSqpZiahAKCgqw2+3k5+cTHh5eZ9t58ut1fLhkN8P/0oLRA1rX2XaEEEKcHQ4ePEheXh6NGzcmODgYTZPBJKfD6/Vy4MABzGYzSUlJVfbf6Zy/a1Rzs3z5crxeLz169Kg0f+nSpRiNRrp161aT1QYUuSO4EEKcOzwejy+xiYqK8nc4DVZMTAwHDhzA7Xb7LtZbEzVq2Bo2bFi1Q6r379/PsGHDahxMIDksyY0QQpwzKvrYBAcH+zmShq2iOepEF+c9FTVKbjZs2MB5551XZX6XLl3YsGHDGQUUKKRDsRBCnHukKerM1Nb+q1FyY7Vaq1yfBvT2RpOpRi1dAUeSGyGEEMI/apTcXHbZZb4r/1bIy8vjscce49JLL6214BoqpZTv9guS3AghhDhXpKSk8Prrr/s7jJp1KH7llVe46KKLSE5OpkuXLgCsWrWK2NhY/ve//9VqgA1RQZkbl0cfhCbJjRBCiLNZ37596dy5c60kJcuXLyckJOTMgzpDNUpumjRpwpo1a/j4449ZvXo1QUFB3HXXXdx6661n1Ls5UFR0Jg6xGLGZjSdZWgghhDh7KaXweDyn1O0kJiamHiI6uRpfBjAkJIQ+ffowaNAgLrroIiIiIvj++++ZNWtWbcbXIFUMA28ktTZCCCHOYunp6SxcuJCJEyeiaRqapjF16lQ0TeP777+na9euWK1Wfv31V7Zv384111xDbGwsoaGhdO/enZ9//rnS+o5tltI0jf/+979cd911BAcH07Jly3rJE2pUc7Njxw6uu+461q5di6ZpKKUq9XA+0yFcDV1FzU2UJDdCCHFOUkpR6vLPuTDIbDzlUUcTJ05ky5YtdOjQgWeffRaA9evXAzBmzBheeeUVmjVrRqNGjdi7dy8DBw7k+eefx2q18uGHHzJo0CA2b95MUlLScbfxzDPP8NJLL/Hyyy8zadIkbrvtNnbv3k1kZOSZF/Y4apTcjBgxgtTUVObOnUtqaipLly4lNzeXv/3tb7zyyiu1HWODkys1N0IIcU4rdXlo9+SPftn2hmcHEGw5tdO73W7HYrEQHBxMXFwcAJs2bQLg2WefrTRIKDIykk6dOvn+fu6555gxYwazZs1i+PDhx91Geno6t956KwDjx4/njTfeYNmyZVx++eWnXbZTVaNmqSVLlvDss88SHR2NwWDAaDTSp08fJkyYcFbexLK+ydWJhRBCNHTH3m2gqKiI0aNH07ZtWyIiIggNDWXjxo3s2bPnhOvp2LGj73lISAjh4eFkZWXVScwValRz4/F4CAsLAyA6OpoDBw7QunVrkpOT2bx5c60G2BBVDAOXZikhhDg3BZmNbHh2gN+2XRuOHfU0evRo5syZwyuvvEKLFi0ICgrixhtvxOl0nnA9xw400jQNr9dbKzEeT42Smw4dOrB69WpSU1Pp0aMHL730EhaLhX//+980a9astmNscA4VSbOUEEKcyzRNO+WmIX+zWCyn1Fd28eLFpKenc9111wF6Tc6uXbvqOLqaqdGef+KJJyguLgb0NrmrrrqKCy+8kKioKD7//PNaDbAhkpobIYQQDUVKSgpLly5l165dhIaGHrdWpWXLlkyfPp1BgwahaRrjxo2r8xqYmqpRn5sBAwZw/fXXA9CiRQs2bdpETk4OWVlZXHLJJbUaYEPkGwoeLMmNEEKIs9vo0aMxGo20a9eOmJiY4/ahee2112jUqBG9evVi0KBBDBgwoNr7TJ4Naq3OrC6HdDU0ucUOAKJCJbkRQghxdmvVqhVLliypNC89Pb3KcikpKcybN6/SvGHDhlX6+9hmKqVUlfXk5eXVKM7TUeOL+InjO1zsAiAyxOrnSIQQQohzjyQ3tczh9lDkcAMQKc1SQgghRL2T5KaWVdTamAwa4UENo6e8EEIIEUgkuallh8r72zQKsZzy5a+FEEIIUXskuallFbdekCYpIYQQwj8kualluXLrBSGEEMKvJLmpZZLcCCGEEP4lyU0tOyzJjRBCCOFXktzUMrkjuBBCCOFfktzUMmmWEkIIIfxLkptaJsmNEEKIhqRv376MHDmy1taXnp7OtddeW2vrq4mzIrl56623SElJwWaz0aNHD5YtW3ZK7/vss8/QNM3vO/FoFcmN3BFcCCGE8A+/Jzeff/45o0aN4qmnnuKPP/6gU6dODBgwgKysrBO+b9euXYwePZoLL7ywniI9NRXJTSNJboQQQpzl0tPTWbhwIRMnTkTTNDRNY9euXaxbt44rrriC0NBQYmNjueOOO8jJyfG9b9q0aaSlpREUFERUVBT9+/enuLiYp59+mg8++ICvv/7at74FCxbUe7n8nty89tpr3Hvvvdx11120a9eOyZMnExwczJQpU477Ho/Hw2233cYzzzxDs2bN6jHaE/N6FYdLpOZGCCHOeUqBs9g/UzV34j6eiRMn0rNnT+69914OHjzIwYMHCQsL45JLLqFLly6sWLGCH374gczMTG6++WYADh48yK233srQoUPZuHEjCxYs4Prrr0cpxejRo7n55pu5/PLLfevr1atXXe3l4/LrzY+cTicrV65k7NixvnkGg4H+/ftXuf360Z599lkaN27M3XffzS+//HLCbTgcDhwOh+/vgoKCMw/8OPJLXXjLP1MRcoViIYQ4d7lKYHyCf7b92AGwhJzSona7HYvFQnBwMHFxcQD885//pEuXLowfP9633JQpU0hMTGTLli0UFRXhdru5/vrrSU5OBiAtLc23bFBQEA6Hw7c+f/BrzU1OTg4ej4fY2NhK82NjY8nIyKj2Pb/++ivvvfce//nPf05pGxMmTMBut/umxMTEM477eHLLa23CbCYsJr9XigkhhBCnbfXq1cyfP5/Q0FDf1KZNGwC2b99Op06d6NevH2lpadx000385z//4fDhw36OurIGddvqwsJC7rjjDv7zn/8QHR19Su8ZO3Yso0aN8v1dUFBQZwmOdCYWQggBgDlYr0Hx17bPQFFREYMGDeLFF1+s8lp8fDxGo5E5c+bw22+/8dNPPzFp0iQef/xxli5dSmpq6hltu7b4NbmJjo7GaDSSmZlZaX5mZma11Vnbt29n165dDBo0yDfP6/UCYDKZ2Lx5M82bN6/0HqvVitVqrYPoqzpUJJ2JhRBCAJp2yk1D/maxWPB4PL6/zzvvPL766itSUlIwmapPEzRNo3fv3vTu3Zsnn3yS5ORkZsyYwahRo6qszx/82nZisVjo2rUrc+fO9c3zer3MnTuXnj17Vlm+TZs2rF27llWrVvmmq6++mr/85S+sWrWqTpucToV0JhZCCNHQpKSksHTpUnbt2kVOTg7Dhg0jNzeXW2+9leXLl7N9+3Z+/PFH7rrrLjweD0uXLmX8+PGsWLGCPXv2MH36dLKzs2nbtq1vfWvWrGHz5s3k5OTgcrnqvUx+7xgyatQo/vOf//DBBx+wceNGHnjgAYqLi7nrrrsAuPPOO30djm02Gx06dKg0RUREEBYWRocOHbBY/JtUyAX8hBBCNDSjR4/GaDTSrl07YmJicDqdLF68GI/Hw2WXXUZaWhojR44kIiICg8FAeHg4ixYtYuDAgbRq1YonnniCV199lSuuuAKAe++9l9atW9OtWzdiYmJYvHhxvZfJ731uBg8eTHZ2Nk8++SQZGRl07tyZH374wdfJeM+ePRgMfs/BTolc40YIIURD06pVq2pHKE+fPr3a5du2bcsPP/xw3PXFxMTw008/1Vp8NeH35AZg+PDhDB8+vNrXTnbxn6lTp9Z+QDUkHYqFEEII/2sYVSINRMUdwRvJNW6EEEIIv5HkphYdrqi5CZXkRgghhPAXSW5q0ZEOxfUz9FwIIYQQVUlyU4t8yY00SwkhxDlJncZ9nURVtbX/JLmpJaVOD6Uu/aJFkdIsJYQQ5xSz2QxASUmJnyNp2JxOvZLAaDSe0XrOitFSgeBQsX5zTovRQIjlzA6KEEKIhsVoNBIREUFWVhYAwcHBaJrm56gaFq/XS3Z2NsHBwce9MvKpkuSmlhwu1q/AGBlikQ+0EEKcgypuG1SR4IjTZzAYSEpKOuPzqCQ3tUShaJ8QTnSodCYWQohzkaZpxMfH07hxY7/cciAQWCyWWrlwr6bOsd5PBQUF2O128vPzCQ8P93c4QgghhDgFp3P+lg7FQgghhAgoktwIIYQQIqBIciOEEEKIgHLOdSiu6GJUUFDg50iEEEIIcaoqztun0lX4nEtuCgsLAUhMTPRzJEIIIYQ4XYWFhdjt9hMuc86NlvJ6vRw4cICwsLBavx5NQUEBiYmJ7N27N2BHYkkZA4OUMTBIGQODlPHUKKUoLCwkISHhpMPFz7maG4PBQNOmTet0G+Hh4QH7Aa0gZQwMUsbAIGUMDFLGkztZjU0F6VAshBBCiIAiyY0QQgghAookN7XIarXy1FNPYbUG7i0YpIyBQcoYGKSMgUHKWPvOuQ7FQgghhAhsUnMjhBBCiIAiyY0QQgghAookN0IIIYQIKJLcCCGEECKgSHJTS9566y1SUlKw2Wz06NGDZcuW+TukM7Jo0SIGDRpEQkICmqYxc+bMSq8rpXjyySeJj48nKCiI/v37s3XrVv8EWwMTJkyge/fuhIWF0bhxY6699lo2b95caZmysjKGDRtGVFQUoaGh3HDDDWRmZvop4tP3zjvv0LFjR99Fs3r27Mn333/ve72hl686L7zwApqmMXLkSN+8QCjn008/jaZplaY2bdr4Xg+EMu7fv5/bb7+dqKgogoKCSEtLY8WKFb7XG/p3DkBKSkqV46hpGsOGDQMC4zh6PB7GjRtHamoqQUFBNG/enOeee67S/aDq5VgqccY+++wzZbFY1JQpU9T69evVvffeqyIiIlRmZqa/Q6ux7777Tj3++ONq+vTpClAzZsyo9PoLL7yg7Ha7mjlzplq9erW6+uqrVWpqqiotLfVPwKdpwIAB6v3331fr1q1Tq1atUgMHDlRJSUmqqKjIt8z999+vEhMT1dy5c9WKFSvUBRdcoHr16uXHqE/PrFmz1OzZs9WWLVvU5s2b1WOPPabMZrNat26dUqrhl+9Yy5YtUykpKapjx45qxIgRvvmBUM6nnnpKtW/fXh08eNA3ZWdn+15v6GXMzc1VycnJKj09XS1dulTt2LFD/fjjj2rbtm2+ZRr6d45SSmVlZVU6hnPmzFGAmj9/vlKq4R9HpZR6/vnnVVRUlPr222/Vzp071ZdffqlCQ0PVxIkTfcvUx7GU5KYWnH/++WrYsGG+vz0ej0pISFATJkzwY1S159jkxuv1qri4OPXyyy/75uXl5Smr1ao+/fRTP0R45rKyshSgFi5cqJTSy2M2m9WXX37pW2bjxo0KUEuWLPFXmGesUaNG6r///W/Ala+wsFC1bNlSzZkzR1188cW+5CZQyvnUU0+pTp06VftaIJTx0UcfVX369Dnu64H4naOUUiNGjFDNmzdXXq83II6jUkpdeeWVaujQoZXmXX/99eq2225TStXfsZRmqTPkdDpZuXIl/fv3980zGAz079+fJUuW+DGyurNz504yMjIqldlut9OjR48GW+b8/HwAIiMjAVi5ciUul6tSGdu0aUNSUlKDLKPH4+Gzzz6juLiYnj17Blz5hg0bxpVXXlmpPBBYx3Hr1q0kJCTQrFkzbrvtNvbs2QMERhlnzZpFt27duOmmm2jcuDFdunThP//5j+/1QPzOcTqdfPTRRwwdOhRN0wLiOAL06tWLuXPnsmXLFgBWr17Nr7/+yhVXXAHU37E8526cWdtycnLweDzExsZWmh8bG8umTZv8FFXdysjIAKi2zBWvNSRer5eRI0fSu3dvOnToAOhltFgsREREVFq2oZVx7dq19OzZk7KyMkJDQ5kxYwbt2rVj1apVAVE+gM8++4w//viD5cuXV3ktUI5jjx49mDp1Kq1bt+bgwYM888wzXHjhhaxbty4gyrhjxw7eeecdRo0axWOPPcby5ct5+OGHsVgsDBkyJOC+cwBmzpxJXl4e6enpQOB8VseMGUNBQQFt2rTBaDTi8Xh4/vnnue2224D6O39IciPOecOGDWPdunX8+uuv/g6l1rVu3ZpVq1aRn5/PtGnTGDJkCAsXLvR3WLVm7969jBgxgjlz5mCz2fwdTp2p+NUL0LFjR3r06EFycjJffPEFQUFBfoysdni9Xrp168b48eMB6NKlC+vWrWPy5MkMGTLEz9HVjffee48rrriChIQEf4dSq7744gs+/vhjPvnkE9q3b8+qVasYOXIkCQkJ9XospVnqDEVHR2M0Gqv0aM/MzCQuLs5PUdWtinIFQpmHDx/Ot99+y/z582natKlvflxcHE6nk7y8vErLN7QyWiwWWrRoQdeuXZkwYQKdOnVi4sSJAVO+lStXkpWVxXnnnYfJZMJkMrFw4ULeeOMNTCYTsbGxAVHOY0VERNCqVSu2bdsWEMcyPj6edu3aVZrXtm1bX9NbIH3nAOzevZuff/6Ze+65xzcvEI4jwN///nfGjBnDLbfcQlpaGnfccQePPPIIEyZMAOrvWEpyc4YsFgtdu3Zl7ty5vnler5e5c+fSs2dPP0ZWd1JTU4mLi6tU5oKCApYuXdpgyqyUYvjw4cyYMYN58+aRmppa6fWuXbtiNpsrlXHz5s3s2bOnwZSxOl6vF4fDETDl69evH2vXrmXVqlW+qVu3btx2222+54FQzmMVFRWxfft24uPjA+JY9u7du8qlGLZs2UJycjIQGN85R3v//fdp3LgxV155pW9eIBxHgJKSEgyGyqmF0WjE6/UC9Xgsa61r8jnss88+U1arVU2dOlVt2LBB3XfffSoiIkJlZGT4O7QaKywsVH/++af6888/FaBee+019eeff6rdu3crpfShfBEREerrr79Wa9asUddcc02DGpb5wAMPKLvdrhYsWFBpaGZJSYlvmfvvv18lJSWpefPmqRUrVqiePXuqnj17+jHq0zNmzBi1cOFCtXPnTrVmzRo1ZswYpWma+umnn5RSDb98x3P0aCmlAqOcf/vb39SCBQvUzp071eLFi1X//v1VdHS0ysrKUko1/DIuW7ZMmUwm9fzzz6utW7eqjz/+WAUHB6uPPvrIt0xD/86p4PF4VFJSknr00UervNbQj6NSSg0ZMkQ1adLENxR8+vTpKjo6Wv3jH//wLVMfx1KSm1oyadIklZSUpCwWizr//PPV77//7u+Qzsj8+fMVUGUaMmSIUkofzjdu3DgVGxurrFar6tevn9q8ebN/gz4N1ZUNUO+//75vmdLSUvXggw+qRo0aqeDgYHXdddepgwcP+i/o0zR06FCVnJysLBaLiomJUf369fMlNko1/PIdz7HJTSCUc/DgwSo+Pl5ZLBbVpEkTNXjw4ErXgAmEMn7zzTeqQ4cOymq1qjZt2qh///vflV5v6N85FX788UcFVBt7IBzHgoICNWLECJWUlKRsNptq1qyZevzxx5XD4fAtUx/HUlPqqMsGCiGEEEI0cNLnRgghhBABRZIbIYQQQgQUSW6EEEIIEVAkuRFCCCFEQJHkRgghhBABRZIbIYQQQgQUSW6EEEIIEVAkuRFCnPMWLFiApmlV7usjhGiYJLkRQgghRECR5EYIIYQQAUWSGyGE33m9XiZMmEBqaipBQUF06tSJadOmAUeajGbPnk3Hjh2x2WxccMEFrFu3rtI6vvrqK9q3b4/VaiUlJYVXX3210usOh4NHH32UxMRErFYrLVq04L333qu0zMqVK+nWrRvBwcH06tWryp2qhRANgyQ3Qgi/mzBhAh9++CGTJ09m/fr1PPLII9x+++0sXLjQt8zf//53Xn31VZYvX05MTAyDBg3C5XIBelJy8803c8stt7B27Vqefvppxo0bx9SpU33vv/POO/n0009544032LhxI++++y6hoaGV4nj88cd59dVXWbFiBSaTiaFDh9ZL+YUQtUtunCmE8CuHw0FkZCQ///wzPXv29M2/5557KCkp4b777uMvf/kLn332GYMHDwYgNzeXpk2bMnXqVG6++WZuu+02srOz+emnn3zv/8c//sHs2bNZv349W7ZsoXXr1syZM4f+/ftXiWHBggX85S9/4eeff6Zfv34AfPfdd1x55ZWUlpZis9nqeC8IIWqT1NwIIfxq27ZtlJSUcOmllxIaGuqbPvzwQ7Zv3+5b7ujEJzIyktatW7Nx40YANm7cSO/evSutt3fv3mzduhWPx8OqVaswGo1cfPHFJ4ylY8eOvufx8fEAZGVlnXEZhRD1y+TvAIQQ57aioiIAZs+eTZMmTSq9ZrVaKyU4NRUUFHRKy5nNZt9zTdMAvT+QEKJhkZobIYRftWvXDqvVyp49e2jRokWlKTEx0bfc77//7nt++PBhtmzZQtu2bQFo27YtixcvrrTexYsX06pVK4xGI2lpaXi93kp9eIQQgUtqboQQfhUWFsbo0aN55JFH8Hq99OnTh/z8fBYvXkx4eDjJyckAPPvss0RFRREbG8vjjz9OdHQ01157LQB/+9vf6N69O8899xyDBw9myZIlvPnmm7z99tsApKSkMGTIEIYOHcobb7xBp06d2L17N1lZWdx8883+KroQoo5IciOE8LvnnnuOmJgYJkyYwI4dO4iIiOC8887jscce8zULvfDCC4wYMYKtW7fSuXNnvvnmGywWCwDnnXceX3zxBU8++STPPfcc8fHxPPvss6Snp/u28c477/DYY4/x4IMPcujQIZKSknjsscf8UVwhRB2T0VJCiLNaxUimw4cPExER4e9whBANgPS5EUIIIURAkeRGCCGEEAFFmqWEEEIIEVCk5kYIIYQQAUWSGyGEEEIEFEluhBBCCBFQJLkRQgghRECR5EYIIYQQAUWSGyGEEEIEFEluhBBCCBFQJLkRQgghRECR5EYIIYQQAUWSGyGEEEIEFEluhBBCCBFQJLkRQgghRECR5EYIIYQQAUWSGyGEEEIEFEluhBBCCBFQJLkRQgghRECR5EYIIYQQAUWSGyGEEEIEFEluhBBCCBFQJLkRQgghRECR5EYIIYQQAUWSGyGEEEIEFEluhBBCCBFQJLkRQgghRECR5EYIIYQQAUWSGyGEEEIEFEluhBBCCBFQJLkRQgghRECR5EYIIYQQAUWSGyGEEEIEFEluhBBnvV27dqFpGlOnTj3t9y5YsABN01iwYMEJl5s6dSqaprFr164axSiEOHtIciOEEEKIgCLJjRBCCCECiiQ3QgghhAgoktwIIU7q6aefRtM0tmzZwu23347dbicmJoZx48ahlGLv3r1cc801hIeHExcXx6uvvlplHVlZWdx9993ExsZis9no1KkTH3zwQZXl8vLySE9Px263ExERwZAhQ8jLy6s2rk2bNnHjjTcSGRmJzWajW7duzJo1q1bL/vbbb9O+fXusVisJCQkMGzasSjxbt27lhhtuIC4uDpvNRtOmTbnlllvIz8/3LTNnzhz69OlDREQEoaGhtG7dmscee6xWYxVC6Ez+DkAI0XAMHjyYtm3b8sILLzB79mz++c9/EhkZybvvvssll1zCiy++yMcff8zo0aPp3r07F110EQClpaX07duXbdu2MXz4cFJTU/nyyy9JT08nLy+PESNGAKCU4pprruHXX3/l/vvvp23btsyYMYMhQ4ZUiWX9+vX07t2bJk2aMGbMGEJCQvjiiy+49tpr+eqrr7juuuvOuLxPP/00zzzzDP379+eBBx5g8+bNvPPOOyxfvpzFixdjNptxOp0MGDAAh8PBQw89RFxcHPv37+fbb78lLy8Pu93O+vXrueqqq+jYsSPPPvssVquVbdu2sXjx4jOOUQhRDSWEECfx1FNPKUDdd999vnlut1s1bdpUaZqmXnjhBd/8w4cPq6CgIDVkyBDfvNdff10B6qOPPvLNczqdqmfPnio0NFQVFBQopZSaOXOmAtRLL71UaTsXXnihAtT777/vm9+vXz+VlpamysrKfPO8Xq/q1auXatmypW/e/PnzFaDmz59/wjK+//77ClA7d+5USimVlZWlLBaLuuyyy5TH4/Et9+abbypATZkyRSml1J9//qkA9eWXXx533f/6178UoLKzs08YgxCidkizlBDilN1zzz2+50ajkW7duqGU4u677/bNj4iIoHXr1uzYscM377vvviMuLo5bb73VN89sNvPwww9TVFTEwoULfcuZTCYeeOCBStt56KGHKsWRm5vLvHnzuPnmmyksLCQnJ4ecnBwOHTrEgAED2Lp1K/v37z+jsv788884nU5GjhyJwXDkq/Lee+8lPDyc2bNnA2C32wH48ccfKSkpqXZdERERAHz99dd4vd4ziksIcXKS3AghTllSUlKlv+12Ozabjejo6CrzDx8+7Pt79+7dtGzZslKSANC2bVvf6xWP8fHxhIaGVlqudevWlf7etm0bSinGjRtHTExMpempp54C9D4+Z6IipmO3bbFYaNasme/11NRURo0axX//+1+io6MZMGAAb731VqX+NoMHD6Z3797cc889xMbGcsstt/DFF19IoiNEHZE+N0KIU2Y0Gk9pHuj9Z+pKRVIwevRoBgwYUO0yLVq0qLPtH+vVV18lPT2dr7/+mp9++omHH36YCRMm8Pvvv9O0aVOCgoJYtGgR8+fPZ/bs2fzwww98/vnnXHLJJfz000/H3YdCiJqRmhshRJ1LTk5m69atVWoqNm3a5Hu94vHgwYMUFRVVWm7z5s2V/m7WrBmgN23179+/2iksLOyMY65u206nk507d/per5CWlsYTTzzBokWL+OWXX9i/fz+TJ0/2vW4wGOjXrx+vvfYaGzZs4Pnnn2fevHnMnz//jOIUQlQlyY0Qos4NHDiQjIwMPv/8c988t9vNpEmTCA0N5eKLL/Yt53a7eeedd3zLeTweJk2aVGl9jRs3pm/fvrz77rscPHiwyvays7PPOOb+/ftjsVh44403KtVCvffee+Tn53PllVcCUFBQgNvtrvTetLQ0DAYDDocD0PsIHatz584AvmWEELVHmqWEEHXuvvvu49133yU9PZ2VK1eSkpLCtGnTWLx4Ma+//rqvlmXQoEH07t2bMWPGsGvXLtq1a8f06dMr9V+p8NZbb9GnTx/S0tK49957adasGZmZmSxZsoR9+/axevXqM4o5JiaGsWPH8swzz3D55Zdz9dVXs3nzZt5++226d+/O7bffDsC8efMYPnw4N910E61atcLtdvO///0Po9HIDTfcAMCzzz7LokWLuPLKK0lOTiYrK4u3336bpk2b0qdPnzOKUwhRlSQ3Qog6FxQUxIIFCxgzZgwffPABBQUFtG7dmvfff5/09HTfcgaDgVmzZjFy5Eg++ugjNE3j6quv5tVXX6VLly6V1tmuXTtWrFjBM888w9SpUzl06BCNGzemS5cuPPnkk7US99NPP01MTAxvvvkmjzzyCJGRkdx3332MHz8es9kMQKdOnRgwYADffPMN+/fvJzg4mE6dOvH9999zwQUXAHD11Veza9cupkyZQk5ODtHR0Vx88cU888wzvtFWQojao6m67PUnhBBCCFHPpM+NEEIIIQKKJDdCCCGECCiS3AghhBAioEhyI4QQQoiAIsmNEEIIIQKKJDdCCCGECCjn3HVuvF4vBw4cICwsDE3T/B2OEEIIIU6BUorCwkISEhKq3IT3WOdccnPgwAESExP9HYYQQgghamDv3r00bdr0hMucc8lNxWXe9+7dS3h4uJ+jEUIIIcSpKCgoIDEx8ZRuinvOJTcVTVHh4eGS3AghhBANzKl0KZEOxUIIIYQIKJLc1CKlFGUuj7/DEEIIIc5pktzUkt93HKLNuB+45s3F/g5FCCGEOKedc31u6kqYzYTD7eVQsdPfoQghhPAjj8eDy+XydxgNksViOekw71MhyU0tiQqxAnC4xInXqzAY5Bo6QghxLlFKkZGRQV5enr9DabAMBgOpqalYLJYzWo8kN7WkUYgZAI9XUVDmIiL4zA6MEEKIhqUisWncuDHBwcFyodjTVHGR3YMHD5KUlHRG+0+Sm1piNRkJs5oodLg5VOyU5EYIIc4hHo/Hl9hERUX5O5wGKyYmhgMHDuB2uzGbzTVej3QorkWRoXpCc6hI+t0IIcS5pKKPTXBwsJ8jadgqmqM8njMbeSzJTS2KDNEPSm6xw8+RCCGE8AdpijoztbX/JLmpRVHlyY2MmBJCCCH8R5KbWlQxYipXmqWEEEKcg1JSUnj99df9HYZ0KK5Nvj43UnMjhBCigejbty+dO3eulaRk+fLlhISEnHlQZ0iSm1oU5etzI8mNEEKIwKCUwuPxYDKdPGWIiYmph4hOTpqlalGkJDdCCCHQE4ISp9svk1LqlONMT09n4cKFTJw4EU3T0DSNqVOnomka33//PV27dsVqtfLrr7+yfft2rrnmGmJjYwkNDaV79+78/PPPldZ3bLOUpmn897//5brrriM4OJiWLVsya9as2trNxyU1N7WoIrnJKZLRUkIIcS4rdXlo9+SPftn2hmcHEGw5tdP7xIkT2bJlCx06dODZZ58FYP369QCMGTOGV155hWbNmtGoUSP27t3LwIEDef7557FarXz44YcMGjSIzZs3k5SUdNxtPPPMM7z00ku8/PLLTJo0idtuu43du3cTGRl55oU9Dqm5qUW+DsVScyOEEKIBsNvtWCwWgoODiYuLIy4uDqPRCMCzzz7LpZdeSvPmzYmMjKRTp0783//9Hx06dKBly5Y899xzNG/e/KQ1Menp6dx66620aNGC8ePHU1RUxLJly+q0XFJzU4sqOhQfLnGilJLrHQghxDkqyGxkw7MD/Lbt2tCtW7dKfxcVFfH0008ze/ZsDh48iNvtprS0lD179pxwPR07dvQ9DwkJITw8nKysrFqJ8XgkualFFR2KXR5FQZkbe1DNLx0thBCi4dI07ZSbhs5Wx456Gj16NHPmzOGVV16hRYsWBAUFceONN+J0nri14tjbKGiahtfrrfV4j9aw9/xZxmY2EmIxUuz0kFvslORGCCHEWc9isZzS7Q4WL15Meno61113HaDX5OzatauOo6uZBtfn5p133qFjx46Eh4cTHh5Oz549+f777/0dlk9F05TcgkEIIURDkJKSwtKlS9m1axc5OTnHrVVp2bIl06dPZ9WqVaxevZq//vWvdV4DU1MNLrlp2rQpL7zwAitXrmTFihVccsklXHPNNb7e3f4WWd6pWG6eKYQQoiEYPXo0RqORdu3aERMTc9w+NK+99hqNGjWiV69eDBo0iAEDBnDeeefVc7SnRlOnMyD+LBUZGcnLL7/M3XfffdJlCwoKsNvt5OfnEx4eXuuxDJ26nHmbsnjh+jRuOf/4Q+OEEEIEjrKyMnbu3Elqaio2m83f4TRYJ9qPp3P+btB9bjweD19++SXFxcX07Nmz2mUcDgcOx5EmooKCgjqNKVJunimEEEL4VYNrlgJYu3YtoaGhWK1W7r//fmbMmEG7du2qXXbChAnY7XbflJiYWKex+e4MLs1SQgghhF80yOSmdevWrFq1iqVLl/LAAw8wZMgQNmzYUO2yY8eOJT8/3zft3bu3TmOLkg7FQgghhF81yGYpi8VCixYtAOjatSvLly9n4sSJvPvuu1WWtVqtWK3WeovN16FYmqWEEEIIv2iQNTfH8nq9lfrV+JPcGVwIIYTwrwZXczN27FiuuOIKkpKSKCws5JNPPmHBggX8+KN/blB2LLkzuBBCCOFfDS65ycrK4s477+TgwYPY7XY6duzIjz/+yKWXXurv0IDKo6Xk/lJCCCFE/Wtwyc17773n7xBOqKJDsdPtpcjhJswmt2AQQggh6lNA9Lk5mwRbTNjM+m6VpikhhBCi/klyUweiZMSUEEKIBqJv376MHDmy1taXnp7OtddeW2vrqwlJbuqA71o3ciE/IYQQot5JclMHZMSUEEKIhiA9PZ2FCxcyceJENE1D0zR27drFunXruOKKKwgNDSU2NpY77riDnJwc3/umTZtGWloaQUFBREVF0b9/f4qLi3n66af54IMP+Prrr33rW7BgQb2Xq8F1KG4I5P5SQghxjlMKXCX+2bY5GE5xpO7EiRPZsmULHTp04Nlnn9XfbjZz/vnnc8899/Cvf/2L0tJSHn30UW6++WbmzZvHwYMHufXWW3nppZe47rrrKCws5JdffkEpxejRo9m4cSMFBQW8//77gH5z6/omyU0dOHIhv7PjwoJCCCHqmasExif4Z9uPHQBLyCktarfbsVgsBAcHExcXB8A///lPunTpwvjx433LTZkyhcTERLZs2UJRURFut5vrr7+e5ORkANLS0nzLBgUF4XA4fOvzB0lu6oDvFgzS50YIIUQDs3r1aubPn09oaGiV17Zv385ll11Gv379SEtLY8CAAVx22WXceOONNGrUyA/RVk+SmzoQJc1SQghxbjMH6zUo/tr2GSgqKmLQoEG8+OKLVV6Lj4/HaDQyZ84cfvvtN3766ScmTZrE448/ztKlS0lNTT2jbdcWSW7qgHQoFkKIc5ymnXLTkL9ZLBY8Ho/v7/POO4+vvvqKlJQUTKbq0wRN0+jduze9e/fmySefJDk5mRkzZjBq1Kgq6/MHGS1VB3xDwSW5EUIIcZZLSUlh6dKl7Nq1i5ycHIYNG0Zubi633nory5cvZ/v27fz444/cddddeDweli5dyvjx41mxYgV79uxh+vTpZGdn07ZtW9/61qxZw+bNm8nJycHlctV7mSS5qQNHLuInHYqFEEKc3UaPHo3RaKRdu3bExMTgdDpZvHgxHo+Hyy67jLS0NEaOHElERAQGg4Hw8HAWLVrEwIEDadWqFU888QSvvvoqV1xxBQD33nsvrVu3plu3bsTExLB48eJ6L5M0S9WByPKamzKXlxKnm2CL7GYhhBBnp1atWrFkyZIq86dPn17t8m3btuWHH3447vpiYmL46aefai2+mpCamzoQYjFiMem7VkZMCSGEEPVLkps6oGnaUde6keRGCCGEqE+S3NQWtxMy1sGepcDRVymWfjdCCCFEfZLkprbsWACTe8O3I4GjkhtplhJCCCHqlSQ3tSWmtf6YsxU8bqJD9RFT0iwlhBBC1C9JbmqLPRHMIeB1weGdciE/IYQ4Byml/B1Cg1Zb+0+Sm9piMEBMK/151ka5M7gQQpxDzGYzACUlfroTeIBwOvVzptFoPKP1yAVYalNMGzjwJ2RvJiqkMyA1N0IIcS4wGo1ERESQlZUFQHBwMJqm+TmqhsXr9ZKdnU1wcPBxb/twqiS5qU0xbfTH7E1EtpWaGyGEOJfExcUB+BIccfoMBgNJSUlnnBhKclObjkpuorpXjJaSoeBCCHEu0DSN+Ph4Gjdu7Jf7KQUCi8WCwXDmPWYkualNR42YigzS2wulWUoIIc4tRqPxjPuMiDMjHYprU0QymILA4yDGfRCAEqeHMpd/b/0uhBBCnEsaXHIzYcIEunfvTlhYGI0bN+baa69l8+bN/g5Ld9SIqZD8rZiNepuh9LsRQggh6k+DS24WLlzIsGHD+P3335kzZw4ul4vLLruM4uJif4emK+93o2VvPnKtG7lKsRBCCFFv6i25+eCDD5g9e7bv73/84x9ERETQq1cvdu/efcrr+eGHH0hPT6d9+/Z06tSJqVOnsmfPHlauXFkXYZ8+X6fizUSG6FcplvtLCSGEEPWn3pKb8ePHExQUBMCSJUt46623eOmll4iOjuaRRx6p8Xrz8/MBiIyMrJU4z5gvudkodwYXQggh/KDeRkvt3buXFi1aADBz5kxuuOEG7rvvPnr37k3fvn1rtE6v18vIkSPp3bs3HTp0qHYZh8OBw3Gk5qSgoKBG2zplR42Yimqm95aXm2cKIYQQ9afeam5CQ0M5dOgQAD/99BOXXnopADabjdLS0hqtc9iwYaxbt47PPvvsuMtMmDABu93umxITE2u0rVPWKAVMNnCX0dykl1c6FAshhBD1p96Sm0svvZR77rmHe+65hy1btjBw4EAA1q9fT0pKymmvb/jw4Xz77bfMnz+fpk2bHne5sWPHkp+f75v27t1b0yKcGoMRolsC0EzTt5UrfW6EEEKIelNvyc1bb71Fz549yc7O5quvviIqKgqAlStXcuutt57yepRSDB8+nBkzZjBv3jxSU1NPuLzVaiU8PLzSVOdi2gLQ1LUHkD43QgghRH2qtz43ERERvPnmm1XmP/PMM6e1nmHDhvHJJ5/w9ddfExYWRkZGBgB2u93XYdnvyvvdxJTtBHpIs5QQQghRj+qt5uaHH37g119/9f391ltv0blzZ/76179y+PDhU17PO++8Q35+Pn379iU+Pt43ff7553URds2Uj5iKKN4BSM2NEEIIUZ/qLbn5+9//7huptHbtWv72t78xcOBAdu7cyahRo055PUqpaqf09PQ6irwGGuvNUkH529DwykX8hBBCiHpUb81SO3fupF27dgB89dVXXHXVVYwfP54//vjD17k4YEQkg9GKwV1GUy2bvY5YHG4PVpPcSE0IIYSoa/VWc2OxWCgpKQHg559/5rLLLgP0i+/V+bVn6pvR5Bsx1dpwAJCmKSGEEKK+1Fty06dPH0aNGsVzzz3HsmXLuPLKKwHYsmXLCYdyN1jl/W46WvUOz3IhPyGEEKJ+1Fty8+abb2IymZg2bRrvvPMOTZo0AeD777/n8ssvr68w6k95ctPWuB+QmhshhBCivtRbn5ukpCS+/fbbKvP/9a9/1VcI9at8OHgz9gGS3AghhBD1pd6SGwCPx8PMmTPZuHEjAO3bt+fqq6/GaAzAjrblI6aauveg4ZVr3QghhBD1pN6Sm23btjFw4ED2799P69Z6rcaECRNITExk9uzZNG/evL5CqR+NUsFgxuoto4l2SG7BIIQQQtSTeutz8/DDD9O8eXP27t3LH3/8wR9//MGePXtITU3l4Ycfrq8w6s9RI6ZaaPvYmlnk54CEEEKIc0O91dwsXLiQ33//ncjISN+8qKgoXnjhBXr37l1fYdSvmDaQtYFW2j6+3JWL16swGDR/RyWEEEIEtHqrubFarRQWFlaZX1RUhMViqa8w6lf5iKk2xgMcLnGxLVtqb4QQQoi6Vm/JzVVXXcV9993H0qVLfbdM+P3337n//vu5+uqr6yuM+tW48rVulu7M9Wc0QgghxDmh3pKbN954g+bNm9OzZ09sNhs2m41evXrRokULXn/99foKo36V19wkefcCiqU7Dvk3HiGEEOIcUG99biIiIvj666/Ztm2bbyh427ZtadGiRX2FUP8im4HBjMVTQgKHWLbThlIKTZN+N0IIIURdqdPk5mR3+54/f77v+WuvvVaXofiH0QxRLSB7I21NB5hbGM3uQyWkRIf4OzIhhBAiYNVpcvPnn3+e0nIBXZMR0xqyN3JRoxzmZsOynbmS3AghhBB1qE6Tm6NrZs5ZcR1gw0wuNqwBLuH3nYe4uXuiv6MSQgghAla9dSg+Z6XdDGik5C8jVTvIMhkxJYQQQtQpSW7qWqNkaDUAgNtNc9l3uJT9eaV+DkoIIYQIXJLc1Ifu9wAw2LQQGw6WS+2NEEIIUWckuakPzftBRDKhqphBxiUs3SnXuxFCCCHqiiQ39cFggO53A3C78We5UrEQQghRhyS5qS+db0cZrXQy7CA0Zw3ZhQ5/RySEEEIEJElu6ktIFFr76wC4wziH5buk9kYIIYSoC5Lc1KfyjsWDjEtYs2WHn4MRQgghApMkN/WpaTfyI9ph01xEbp3m72iEEEKIgNTgkptFixYxaNAgEhIS0DSNmTNn+jukU6dpGMprby4rnU1ecZmfAxJCCCECT4NLboqLi+nUqRNvvfWWv0OpkbDut1BECClaJjuWfuvvcIQQQoiAU6f3lqoLV1xxBVdccYW/w6g5SwirowfSO+dLQtZ8AJfc6O+IhBBCiIDS4GpuTpfD4aCgoKDS5G+lHdMBaJH3K+RKx2IhhBCiNgV8cjNhwgTsdrtvSkz0/x2523XsykJPR4x48cx4ELwef4ckhBBCBIyAT27Gjh1Lfn6+b9q7d6+/QyIhIoi3gh+gSNkw7l0Cv73h75CEEEKIgBHwyY3VaiU8PLzSdDbo1b0bz7jvBEDNex4OrvFzREIIIURgCPjk5mw1tE8qcyz9+dHTDc3rgun3gUuGhgshhBBnqsElN0VFRaxatYpVq1YBsHPnTlatWsWePXv8G9hpCreZ+b+LWzDWdQ+HiIDsjTD3WX+HJYQQQjR4DS65WbFiBV26dKFLly4AjBo1ii5duvDkk0/6ObLTN6RXMobQaEY779Vn/P4W7Fjg15iEEEKIhq7BJTd9+/ZFKVVlmjp1qr9DO23BFhMP9m3BfG8XphsG6DNnPgilh/0bmBBCCNGANbjkJtD8tUcSceE2Hi8ZTH5wEhTshy/TYe8yUMrf4QkhhBANjiQ3fmYzG3moXwtKsfGw40GUwaQ3Tb13KUzqCotehjz/D18XQgghGgpJbs4CN3VNJDEyiIXFSczo8j50uhXMwZC7Heb9E15Pgw8Gwd7l/g5VCCGEOOtJcnMWsJgMjOjXCoDn/rRReMUkGL0Vrn0HUi4EFOxcpCc4W3/2b7BCCCHEWU6Sm7PEtZ0TaBYTwuESF+8v3gXWUOj8V0j/FkasgZaXgbsUPr0FNnzt73CFEEKIs5YkN2cJk9HAI/312pt3Fmxn9d68Iy82SobBH0P768Dr0jscr/rEL3EKIYQQZztJbs4iV6bFc2HLaEpdHu6aupwd2UVHXjRZ4Ib3oMvtoLww8wFY+m//BSuEEEKcpSS5OYsYDBrv3N6VtCZ2coud3PHeMjILjrolg8EIgyZBjwf0v7//Oyx6RYaMCyGEEEeR5OYsE2o18f5d3UmJCmZ/XilDpiwjv9R1ZAGDAS6fABf9Q/973nPw1vmw5C0oyfVP0EIIIcRZRFPq3PrZX1BQgN1uJz8//6y5Q3h19uaWcP07v5Fd6OD81Eg+HHo+NrOx8kJL3taTG1eJ/rfRAm2vhq7pkNJHr9Fxl4GrVO+M7HaAvSmYrPVeHiGEEOJMnM75W5Kbs9iGAwUMfncJhQ43l7WL5Z3bu2I0aJUXKiuAtV/CyqmQsebIfKMFPM6qKw2KhPPuhG5D9Y7KQgghRAMgyc0JNKTkBuD3HYe4c8oynG4vl7WL5cUbOtIoxFL9wgf+1JOctdPAWVT5NaMVNINegwOABq0uh/PvgWaXgKZBUSbkbIVD2/QJoMP1kHCe/roQQgjhJ5LcnEBDS24Aflh3kOGf/Inbq2gcZuXlmzpxcauY47/BWQLF2fpVjs1B+mQwgscNW36A5f+pfPfxsHhwFIGzsPr1xabptT0db4KgRrVaNiGEEOJUSHJzAg0xuQFYuy+fkZ//yfbsYgDSe6Uw5oo2VfvhnKqcrbD8v/r1chwF+jzNABHJENUColvqCdKGWeBx6K+bbNDuGn2K7wzhCVKjI4QQol5IcnMCDTW5ASh1epjw/UY+XLIbgBaNQ3l9cGc6NLHXfKWOIti/EkJjITK1amfj0sOw5gtY+QFkra/8WkgMxHfSE524Dvr1d0oPQ2kelOXpz8vywVFYPhUdeW6zQ9IFkNxLn6Jb6yPBjsfthMM7IWcLZG/WkzPlgeTe0KyvHvvZwuvRa8bcDmh5KRjNtbfezd/Bnx+DLRwuHA0xrWpn3UIIcZaT5OYEGnJyU2HB5iz+Pm0N2YUOTAaNQZ0SGNo7lbSmZ5DknIxScOAP/cS653fI3qQnF7UlqBEk9QRruD76y1V6ZJRXaR7k7Qav+/jvj0iC1Iv1RMcaBgX7oeAA5O/Xn5fkQlwatOgHzf4CIVG1F3uFomz483+w8n3I21MeVzL0eQQ636ZfiLEmSvP09S7795H1gl7T1uV26DtWr0UTQogAJsnNCQRCcgOQW+zk8Rlr+X5dhm9et+RGDO2TymXtYjEZ6/gSRq5SyFyvd2I+uBqyNurNVkER+mSL0BMWm12frGFHJkuonnDsXgK7F8O+5UeGs5+IJVRvLotupT96PbBjIexbduLEpwpNr3Fq0Q+SeunxWkL0PkqWULAE6zVOh7brd2aveMzbo5clIgkiUvTRZhHJ+qi0Pz6A9TP122OAXn6DCUpy9L/Dm+hJTpc7wGyrPiyl9I7gxTnlUzZsn6c3Hbr05kiCIqHrEMjeAptn6/NMNujxf/r6a9InylkMW3+C9TP0G7OGROkJYPNLIPUiCI48/XWK2qMU7Fuh17A26wuN2/g7orOTUvo+2jQbYtvrt6sx1LDZXpyVJLk5gUBJbiqs3pvH+4t38u2ag7i9+qFsEhHETd2a0qt5NB2b2mveL6e+eFx6grRvuZ6kmGxHdYYO1hOPqOZ6x+fq+vg4imDPEr0paNcvevNYeFO9NiM8Qb+2jzVMr3HaPg8y19VdWRLOg+736KPMlNJHry2eCEXlSWhoHDTpqidz7rIjtVTOEj0RcpdVv97G7eCCByDtJn2/AOxZCj8/DXt+0/+22SGxB4Q0htDGelNjaGMIjtL3qdGsNzsaLXrilbFGT2i2/HiC5FKDJufptWpK6c2NZflHmh4NJkjoAk2761NUi8rNix6XnhTm7oT8vXqiFJEE9iT9eSD12So+BFkb9H0e1eLMT6yZG/TLPKz7Sq+5rNDiUug1XK+pPN7+83r1z1zenvJpNxzeDYUH9c9DoxQ9MW+UoifpYQknbhY+m7lKYd10vWbz4Koj86NbwcWPnjjJ8bj0z7M5CExBp7cPlNL/b0rz9O+tsLjAvYaYq0wfTWtP9OvnRJKbEwi05KZCZkEZH/2+m4+X7iG3+Mj1bSwmA52bRnB+aiTnp0bSOSmCcFst9QFpqAozYPt82D4XMtbpNRfOoiMJB+hNPvZEPamKbK4/RiTrna8P79ZPFnl79OeOAmh7FXS7W08EjuUq05uVfn0dCvadPD5TEITG6H2aGqXqI9VSL6r+RKaUXuvy8zNV+0Sdjohk/STQ9mooOaQngTvm682Pp8Nq1/eBwQi5O/R9dLxaNXOwvo/DYkErP/n4yqgBSn+v13PkUXn0JK4icQuN1SdbhH4cKvp6lZY/et3ltYcRR9UoRujr9zj0vlweh94/yuPSE2mbXe/TZLPr5bEE6yEppcekvPrzw7v0mssDf+pNtkc3GZpsekIa10EfbRjVTE9gSw9XnjxOPUE0WvTk02jW1719np4o+fZVCMR31BN0yr+yY9Og5zBofYVeu5ixBjLW6lPm+iO1fafCYD6yP8PijjwaLeX7NE9PAsry9GtrBTUqT4xSjiRI9kR9/xktlT+rSunNwnm7jvzP5O/Vj3lY+fELjTuyfWuYnmwc7/PuKNDXV3IINs6CPz7U9yXol7xoeSns+lWPFfT+fH0fhXbX6f/n+5bp+3HP73qNmO/yGBz1wypYPxYGU/mjUX+uGfTyV+wTr6tyfCEx5T+qmuiPJpt+jN1l+mfNXaZ/zmx2/X88NPbIj5HgqCPb0Ax6+TVN/34qzNCb2QszoPAAFGXptcwVtccVjyExei1z5gb9+yBzvf68KKN8nUa9LJpRT1LCm+j/r0266j/MYtvr5XU79H2z6xfY+Yv+w9PjAEuYXuud0Fn/UZPQRf+xQvmxqvT/S60nQpLcnECgJjcVylwevl1zkPmbsli6M5ecIkeVZVKigunQxE5a+dQ+wY49+BxPeCp4PfqXicla+7/C3E69Kak078gQfVPQkRqqkCj9y8kSUrO4d/0CeXv1X1hFWUceSw7pX7CVJpe+rXZXQ/vr9S+p6k4m+fv1GrGDq/Q4bRH6F3NQ+aOjCPavgH0r9ZP80SeKCqYgiGym16CV5pbHmFF1uUAQkaQ3KZ5KM+vJGC3Q8jLocIN+TSpLsJ4w/j4Z/vzo5MmLZtBrMBsllzelJum1nyWH9MQsb7f+mL/vNJt1TzF2o1XvZ+Z2VL3u1klpRzUVB+sn/YqEtbq+fvYk6H633uwbEqUnIEvfhSWT9KQM9M97ySE9Oa1NFQlDdRdNbWhMNohqCYe2Vq1F1oyn18+y6flwz5xaDU+SmxMI9OTmaEopduYUs3xXLkt35rJ8Vy57c6s5+aDf06pxuJXGYVZiw200DrMSZw8iOTKYlOhgmjYKPvubt4R/eVx6bcP+lfoXYVRzPakJjav6C85Vpve7ytujJwO+E46qfCPYil/N2tG/nPOOSeAy9ZOetTzpCmp05NFgqtyMVvEI5SffoyaDSU9sywrKR/mVPzqLyxM/rfJjaGP9127FL9iEznrC5/XozXCZa/Wawcx1em2FLbw8tqMmk1Xfbx6XXgvgcervb9wO2g4qr2WqRulhvclz6bt6U1NIDMR11GuK4jrqnecjm53aSD2PW082CzPLHzP0fVqYocd1dI2XLUKvWalIkI6eKvqXHU9oXOVES3mPHMPC8uNYnI2vZupEzMF6/7PYdvrV1lteVn3TU1m+ngwueQsc5UlOoxS9mTXpAv0xsvmR29T4BjMUlx8T91GTR5+sYZX3iSVUX2/p4SMDGQr26z8MPA49YTBZyz9vNjCWJ2pFWVCcVb4PsvTEX3mPmsr/F0wWvdkwPF6vTQtL0D97R9ciV9SGeZz6/0Fse33fNG4HsR3Ka1fUkdrPirIc2qb/vx74Q3+sSARB/0ylXAipF0LKRfp+y9lypLby4Cq9lvB4TemS3NSvcym5qc7hYidr9+ezdn8+68of9x2uPuE5mqZBfLiN5KgQYsKshFhNhNlMhFhMhNpMhFqNhNvMhNnMhAeZCLeZCQ8yE2o1YTE10LZ8Ic52Hrd+kjsbOn27ysqbXZzlzXzlj0aLXmt3vI70R/N6yxOMEr22x1n+vCLJCorUk8JTWdfRSvP0fn0xrfUEIRB5vXriHtSoZn3ZlNJrBrM26n3GYlqffD0et37x12PTCKX0ZPN4yXkNSXJzAud6clOdIoebrIIyMgscZBWWkVX+uD+vlN2HSth9qIQiR82rrU0GjSCzkSBL+WQ2EmwxEmYzE2ozEW4z6c+tJkKsJkIsRoKtesIUbDFhMxtxe7w4PV6cbi8uj8Lp9mI0aMSEWYgJtREdZiHYYqrFvSKEEOJscjrnbzkbCEKtJkJjQmkWE1rt60opcoud7M4tYfehYnKLXRSVuSl2uiksc1PkcFNU5qKwTP+7oMxFQamLYqfePuv2KgodbgrPIEE6FSEWIzFh1mqbzzRNw2TQMBo0zEYNk8GAyahhNRlpFGwmMtRCZLCFRiH6o9lkoNTpweH2UOr0UObyUOb2YjEajiRhViOhVj35UgrcXi8er/JNAGaTAbPRgMVowGLSMBsNaOWd7RRKr3kuj9FmNhBsNmGz6Mtrx/xq8noVTo8Xh9uL2agnjMcucyyH20OZy0uo1VT1pqtCCBGgJLkRJ6VpGlGhVqJCrZyXdOrXUXF7vBQ7PJS6PJQ43ZS69CShxOmh2OGhsDwhKnK4fc+LnR5KHHripC/npszlxWTUsBjLEwWTfvJ3eb3kFDnILnRQ5vJS7PRQfKgWOnKeBYwGjWCzEZNRw+nWa61cnsqVrCaDRniQuVLNV5nbQ0Gpi4IyNwWlLhxuvS+LpkG4zUxEsJmIYAsRQWYsJoO+bveRWjGn24um6duvSAZNBgNGg4bVbMBmMvoebWYDJqPhSEKnFF6vwu1VeMuzNoWeHFdErqF/njQNNDQM5duymgxYzUZs5Y9WkwGTQcNg0Cq9x6BpeMu3o29TX79XKYwGw1Exa5iMBszlnxuLyYDVZNQ/OyYDGuBRRxJRr1fh8qryz57+uStyuCl2uHF7FaHWIzWMYTYT4UFmzEYNj/dIUuv2Kjwe/dE3z6M/BwizmbEHHTUFm7EYDXrC6jpyDBxuDy63wuX16u/3eHGVx2gyapX+ByoeK+abDJqeUBv0146X0CqlKHF6yC91kV/qotTlwWI0YCvf9zazfpyDzEbMJ7hmllKKMpeXwjIXJU5P+Y+HI/FU7P9Tue6Wy+OlzOXxlel4ibvTrW8vv9SFV0GQRf/c6I9GDJLECxpwcvPWW2/x8ssvk5GRQadOnZg0aRLnn3++v8MSRzEZDdiDDdip25FYSimKHG5yipxkFzpwuquOhvAq/eR79MnC4/VS6vRyuMTJ4WInuSVOcov15y6P0r8sy7/gK064TreXYoebYodHP/k53ZQ6PfpJ1ahh1I4kBArla0LTkxP95KVU+ShPyk/a6ElAmcvju1aRp7y260TcXr1G7eih/8ffR/hOZLsDJAEUJ2c6KnG0lid2xQ43+aWuKsnyidYRZDZiK29StpkNONxeCkr1HyQVn9kT0RMng69Z2mY24vHqCVax002Jw4PTc+T/1mjQCLYYyycTJoNWXiOs/0g64bbKE2NjeUJsLE94DZqecFXshyNJFOVJ5dFN317f8uajEkqTQcPjVTg9Clf5/7TL7UWBr+k92GIkyGIiuLwGucxdXvPr0pO3iu8nwzExVsRx9A8Oh1uPI7S8j2OotaKPownFkeUdbn29Hq/CajZW2nfBFiMmg4FSl/6DscSp10aXOPVjp5T+/VjxePQxMGj6DxBNO/KjoWI/VPx40DQNb/kPGo9XX4dXKVrEhPLEVe1O6TNWFxpkcvP5558zatQoJk+eTI8ePXj99dcZMGAAmzdvpnHjxv4OT9QzTdPKf1GbSY2uwTDqs4jL4/V9+ZS6PLg83iNfxkb9JGUxGnB5vBSU13bpNTX68yCzsbw250gNg9VkoLDMTV6Jk7xSF3klLg6XOHF7VKUv+YrtgJ44ecprDjzltRqO8qY5h8uDw61/Ubs8CqOB8qTOgNGgf2kbtIoaF72G5tjLnnjLa3MqamEc5SeXSuv26lU/R3/xehW+2h6DppWfIPTPQEUtzNE1Ka6jaqQcRz3C0Sc9MBkMGAwaIRajr8kxxKI3P5oMWnntotu3nwvLXHi8CoOvhutITZPZ1/xp8DWDKgUF5bUN+eXHwHFMEn70MTi29qOi9qzihHps/zOXx1t+zConGm6vwu30+JqIj2UyaEQEmwmyGHG6vZS5vL6mzKPXcbJmZU2DYLMRr8IXy9Gc5TEXlJ1a07THq3zN3FD1chYAYVYTBoNGWflnxrctt5cAGJRdSX6p6+QLnWUK/Bxzg+xQ3KNHD7p3786bb74JgNfrJTExkYceeogxY8ac8L3SoVgIcTYoK09eT9YMczr05jU9KdWbefRkRU8cvTg9HoItJl/TWLCl+n5bSinfe8rcR5LtUpeHMqfedFTRRFcxavLo5iCl9FpLt7fyOkrK+6+VujzltTNHBhCEWPQaHYfbS0l5s3TFe1weL+HlzXrhQXrz4NFNbl6vKq8h8VLq8uDxlDeTlifP3vI+cb6aVLe+LypqUo9O8iuSS6BSTY6eKCu9qa18mYr+dICv+f1I7YieyFnLa6pspiPNfgBedaSWw+PVk32r8UitUkVtkder10zrfRv1JLOozI2mUamp1VLeLOlwe301yhWPLo/y1eb4apfMJiwmzVd7rNfS6D9EKn5IHL3/Kn44uD1637+KJlevV+k/Esp/cBjLf3REhVr4S+varWwI6A7FTqeTlStXMnbsWN88g8FA//79WbJkSZXlHQ4HDseRzL+goKBe4hRCiBOxlZ/0apPBoGE1GLGe4Te7pmm++GrSrKxpGhaThgUDwad5v1ib2Yg96PS2aShPlE53WyJwNbgLkOTk5ODxeIiNja00PzY2loyMqlc9nTBhAna73TclJibWV6hCCCGE8IMGl9ycrrFjx5Kfn++b9u7d6++QhBBCCFGHGlyzVHR0NEajkczMzErzMzMziYureuVJq9WK1Rqgd2oVQgghRBUNLrmxWCx07dqVuXPncu211wJ6h+K5c+cyfPjwk76/ov+09L0RQgghGo6K8/apjINqcMkNwKhRoxgyZAjdunXj/PPP5/XXX6e4uJi77rrrpO8tLCwEkL43QgghRANUWFiI3W4/4TINMrkZPHgw2dnZPPnkk2RkZNC5c2d++OGHKp2Mq5OQkMDevXsJCwurlaGXRysoKCAxMZG9e/cG7DBzKWNgkDIGBiljYJAynhqlFIWFhSQkJJx02QaZ3AAMHz78lJqhjmUwGGjatGkdRHREeHh4wH5AK0gZA4OUMTBIGQODlPHkTlZjUyHgR0sJIYQQ4twiyY0QQgghAookN7XIarXy1FNPBfTQcyljYJAyBgYpY2CQMta+BnlvKSGEEEKI45GaGyGEEEIEFEluhBBCCBFQJLkRQgghRECR5EYIIYQQAUWSm1ry1ltvkZKSgs1mo0ePHixbtszfIZ2RRYsWMWjQIBISEtA0jZkzZ1Z6XSnFk08+SXx8PEFBQfTv35+tW7f6J9gamDBhAt27dycsLIzGjRtz7bXXsnnz5krLlJWVMWzYMKKioggNDeWGG26ocsPWs9k777xDx44dfRfN6tmzJ99//73v9YZevuq88MILaJrGyJEjffMCoZxPP/00mqZVmtq0aeN7PRDKuH//fm6//XaioqIICgoiLS2NFStW+F5v6N85ACkpKVWOo6ZpDBs2DAiM4+jxeBg3bhypqakEBQXRvHlznnvuuUr3g6qXY6nEGfvss8+UxWJRU6ZMUevXr1f33nuvioiIUJmZmf4Orca+++479fjjj6vp06crQM2YMaPS6y+88IKy2+1q5syZavXq1erqq69WqampqrS01D8Bn6YBAwao999/X61bt06tWrVKDRw4UCUlJamioiLfMvfff79KTExUc+fOVStWrFAXXHCB6tWrlx+jPj2zZs1Ss2fPVlu2bFGbN29Wjz32mDKbzWrdunVKqYZfvmMtW7ZMpaSkqI4dO6oRI0b45gdCOZ966inVvn17dfDgQd+UnZ3te72hlzE3N1clJyer9PR0tXTpUrVjxw71448/qm3btvmWaejfOUoplZWVVekYzpkzRwFq/vz5SqmGfxyVUur5559XUVFR6ttvv1U7d+5UX375pQoNDVUTJ070LVMfx1KSm1pw/vnnq2HDhvn+9ng8KiEhQU2YMMGPUdWeY5Mbr9er4uLi1Msvv+ybl5eXp6xWq/r000/9EOGZy8rKUoBauHChUkovj9lsVl9++aVvmY0bNypALVmyxF9hnrFGjRqp//73vwFXvsLCQtWyZUs1Z84cdfHFF/uSm0Ap51NPPaU6depU7WuBUMZHH31U9enT57ivB+J3jlJKjRgxQjVv3lx5vd6AOI5KKXXllVeqoUOHVpp3/fXXq9tuu00pVX/HUpqlzpDT6WTlypX079/fN89gMNC/f3+WLFnix8jqzs6dO8nIyKhUZrvdTo8ePRpsmfPz8wGIjIwEYOXKlbhcrkplbNOmDUlJSQ2yjB6Ph88++4zi4mJ69uwZcOUbNmwYV155ZaXyQGAdx61bt5KQkECzZs247bbb2LNnDxAYZZw1axbdunXjpptuonHjxnTp0oX//Oc/vtcD8TvH6XTy0UcfMXToUDRNC4jjCNCrVy/mzp3Lli1bAFi9ejW//vorV1xxBVB/x7LB3jjzbJGTk4PH46lyR/LY2Fg2bdrkp6jqVkZGBkC1Za54rSHxer2MHDmS3r1706FDB0Avo8ViISIiotKyDa2Ma9eupWfPnpSVlREaGsqMGTNo164dq1atCojyAXz22Wf88ccfLF++vMprgXIce/TowdSpU2ndujUHDx7kmWee4cILL2TdunUBUcYdO3bwzjvvMGrUKB577DGWL1/Oww8/jMViYciQIQH3nQMwc+ZM8vLySE9PBwLnszpmzBgKCgpo06YNRqMRj8fD888/z2233QbU3/lDkhtxzhs2bBjr1q3j119/9Xcota5169asWrWK/Px8pk2bxpAhQ1i4cKG/w6o1e/fuZcSIEcyZMwebzebvcOpMxa9egI4dO9KjRw+Sk5P54osvCAoK8mNktcPr9dKtWzfGjx8PQJcuXVi3bh2TJ09myJAhfo6ubrz33ntcccUVJCQk+DuUWvXFF1/w8ccf88knn9C+fXtWrVrFyJEjSUhIqNdjKc1SZyg6Ohqj0VilR3tmZiZxcXF+iqpuVZQrEMo8fPhwvv32W+bPn0/Tpk198+Pi4nA6neTl5VVavqGV0WKx0KJFC7p27cqECRPo1KkTEydODJjyrVy5kqysLM477zxMJhMmk4mFCxfyxhtvYDKZiI2NDYhyHisiIoJWrVqxbdu2gDiW8fHxtGvXrtK8tm3b+preAuk7B2D37t38/PPP3HPPPb55gXAcAf7+978zZswYbrnlFtLS0rjjjjt45JFHmDBhAlB/x1KSmzNksVjo2rUrc+fO9c3zer3MnTuXnj17+jGyupOamkpcXFylMhcUFLB06dIGU2alFMOHD2fGjBnMmzeP1NTUSq937doVs9lcqYybN29mz549DaaM1fF6vTgcjoApX79+/Vi7di2rVq3yTd26deO2227zPQ+Ech6rqKiI7du3Ex8fHxDHsnfv3lUuxbBlyxaSk5OBwPjOOdr7779P48aNufLKK33zAuE4ApSUlGAwVE4tjEYjXq8XqMdjWWtdk89hn332mbJarWrq1Klqw4YN6r777lMREREqIyPD36HVWGFhofrzzz/Vn3/+qQD12muvqT///FPt3r1bKaUP5YuIiFBff/21WrNmjbrmmmsa1LDMBx54QNntdrVgwYJKQzNLSkp8y9x///0qKSlJzZs3T61YsUL17NlT9ezZ049Rn54xY8aohQsXqp07d6o1a9aoMWPGKE3T1E8//aSUavjlO56jR0spFRjl/Nvf/qYWLFigdu7cqRYvXqz69++voqOjVVZWllKq4Zdx2bJlymQyqeeff15t3bpVffzxxyo4OFh99NFHvmUa+ndOBY/Ho5KSktSjjz5a5bWGfhyVUmrIkCGqSZMmvqHg06dPV9HR0eof//iHb5n6OJaS3NSSSZMmqaSkJGWxWNT555+vfv/9d3+HdEbmz5+vgCrTkCFDlFL6cL5x48ap2NhYZbVaVb9+/dTmzZv9G/RpqK5sgHr//fd9y5SWlqoHH3xQNWrUSAUHB6vrrrtOHTx40H9Bn6ahQ4eq5ORkZbFYVExMjOrXr58vsVGq4ZfveI5NbgKhnIMHD1bx8fHKYrGoJk2aqMGDB1e6BkwglPGbb75RHTp0UFarVbVp00b9+9//rvR6Q//OqfDjjz8qoNrYA+E4FhQUqBEjRqikpCRls9lUs2bN1OOPP64cDodvmfo4lppSR102UAghhBCigZM+N0IIIYQIKJLcCCGEECKgSHIjhBBCiIAiyY0QQgghAookN0IIIYQIKJLcCCGEECKgSHIjhBBCiIAiyY0Q4py3YMECNE2rcl8fIUTDJMmNEEIIIQKKJDdCCCGECCiS3Agh/M7r9TJhwgRSU1MJCgqiU6dOTPv/9u4llL4tgOP4Vx4HoZNHkudAhBwS5VUSRlJGhyIkGZhIXnVEcgZMzkTyGCiZkP5GOgYYMDhRKIVOOSiGhJRIojv4d8+9p3/dbvf+/c+17+9Tu1Z7r732Wnv0a62129++AX8sGTmdTiwWC6GhoRQXF3NycuLTxurqKjk5OZhMJtLS0nA4HD7XX19fGRwcJDk5GZPJRHp6OvPz8z51Dg8PKSwsJDw8nNLS0h/+VC0iX4PCjYj43fj4OIuLi8zOznJ6ekpPTw/Nzc3s7Ox46/T39+NwONjf3ycuLo66ujre3t6A76HEarXS2NjI8fExo6OjDA8Ps7Cw4L2/paWFpaUlJicncbvdzM3NERER4dOPoaEhHA4HBwcHBAUF0d7e/kvGLyI/l36cKSJ+9fr6SnR0NFtbW5SUlHjPd3R08Pz8TGdnJ5WVlSwvL9PQ0ADA/f09SUlJLCwsYLVaaWpq4vb2lo2NDe/9AwMDOJ1OTk9POTs7IzMzk83NTaqrq3/ow/b2NpWVlWxtbVFVVQXA+vo6tbW1vLy8EBoa+slvQUR+Js3ciIhfnZ+f8/z8TE1NDREREd5jcXGRi4sLb70/B5/o6GgyMzNxu90AuN1uysrKfNotKyvD4/Hw/v7O0dERgYGBVFRU/GVfLBaLt5yQkADAzc3Nvx6jiPxaQf7ugIj8vz09PQHgdDpJTEz0uWYymXwCzj8VFhb2t+oFBwd7ywEBAcD3/UAi8rVo5kZE/Co7OxuTycT19TXp6ek+R3Jysrfe3t6et/zw8MDZ2RlZWVkAZGVl4XK5fNp1uVxkZGQQGBhIbm4uHx8fPnt4RMS4NHMjIn4VGRlJX18fPT09fHx8UF5ezuPjIy6Xi6ioKFJTUwEYGxsjJiaG+Ph4hoaGiI2Npb6+HoDe3l6Kioqw2+00NDSwu7vL1NQU09PTAKSlpdHa2kp7ezuTk5Pk5eVxdXXFzc0NVqvVX0MXkU+icCMifme324mLi2N8fJzLy0vMZjMFBQXYbDbvstDExATd3d14PB7y8/NZW1sjJCQEgIKCAlZWVhgZGcFut5OQkMDY2BhtbW3eZ8zMzGCz2ejq6uLu7o6UlBRsNps/hisin0xfS4nIf9rvXzI9PDxgNpv93R0R+QK050ZEREQMReFGREREDEXLUiIiImIomrkRERERQ1G4EREREUNRuBERERFDUbgRERERQ1G4EREREUNRuBERERFDUbgRERERQ1G4EREREUNRuBERERFD+Q2CuXRedNL1eQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Accuracy: 0.9885752201080322\n"
     ]
    }
   ],
   "source": [
    "# Select the final model based on the max test accuracy across all models\n",
    "\n",
    "best_model_index = model_accuracy.index(max(model_accuracy))\n",
    "\n",
    "best_model = models[best_model_index]\n",
    "best_model_history = model_history[best_model_index]\n",
    "best_model_train_acc = model_train_acc[best_model_index]\n",
    "best_model_train_loss = model_train_loss[best_model_index]\n",
    "best_model_val_acc = model_val_acc[best_model_index]\n",
    "best_model_val_loss = model_val_loss[best_model_index]\n",
    "\n",
    "# summarize history for accuracy  \n",
    "plt.subplot(211)  \n",
    "plt.plot(best_model_history.history['accuracy'])  \n",
    "plt.plot(best_model_history.history['val_accuracy'])  \n",
    "plt.title('model accuracy')  \n",
    "plt.ylabel('accuracy')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='lower right')  \n",
    "\n",
    "# summarize history for loss\n",
    "plt.subplot(212)  \n",
    "plt.plot(best_model_history.history['loss'])  \n",
    "plt.plot(best_model_history.history['val_loss'])  \n",
    "plt.title('model loss')  \n",
    "plt.ylabel('loss')  \n",
    "plt.xlabel('epoch')  \n",
    "plt.legend(['train', 'test'], loc='upper right')  \n",
    "plt.subplots_adjust(hspace=0.7)\n",
    "\n",
    "plt.show() \n",
    "\n",
    "print(\"Final Test Accuracy:\", model_accuracy[best_model_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "424/424 [==============================] - 1s 2ms/step\n",
      "Classification report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       591\n",
      "           1       1.00      1.00      1.00       430\n",
      "           2       1.00      1.00      1.00       419\n",
      "           3       1.00      1.00      1.00       384\n",
      "           4       1.00      1.00      1.00       339\n",
      "           5       1.00      1.00      1.00       342\n",
      "           6       1.00      1.00      1.00       310\n",
      "           7       1.00      1.00      1.00       325\n",
      "           8       1.00      1.00      1.00       294\n",
      "           9       1.00      1.00      1.00       269\n",
      "          10       1.00      1.00      1.00       296\n",
      "          11       1.00      1.00      1.00       258\n",
      "          12       1.00      1.00      1.00       247\n",
      "          13       1.00      1.00      1.00       237\n",
      "          14       1.00      1.00      1.00       239\n",
      "          15       1.00      1.00      1.00       235\n",
      "          16       1.00      1.00      1.00       213\n",
      "          17       1.00      1.00      1.00       202\n",
      "          18       1.00      1.00      1.00       196\n",
      "          19       0.95      1.00      0.98       181\n",
      "          20       1.00      1.00      1.00       177\n",
      "          21       1.00      1.00      1.00       177\n",
      "          22       1.00      1.00      1.00       155\n",
      "          23       1.00      1.00      1.00       155\n",
      "          24       1.00      1.00      1.00       144\n",
      "          25       1.00      1.00      1.00       126\n",
      "          26       1.00      1.00      1.00       108\n",
      "          27       0.99      1.00      1.00       121\n",
      "          28       1.00      1.00      1.00        95\n",
      "          29       1.00      1.00      1.00       106\n",
      "          30       1.00      1.00      1.00       102\n",
      "          31       1.00      1.00      1.00        86\n",
      "          32       1.00      1.00      1.00       108\n",
      "          33       1.00      1.00      1.00        88\n",
      "          34       1.00      1.00      1.00       102\n",
      "          35       1.00      1.00      1.00        88\n",
      "          36       1.00      1.00      1.00        83\n",
      "          37       1.00      1.00      1.00        93\n",
      "          38       1.00      1.00      1.00        76\n",
      "          39       1.00      1.00      1.00        85\n",
      "          40       1.00      1.00      1.00        86\n",
      "          41       1.00      1.00      1.00        85\n",
      "          42       1.00      1.00      1.00        68\n",
      "          43       1.00      1.00      1.00        75\n",
      "          44       0.99      1.00      0.99        71\n",
      "          45       1.00      0.78      0.87        58\n",
      "          46       1.00      1.00      1.00        71\n",
      "          47       0.70      1.00      0.83        57\n",
      "          48       1.00      1.00      1.00        67\n",
      "          49       0.88      0.98      0.93        47\n",
      "          50       1.00      1.00      1.00        48\n",
      "          51       1.00      1.00      1.00        47\n",
      "          52       1.00      1.00      1.00        43\n",
      "          53       1.00      1.00      1.00        51\n",
      "          54       1.00      1.00      1.00        44\n",
      "          55       1.00      1.00      1.00        51\n",
      "          56       1.00      1.00      1.00        45\n",
      "          57       1.00      1.00      1.00        44\n",
      "          58       1.00      1.00      1.00        41\n",
      "          59       1.00      1.00      1.00        41\n",
      "          60       1.00      1.00      1.00        52\n",
      "          61       1.00      1.00      1.00        43\n",
      "          62       1.00      1.00      1.00        37\n",
      "          63       1.00      1.00      1.00        43\n",
      "          64       1.00      1.00      1.00        42\n",
      "          65       1.00      1.00      1.00        46\n",
      "          66       1.00      1.00      1.00        43\n",
      "          67       1.00      1.00      1.00        40\n",
      "          68       1.00      1.00      1.00        44\n",
      "          69       1.00      1.00      1.00        43\n",
      "          70       1.00      1.00      1.00        38\n",
      "          71       1.00      1.00      1.00        33\n",
      "          72       1.00      1.00      1.00        45\n",
      "          73       1.00      1.00      1.00        38\n",
      "          74       1.00      1.00      1.00        42\n",
      "          75       1.00      1.00      1.00        39\n",
      "          76       0.95      0.63      0.76        30\n",
      "          77       1.00      1.00      1.00        28\n",
      "          78       0.90      1.00      0.95        28\n",
      "          79       1.00      1.00      1.00        32\n",
      "          80       1.00      1.00      1.00        33\n",
      "          81       1.00      1.00      1.00        31\n",
      "          82       1.00      1.00      1.00        35\n",
      "          83       1.00      1.00      1.00        39\n",
      "          84       1.00      1.00      1.00        27\n",
      "          85       1.00      1.00      1.00        36\n",
      "          86       1.00      1.00      1.00        31\n",
      "          87       1.00      1.00      1.00        28\n",
      "          88       1.00      1.00      1.00        20\n",
      "          89       1.00      1.00      1.00        33\n",
      "          90       1.00      1.00      1.00        24\n",
      "          91       1.00      1.00      1.00        22\n",
      "          92       1.00      1.00      1.00        26\n",
      "          93       1.00      1.00      1.00        35\n",
      "          94       1.00      1.00      1.00        27\n",
      "          95       1.00      1.00      1.00        23\n",
      "          96       1.00      1.00      1.00        27\n",
      "          97       1.00      1.00      1.00        28\n",
      "          98       0.47      0.94      0.62        16\n",
      "          99       1.00      1.00      1.00        35\n",
      "         100       1.00      1.00      1.00        28\n",
      "         101       1.00      1.00      1.00        25\n",
      "         102       1.00      1.00      1.00        26\n",
      "         103       1.00      1.00      1.00        33\n",
      "         104       1.00      1.00      1.00        26\n",
      "         105       1.00      1.00      1.00        24\n",
      "         106       1.00      1.00      1.00        22\n",
      "         107       1.00      1.00      1.00        26\n",
      "         108       1.00      1.00      1.00        25\n",
      "         109       1.00      1.00      1.00        16\n",
      "         110       1.00      1.00      1.00        20\n",
      "         111       1.00      1.00      1.00        26\n",
      "         112       1.00      1.00      1.00        18\n",
      "         113       0.68      1.00      0.81        23\n",
      "         114       1.00      1.00      1.00        25\n",
      "         115       1.00      1.00      1.00        18\n",
      "         116       1.00      0.79      0.88        19\n",
      "         117       1.00      1.00      1.00        16\n",
      "         118       1.00      1.00      1.00        26\n",
      "         119       0.88      1.00      0.94        22\n",
      "         120       1.00      1.00      1.00        17\n",
      "         121       1.00      1.00      1.00        15\n",
      "         122       1.00      1.00      1.00        18\n",
      "         123       1.00      1.00      1.00        20\n",
      "         124       1.00      1.00      1.00        14\n",
      "         125       1.00      1.00      1.00        22\n",
      "         126       1.00      1.00      1.00        19\n",
      "         127       1.00      1.00      1.00        27\n",
      "         128       0.90      1.00      0.95        26\n",
      "         129       0.84      1.00      0.91        21\n",
      "         130       1.00      1.00      1.00        18\n",
      "         131       1.00      1.00      1.00        18\n",
      "         132       1.00      1.00      1.00        20\n",
      "         133       1.00      1.00      1.00        14\n",
      "         134       1.00      1.00      1.00        19\n",
      "         135       1.00      1.00      1.00        16\n",
      "         136       1.00      1.00      1.00        23\n",
      "         137       1.00      1.00      1.00        11\n",
      "         138       1.00      1.00      1.00        14\n",
      "         139       1.00      1.00      1.00        20\n",
      "         140       1.00      1.00      1.00        23\n",
      "         141       1.00      1.00      1.00        14\n",
      "         142       1.00      1.00      1.00        13\n",
      "         143       1.00      1.00      1.00        23\n",
      "         144       1.00      1.00      1.00        17\n",
      "         145       1.00      1.00      1.00        24\n",
      "         146       0.80      1.00      0.89        16\n",
      "         147       1.00      1.00      1.00        19\n",
      "         148       1.00      1.00      1.00        22\n",
      "         149       1.00      1.00      1.00        15\n",
      "         150       1.00      1.00      1.00        11\n",
      "         151       1.00      1.00      1.00        19\n",
      "         152       1.00      1.00      1.00        20\n",
      "         153       0.89      1.00      0.94        24\n",
      "         154       1.00      1.00      1.00        11\n",
      "         155       1.00      1.00      1.00        17\n",
      "         156       1.00      1.00      1.00        18\n",
      "         157       1.00      1.00      1.00        12\n",
      "         158       1.00      1.00      1.00        18\n",
      "         159       1.00      1.00      1.00        20\n",
      "         160       1.00      1.00      1.00        20\n",
      "         161       1.00      1.00      1.00        16\n",
      "         162       1.00      1.00      1.00        15\n",
      "         163       1.00      1.00      1.00        15\n",
      "         164       1.00      1.00      1.00        13\n",
      "         165       1.00      1.00      1.00        19\n",
      "         166       1.00      1.00      1.00        11\n",
      "         167       1.00      1.00      1.00         9\n",
      "         168       1.00      1.00      1.00        11\n",
      "         169       1.00      1.00      1.00        21\n",
      "         170       1.00      1.00      1.00        15\n",
      "         171       1.00      1.00      1.00        18\n",
      "         172       1.00      1.00      1.00        11\n",
      "         173       1.00      1.00      1.00        16\n",
      "         174       1.00      1.00      1.00        10\n",
      "         175       1.00      1.00      1.00        11\n",
      "         176       1.00      1.00      1.00        10\n",
      "         177       1.00      1.00      1.00        15\n",
      "         178       1.00      1.00      1.00        11\n",
      "         179       1.00      1.00      1.00        15\n",
      "         180       1.00      1.00      1.00        13\n",
      "         181       1.00      1.00      1.00        15\n",
      "         182       1.00      1.00      1.00         9\n",
      "         183       1.00      1.00      1.00        16\n",
      "         184       1.00      1.00      1.00         8\n",
      "         185       0.50      0.58      0.54        12\n",
      "         186       1.00      1.00      1.00        15\n",
      "         187       1.00      1.00      1.00        15\n",
      "         188       1.00      0.08      0.14        13\n",
      "         189       1.00      1.00      1.00        14\n",
      "         190       1.00      1.00      1.00        11\n",
      "         191       1.00      1.00      1.00        10\n",
      "         192       1.00      1.00      1.00        17\n",
      "         193       1.00      1.00      1.00         9\n",
      "         194       1.00      1.00      1.00         9\n",
      "         195       1.00      1.00      1.00         4\n",
      "         196       1.00      1.00      1.00         7\n",
      "         197       1.00      1.00      1.00         7\n",
      "         198       1.00      1.00      1.00        12\n",
      "         199       1.00      1.00      1.00        14\n",
      "         200       1.00      1.00      1.00         6\n",
      "         201       1.00      1.00      1.00         9\n",
      "         202       1.00      1.00      1.00         7\n",
      "         203       1.00      0.50      0.67         6\n",
      "         204       1.00      1.00      1.00        11\n",
      "         205       1.00      1.00      1.00        14\n",
      "         206       1.00      1.00      1.00        12\n",
      "         207       1.00      1.00      1.00        14\n",
      "         208       1.00      1.00      1.00        12\n",
      "         209       1.00      1.00      1.00         7\n",
      "         210       1.00      1.00      1.00        19\n",
      "         211       1.00      1.00      1.00         7\n",
      "         212       1.00      1.00      1.00        11\n",
      "         213       1.00      1.00      1.00         9\n",
      "         214       1.00      1.00      1.00         7\n",
      "         215       1.00      1.00      1.00         6\n",
      "         216       1.00      1.00      1.00        12\n",
      "         217       1.00      1.00      1.00        12\n",
      "         218       0.00      0.00      0.00         9\n",
      "         219       1.00      1.00      1.00         6\n",
      "         220       1.00      1.00      1.00         8\n",
      "         221       1.00      1.00      1.00         5\n",
      "         222       0.31      1.00      0.47         4\n",
      "         223       1.00      1.00      1.00        14\n",
      "         224       1.00      1.00      1.00        13\n",
      "         225       1.00      1.00      1.00         4\n",
      "         226       1.00      1.00      1.00        10\n",
      "         227       1.00      1.00      1.00        12\n",
      "         228       1.00      1.00      1.00        13\n",
      "         229       0.92      1.00      0.96        11\n",
      "         230       1.00      1.00      1.00         5\n",
      "         231       1.00      1.00      1.00         6\n",
      "         232       0.00      0.00      0.00         8\n",
      "         233       1.00      1.00      1.00        10\n",
      "         234       1.00      1.00      1.00         4\n",
      "         235       1.00      1.00      1.00         8\n",
      "         236       1.00      1.00      1.00         9\n",
      "         237       1.00      1.00      1.00         8\n",
      "         238       1.00      1.00      1.00        10\n",
      "         239       0.00      0.00      0.00         9\n",
      "         240       1.00      1.00      1.00         7\n",
      "         241       1.00      1.00      1.00         8\n",
      "         242       1.00      1.00      1.00         6\n",
      "         243       0.78      1.00      0.88         7\n",
      "         244       1.00      1.00      1.00         9\n",
      "         245       1.00      1.00      1.00         7\n",
      "         246       1.00      1.00      1.00         9\n",
      "         247       1.00      1.00      1.00         7\n",
      "         248       1.00      0.80      0.89        10\n",
      "         249       1.00      1.00      1.00        10\n",
      "         250       1.00      1.00      1.00         7\n",
      "         251       1.00      1.00      1.00         6\n",
      "         252       1.00      1.00      1.00        11\n",
      "         253       1.00      1.00      1.00         7\n",
      "         254       1.00      1.00      1.00         8\n",
      "         255       1.00      1.00      1.00         5\n",
      "         256       1.00      1.00      1.00         7\n",
      "         257       0.90      1.00      0.95         9\n",
      "         258       1.00      1.00      1.00         6\n",
      "         259       1.00      0.67      0.80         3\n",
      "         260       1.00      1.00      1.00         4\n",
      "         261       1.00      1.00      1.00         2\n",
      "         262       1.00      1.00      1.00         5\n",
      "         263       1.00      1.00      1.00        12\n",
      "         264       1.00      1.00      1.00         5\n",
      "         265       1.00      1.00      1.00         7\n",
      "         266       1.00      1.00      1.00        10\n",
      "         267       1.00      1.00      1.00         8\n",
      "         268       0.00      0.00      0.00         9\n",
      "         269       1.00      1.00      1.00         6\n",
      "         270       1.00      1.00      1.00         4\n",
      "         271       1.00      1.00      1.00         7\n",
      "         272       1.00      0.70      0.82        10\n",
      "         273       1.00      1.00      1.00         3\n",
      "         274       1.00      1.00      1.00         9\n",
      "         275       1.00      1.00      1.00         6\n",
      "         276       1.00      1.00      1.00         5\n",
      "         277       0.00      0.00      0.00         4\n",
      "         278       1.00      1.00      1.00         3\n",
      "         279       1.00      1.00      1.00         4\n",
      "         280       0.00      0.00      0.00         5\n",
      "         281       1.00      1.00      1.00         6\n",
      "         282       1.00      1.00      1.00        11\n",
      "         283       1.00      1.00      1.00         6\n",
      "         284       1.00      1.00      1.00         2\n",
      "         285       1.00      1.00      1.00         4\n",
      "         286       1.00      1.00      1.00         7\n",
      "         287       1.00      1.00      1.00         9\n",
      "         288       1.00      1.00      1.00         7\n",
      "         289       1.00      1.00      1.00         7\n",
      "         290       1.00      1.00      1.00         6\n",
      "         291       0.00      0.00      0.00         5\n",
      "         292       1.00      0.50      0.67         6\n",
      "         293       1.00      1.00      1.00         8\n",
      "         294       1.00      1.00      1.00         7\n",
      "         295       1.00      0.33      0.50         3\n",
      "         296       1.00      1.00      1.00         6\n",
      "         297       1.00      1.00      1.00         8\n",
      "         298       1.00      1.00      1.00         4\n",
      "         299       1.00      1.00      1.00         6\n",
      "         300       1.00      1.00      1.00         5\n",
      "         301       0.00      0.00      0.00         5\n",
      "         302       1.00      1.00      1.00         5\n",
      "         303       1.00      1.00      1.00         2\n",
      "         304       1.00      1.00      1.00         8\n",
      "         305       1.00      1.00      1.00         3\n",
      "         306       1.00      1.00      1.00         6\n",
      "         307       1.00      1.00      1.00         7\n",
      "         308       1.00      1.00      1.00         4\n",
      "         309       1.00      1.00      1.00         4\n",
      "         310       0.00      0.00      0.00         9\n",
      "         311       1.00      1.00      1.00         7\n",
      "         312       1.00      1.00      1.00         6\n",
      "         313       1.00      1.00      1.00         6\n",
      "         314       1.00      1.00      1.00         8\n",
      "         315       1.00      1.00      1.00         7\n",
      "         316       1.00      1.00      1.00         3\n",
      "         317       1.00      1.00      1.00         6\n",
      "         318       1.00      1.00      1.00        10\n",
      "         319       1.00      1.00      1.00         6\n",
      "         320       1.00      1.00      1.00         2\n",
      "         321       1.00      1.00      1.00         8\n",
      "         322       1.00      1.00      1.00         4\n",
      "         323       1.00      1.00      1.00         4\n",
      "         324       0.53      1.00      0.70         8\n",
      "         325       1.00      1.00      1.00         4\n",
      "         326       1.00      1.00      1.00         7\n",
      "         327       1.00      1.00      1.00         4\n",
      "         328       1.00      1.00      1.00         6\n",
      "         329       1.00      1.00      1.00         4\n",
      "         330       0.75      1.00      0.86         3\n",
      "         331       0.73      1.00      0.84         8\n",
      "         332       1.00      1.00      1.00         1\n",
      "         333       1.00      1.00      1.00         3\n",
      "         334       1.00      1.00      1.00         4\n",
      "         335       1.00      1.00      1.00         3\n",
      "         336       0.00      0.00      0.00         6\n",
      "         337       1.00      1.00      1.00         2\n",
      "         338       1.00      1.00      1.00         7\n",
      "         339       1.00      1.00      1.00         4\n",
      "         340       1.00      1.00      1.00         6\n",
      "         341       1.00      1.00      1.00         7\n",
      "         342       1.00      1.00      1.00         2\n",
      "         343       1.00      1.00      1.00         5\n",
      "         344       1.00      0.25      0.40         4\n",
      "         345       0.00      0.00      0.00         1\n",
      "         346       1.00      1.00      1.00         2\n",
      "         347       0.00      0.00      0.00         4\n",
      "         348       1.00      1.00      1.00         7\n",
      "         349       1.00      1.00      1.00         4\n",
      "         350       1.00      1.00      1.00         6\n",
      "         351       1.00      1.00      1.00         4\n",
      "         352       1.00      1.00      1.00         5\n",
      "         353       1.00      1.00      1.00         4\n",
      "         354       1.00      1.00      1.00         3\n",
      "         355       1.00      1.00      1.00         1\n",
      "         356       1.00      1.00      1.00         4\n",
      "         357       0.17      1.00      0.29         1\n",
      "         358       1.00      1.00      1.00         3\n",
      "         359       1.00      1.00      1.00         4\n",
      "         360       0.00      0.00      0.00         3\n",
      "         361       0.00      0.00      0.00         3\n",
      "         362       1.00      1.00      1.00         3\n",
      "         363       0.00      0.00      0.00         2\n",
      "         364       0.12      1.00      0.21         3\n",
      "         365       0.00      0.00      0.00         3\n",
      "         366       0.00      0.00      0.00         2\n",
      "         367       1.00      1.00      1.00         3\n",
      "         368       1.00      1.00      1.00         1\n",
      "         369       1.00      1.00      1.00         2\n",
      "         370       1.00      1.00      1.00         2\n",
      "         372       0.00      0.00      0.00         4\n",
      "\n",
      "    accuracy                           0.99     13567\n",
      "   macro avg       0.93      0.94      0.93     13567\n",
      "weighted avg       0.99      0.99      0.99     13567\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Python\\Pyhton3.10.0\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1334: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#Select only the optimal number of input features for X_test\n",
    "X_test = X_test[:,:(best_model_index+1)]\n",
    "\n",
    "# Evaluate the best model on the test data\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# np.argmax() is used to convert the one-hot encoded predictions and test labels to class labels.\n",
    "y_pred_label = np.argmax(y_pred, axis = 1)\n",
    "\n",
    "# Print the classification report\n",
    "print(\"Classification report:\\n\", classification_report(y_test_enc, y_pred_label))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           OsID  True Class  Predicted Class  True/False\n",
      "0  Os11g0704500         328              328        True\n",
      "1  Os09g0279600         161              161        True\n",
      "2  Os03g0669100          17               17        True\n",
      "3  Os05g0542500          34               34        True\n",
      "4  Os09g0522000           7                7        True\n"
     ]
    }
   ],
   "source": [
    "# extract class labels from test data\n",
    "class_test = y_test_enc\n",
    "\n",
    "# Invert OsID_labels dictionary\n",
    "inv_OsID_labels = {v: k for k, v in OsID_labels.items()}\n",
    "\n",
    "# map OsID values to the class labels\n",
    "OsID_test = [inv_OsID_labels.get(value, 'Unknown') for value in class_test]\n",
    "\n",
    "# create dataframe with OsID, true class, predicted class, and true/false columns\n",
    "results = pd.DataFrame({\n",
    "    'OsID': OsID_test,\n",
    "    'True Class': y_test_enc,\n",
    "    'Predicted Class': y_pred_label,\n",
    "    'True/False': class_test == y_pred_label\n",
    "})\n",
    "\n",
    "# display dataframe\n",
    "print(results.head())\n",
    "\n",
    "# save results_df to a CSV file\n",
    "results.to_csv('MLP_gene classification.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "54645332476aec3a1589d49135d9c8280fdb5d7db877f5b7af7a1b58b8f996bc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
