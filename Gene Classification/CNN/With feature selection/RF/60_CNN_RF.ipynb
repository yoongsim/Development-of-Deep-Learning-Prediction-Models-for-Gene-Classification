{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":12731,"status":"ok","timestamp":1682739185373,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"UsLpi_0MmZ9Z"},"outputs":[],"source":["from itertools import cycle\n","\n","import numpy as np\n","import pandas as pd \n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Model ,Sequential #for CNN\n","from keras.layers import Dense \n","from sklearn.model_selection import KFold\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from keras.layers import Conv2D, Input, MaxPooling2D, Dropout, Flatten, Dense, Activation\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.model_selection import StratifiedKFold\n","from keras import regularizers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1682739185374,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"B95hUV4pmZ9g"},"outputs":[],"source":["#fixed random seed for reproducibility \n","np.random.seed(0)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"EECGNCI3mZ9i","outputId":"76fe3d35-bbf6-4b5a-9bfd-0ba29b4997d9"},"outputs":[],"source":["# load dataset (input variables = X, output variables = Y)\n","df = pd.read_csv(\"TrainingData.csv\")\n","\n","#count the number of occurances for each osID\n","OsID_counts = df['OsID'].value_counts()\n","\n","#filter for osIDs that have 10 or more occurances\n","OsID_counts_filtered = OsID_counts[OsID_counts >= 10]\n","\n","#assign a label for each osID \n","OsID_labels = {}\n","class_no = 1\n","for osID in OsID_counts_filtered.index:\n","    OsID_labels[osID] = class_no\n","    class_no +=1\n","\n","#filter the dataset with osID that contain 10 or more occurances\n","dataGene = df[df['OsID'].isin(OsID_counts_filtered.index)]\n","\n","dataGene = dataGene.drop(['Class', 'Trait'],axis=1)\n","\n","# Add a new column 'class' to the filtered dataset\n","dataGene['class'] = dataGene['OsID'].map(OsID_labels)\n","\n","#print(\"Summary of dataGene:\\n\",dataGene.describe())"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"Vuf_bBJBUC1h"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X:\n"," (41110, 20)\n","Shape of Y:\n"," (41110,)\n","class\n","1.0      1800\n","2.0      1296\n","3.0      1260\n","4.0      1218\n","5.0      1026\n","6.0      1008\n","7.0       930\n","8.0       912\n","9.0       880\n","10.0      798\n","11.0      792\n","12.0      759\n","13.0      729\n","14.0      720\n","15.0      702\n","16.0      693\n","17.0      672\n","18.0      640\n","19.0      625\n","20.0      570\n","21.0      546\n","22.0      506\n","23.0      483\n","24.0      448\n","25.0      432\n","26.0      384\n","27.0      360\n","28.0      360\n","29.0      320\n","30.0      312\n","         ... \n","344.0      12\n","345.0      12\n","346.0      12\n","347.0      12\n","348.0      12\n","349.0      12\n","350.0      12\n","351.0      12\n","352.0      12\n","353.0      12\n","354.0      12\n","355.0      12\n","356.0      11\n","357.0      11\n","358.0      11\n","359.0      11\n","360.0      11\n","361.0      11\n","362.0      10\n","363.0      10\n","364.0      10\n","365.0      10\n","366.0      10\n","367.0      10\n","368.0      10\n","369.0      10\n","370.0      10\n","371.0      10\n","372.0      10\n","373.0      10\n","Length: 373, dtype: int64\n"]}],"source":["X = dataGene.drop(['class','OsID'], axis=1) # exclude class & OsID column\n","Y = dataGene['class']\n","\n","#input feature names in order of descending importance scores in MI feature selection method\n","feature_names = ['Root10DaysSeedling', 'Leaf45DaysOldPlant', 'Shoot10DaysSeedling', 'Shoot35DaysSeedling', 'Root35DaysSeedling', \n","                 'Leaf21DaysSeedling', 'Root14DaysSeedling', 'Shoot3DaysSeedling', 'Root24DaysSeedling', 'Root52DaysSeedling', \n","                 'Root17DaysSeedling', 'Root21DaysSeedling', 'Shoot14DaysSeedling', 'Shoot21DaysSeedling', 'Shoot17DaysSeedling', \n","                 'ET', 'PCC', 'log_2FoldChange', 'PPI', 'CoExpression']\n","\n","X_fs = X.reindex(columns=feature_names)\n","\n","print(\"Shape of X:\\n\",X_fs.shape)\n","print(\"Shape of Y:\\n\",Y.shape)\n","\n","# Statistical summary of the variables\n","#print(\"Summary of X:\\n\",X_fs.describe())\n","#print(\"Summary of Y:\\n\",Y.describe())\n","\n","# Check for class imbalance\n","print(df.groupby(Y).size())\n","\n","# change both input and target variables datatype to ndarray\n","X_fs = X_fs.values # 2-D array\n","\n","# select target variable \n","\n","Y = Y.values #1-D array\n","Y = Y.reshape(-1, 1)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"W5zIyx8RVDJu"},"outputs":[{"name":"stdout","output_type":"stream","text":["Class=0, n=1800 (4.378%)\n","Class=1, n=1296 (3.153%)\n","Class=2, n=1260 (3.065%)\n","Class=3, n=1218 (2.963%)\n","Class=4, n=1026 (2.496%)\n","Class=5, n=1008 (2.452%)\n","Class=6, n=930 (2.262%)\n","Class=7, n=912 (2.218%)\n","Class=8, n=880 (2.141%)\n","Class=9, n=798 (1.941%)\n","Class=10, n=792 (1.927%)\n","Class=11, n=759 (1.846%)\n","Class=12, n=729 (1.773%)\n","Class=13, n=720 (1.751%)\n","Class=14, n=702 (1.708%)\n","Class=15, n=693 (1.686%)\n","Class=16, n=672 (1.635%)\n","Class=17, n=640 (1.557%)\n","Class=18, n=625 (1.520%)\n","Class=19, n=570 (1.387%)\n","Class=20, n=546 (1.328%)\n","Class=21, n=506 (1.231%)\n","Class=22, n=483 (1.175%)\n","Class=23, n=448 (1.090%)\n","Class=24, n=432 (1.051%)\n","Class=25, n=384 (0.934%)\n","Class=26, n=360 (0.876%)\n","Class=27, n=360 (0.876%)\n","Class=28, n=320 (0.778%)\n","Class=29, n=312 (0.759%)\n","Class=30, n=312 (0.759%)\n","Class=31, n=306 (0.744%)\n","Class=32, n=304 (0.739%)\n","Class=33, n=299 (0.727%)\n","Class=34, n=297 (0.722%)\n","Class=35, n=296 (0.720%)\n","Class=36, n=280 (0.681%)\n","Class=37, n=264 (0.642%)\n","Class=38, n=260 (0.632%)\n","Class=39, n=253 (0.615%)\n","Class=40, n=252 (0.613%)\n","Class=41, n=248 (0.603%)\n","Class=42, n=242 (0.589%)\n","Class=43, n=228 (0.555%)\n","Class=44, n=216 (0.525%)\n","Class=45, n=210 (0.511%)\n","Class=46, n=200 (0.486%)\n","Class=47, n=192 (0.467%)\n","Class=48, n=180 (0.438%)\n","Class=49, n=171 (0.416%)\n","Class=50, n=168 (0.409%)\n","Class=51, n=168 (0.409%)\n","Class=52, n=162 (0.394%)\n","Class=53, n=150 (0.365%)\n","Class=54, n=148 (0.360%)\n","Class=55, n=138 (0.336%)\n","Class=56, n=135 (0.328%)\n","Class=57, n=135 (0.328%)\n","Class=58, n=133 (0.324%)\n","Class=59, n=132 (0.321%)\n","Class=60, n=132 (0.321%)\n","Class=61, n=130 (0.316%)\n","Class=62, n=130 (0.316%)\n","Class=63, n=130 (0.316%)\n","Class=64, n=128 (0.311%)\n","Class=65, n=128 (0.311%)\n","Class=66, n=126 (0.306%)\n","Class=67, n=124 (0.302%)\n","Class=68, n=124 (0.302%)\n","Class=69, n=124 (0.302%)\n","Class=70, n=120 (0.292%)\n","Class=71, n=120 (0.292%)\n","Class=72, n=118 (0.287%)\n","Class=73, n=116 (0.282%)\n","Class=74, n=114 (0.277%)\n","Class=75, n=105 (0.255%)\n","Class=76, n=104 (0.253%)\n","Class=77, n=102 (0.248%)\n","Class=78, n=99 (0.241%)\n","Class=79, n=98 (0.238%)\n","Class=80, n=98 (0.238%)\n","Class=81, n=98 (0.238%)\n","Class=82, n=98 (0.238%)\n","Class=83, n=96 (0.234%)\n","Class=84, n=96 (0.234%)\n","Class=85, n=96 (0.234%)\n","Class=86, n=93 (0.226%)\n","Class=87, n=92 (0.224%)\n","Class=88, n=92 (0.224%)\n","Class=89, n=91 (0.221%)\n","Class=90, n=88 (0.214%)\n","Class=91, n=88 (0.214%)\n","Class=92, n=86 (0.209%)\n","Class=93, n=86 (0.209%)\n","Class=94, n=84 (0.204%)\n","Class=95, n=84 (0.204%)\n","Class=96, n=84 (0.204%)\n","Class=97, n=78 (0.190%)\n","Class=98, n=78 (0.190%)\n","Class=99, n=76 (0.185%)\n","Class=100, n=75 (0.182%)\n","Class=101, n=75 (0.182%)\n","Class=102, n=73 (0.178%)\n","Class=103, n=72 (0.175%)\n","Class=104, n=72 (0.175%)\n","Class=105, n=70 (0.170%)\n","Class=106, n=69 (0.168%)\n","Class=107, n=68 (0.165%)\n","Class=108, n=67 (0.163%)\n","Class=109, n=66 (0.161%)\n","Class=110, n=66 (0.161%)\n","Class=111, n=66 (0.161%)\n","Class=112, n=66 (0.161%)\n","Class=113, n=66 (0.161%)\n","Class=114, n=65 (0.158%)\n","Class=115, n=64 (0.156%)\n","Class=116, n=63 (0.153%)\n","Class=117, n=63 (0.153%)\n","Class=118, n=62 (0.151%)\n","Class=119, n=61 (0.148%)\n","Class=120, n=60 (0.146%)\n","Class=121, n=60 (0.146%)\n","Class=122, n=60 (0.146%)\n","Class=123, n=60 (0.146%)\n","Class=124, n=60 (0.146%)\n","Class=125, n=60 (0.146%)\n","Class=126, n=60 (0.146%)\n","Class=127, n=60 (0.146%)\n","Class=128, n=60 (0.146%)\n","Class=129, n=60 (0.146%)\n","Class=130, n=59 (0.144%)\n","Class=131, n=59 (0.144%)\n","Class=132, n=58 (0.141%)\n","Class=133, n=56 (0.136%)\n","Class=134, n=56 (0.136%)\n","Class=135, n=56 (0.136%)\n","Class=136, n=56 (0.136%)\n","Class=137, n=56 (0.136%)\n","Class=138, n=56 (0.136%)\n","Class=139, n=56 (0.136%)\n","Class=140, n=56 (0.136%)\n","Class=141, n=56 (0.136%)\n","Class=142, n=55 (0.134%)\n","Class=143, n=55 (0.134%)\n","Class=144, n=54 (0.131%)\n","Class=145, n=54 (0.131%)\n","Class=146, n=54 (0.131%)\n","Class=147, n=54 (0.131%)\n","Class=148, n=54 (0.131%)\n","Class=149, n=53 (0.129%)\n","Class=150, n=52 (0.126%)\n","Class=151, n=52 (0.126%)\n","Class=152, n=52 (0.126%)\n","Class=153, n=52 (0.126%)\n","Class=154, n=50 (0.122%)\n","Class=155, n=50 (0.122%)\n","Class=156, n=49 (0.119%)\n","Class=157, n=49 (0.119%)\n","Class=158, n=48 (0.117%)\n","Class=159, n=48 (0.117%)\n","Class=160, n=48 (0.117%)\n","Class=161, n=46 (0.112%)\n","Class=162, n=45 (0.109%)\n","Class=163, n=44 (0.107%)\n","Class=164, n=44 (0.107%)\n","Class=165, n=44 (0.107%)\n","Class=166, n=42 (0.102%)\n","Class=167, n=42 (0.102%)\n","Class=168, n=42 (0.102%)\n","Class=169, n=42 (0.102%)\n","Class=170, n=42 (0.102%)\n","Class=171, n=42 (0.102%)\n","Class=172, n=42 (0.102%)\n","Class=173, n=41 (0.100%)\n","Class=174, n=41 (0.100%)\n","Class=175, n=40 (0.097%)\n","Class=176, n=40 (0.097%)\n","Class=177, n=39 (0.095%)\n","Class=178, n=39 (0.095%)\n","Class=179, n=38 (0.092%)\n","Class=180, n=37 (0.090%)\n","Class=181, n=36 (0.088%)\n","Class=182, n=35 (0.085%)\n","Class=183, n=35 (0.085%)\n","Class=184, n=35 (0.085%)\n","Class=185, n=35 (0.085%)\n","Class=186, n=34 (0.083%)\n","Class=187, n=34 (0.083%)\n","Class=188, n=34 (0.083%)\n","Class=189, n=34 (0.083%)\n","Class=190, n=32 (0.078%)\n","Class=191, n=32 (0.078%)\n","Class=192, n=32 (0.078%)\n","Class=193, n=32 (0.078%)\n","Class=194, n=32 (0.078%)\n","Class=195, n=32 (0.078%)\n","Class=196, n=31 (0.075%)\n","Class=197, n=31 (0.075%)\n","Class=198, n=31 (0.075%)\n","Class=199, n=31 (0.075%)\n","Class=200, n=30 (0.073%)\n","Class=201, n=30 (0.073%)\n","Class=202, n=30 (0.073%)\n","Class=203, n=30 (0.073%)\n","Class=204, n=30 (0.073%)\n","Class=205, n=30 (0.073%)\n","Class=206, n=30 (0.073%)\n","Class=207, n=30 (0.073%)\n","Class=208, n=30 (0.073%)\n","Class=209, n=29 (0.071%)\n","Class=210, n=29 (0.071%)\n","Class=211, n=28 (0.068%)\n","Class=212, n=28 (0.068%)\n","Class=213, n=28 (0.068%)\n","Class=214, n=28 (0.068%)\n","Class=215, n=28 (0.068%)\n","Class=216, n=28 (0.068%)\n","Class=217, n=27 (0.066%)\n","Class=218, n=27 (0.066%)\n","Class=219, n=27 (0.066%)\n","Class=220, n=27 (0.066%)\n","Class=221, n=27 (0.066%)\n","Class=222, n=27 (0.066%)\n","Class=223, n=26 (0.063%)\n","Class=224, n=26 (0.063%)\n","Class=225, n=26 (0.063%)\n","Class=226, n=26 (0.063%)\n","Class=227, n=26 (0.063%)\n","Class=228, n=25 (0.061%)\n","Class=229, n=25 (0.061%)\n","Class=230, n=25 (0.061%)\n","Class=231, n=25 (0.061%)\n","Class=232, n=24 (0.058%)\n","Class=233, n=24 (0.058%)\n","Class=234, n=24 (0.058%)\n","Class=235, n=24 (0.058%)\n","Class=236, n=24 (0.058%)\n","Class=237, n=24 (0.058%)\n","Class=238, n=24 (0.058%)\n","Class=239, n=24 (0.058%)\n","Class=240, n=24 (0.058%)\n","Class=241, n=24 (0.058%)\n","Class=242, n=24 (0.058%)\n","Class=243, n=24 (0.058%)\n","Class=244, n=23 (0.056%)\n","Class=245, n=23 (0.056%)\n","Class=246, n=22 (0.054%)\n","Class=247, n=22 (0.054%)\n","Class=248, n=22 (0.054%)\n","Class=249, n=22 (0.054%)\n","Class=250, n=22 (0.054%)\n","Class=251, n=22 (0.054%)\n","Class=252, n=22 (0.054%)\n","Class=253, n=22 (0.054%)\n","Class=254, n=22 (0.054%)\n","Class=255, n=22 (0.054%)\n","Class=256, n=22 (0.054%)\n","Class=257, n=22 (0.054%)\n","Class=258, n=22 (0.054%)\n","Class=259, n=22 (0.054%)\n","Class=260, n=22 (0.054%)\n","Class=261, n=22 (0.054%)\n","Class=262, n=22 (0.054%)\n","Class=263, n=22 (0.054%)\n","Class=264, n=21 (0.051%)\n","Class=265, n=21 (0.051%)\n","Class=266, n=21 (0.051%)\n","Class=267, n=21 (0.051%)\n","Class=268, n=21 (0.051%)\n","Class=269, n=20 (0.049%)\n","Class=270, n=20 (0.049%)\n","Class=271, n=20 (0.049%)\n","Class=272, n=20 (0.049%)\n","Class=273, n=20 (0.049%)\n","Class=274, n=20 (0.049%)\n","Class=275, n=20 (0.049%)\n","Class=276, n=20 (0.049%)\n","Class=277, n=20 (0.049%)\n","Class=278, n=20 (0.049%)\n","Class=279, n=20 (0.049%)\n","Class=280, n=19 (0.046%)\n","Class=281, n=19 (0.046%)\n","Class=282, n=19 (0.046%)\n","Class=283, n=18 (0.044%)\n","Class=284, n=18 (0.044%)\n","Class=285, n=18 (0.044%)\n","Class=286, n=18 (0.044%)\n","Class=287, n=18 (0.044%)\n","Class=288, n=18 (0.044%)\n","Class=289, n=18 (0.044%)\n","Class=290, n=18 (0.044%)\n","Class=291, n=18 (0.044%)\n","Class=292, n=17 (0.041%)\n","Class=293, n=17 (0.041%)\n","Class=294, n=17 (0.041%)\n","Class=295, n=17 (0.041%)\n","Class=296, n=17 (0.041%)\n","Class=297, n=17 (0.041%)\n","Class=298, n=16 (0.039%)\n","Class=299, n=16 (0.039%)\n","Class=300, n=16 (0.039%)\n","Class=301, n=16 (0.039%)\n","Class=302, n=16 (0.039%)\n","Class=303, n=16 (0.039%)\n","Class=304, n=16 (0.039%)\n","Class=305, n=16 (0.039%)\n","Class=306, n=15 (0.036%)\n","Class=307, n=15 (0.036%)\n","Class=308, n=15 (0.036%)\n","Class=309, n=15 (0.036%)\n","Class=310, n=15 (0.036%)\n","Class=311, n=14 (0.034%)\n","Class=312, n=14 (0.034%)\n","Class=313, n=14 (0.034%)\n","Class=314, n=14 (0.034%)\n","Class=315, n=14 (0.034%)\n","Class=316, n=14 (0.034%)\n","Class=317, n=14 (0.034%)\n","Class=318, n=14 (0.034%)\n","Class=319, n=14 (0.034%)\n","Class=320, n=14 (0.034%)\n","Class=321, n=14 (0.034%)\n","Class=322, n=14 (0.034%)\n","Class=323, n=14 (0.034%)\n","Class=324, n=14 (0.034%)\n","Class=325, n=14 (0.034%)\n","Class=326, n=14 (0.034%)\n","Class=327, n=14 (0.034%)\n","Class=328, n=13 (0.032%)\n","Class=329, n=13 (0.032%)\n","Class=330, n=13 (0.032%)\n","Class=331, n=13 (0.032%)\n","Class=332, n=13 (0.032%)\n","Class=333, n=13 (0.032%)\n","Class=334, n=13 (0.032%)\n","Class=335, n=13 (0.032%)\n","Class=336, n=13 (0.032%)\n","Class=337, n=12 (0.029%)\n","Class=338, n=12 (0.029%)\n","Class=339, n=12 (0.029%)\n","Class=340, n=12 (0.029%)\n","Class=341, n=12 (0.029%)\n","Class=342, n=12 (0.029%)\n","Class=343, n=12 (0.029%)\n","Class=344, n=12 (0.029%)\n","Class=345, n=12 (0.029%)\n","Class=346, n=12 (0.029%)\n","Class=347, n=12 (0.029%)\n","Class=348, n=12 (0.029%)\n","Class=349, n=12 (0.029%)\n","Class=350, n=12 (0.029%)\n","Class=351, n=12 (0.029%)\n","Class=352, n=12 (0.029%)\n","Class=353, n=12 (0.029%)\n","Class=354, n=12 (0.029%)\n","Class=355, n=11 (0.027%)\n","Class=356, n=11 (0.027%)\n","Class=357, n=11 (0.027%)\n","Class=358, n=11 (0.027%)\n","Class=359, n=11 (0.027%)\n","Class=360, n=11 (0.027%)\n","Class=361, n=10 (0.024%)\n","Class=362, n=10 (0.024%)\n","Class=363, n=10 (0.024%)\n","Class=364, n=10 (0.024%)\n","Class=365, n=10 (0.024%)\n","Class=366, n=10 (0.024%)\n","Class=367, n=10 (0.024%)\n","Class=368, n=10 (0.024%)\n","Class=369, n=10 (0.024%)\n","Class=370, n=10 (0.024%)\n","Class=371, n=10 (0.024%)\n","Class=372, n=10 (0.024%)\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["y_labelenc = LabelEncoder().fit_transform(Y)\n","\n","from collections import Counter\n","# summarize distribution\n","counter = Counter(y_labelenc)\n","\n","# sort counter by keys\n","counter = dict(sorted(counter.items()))\n","\n","\n","for k,v in counter.items():\n"," per = v / len(y_labelenc) * 100\n"," print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n","# plot the distribution\n","plt.bar( counter.keys(), counter.values())\n","\n","plt.ylabel('No of gene samples')\n","plt.xlabel('Class Index of OsID')\n","plt.title('Distribution of Target Classes (OsID)')\n","plt.show()"]},{"cell_type":"code","execution_count":6,"metadata":{"id":"W1WdWupjmZ9l"},"outputs":[],"source":["# prepare target data\n","def prepare_targets(y_train, y_test):\n","\tle = LabelEncoder()\n","\t\n","\t#fit the encoders only to the training data and then transform both train and test data\n","\ty_train_enc = le.fit_transform(y_train)\n","\ty_test_enc = le.transform(y_test)\n","\n","\treturn y_train_enc, y_test_enc"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"JjjBaPUOtmlx"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_fs, Y, test_size=0.33, random_state=1)\n","\n","# prepare output data\n","y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"POiHy56emZ9m"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of input features: 1\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 4.7993 - accuracy: 0.0723 - val_loss: 4.4386 - val_accuracy: 0.1102\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.0849 - accuracy: 0.1417 - val_loss: 4.0338 - val_accuracy: 0.1633\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.7236 - accuracy: 0.1935 - val_loss: 3.7500 - val_accuracy: 0.1952\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.4519 - accuracy: 0.2231 - val_loss: 3.5247 - val_accuracy: 0.1875\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.2283 - accuracy: 0.2641 - val_loss: 3.3338 - val_accuracy: 0.2576\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.0341 - accuracy: 0.3074 - val_loss: 3.1702 - val_accuracy: 0.3732\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.8716 - accuracy: 0.3318 - val_loss: 3.0503 - val_accuracy: 0.3076\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.7345 - accuracy: 0.3549 - val_loss: 2.9439 - val_accuracy: 0.3351\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.6275 - accuracy: 0.3725 - val_loss: 2.8697 - val_accuracy: 0.3384\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.5394 - accuracy: 0.3764 - val_loss: 2.8795 - val_accuracy: 0.3144\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4737 - accuracy: 0.3906 - val_loss: 2.7374 - val_accuracy: 0.4000\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.4151 - accuracy: 0.3866 - val_loss: 2.7133 - val_accuracy: 0.3725\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.3673 - accuracy: 0.3917 - val_loss: 2.6464 - val_accuracy: 0.4037\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.3246 - accuracy: 0.4030 - val_loss: 2.6245 - val_accuracy: 0.4330\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.2861 - accuracy: 0.4035 - val_loss: 2.6275 - val_accuracy: 0.3597\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.2535 - accuracy: 0.4162 - val_loss: 2.5822 - val_accuracy: 0.4222\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2235 - accuracy: 0.4192 - val_loss: 2.6060 - val_accuracy: 0.3538\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.2051 - accuracy: 0.4171 - val_loss: 2.5854 - val_accuracy: 0.3789\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.1695 - accuracy: 0.4306 - val_loss: 2.6860 - val_accuracy: 0.3474\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.1525 - accuracy: 0.4301 - val_loss: 2.4856 - val_accuracy: 0.4066\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.1391 - accuracy: 0.4361 - val_loss: 2.4860 - val_accuracy: 0.4308\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.1167 - accuracy: 0.4354 - val_loss: 2.4746 - val_accuracy: 0.4231\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0987 - accuracy: 0.4427 - val_loss: 2.5329 - val_accuracy: 0.3916\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0965 - accuracy: 0.4413 - val_loss: 2.4185 - val_accuracy: 0.4319\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0784 - accuracy: 0.4420 - val_loss: 2.3890 - val_accuracy: 0.4422\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0557 - accuracy: 0.4515 - val_loss: 2.4250 - val_accuracy: 0.4519\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0488 - accuracy: 0.4507 - val_loss: 2.4232 - val_accuracy: 0.4141\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0383 - accuracy: 0.4491 - val_loss: 2.4329 - val_accuracy: 0.4361\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0252 - accuracy: 0.4625 - val_loss: 2.3796 - val_accuracy: 0.4275\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0160 - accuracy: 0.4562 - val_loss: 2.3779 - val_accuracy: 0.4675\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0133 - accuracy: 0.4538 - val_loss: 2.3666 - val_accuracy: 0.4735\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9949 - accuracy: 0.4640 - val_loss: 2.3881 - val_accuracy: 0.4455\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9972 - accuracy: 0.4576 - val_loss: 2.4870 - val_accuracy: 0.4117\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9853 - accuracy: 0.4653 - val_loss: 2.3033 - val_accuracy: 0.5010\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9683 - accuracy: 0.4662 - val_loss: 2.3112 - val_accuracy: 0.4546\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9715 - accuracy: 0.4656 - val_loss: 2.3559 - val_accuracy: 0.4295\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9686 - accuracy: 0.4713 - val_loss: 2.3903 - val_accuracy: 0.4119\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9634 - accuracy: 0.4677 - val_loss: 2.2805 - val_accuracy: 0.4983\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9511 - accuracy: 0.4701 - val_loss: 2.3121 - val_accuracy: 0.4629\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9430 - accuracy: 0.4771 - val_loss: 2.3284 - val_accuracy: 0.4343\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9511 - accuracy: 0.4716 - val_loss: 2.3300 - val_accuracy: 0.4678\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9522 - accuracy: 0.4670 - val_loss: 2.3086 - val_accuracy: 0.4955\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9352 - accuracy: 0.4776 - val_loss: 2.3082 - val_accuracy: 0.4667\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9261 - accuracy: 0.4783 - val_loss: 2.3544 - val_accuracy: 0.4174\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9220 - accuracy: 0.4752 - val_loss: 2.3311 - val_accuracy: 0.4026\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9289 - accuracy: 0.4708 - val_loss: 2.2769 - val_accuracy: 0.4592\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9066 - accuracy: 0.4794 - val_loss: 2.2491 - val_accuracy: 0.4660\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9156 - accuracy: 0.4759 - val_loss: 2.2562 - val_accuracy: 0.4790\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9094 - accuracy: 0.4757 - val_loss: 2.2377 - val_accuracy: 0.4917\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9091 - accuracy: 0.4784 - val_loss: 2.3244 - val_accuracy: 0.4242\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8961 - accuracy: 0.4821 - val_loss: 2.2423 - val_accuracy: 0.4757\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8803 - accuracy: 0.4853 - val_loss: 2.1726 - val_accuracy: 0.4854\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.8756 - accuracy: 0.4886 - val_loss: 2.2092 - val_accuracy: 0.5006\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8831 - accuracy: 0.4870 - val_loss: 2.2676 - val_accuracy: 0.4024\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8728 - accuracy: 0.4918 - val_loss: 2.3084 - val_accuracy: 0.4088\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8716 - accuracy: 0.4912 - val_loss: 2.1975 - val_accuracy: 0.4851\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8827 - accuracy: 0.4887 - val_loss: 2.2642 - val_accuracy: 0.4491\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8770 - accuracy: 0.4907 - val_loss: 2.1593 - val_accuracy: 0.5118\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8542 - accuracy: 0.4922 - val_loss: 2.2090 - val_accuracy: 0.4691\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8456 - accuracy: 0.4953 - val_loss: 2.2721 - val_accuracy: 0.4651\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 4.8538 - accuracy: 0.0622 - val_loss: 4.5259 - val_accuracy: 0.0768\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 4.1599 - accuracy: 0.1264 - val_loss: 4.0702 - val_accuracy: 0.1606\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.7493 - accuracy: 0.1813 - val_loss: 3.8069 - val_accuracy: 0.2475\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.4616 - accuracy: 0.2113 - val_loss: 3.5538 - val_accuracy: 0.2218\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.2350 - accuracy: 0.2458 - val_loss: 3.4237 - val_accuracy: 0.3025\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0514 - accuracy: 0.2851 - val_loss: 3.2778 - val_accuracy: 0.2627\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.9075 - accuracy: 0.3140 - val_loss: 3.1247 - val_accuracy: 0.2858\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7826 - accuracy: 0.3337 - val_loss: 3.0646 - val_accuracy: 0.3439\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6762 - accuracy: 0.3596 - val_loss: 2.9216 - val_accuracy: 0.3798\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5968 - accuracy: 0.3643 - val_loss: 2.9067 - val_accuracy: 0.3303\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5205 - accuracy: 0.3782 - val_loss: 2.8139 - val_accuracy: 0.4240\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4553 - accuracy: 0.3954 - val_loss: 2.7401 - val_accuracy: 0.4108\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3890 - accuracy: 0.4002 - val_loss: 2.7526 - val_accuracy: 0.3329\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3359 - accuracy: 0.4108 - val_loss: 2.6693 - val_accuracy: 0.4224\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2910 - accuracy: 0.4166 - val_loss: 2.6361 - val_accuracy: 0.3782\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2488 - accuracy: 0.4220 - val_loss: 2.6210 - val_accuracy: 0.4372\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2200 - accuracy: 0.4260 - val_loss: 2.5706 - val_accuracy: 0.4059\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1807 - accuracy: 0.4351 - val_loss: 2.5513 - val_accuracy: 0.4312\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1609 - accuracy: 0.4441 - val_loss: 2.4896 - val_accuracy: 0.4554\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1350 - accuracy: 0.4388 - val_loss: 2.5673 - val_accuracy: 0.3468\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1141 - accuracy: 0.4499 - val_loss: 2.5035 - val_accuracy: 0.4304\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0934 - accuracy: 0.4522 - val_loss: 2.4376 - val_accuracy: 0.4640\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0786 - accuracy: 0.4554 - val_loss: 2.4349 - val_accuracy: 0.4521\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0539 - accuracy: 0.4576 - val_loss: 2.4213 - val_accuracy: 0.4777\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0368 - accuracy: 0.4609 - val_loss: 2.4202 - val_accuracy: 0.4581\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0302 - accuracy: 0.4619 - val_loss: 2.3801 - val_accuracy: 0.4832\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0128 - accuracy: 0.4671 - val_loss: 2.3671 - val_accuracy: 0.4680\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9927 - accuracy: 0.4703 - val_loss: 2.3556 - val_accuracy: 0.4680\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9902 - accuracy: 0.4698 - val_loss: 2.3724 - val_accuracy: 0.4609\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9725 - accuracy: 0.4698 - val_loss: 2.4190 - val_accuracy: 0.4431\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9721 - accuracy: 0.4704 - val_loss: 2.3476 - val_accuracy: 0.4031\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9547 - accuracy: 0.4746 - val_loss: 2.2910 - val_accuracy: 0.4926\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9431 - accuracy: 0.4727 - val_loss: 2.2860 - val_accuracy: 0.4865\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9398 - accuracy: 0.4808 - val_loss: 2.3581 - val_accuracy: 0.4491\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9316 - accuracy: 0.4766 - val_loss: 2.2515 - val_accuracy: 0.4697\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9193 - accuracy: 0.4763 - val_loss: 2.3149 - val_accuracy: 0.4508\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9121 - accuracy: 0.4778 - val_loss: 2.2573 - val_accuracy: 0.4763\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8988 - accuracy: 0.4879 - val_loss: 2.2943 - val_accuracy: 0.4609\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9056 - accuracy: 0.4808 - val_loss: 2.2823 - val_accuracy: 0.4649\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8894 - accuracy: 0.4844 - val_loss: 2.2264 - val_accuracy: 0.4915\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8846 - accuracy: 0.4850 - val_loss: 2.2281 - val_accuracy: 0.5127\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8720 - accuracy: 0.4895 - val_loss: 2.2877 - val_accuracy: 0.4451\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.8692 - accuracy: 0.4887 - val_loss: 2.2161 - val_accuracy: 0.4689\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8650 - accuracy: 0.4925 - val_loss: 2.2357 - val_accuracy: 0.4662\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8539 - accuracy: 0.4942 - val_loss: 2.2748 - val_accuracy: 0.4491\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8581 - accuracy: 0.4928 - val_loss: 2.2447 - val_accuracy: 0.4779\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8499 - accuracy: 0.4956 - val_loss: 2.1906 - val_accuracy: 0.5010\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8442 - accuracy: 0.4907 - val_loss: 2.4274 - val_accuracy: 0.4524\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8405 - accuracy: 0.4945 - val_loss: 2.3354 - val_accuracy: 0.4381\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8327 - accuracy: 0.4938 - val_loss: 2.1275 - val_accuracy: 0.5303\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8256 - accuracy: 0.4973 - val_loss: 2.1670 - val_accuracy: 0.5138\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8248 - accuracy: 0.5015 - val_loss: 2.1544 - val_accuracy: 0.4730\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.8145 - accuracy: 0.4991 - val_loss: 2.2318 - val_accuracy: 0.4818\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8163 - accuracy: 0.5043 - val_loss: 2.1689 - val_accuracy: 0.4979\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8033 - accuracy: 0.5034 - val_loss: 2.1578 - val_accuracy: 0.4726\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8062 - accuracy: 0.4986 - val_loss: 2.1531 - val_accuracy: 0.4928\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8020 - accuracy: 0.5058 - val_loss: 2.2038 - val_accuracy: 0.5001\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8176 - accuracy: 0.4978 - val_loss: 2.2114 - val_accuracy: 0.5162\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.7911 - accuracy: 0.5036 - val_loss: 2.1708 - val_accuracy: 0.5177\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.7990 - accuracy: 0.5030 - val_loss: 2.1940 - val_accuracy: 0.4766\n","Average Validation Accuracy: 0.48179224133491516\n","Average Validation Loss: 1.9699054956436157\n","Average Test Accuracy: 0.47855089604854584\n","------------------------------------------------------------------------\n","\n","Number of input features: 2\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.5346 - accuracy: 0.1168 - val_loss: 3.8732 - val_accuracy: 0.2200\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.2762 - accuracy: 0.3128 - val_loss: 3.0859 - val_accuracy: 0.3320\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6243 - accuracy: 0.4196 - val_loss: 2.6081 - val_accuracy: 0.4607\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1561 - accuracy: 0.5052 - val_loss: 2.3208 - val_accuracy: 0.4939\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8242 - accuracy: 0.5606 - val_loss: 2.0979 - val_accuracy: 0.6068\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6202 - accuracy: 0.6013 - val_loss: 1.9758 - val_accuracy: 0.6202\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4920 - accuracy: 0.6261 - val_loss: 1.8357 - val_accuracy: 0.6260\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3877 - accuracy: 0.6462 - val_loss: 1.7032 - val_accuracy: 0.6889\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3160 - accuracy: 0.6572 - val_loss: 1.7037 - val_accuracy: 0.6196\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2482 - accuracy: 0.6727 - val_loss: 1.6130 - val_accuracy: 0.6493\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2085 - accuracy: 0.6753 - val_loss: 1.6115 - val_accuracy: 0.6979\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1672 - accuracy: 0.6898 - val_loss: 1.5225 - val_accuracy: 0.6638\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1258 - accuracy: 0.6952 - val_loss: 1.4643 - val_accuracy: 0.6706\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1074 - accuracy: 0.6991 - val_loss: 1.4861 - val_accuracy: 0.6889\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0683 - accuracy: 0.7033 - val_loss: 1.3856 - val_accuracy: 0.7223\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0532 - accuracy: 0.7060 - val_loss: 1.4296 - val_accuracy: 0.6880\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0265 - accuracy: 0.7119 - val_loss: 1.3537 - val_accuracy: 0.7285\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0062 - accuracy: 0.7189 - val_loss: 1.3608 - val_accuracy: 0.7173\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0068 - accuracy: 0.7185 - val_loss: 1.3636 - val_accuracy: 0.7215\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9716 - accuracy: 0.7285 - val_loss: 1.3986 - val_accuracy: 0.6889\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9574 - accuracy: 0.7316 - val_loss: 1.3437 - val_accuracy: 0.7237\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9632 - accuracy: 0.7256 - val_loss: 1.2425 - val_accuracy: 0.7494\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.9442 - accuracy: 0.7374 - val_loss: 1.2654 - val_accuracy: 0.7463\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9348 - accuracy: 0.7347 - val_loss: 1.3214 - val_accuracy: 0.7228\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9147 - accuracy: 0.7374 - val_loss: 1.2685 - val_accuracy: 0.7446\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.9042 - accuracy: 0.7479 - val_loss: 1.2843 - val_accuracy: 0.7263\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8982 - accuracy: 0.7445 - val_loss: 1.2409 - val_accuracy: 0.7432\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8963 - accuracy: 0.7436 - val_loss: 1.2397 - val_accuracy: 0.7201\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8820 - accuracy: 0.7488 - val_loss: 1.2537 - val_accuracy: 0.7327\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8779 - accuracy: 0.7530 - val_loss: 1.3163 - val_accuracy: 0.6920\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8562 - accuracy: 0.7567 - val_loss: 1.2028 - val_accuracy: 0.7681\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8669 - accuracy: 0.7542 - val_loss: 1.2769 - val_accuracy: 0.7413\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8570 - accuracy: 0.7568 - val_loss: 1.2767 - val_accuracy: 0.7017\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8325 - accuracy: 0.7623 - val_loss: 1.1914 - val_accuracy: 0.7626\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8356 - accuracy: 0.7588 - val_loss: 1.2164 - val_accuracy: 0.7278\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8442 - accuracy: 0.7577 - val_loss: 1.1745 - val_accuracy: 0.7437\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8267 - accuracy: 0.7620 - val_loss: 1.1669 - val_accuracy: 0.7659\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8104 - accuracy: 0.7645 - val_loss: 1.1136 - val_accuracy: 0.7806\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8153 - accuracy: 0.7665 - val_loss: 1.1990 - val_accuracy: 0.7448\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7999 - accuracy: 0.7727 - val_loss: 1.0935 - val_accuracy: 0.7712\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8002 - accuracy: 0.7695 - val_loss: 1.0938 - val_accuracy: 0.7875\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7926 - accuracy: 0.7696 - val_loss: 1.0693 - val_accuracy: 0.7914\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7817 - accuracy: 0.7744 - val_loss: 1.1189 - val_accuracy: 0.7776\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7841 - accuracy: 0.7759 - val_loss: 1.1359 - val_accuracy: 0.7804\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7794 - accuracy: 0.7748 - val_loss: 1.4104 - val_accuracy: 0.6768\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7823 - accuracy: 0.7715 - val_loss: 1.0686 - val_accuracy: 0.7835\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7664 - accuracy: 0.7775 - val_loss: 1.0652 - val_accuracy: 0.7826\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7689 - accuracy: 0.7792 - val_loss: 1.0769 - val_accuracy: 0.8004\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7575 - accuracy: 0.7766 - val_loss: 1.0596 - val_accuracy: 0.7538\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7546 - accuracy: 0.7798 - val_loss: 1.0751 - val_accuracy: 0.7927\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7500 - accuracy: 0.7817 - val_loss: 1.1163 - val_accuracy: 0.7518\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7312 - accuracy: 0.7858 - val_loss: 1.2147 - val_accuracy: 0.7474\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.7472 - accuracy: 0.7856 - val_loss: 1.0180 - val_accuracy: 0.7952\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7304 - accuracy: 0.7846 - val_loss: 1.0335 - val_accuracy: 0.7824\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7443 - accuracy: 0.7822 - val_loss: 1.1099 - val_accuracy: 0.7817\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7134 - accuracy: 0.7903 - val_loss: 1.0501 - val_accuracy: 0.7734\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7335 - accuracy: 0.7861 - val_loss: 1.0277 - val_accuracy: 0.7762\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7299 - accuracy: 0.7872 - val_loss: 1.0547 - val_accuracy: 0.8095\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7157 - accuracy: 0.7905 - val_loss: 1.0318 - val_accuracy: 0.7993\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7057 - accuracy: 0.7921 - val_loss: 1.0037 - val_accuracy: 0.7791\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.4302 - accuracy: 0.1226 - val_loss: 3.8154 - val_accuracy: 0.2590\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.1488 - accuracy: 0.3178 - val_loss: 2.9540 - val_accuracy: 0.3798\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3849 - accuracy: 0.4674 - val_loss: 2.4542 - val_accuracy: 0.5481\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.9337 - accuracy: 0.5545 - val_loss: 2.2110 - val_accuracy: 0.5630\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6236 - accuracy: 0.6109 - val_loss: 1.9307 - val_accuracy: 0.6504\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4168 - accuracy: 0.6505 - val_loss: 1.7966 - val_accuracy: 0.6671\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2757 - accuracy: 0.6806 - val_loss: 1.6858 - val_accuracy: 0.6968\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1721 - accuracy: 0.6967 - val_loss: 1.6758 - val_accuracy: 0.6748\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1203 - accuracy: 0.7079 - val_loss: 1.6138 - val_accuracy: 0.6854\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0483 - accuracy: 0.7297 - val_loss: 1.4992 - val_accuracy: 0.7377\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0067 - accuracy: 0.7352 - val_loss: 1.4218 - val_accuracy: 0.7138\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9603 - accuracy: 0.7444 - val_loss: 1.4005 - val_accuracy: 0.7386\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9366 - accuracy: 0.7489 - val_loss: 1.3544 - val_accuracy: 0.7252\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9001 - accuracy: 0.7602 - val_loss: 1.3074 - val_accuracy: 0.7505\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8702 - accuracy: 0.7622 - val_loss: 1.2694 - val_accuracy: 0.7729\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8469 - accuracy: 0.7673 - val_loss: 1.2217 - val_accuracy: 0.7751\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8145 - accuracy: 0.7747 - val_loss: 1.1619 - val_accuracy: 0.7754\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8015 - accuracy: 0.7770 - val_loss: 1.1689 - val_accuracy: 0.7780\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7914 - accuracy: 0.7816 - val_loss: 1.1710 - val_accuracy: 0.7754\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7685 - accuracy: 0.7876 - val_loss: 1.1396 - val_accuracy: 0.7791\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7632 - accuracy: 0.7842 - val_loss: 1.1292 - val_accuracy: 0.7839\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7478 - accuracy: 0.7888 - val_loss: 1.0885 - val_accuracy: 0.7828\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7302 - accuracy: 0.7941 - val_loss: 1.1403 - val_accuracy: 0.7782\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7203 - accuracy: 0.7972 - val_loss: 1.1441 - val_accuracy: 0.8011\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7251 - accuracy: 0.7955 - val_loss: 1.1240 - val_accuracy: 0.7815\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6977 - accuracy: 0.8039 - val_loss: 1.0845 - val_accuracy: 0.7905\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6929 - accuracy: 0.8008 - val_loss: 1.0684 - val_accuracy: 0.7815\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6838 - accuracy: 0.8024 - val_loss: 1.0391 - val_accuracy: 0.8011\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6819 - accuracy: 0.8018 - val_loss: 1.0512 - val_accuracy: 0.7798\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6594 - accuracy: 0.8124 - val_loss: 1.0037 - val_accuracy: 0.7921\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6654 - accuracy: 0.8052 - val_loss: 1.0193 - val_accuracy: 0.8117\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6501 - accuracy: 0.8129 - val_loss: 1.0309 - val_accuracy: 0.7947\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6390 - accuracy: 0.8166 - val_loss: 1.0654 - val_accuracy: 0.7523\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6525 - accuracy: 0.8098 - val_loss: 0.9891 - val_accuracy: 0.8004\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6204 - accuracy: 0.8227 - val_loss: 1.0068 - val_accuracy: 0.8009\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6301 - accuracy: 0.8133 - val_loss: 0.9849 - val_accuracy: 0.7859\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6254 - accuracy: 0.8185 - val_loss: 0.9516 - val_accuracy: 0.8176\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6180 - accuracy: 0.8209 - val_loss: 1.0008 - val_accuracy: 0.7960\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6100 - accuracy: 0.8216 - val_loss: 0.9811 - val_accuracy: 0.8198\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6036 - accuracy: 0.8235 - val_loss: 0.9669 - val_accuracy: 0.8174\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6057 - accuracy: 0.8218 - val_loss: 0.9466 - val_accuracy: 0.8295\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5952 - accuracy: 0.8305 - val_loss: 0.9757 - val_accuracy: 0.7991\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5860 - accuracy: 0.8305 - val_loss: 0.9688 - val_accuracy: 0.7991\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6025 - accuracy: 0.8243 - val_loss: 1.1963 - val_accuracy: 0.7375\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5834 - accuracy: 0.8271 - val_loss: 0.9552 - val_accuracy: 0.8233\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.5774 - accuracy: 0.8314 - val_loss: 0.9365 - val_accuracy: 0.8205\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5833 - accuracy: 0.8283 - val_loss: 0.9237 - val_accuracy: 0.8059\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5720 - accuracy: 0.8316 - val_loss: 0.9851 - val_accuracy: 0.7903\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5734 - accuracy: 0.8317 - val_loss: 0.9343 - val_accuracy: 0.8207\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5696 - accuracy: 0.8349 - val_loss: 0.8806 - val_accuracy: 0.8297\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5575 - accuracy: 0.8355 - val_loss: 0.9023 - val_accuracy: 0.8029\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5597 - accuracy: 0.8350 - val_loss: 0.9141 - val_accuracy: 0.8081\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5534 - accuracy: 0.8373 - val_loss: 0.9010 - val_accuracy: 0.8169\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.5560 - accuracy: 0.8386 - val_loss: 0.8535 - val_accuracy: 0.8295\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5431 - accuracy: 0.8373 - val_loss: 0.8925 - val_accuracy: 0.8209\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5671 - accuracy: 0.8307 - val_loss: 0.8823 - val_accuracy: 0.8106\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5374 - accuracy: 0.8432 - val_loss: 0.8640 - val_accuracy: 0.8251\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5353 - accuracy: 0.8394 - val_loss: 0.8372 - val_accuracy: 0.8392\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5313 - accuracy: 0.8411 - val_loss: 0.8297 - val_accuracy: 0.8629\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5469 - accuracy: 0.8360 - val_loss: 0.8130 - val_accuracy: 0.8528\n","Average Validation Accuracy: 0.8195562958717346\n","Average Validation Loss: 0.6873789131641388\n","Average Test Accuracy: 0.8142183423042297\n","------------------------------------------------------------------------\n","\n","Number of input features: 3\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.8336 - accuracy: 0.2803 - val_loss: 2.8410 - val_accuracy: 0.4942\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1404 - accuracy: 0.5755 - val_loss: 1.9370 - val_accuracy: 0.6315\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4467 - accuracy: 0.6768 - val_loss: 1.5373 - val_accuracy: 0.6836\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1151 - accuracy: 0.7254 - val_loss: 1.2697 - val_accuracy: 0.7492\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9448 - accuracy: 0.7546 - val_loss: 1.1704 - val_accuracy: 0.7303\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8296 - accuracy: 0.7803 - val_loss: 1.0061 - val_accuracy: 0.7890\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7464 - accuracy: 0.7933 - val_loss: 0.9697 - val_accuracy: 0.8075\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6878 - accuracy: 0.8080 - val_loss: 0.9228 - val_accuracy: 0.7745\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6452 - accuracy: 0.8206 - val_loss: 0.9084 - val_accuracy: 0.8000\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6110 - accuracy: 0.8265 - val_loss: 0.7871 - val_accuracy: 0.8185\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5772 - accuracy: 0.8351 - val_loss: 0.7722 - val_accuracy: 0.8462\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5531 - accuracy: 0.8432 - val_loss: 0.7535 - val_accuracy: 0.8295\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5238 - accuracy: 0.8477 - val_loss: 0.7491 - val_accuracy: 0.8530\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5194 - accuracy: 0.8484 - val_loss: 0.6973 - val_accuracy: 0.8506\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4895 - accuracy: 0.8594 - val_loss: 0.6664 - val_accuracy: 0.8691\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4828 - accuracy: 0.8581 - val_loss: 0.7235 - val_accuracy: 0.8609\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4572 - accuracy: 0.8678 - val_loss: 0.6777 - val_accuracy: 0.8667\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4464 - accuracy: 0.8693 - val_loss: 0.6890 - val_accuracy: 0.8614\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4448 - accuracy: 0.8767 - val_loss: 0.6530 - val_accuracy: 0.8715\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4266 - accuracy: 0.8762 - val_loss: 0.6298 - val_accuracy: 0.8669\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4198 - accuracy: 0.8774 - val_loss: 0.6105 - val_accuracy: 0.8805\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4178 - accuracy: 0.8817 - val_loss: 0.6628 - val_accuracy: 0.8647\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4014 - accuracy: 0.8804 - val_loss: 0.6409 - val_accuracy: 0.8898\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3987 - accuracy: 0.8860 - val_loss: 0.5745 - val_accuracy: 0.8933\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3893 - accuracy: 0.8867 - val_loss: 0.5635 - val_accuracy: 0.9058\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3733 - accuracy: 0.8951 - val_loss: 0.6008 - val_accuracy: 0.8832\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3757 - accuracy: 0.8906 - val_loss: 0.5726 - val_accuracy: 0.8979\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3650 - accuracy: 0.8948 - val_loss: 0.5704 - val_accuracy: 0.8849\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3538 - accuracy: 0.8970 - val_loss: 0.5392 - val_accuracy: 0.9094\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3486 - accuracy: 0.9003 - val_loss: 0.6336 - val_accuracy: 0.8810\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3513 - accuracy: 0.9023 - val_loss: 0.5469 - val_accuracy: 0.8922\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3460 - accuracy: 0.9019 - val_loss: 0.5559 - val_accuracy: 0.8948\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3330 - accuracy: 0.9077 - val_loss: 0.5125 - val_accuracy: 0.9221\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3357 - accuracy: 0.9059 - val_loss: 0.5123 - val_accuracy: 0.9230\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3327 - accuracy: 0.9059 - val_loss: 0.5252 - val_accuracy: 0.9111\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3169 - accuracy: 0.9117 - val_loss: 0.5388 - val_accuracy: 0.9085\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3122 - accuracy: 0.9107 - val_loss: 0.5672 - val_accuracy: 0.8997\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3216 - accuracy: 0.9079 - val_loss: 0.5307 - val_accuracy: 0.9017\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3067 - accuracy: 0.9113 - val_loss: 0.5725 - val_accuracy: 0.8777\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3133 - accuracy: 0.9108 - val_loss: 0.5204 - val_accuracy: 0.9085\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3017 - accuracy: 0.9159 - val_loss: 0.5273 - val_accuracy: 0.9133\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3021 - accuracy: 0.9144 - val_loss: 0.5187 - val_accuracy: 0.9021\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3059 - accuracy: 0.9112 - val_loss: 0.5114 - val_accuracy: 0.9237\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2980 - accuracy: 0.9158 - val_loss: 0.5172 - val_accuracy: 0.9175\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3010 - accuracy: 0.9155 - val_loss: 0.6116 - val_accuracy: 0.8902\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2868 - accuracy: 0.9197 - val_loss: 0.5108 - val_accuracy: 0.9078\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2898 - accuracy: 0.9199 - val_loss: 0.4873 - val_accuracy: 0.9215\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2978 - accuracy: 0.9127 - val_loss: 0.4890 - val_accuracy: 0.9254\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2838 - accuracy: 0.9202 - val_loss: 0.4615 - val_accuracy: 0.9272\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2852 - accuracy: 0.9203 - val_loss: 0.5066 - val_accuracy: 0.9133\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2914 - accuracy: 0.9188 - val_loss: 0.4667 - val_accuracy: 0.9208\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2703 - accuracy: 0.9235 - val_loss: 0.4719 - val_accuracy: 0.9210\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2756 - accuracy: 0.9247 - val_loss: 0.4762 - val_accuracy: 0.9215\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2740 - accuracy: 0.9233 - val_loss: 0.4676 - val_accuracy: 0.9281\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2674 - accuracy: 0.9266 - val_loss: 0.4739 - val_accuracy: 0.8950\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2820 - accuracy: 0.9207 - val_loss: 0.4827 - val_accuracy: 0.9197\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2608 - accuracy: 0.9262 - val_loss: 0.4954 - val_accuracy: 0.9050\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2673 - accuracy: 0.9240 - val_loss: 0.4604 - val_accuracy: 0.9259\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2562 - accuracy: 0.9310 - val_loss: 0.4829 - val_accuracy: 0.9054\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2615 - accuracy: 0.9277 - val_loss: 0.4877 - val_accuracy: 0.9105\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.1177 - accuracy: 0.1938 - val_loss: 3.2745 - val_accuracy: 0.3980\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4171 - accuracy: 0.5173 - val_loss: 2.2011 - val_accuracy: 0.6081\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5794 - accuracy: 0.6583 - val_loss: 1.7427 - val_accuracy: 0.6975\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1868 - accuracy: 0.7241 - val_loss: 1.5207 - val_accuracy: 0.6979\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9661 - accuracy: 0.7642 - val_loss: 1.3587 - val_accuracy: 0.7336\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8302 - accuracy: 0.7882 - val_loss: 1.1966 - val_accuracy: 0.7901\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7417 - accuracy: 0.8046 - val_loss: 1.1460 - val_accuracy: 0.7725\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6763 - accuracy: 0.8170 - val_loss: 0.9926 - val_accuracy: 0.8271\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6277 - accuracy: 0.8282 - val_loss: 0.9705 - val_accuracy: 0.8227\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5866 - accuracy: 0.8384 - val_loss: 0.9109 - val_accuracy: 0.8235\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5556 - accuracy: 0.8472 - val_loss: 0.8574 - val_accuracy: 0.8561\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5190 - accuracy: 0.8550 - val_loss: 0.8475 - val_accuracy: 0.8370\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5095 - accuracy: 0.8600 - val_loss: 0.8030 - val_accuracy: 0.8383\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4883 - accuracy: 0.8624 - val_loss: 0.7786 - val_accuracy: 0.8568\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4663 - accuracy: 0.8718 - val_loss: 0.7589 - val_accuracy: 0.8658\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4530 - accuracy: 0.8720 - val_loss: 0.7354 - val_accuracy: 0.8737\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4439 - accuracy: 0.8786 - val_loss: 0.8939 - val_accuracy: 0.8266\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4305 - accuracy: 0.8779 - val_loss: 0.7073 - val_accuracy: 0.8785\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4153 - accuracy: 0.8857 - val_loss: 0.6754 - val_accuracy: 0.8834\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4085 - accuracy: 0.8854 - val_loss: 0.6760 - val_accuracy: 0.8972\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3969 - accuracy: 0.8912 - val_loss: 0.7521 - val_accuracy: 0.8552\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3984 - accuracy: 0.8895 - val_loss: 0.6402 - val_accuracy: 0.9008\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3879 - accuracy: 0.8935 - val_loss: 0.6740 - val_accuracy: 0.8653\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3754 - accuracy: 0.8960 - val_loss: 0.6446 - val_accuracy: 0.8862\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3668 - accuracy: 0.8978 - val_loss: 0.7263 - val_accuracy: 0.8724\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3735 - accuracy: 0.8955 - val_loss: 0.6907 - val_accuracy: 0.8744\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3589 - accuracy: 0.9014 - val_loss: 0.6375 - val_accuracy: 0.9047\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3567 - accuracy: 0.9014 - val_loss: 0.6042 - val_accuracy: 0.8884\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3502 - accuracy: 0.9045 - val_loss: 0.5982 - val_accuracy: 0.8977\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3403 - accuracy: 0.9056 - val_loss: 0.5829 - val_accuracy: 0.9043\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3432 - accuracy: 0.9043 - val_loss: 0.5790 - val_accuracy: 0.9045\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3331 - accuracy: 0.9065 - val_loss: 0.5867 - val_accuracy: 0.8964\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3249 - accuracy: 0.9118 - val_loss: 0.6122 - val_accuracy: 0.8997\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3229 - accuracy: 0.9098 - val_loss: 0.6207 - val_accuracy: 0.8814\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3250 - accuracy: 0.9117 - val_loss: 0.5879 - val_accuracy: 0.8964\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3195 - accuracy: 0.9116 - val_loss: 0.6143 - val_accuracy: 0.8838\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3082 - accuracy: 0.9132 - val_loss: 0.5459 - val_accuracy: 0.9155\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3089 - accuracy: 0.9150 - val_loss: 0.5513 - val_accuracy: 0.9028\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3074 - accuracy: 0.9160 - val_loss: 0.5467 - val_accuracy: 0.9177\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3091 - accuracy: 0.9133 - val_loss: 0.5565 - val_accuracy: 0.9063\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3002 - accuracy: 0.9183 - val_loss: 0.5629 - val_accuracy: 0.8913\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3063 - accuracy: 0.9149 - val_loss: 0.5581 - val_accuracy: 0.9118\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3045 - accuracy: 0.9185 - val_loss: 0.5657 - val_accuracy: 0.8955\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2976 - accuracy: 0.9178 - val_loss: 0.5611 - val_accuracy: 0.9028\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2952 - accuracy: 0.9198 - val_loss: 0.5544 - val_accuracy: 0.9212\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2844 - accuracy: 0.9190 - val_loss: 0.6111 - val_accuracy: 0.8990\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2852 - accuracy: 0.9214 - val_loss: 0.5656 - val_accuracy: 0.9120\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2973 - accuracy: 0.9184 - val_loss: 0.5289 - val_accuracy: 0.9265\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2836 - accuracy: 0.9235 - val_loss: 0.5705 - val_accuracy: 0.9039\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2738 - accuracy: 0.9246 - val_loss: 0.5196 - val_accuracy: 0.9278\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2798 - accuracy: 0.9239 - val_loss: 0.5284 - val_accuracy: 0.9054\n","Epoch 52/60\n","1846/1846 [==============================] - 9s 5ms/step - loss: 0.2750 - accuracy: 0.9235 - val_loss: 0.5036 - val_accuracy: 0.9278\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2753 - accuracy: 0.9222 - val_loss: 0.5438 - val_accuracy: 0.9252\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2690 - accuracy: 0.9265 - val_loss: 0.5594 - val_accuracy: 0.8946\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2738 - accuracy: 0.9223 - val_loss: 0.5463 - val_accuracy: 0.9283\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2729 - accuracy: 0.9247 - val_loss: 0.5206 - val_accuracy: 0.9259\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2715 - accuracy: 0.9275 - val_loss: 0.5387 - val_accuracy: 0.9171\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2617 - accuracy: 0.9273 - val_loss: 0.5287 - val_accuracy: 0.9296\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2640 - accuracy: 0.9272 - val_loss: 0.5426 - val_accuracy: 0.9294\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2576 - accuracy: 0.9280 - val_loss: 0.5896 - val_accuracy: 0.8968\n","Average Validation Accuracy: 0.9162763059139252\n","Average Validation Loss: 0.3563217669725418\n","Average Test Accuracy: 0.9119186401367188\n","------------------------------------------------------------------------\n","\n","Number of input features: 4\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.9681 - accuracy: 0.2459 - val_loss: 2.9124 - val_accuracy: 0.5325\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0469 - accuracy: 0.6155 - val_loss: 1.7441 - val_accuracy: 0.7019\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2208 - accuracy: 0.7473 - val_loss: 1.2453 - val_accuracy: 0.7859\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8619 - accuracy: 0.8033 - val_loss: 0.9963 - val_accuracy: 0.8189\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6973 - accuracy: 0.8294 - val_loss: 0.8661 - val_accuracy: 0.8262\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5936 - accuracy: 0.8494 - val_loss: 0.7455 - val_accuracy: 0.8607\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5278 - accuracy: 0.8641 - val_loss: 0.7047 - val_accuracy: 0.8689\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4884 - accuracy: 0.8701 - val_loss: 0.6705 - val_accuracy: 0.8502\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4404 - accuracy: 0.8822 - val_loss: 0.6838 - val_accuracy: 0.8469\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4204 - accuracy: 0.8888 - val_loss: 0.6079 - val_accuracy: 0.8634\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4023 - accuracy: 0.8923 - val_loss: 0.5790 - val_accuracy: 0.8812\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3780 - accuracy: 0.8975 - val_loss: 0.5626 - val_accuracy: 0.8825\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3609 - accuracy: 0.9013 - val_loss: 0.5526 - val_accuracy: 0.8794\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3535 - accuracy: 0.9054 - val_loss: 0.5061 - val_accuracy: 0.9107\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3477 - accuracy: 0.9055 - val_loss: 0.5243 - val_accuracy: 0.9041\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3286 - accuracy: 0.9132 - val_loss: 0.5051 - val_accuracy: 0.8981\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3222 - accuracy: 0.9126 - val_loss: 0.4569 - val_accuracy: 0.9298\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3088 - accuracy: 0.9142 - val_loss: 0.4955 - val_accuracy: 0.9030\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2962 - accuracy: 0.9199 - val_loss: 0.4755 - val_accuracy: 0.9063\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2893 - accuracy: 0.9213 - val_loss: 0.4318 - val_accuracy: 0.9186\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2800 - accuracy: 0.9247 - val_loss: 0.4298 - val_accuracy: 0.9254\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2763 - accuracy: 0.9269 - val_loss: 0.4234 - val_accuracy: 0.9397\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2691 - accuracy: 0.9273 - val_loss: 0.4285 - val_accuracy: 0.9204\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2587 - accuracy: 0.9300 - val_loss: 0.4340 - val_accuracy: 0.9157\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2567 - accuracy: 0.9319 - val_loss: 0.4044 - val_accuracy: 0.9413\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2523 - accuracy: 0.9324 - val_loss: 0.3997 - val_accuracy: 0.9410\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2484 - accuracy: 0.9352 - val_loss: 0.3855 - val_accuracy: 0.9426\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2322 - accuracy: 0.9420 - val_loss: 0.4053 - val_accuracy: 0.9300\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2389 - accuracy: 0.9385 - val_loss: 0.3966 - val_accuracy: 0.9476\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2304 - accuracy: 0.9397 - val_loss: 0.4293 - val_accuracy: 0.9248\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2243 - accuracy: 0.9427 - val_loss: 0.3669 - val_accuracy: 0.9490\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2204 - accuracy: 0.9455 - val_loss: 0.3775 - val_accuracy: 0.9435\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2206 - accuracy: 0.9426 - val_loss: 0.3645 - val_accuracy: 0.9518\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2069 - accuracy: 0.9485 - val_loss: 0.4172 - val_accuracy: 0.9331\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2123 - accuracy: 0.9458 - val_loss: 0.3873 - val_accuracy: 0.9366\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2079 - accuracy: 0.9484 - val_loss: 0.3964 - val_accuracy: 0.9388\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2017 - accuracy: 0.9513 - val_loss: 0.3462 - val_accuracy: 0.9584\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2021 - accuracy: 0.9499 - val_loss: 0.3661 - val_accuracy: 0.9501\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1910 - accuracy: 0.9561 - val_loss: 0.3875 - val_accuracy: 0.9380\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2001 - accuracy: 0.9485 - val_loss: 0.3428 - val_accuracy: 0.9582\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1823 - accuracy: 0.9585 - val_loss: 0.3928 - val_accuracy: 0.9311\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1892 - accuracy: 0.9549 - val_loss: 0.3715 - val_accuracy: 0.9490\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1780 - accuracy: 0.9576 - val_loss: 0.3668 - val_accuracy: 0.9492\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1787 - accuracy: 0.9586 - val_loss: 0.3533 - val_accuracy: 0.9523\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1789 - accuracy: 0.9576 - val_loss: 0.3724 - val_accuracy: 0.9527\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1791 - accuracy: 0.9583 - val_loss: 0.4337 - val_accuracy: 0.9221\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1767 - accuracy: 0.9588 - val_loss: 0.3205 - val_accuracy: 0.9633\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1685 - accuracy: 0.9602 - val_loss: 0.3124 - val_accuracy: 0.9668\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1687 - accuracy: 0.9608 - val_loss: 0.3268 - val_accuracy: 0.9525\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1652 - accuracy: 0.9608 - val_loss: 0.3264 - val_accuracy: 0.9630\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1647 - accuracy: 0.9617 - val_loss: 0.3783 - val_accuracy: 0.9551\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1610 - accuracy: 0.9642 - val_loss: 0.3125 - val_accuracy: 0.9655\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1654 - accuracy: 0.9628 - val_loss: 0.4196 - val_accuracy: 0.9239\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1572 - accuracy: 0.9646 - val_loss: 0.2941 - val_accuracy: 0.9758\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1537 - accuracy: 0.9670 - val_loss: 0.3593 - val_accuracy: 0.9606\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1585 - accuracy: 0.9639 - val_loss: 0.2922 - val_accuracy: 0.9696\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1485 - accuracy: 0.9665 - val_loss: 0.3237 - val_accuracy: 0.9595\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1510 - accuracy: 0.9648 - val_loss: 0.3089 - val_accuracy: 0.9637\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1541 - accuracy: 0.9651 - val_loss: 0.3164 - val_accuracy: 0.9615\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1467 - accuracy: 0.9673 - val_loss: 0.3102 - val_accuracy: 0.9644\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.0226 - accuracy: 0.2406 - val_loss: 2.9643 - val_accuracy: 0.4829\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.1297 - accuracy: 0.5892 - val_loss: 1.9802 - val_accuracy: 0.6620\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3173 - accuracy: 0.7355 - val_loss: 1.4238 - val_accuracy: 0.7853\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9170 - accuracy: 0.8070 - val_loss: 1.1672 - val_accuracy: 0.8022\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7158 - accuracy: 0.8354 - val_loss: 1.0251 - val_accuracy: 0.8381\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6112 - accuracy: 0.8497 - val_loss: 0.9186 - val_accuracy: 0.8455\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5358 - accuracy: 0.8636 - val_loss: 0.8571 - val_accuracy: 0.8440\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4837 - accuracy: 0.8759 - val_loss: 0.7553 - val_accuracy: 0.8693\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4532 - accuracy: 0.8768 - val_loss: 0.7235 - val_accuracy: 0.8614\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4129 - accuracy: 0.8857 - val_loss: 0.7019 - val_accuracy: 0.8847\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4007 - accuracy: 0.8903 - val_loss: 0.6694 - val_accuracy: 0.8785\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3689 - accuracy: 0.8964 - val_loss: 0.6950 - val_accuracy: 0.8757\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3623 - accuracy: 0.8996 - val_loss: 0.6094 - val_accuracy: 0.8834\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3463 - accuracy: 0.9031 - val_loss: 0.6763 - val_accuracy: 0.8869\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3350 - accuracy: 0.9058 - val_loss: 0.5854 - val_accuracy: 0.9113\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3207 - accuracy: 0.9112 - val_loss: 0.5925 - val_accuracy: 0.8999\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3051 - accuracy: 0.9145 - val_loss: 0.5941 - val_accuracy: 0.8981\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3011 - accuracy: 0.9183 - val_loss: 0.6016 - val_accuracy: 0.8968\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2953 - accuracy: 0.9177 - val_loss: 0.5672 - val_accuracy: 0.9017\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2838 - accuracy: 0.9211 - val_loss: 0.5342 - val_accuracy: 0.9151\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2850 - accuracy: 0.9202 - val_loss: 0.5283 - val_accuracy: 0.9278\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2685 - accuracy: 0.9284 - val_loss: 0.5587 - val_accuracy: 0.8979\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2639 - accuracy: 0.9294 - val_loss: 0.5341 - val_accuracy: 0.9267\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2639 - accuracy: 0.9294 - val_loss: 0.5582 - val_accuracy: 0.9127\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2516 - accuracy: 0.9322 - val_loss: 0.5393 - val_accuracy: 0.9168\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2557 - accuracy: 0.9312 - val_loss: 0.5090 - val_accuracy: 0.9164\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2540 - accuracy: 0.9327 - val_loss: 0.4938 - val_accuracy: 0.9318\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2352 - accuracy: 0.9370 - val_loss: 0.4994 - val_accuracy: 0.9369\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2429 - accuracy: 0.9352 - val_loss: 0.5800 - val_accuracy: 0.9058\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2311 - accuracy: 0.9385 - val_loss: 0.4919 - val_accuracy: 0.9316\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2316 - accuracy: 0.9374 - val_loss: 0.4861 - val_accuracy: 0.9252\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2252 - accuracy: 0.9408 - val_loss: 0.4949 - val_accuracy: 0.9309\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2175 - accuracy: 0.9443 - val_loss: 0.5349 - val_accuracy: 0.9340\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2224 - accuracy: 0.9414 - val_loss: 0.5042 - val_accuracy: 0.9243\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2133 - accuracy: 0.9459 - val_loss: 0.4707 - val_accuracy: 0.9472\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2089 - accuracy: 0.9452 - val_loss: 0.5309 - val_accuracy: 0.9307\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2074 - accuracy: 0.9490 - val_loss: 0.4597 - val_accuracy: 0.9459\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2082 - accuracy: 0.9461 - val_loss: 0.4521 - val_accuracy: 0.9556\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1979 - accuracy: 0.9486 - val_loss: 0.4885 - val_accuracy: 0.9421\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2030 - accuracy: 0.9473 - val_loss: 0.4728 - val_accuracy: 0.9274\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1952 - accuracy: 0.9506 - val_loss: 0.5079 - val_accuracy: 0.9241\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1955 - accuracy: 0.9521 - val_loss: 0.4697 - val_accuracy: 0.9358\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1938 - accuracy: 0.9529 - val_loss: 0.6699 - val_accuracy: 0.8702\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1918 - accuracy: 0.9518 - val_loss: 0.4865 - val_accuracy: 0.9314\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1894 - accuracy: 0.9514 - val_loss: 0.4417 - val_accuracy: 0.9575\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1838 - accuracy: 0.9539 - val_loss: 0.4655 - val_accuracy: 0.9443\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1802 - accuracy: 0.9549 - val_loss: 0.4369 - val_accuracy: 0.9481\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1825 - accuracy: 0.9552 - val_loss: 0.5083 - val_accuracy: 0.9331\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1745 - accuracy: 0.9584 - val_loss: 0.4417 - val_accuracy: 0.9481\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1783 - accuracy: 0.9563 - val_loss: 0.4760 - val_accuracy: 0.9463\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1778 - accuracy: 0.9564 - val_loss: 0.4663 - val_accuracy: 0.9487\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1748 - accuracy: 0.9589 - val_loss: 0.4478 - val_accuracy: 0.9474\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1665 - accuracy: 0.9611 - val_loss: 0.4393 - val_accuracy: 0.9520\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1723 - accuracy: 0.9595 - val_loss: 0.4766 - val_accuracy: 0.9459\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1663 - accuracy: 0.9606 - val_loss: 0.4243 - val_accuracy: 0.9564\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1628 - accuracy: 0.9610 - val_loss: 0.4545 - val_accuracy: 0.9476\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1641 - accuracy: 0.9608 - val_loss: 0.4459 - val_accuracy: 0.9446\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1608 - accuracy: 0.9630 - val_loss: 0.4199 - val_accuracy: 0.9661\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1603 - accuracy: 0.9637 - val_loss: 0.4470 - val_accuracy: 0.9490\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1510 - accuracy: 0.9648 - val_loss: 0.4343 - val_accuracy: 0.9450\n","Average Validation Accuracy: 0.960134893655777\n","Average Validation Loss: 0.22246263176202774\n","Average Test Accuracy: 0.9574334621429443\n","------------------------------------------------------------------------\n","\n","Number of input features: 5\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.7440 - accuracy: 0.3179 - val_loss: 2.5420 - val_accuracy: 0.5615\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6823 - accuracy: 0.6892 - val_loss: 1.4306 - val_accuracy: 0.7437\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9266 - accuracy: 0.8065 - val_loss: 0.9712 - val_accuracy: 0.8125\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6185 - accuracy: 0.8550 - val_loss: 0.7576 - val_accuracy: 0.8801\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4870 - accuracy: 0.8778 - val_loss: 0.6922 - val_accuracy: 0.8741\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4081 - accuracy: 0.8939 - val_loss: 0.5852 - val_accuracy: 0.8942\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3646 - accuracy: 0.9055 - val_loss: 0.5926 - val_accuracy: 0.8882\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3328 - accuracy: 0.9139 - val_loss: 0.4913 - val_accuracy: 0.9144\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3093 - accuracy: 0.9186 - val_loss: 0.4781 - val_accuracy: 0.9072\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3018 - accuracy: 0.9208 - val_loss: 0.4777 - val_accuracy: 0.9179\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2739 - accuracy: 0.9265 - val_loss: 0.4300 - val_accuracy: 0.9303\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2613 - accuracy: 0.9294 - val_loss: 0.4394 - val_accuracy: 0.9314\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2524 - accuracy: 0.9330 - val_loss: 0.4397 - val_accuracy: 0.9252\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2371 - accuracy: 0.9366 - val_loss: 0.3877 - val_accuracy: 0.9296\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2354 - accuracy: 0.9358 - val_loss: 0.3798 - val_accuracy: 0.9245\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2220 - accuracy: 0.9403 - val_loss: 0.3783 - val_accuracy: 0.9300\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2115 - accuracy: 0.9420 - val_loss: 0.3722 - val_accuracy: 0.9333\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2115 - accuracy: 0.9469 - val_loss: 0.4216 - val_accuracy: 0.9243\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2011 - accuracy: 0.9474 - val_loss: 0.3692 - val_accuracy: 0.9408\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1960 - accuracy: 0.9508 - val_loss: 0.3632 - val_accuracy: 0.9454\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1917 - accuracy: 0.9497 - val_loss: 0.3543 - val_accuracy: 0.9406\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1870 - accuracy: 0.9508 - val_loss: 0.3081 - val_accuracy: 0.9597\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1809 - accuracy: 0.9527 - val_loss: 0.3522 - val_accuracy: 0.9336\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1665 - accuracy: 0.9577 - val_loss: 0.3509 - val_accuracy: 0.9465\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1760 - accuracy: 0.9555 - val_loss: 0.3143 - val_accuracy: 0.9465\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1663 - accuracy: 0.9568 - val_loss: 0.2992 - val_accuracy: 0.9584\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1687 - accuracy: 0.9574 - val_loss: 0.3076 - val_accuracy: 0.9538\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1574 - accuracy: 0.9588 - val_loss: 0.3079 - val_accuracy: 0.9496\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1543 - accuracy: 0.9608 - val_loss: 0.3300 - val_accuracy: 0.9474\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1585 - accuracy: 0.9600 - val_loss: 0.2970 - val_accuracy: 0.9578\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1575 - accuracy: 0.9594 - val_loss: 0.3007 - val_accuracy: 0.9597\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1553 - accuracy: 0.9603 - val_loss: 0.3078 - val_accuracy: 0.9465\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1466 - accuracy: 0.9643 - val_loss: 0.2854 - val_accuracy: 0.9639\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1450 - accuracy: 0.9614 - val_loss: 0.2828 - val_accuracy: 0.9630\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1394 - accuracy: 0.9664 - val_loss: 0.3438 - val_accuracy: 0.9358\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1444 - accuracy: 0.9653 - val_loss: 0.2888 - val_accuracy: 0.9626\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1469 - accuracy: 0.9623 - val_loss: 0.2857 - val_accuracy: 0.9690\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1311 - accuracy: 0.9707 - val_loss: 0.3152 - val_accuracy: 0.9575\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1397 - accuracy: 0.9655 - val_loss: 0.2936 - val_accuracy: 0.9608\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1371 - accuracy: 0.9661 - val_loss: 0.2882 - val_accuracy: 0.9670\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1401 - accuracy: 0.9640 - val_loss: 0.2631 - val_accuracy: 0.9646\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1254 - accuracy: 0.9703 - val_loss: 0.2989 - val_accuracy: 0.9525\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1331 - accuracy: 0.9677 - val_loss: 0.2774 - val_accuracy: 0.9635\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1269 - accuracy: 0.9684 - val_loss: 0.3039 - val_accuracy: 0.9575\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1332 - accuracy: 0.9673 - val_loss: 0.2696 - val_accuracy: 0.9613\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1260 - accuracy: 0.9697 - val_loss: 0.2778 - val_accuracy: 0.9677\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1261 - accuracy: 0.9686 - val_loss: 0.2634 - val_accuracy: 0.9624\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1241 - accuracy: 0.9699 - val_loss: 0.2563 - val_accuracy: 0.9694\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1224 - accuracy: 0.9706 - val_loss: 0.2545 - val_accuracy: 0.9721\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1244 - accuracy: 0.9705 - val_loss: 0.2990 - val_accuracy: 0.9529\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1204 - accuracy: 0.9703 - val_loss: 0.2725 - val_accuracy: 0.9650\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1179 - accuracy: 0.9706 - val_loss: 0.2573 - val_accuracy: 0.9699\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1196 - accuracy: 0.9717 - val_loss: 0.2535 - val_accuracy: 0.9740\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1159 - accuracy: 0.9713 - val_loss: 0.2848 - val_accuracy: 0.9580\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1176 - accuracy: 0.9714 - val_loss: 0.2494 - val_accuracy: 0.9732\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1178 - accuracy: 0.9725 - val_loss: 0.2368 - val_accuracy: 0.9740\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1140 - accuracy: 0.9729 - val_loss: 0.2540 - val_accuracy: 0.9628\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1107 - accuracy: 0.9736 - val_loss: 0.2427 - val_accuracy: 0.9743\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1155 - accuracy: 0.9716 - val_loss: 0.2361 - val_accuracy: 0.9699\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1096 - accuracy: 0.9746 - val_loss: 0.2425 - val_accuracy: 0.9705\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7095 - accuracy: 0.3032 - val_loss: 2.5695 - val_accuracy: 0.5637\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6815 - accuracy: 0.6976 - val_loss: 1.6080 - val_accuracy: 0.7549\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0001 - accuracy: 0.7976 - val_loss: 1.2238 - val_accuracy: 0.8306\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7206 - accuracy: 0.8418 - val_loss: 1.0225 - val_accuracy: 0.8231\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5722 - accuracy: 0.8672 - val_loss: 0.9097 - val_accuracy: 0.8532\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4864 - accuracy: 0.8831 - val_loss: 0.7569 - val_accuracy: 0.8728\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4186 - accuracy: 0.8939 - val_loss: 0.6877 - val_accuracy: 0.8891\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3745 - accuracy: 0.9038 - val_loss: 0.5822 - val_accuracy: 0.9078\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3408 - accuracy: 0.9097 - val_loss: 0.5441 - val_accuracy: 0.9078\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3067 - accuracy: 0.9180 - val_loss: 0.5006 - val_accuracy: 0.9186\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2929 - accuracy: 0.9234 - val_loss: 0.4792 - val_accuracy: 0.9188\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2794 - accuracy: 0.9266 - val_loss: 0.4849 - val_accuracy: 0.9234\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2626 - accuracy: 0.9307 - val_loss: 0.4857 - val_accuracy: 0.9160\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2500 - accuracy: 0.9348 - val_loss: 0.4181 - val_accuracy: 0.9320\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2301 - accuracy: 0.9399 - val_loss: 0.4438 - val_accuracy: 0.9133\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2281 - accuracy: 0.9403 - val_loss: 0.4051 - val_accuracy: 0.9322\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2245 - accuracy: 0.9409 - val_loss: 0.4461 - val_accuracy: 0.9175\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2126 - accuracy: 0.9433 - val_loss: 0.3650 - val_accuracy: 0.9333\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2029 - accuracy: 0.9486 - val_loss: 0.3792 - val_accuracy: 0.9263\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2009 - accuracy: 0.9464 - val_loss: 0.3915 - val_accuracy: 0.9303\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1919 - accuracy: 0.9504 - val_loss: 0.3296 - val_accuracy: 0.9525\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1853 - accuracy: 0.9530 - val_loss: 0.3385 - val_accuracy: 0.9468\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1808 - accuracy: 0.9537 - val_loss: 0.3449 - val_accuracy: 0.9380\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1786 - accuracy: 0.9526 - val_loss: 0.3598 - val_accuracy: 0.9404\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1683 - accuracy: 0.9556 - val_loss: 0.3177 - val_accuracy: 0.9560\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1719 - accuracy: 0.9547 - val_loss: 0.2889 - val_accuracy: 0.9639\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1589 - accuracy: 0.9590 - val_loss: 0.3171 - val_accuracy: 0.9448\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1660 - accuracy: 0.9586 - val_loss: 0.2983 - val_accuracy: 0.9586\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1516 - accuracy: 0.9627 - val_loss: 0.3128 - val_accuracy: 0.9509\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1528 - accuracy: 0.9621 - val_loss: 0.3141 - val_accuracy: 0.9545\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1509 - accuracy: 0.9615 - val_loss: 0.2956 - val_accuracy: 0.9545\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1452 - accuracy: 0.9635 - val_loss: 0.3105 - val_accuracy: 0.9448\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1424 - accuracy: 0.9652 - val_loss: 0.3225 - val_accuracy: 0.9523\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1392 - accuracy: 0.9648 - val_loss: 0.2835 - val_accuracy: 0.9633\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1426 - accuracy: 0.9641 - val_loss: 0.2953 - val_accuracy: 0.9540\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1332 - accuracy: 0.9673 - val_loss: 0.3143 - val_accuracy: 0.9441\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1359 - accuracy: 0.9672 - val_loss: 0.3037 - val_accuracy: 0.9525\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1272 - accuracy: 0.9685 - val_loss: 0.2810 - val_accuracy: 0.9606\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1276 - accuracy: 0.9689 - val_loss: 0.2878 - val_accuracy: 0.9575\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1323 - accuracy: 0.9689 - val_loss: 0.2836 - val_accuracy: 0.9536\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1256 - accuracy: 0.9695 - val_loss: 0.2652 - val_accuracy: 0.9600\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1175 - accuracy: 0.9719 - val_loss: 0.2997 - val_accuracy: 0.9503\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1218 - accuracy: 0.9711 - val_loss: 0.2915 - val_accuracy: 0.9461\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1285 - accuracy: 0.9682 - val_loss: 0.2509 - val_accuracy: 0.9626\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1135 - accuracy: 0.9725 - val_loss: 0.2613 - val_accuracy: 0.9606\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1212 - accuracy: 0.9674 - val_loss: 0.2666 - val_accuracy: 0.9624\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1170 - accuracy: 0.9730 - val_loss: 0.2718 - val_accuracy: 0.9547\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1143 - accuracy: 0.9720 - val_loss: 0.3553 - val_accuracy: 0.9212\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1116 - accuracy: 0.9741 - val_loss: 0.2921 - val_accuracy: 0.9463\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1125 - accuracy: 0.9719 - val_loss: 0.2712 - val_accuracy: 0.9490\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1100 - accuracy: 0.9734 - val_loss: 0.2563 - val_accuracy: 0.9593\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1056 - accuracy: 0.9738 - val_loss: 0.2463 - val_accuracy: 0.9604\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1108 - accuracy: 0.9728 - val_loss: 0.2593 - val_accuracy: 0.9556\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1026 - accuracy: 0.9745 - val_loss: 0.2411 - val_accuracy: 0.9604\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1021 - accuracy: 0.9758 - val_loss: 0.2482 - val_accuracy: 0.9617\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1045 - accuracy: 0.9739 - val_loss: 0.2606 - val_accuracy: 0.9591\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1088 - accuracy: 0.9741 - val_loss: 0.2358 - val_accuracy: 0.9685\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0951 - accuracy: 0.9781 - val_loss: 0.3976 - val_accuracy: 0.9338\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1088 - accuracy: 0.9726 - val_loss: 0.2314 - val_accuracy: 0.9635\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0933 - accuracy: 0.9777 - val_loss: 0.2369 - val_accuracy: 0.9659\n","Average Validation Accuracy: 0.9708819091320038\n","Average Validation Loss: 0.14899087697267532\n","Average Test Accuracy: 0.9688214063644409\n","------------------------------------------------------------------------\n","\n","Number of input features: 6\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7620 - accuracy: 0.2941 - val_loss: 2.6232 - val_accuracy: 0.5778\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8184 - accuracy: 0.6641 - val_loss: 1.5898 - val_accuracy: 0.7327\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0433 - accuracy: 0.7852 - val_loss: 1.0805 - val_accuracy: 0.8103\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6897 - accuracy: 0.8462 - val_loss: 0.8698 - val_accuracy: 0.8301\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5124 - accuracy: 0.8771 - val_loss: 0.7118 - val_accuracy: 0.8840\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4168 - accuracy: 0.8915 - val_loss: 0.6230 - val_accuracy: 0.9008\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3593 - accuracy: 0.9107 - val_loss: 0.5640 - val_accuracy: 0.9028\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3156 - accuracy: 0.9164 - val_loss: 0.5600 - val_accuracy: 0.9036\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2861 - accuracy: 0.9250 - val_loss: 0.4686 - val_accuracy: 0.9245\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2601 - accuracy: 0.9323 - val_loss: 0.5406 - val_accuracy: 0.8933\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2448 - accuracy: 0.9355 - val_loss: 0.4980 - val_accuracy: 0.9166\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2317 - accuracy: 0.9368 - val_loss: 0.4303 - val_accuracy: 0.9261\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2221 - accuracy: 0.9407 - val_loss: 0.4705 - val_accuracy: 0.9263\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2135 - accuracy: 0.9419 - val_loss: 0.4648 - val_accuracy: 0.9193\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1941 - accuracy: 0.9452 - val_loss: 0.3884 - val_accuracy: 0.9421\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1878 - accuracy: 0.9512 - val_loss: 0.3726 - val_accuracy: 0.9472\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1793 - accuracy: 0.9544 - val_loss: 0.3792 - val_accuracy: 0.9481\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1778 - accuracy: 0.9517 - val_loss: 0.3356 - val_accuracy: 0.9490\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1627 - accuracy: 0.9561 - val_loss: 0.3480 - val_accuracy: 0.9606\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1662 - accuracy: 0.9570 - val_loss: 0.3131 - val_accuracy: 0.9637\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1531 - accuracy: 0.9596 - val_loss: 0.3230 - val_accuracy: 0.9534\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1510 - accuracy: 0.9605 - val_loss: 0.3146 - val_accuracy: 0.9558\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1475 - accuracy: 0.9603 - val_loss: 0.3062 - val_accuracy: 0.9562\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1420 - accuracy: 0.9620 - val_loss: 0.2945 - val_accuracy: 0.9556\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1426 - accuracy: 0.9597 - val_loss: 0.2823 - val_accuracy: 0.9606\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1285 - accuracy: 0.9663 - val_loss: 0.3011 - val_accuracy: 0.9501\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1361 - accuracy: 0.9646 - val_loss: 0.2731 - val_accuracy: 0.9679\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1279 - accuracy: 0.9676 - val_loss: 0.2935 - val_accuracy: 0.9567\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1259 - accuracy: 0.9674 - val_loss: 0.2945 - val_accuracy: 0.9567\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1262 - accuracy: 0.9673 - val_loss: 0.3067 - val_accuracy: 0.9520\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1189 - accuracy: 0.9693 - val_loss: 0.2603 - val_accuracy: 0.9644\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1144 - accuracy: 0.9716 - val_loss: 0.2786 - val_accuracy: 0.9604\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1211 - accuracy: 0.9669 - val_loss: 0.2521 - val_accuracy: 0.9637\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1141 - accuracy: 0.9707 - val_loss: 0.2755 - val_accuracy: 0.9571\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1088 - accuracy: 0.9704 - val_loss: 0.2729 - val_accuracy: 0.9567\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1101 - accuracy: 0.9724 - val_loss: 0.2574 - val_accuracy: 0.9575\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1067 - accuracy: 0.9730 - val_loss: 0.2594 - val_accuracy: 0.9635\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1042 - accuracy: 0.9730 - val_loss: 0.2611 - val_accuracy: 0.9727\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1025 - accuracy: 0.9749 - val_loss: 0.2491 - val_accuracy: 0.9657\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1055 - accuracy: 0.9721 - val_loss: 0.2382 - val_accuracy: 0.9677\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0970 - accuracy: 0.9746 - val_loss: 0.2642 - val_accuracy: 0.9668\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0988 - accuracy: 0.9749 - val_loss: 0.2570 - val_accuracy: 0.9626\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1010 - accuracy: 0.9733 - val_loss: 0.2633 - val_accuracy: 0.9606\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0993 - accuracy: 0.9734 - val_loss: 0.2525 - val_accuracy: 0.9613\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0941 - accuracy: 0.9740 - val_loss: 0.2509 - val_accuracy: 0.9630\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0925 - accuracy: 0.9770 - val_loss: 0.2377 - val_accuracy: 0.9760\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0973 - accuracy: 0.9742 - val_loss: 0.2272 - val_accuracy: 0.9771\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0859 - accuracy: 0.9783 - val_loss: 0.2531 - val_accuracy: 0.9564\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0930 - accuracy: 0.9746 - val_loss: 0.2301 - val_accuracy: 0.9701\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0930 - accuracy: 0.9752 - val_loss: 0.2280 - val_accuracy: 0.9765\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0898 - accuracy: 0.9768 - val_loss: 0.2239 - val_accuracy: 0.9652\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0846 - accuracy: 0.9775 - val_loss: 0.2318 - val_accuracy: 0.9690\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0925 - accuracy: 0.9766 - val_loss: 0.2287 - val_accuracy: 0.9707\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0837 - accuracy: 0.9773 - val_loss: 0.2381 - val_accuracy: 0.9694\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0879 - accuracy: 0.9769 - val_loss: 0.2175 - val_accuracy: 0.9795\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0819 - accuracy: 0.9783 - val_loss: 0.2164 - val_accuracy: 0.9679\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0865 - accuracy: 0.9762 - val_loss: 0.2116 - val_accuracy: 0.9714\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0814 - accuracy: 0.9804 - val_loss: 0.2169 - val_accuracy: 0.9674\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0821 - accuracy: 0.9780 - val_loss: 0.2243 - val_accuracy: 0.9723\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0777 - accuracy: 0.9808 - val_loss: 0.2247 - val_accuracy: 0.9630\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.7246 - accuracy: 0.3032 - val_loss: 2.4990 - val_accuracy: 0.5659\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6931 - accuracy: 0.6978 - val_loss: 1.5671 - val_accuracy: 0.7463\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0048 - accuracy: 0.8024 - val_loss: 1.0874 - val_accuracy: 0.8167\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6550 - accuracy: 0.8594 - val_loss: 0.8043 - val_accuracy: 0.8616\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4703 - accuracy: 0.8947 - val_loss: 0.6614 - val_accuracy: 0.8741\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3666 - accuracy: 0.9109 - val_loss: 0.5320 - val_accuracy: 0.8990\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3132 - accuracy: 0.9218 - val_loss: 0.4911 - val_accuracy: 0.9019\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2617 - accuracy: 0.9313 - val_loss: 0.4520 - val_accuracy: 0.9133\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2451 - accuracy: 0.9375 - val_loss: 0.4170 - val_accuracy: 0.9212\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2162 - accuracy: 0.9441 - val_loss: 0.3708 - val_accuracy: 0.9417\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2146 - accuracy: 0.9458 - val_loss: 0.3991 - val_accuracy: 0.9336\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1857 - accuracy: 0.9526 - val_loss: 0.3685 - val_accuracy: 0.9182\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1825 - accuracy: 0.9527 - val_loss: 0.3768 - val_accuracy: 0.9212\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1705 - accuracy: 0.9576 - val_loss: 0.3423 - val_accuracy: 0.9342\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1713 - accuracy: 0.9576 - val_loss: 0.3106 - val_accuracy: 0.9584\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1580 - accuracy: 0.9609 - val_loss: 0.3534 - val_accuracy: 0.9452\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1524 - accuracy: 0.9627 - val_loss: 0.3271 - val_accuracy: 0.9432\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1511 - accuracy: 0.9637 - val_loss: 0.2888 - val_accuracy: 0.9430\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1406 - accuracy: 0.9676 - val_loss: 0.3551 - val_accuracy: 0.9461\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1377 - accuracy: 0.9669 - val_loss: 0.2928 - val_accuracy: 0.9507\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1282 - accuracy: 0.9699 - val_loss: 0.3121 - val_accuracy: 0.9441\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1377 - accuracy: 0.9656 - val_loss: 0.3052 - val_accuracy: 0.9547\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1230 - accuracy: 0.9695 - val_loss: 0.2723 - val_accuracy: 0.9619\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1132 - accuracy: 0.9734 - val_loss: 0.2883 - val_accuracy: 0.9523\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1230 - accuracy: 0.9699 - val_loss: 0.2806 - val_accuracy: 0.9553\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1170 - accuracy: 0.9742 - val_loss: 0.2884 - val_accuracy: 0.9562\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1081 - accuracy: 0.9742 - val_loss: 0.2497 - val_accuracy: 0.9591\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1117 - accuracy: 0.9713 - val_loss: 0.2607 - val_accuracy: 0.9602\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1062 - accuracy: 0.9747 - val_loss: 0.2341 - val_accuracy: 0.9659\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1079 - accuracy: 0.9713 - val_loss: 0.2353 - val_accuracy: 0.9670\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0994 - accuracy: 0.9772 - val_loss: 0.2404 - val_accuracy: 0.9624\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1048 - accuracy: 0.9753 - val_loss: 0.2403 - val_accuracy: 0.9589\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0967 - accuracy: 0.9763 - val_loss: 0.2265 - val_accuracy: 0.9694\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0992 - accuracy: 0.9747 - val_loss: 0.2338 - val_accuracy: 0.9727\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0977 - accuracy: 0.9771 - val_loss: 0.2269 - val_accuracy: 0.9705\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0925 - accuracy: 0.9770 - val_loss: 0.2713 - val_accuracy: 0.9564\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0938 - accuracy: 0.9781 - val_loss: 0.2253 - val_accuracy: 0.9718\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0945 - accuracy: 0.9762 - val_loss: 0.2214 - val_accuracy: 0.9714\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0936 - accuracy: 0.9762 - val_loss: 0.2307 - val_accuracy: 0.9751\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0856 - accuracy: 0.9800 - val_loss: 0.2318 - val_accuracy: 0.9597\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0848 - accuracy: 0.9797 - val_loss: 0.2269 - val_accuracy: 0.9740\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0844 - accuracy: 0.9791 - val_loss: 0.2197 - val_accuracy: 0.9729\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0799 - accuracy: 0.9807 - val_loss: 0.2508 - val_accuracy: 0.9644\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0868 - accuracy: 0.9786 - val_loss: 0.2234 - val_accuracy: 0.9736\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0802 - accuracy: 0.9797 - val_loss: 0.2326 - val_accuracy: 0.9600\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0809 - accuracy: 0.9801 - val_loss: 0.2025 - val_accuracy: 0.9776\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0792 - accuracy: 0.9800 - val_loss: 0.3024 - val_accuracy: 0.9441\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0780 - accuracy: 0.9797 - val_loss: 0.2721 - val_accuracy: 0.9558\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0812 - accuracy: 0.9794 - val_loss: 0.2074 - val_accuracy: 0.9738\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0810 - accuracy: 0.9789 - val_loss: 0.2189 - val_accuracy: 0.9712\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0744 - accuracy: 0.9823 - val_loss: 0.2194 - val_accuracy: 0.9729\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0730 - accuracy: 0.9815 - val_loss: 0.2130 - val_accuracy: 0.9703\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0723 - accuracy: 0.9820 - val_loss: 0.2120 - val_accuracy: 0.9692\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0758 - accuracy: 0.9804 - val_loss: 0.2054 - val_accuracy: 0.9762\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0713 - accuracy: 0.9829 - val_loss: 0.2051 - val_accuracy: 0.9773\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0769 - accuracy: 0.9789 - val_loss: 0.2225 - val_accuracy: 0.9668\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0722 - accuracy: 0.9800 - val_loss: 0.2189 - val_accuracy: 0.9661\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0716 - accuracy: 0.9807 - val_loss: 0.2164 - val_accuracy: 0.9740\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0647 - accuracy: 0.9839 - val_loss: 0.2105 - val_accuracy: 0.9751\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9808 - val_loss: 0.2100 - val_accuracy: 0.9712\n","Average Validation Accuracy: 0.9758924543857574\n","Average Validation Loss: 0.118862833827734\n","Average Test Accuracy: 0.975492000579834\n","------------------------------------------------------------------------\n","\n","Number of input features: 7\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7226 - accuracy: 0.2955 - val_loss: 2.5110 - val_accuracy: 0.5573\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6429 - accuracy: 0.7020 - val_loss: 1.4016 - val_accuracy: 0.7573\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8836 - accuracy: 0.8212 - val_loss: 0.9441 - val_accuracy: 0.8266\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5686 - accuracy: 0.8724 - val_loss: 0.7313 - val_accuracy: 0.8680\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4136 - accuracy: 0.9062 - val_loss: 0.6176 - val_accuracy: 0.9030\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3294 - accuracy: 0.9202 - val_loss: 0.5752 - val_accuracy: 0.9166\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2796 - accuracy: 0.9307 - val_loss: 0.5769 - val_accuracy: 0.8957\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2558 - accuracy: 0.9358 - val_loss: 0.4593 - val_accuracy: 0.9413\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2209 - accuracy: 0.9455 - val_loss: 0.4615 - val_accuracy: 0.9160\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2158 - accuracy: 0.9459 - val_loss: 0.3886 - val_accuracy: 0.9479\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1839 - accuracy: 0.9546 - val_loss: 0.3632 - val_accuracy: 0.9432\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1761 - accuracy: 0.9574 - val_loss: 0.3414 - val_accuracy: 0.9600\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1744 - accuracy: 0.9551 - val_loss: 0.3331 - val_accuracy: 0.9503\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1585 - accuracy: 0.9601 - val_loss: 0.3177 - val_accuracy: 0.9630\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1499 - accuracy: 0.9646 - val_loss: 0.3031 - val_accuracy: 0.9624\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1508 - accuracy: 0.9626 - val_loss: 0.3213 - val_accuracy: 0.9567\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1427 - accuracy: 0.9659 - val_loss: 0.2847 - val_accuracy: 0.9685\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1416 - accuracy: 0.9653 - val_loss: 0.3072 - val_accuracy: 0.9490\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1321 - accuracy: 0.9681 - val_loss: 0.2701 - val_accuracy: 0.9685\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1256 - accuracy: 0.9685 - val_loss: 0.3593 - val_accuracy: 0.9441\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1273 - accuracy: 0.9690 - val_loss: 0.2738 - val_accuracy: 0.9644\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1215 - accuracy: 0.9704 - val_loss: 0.2831 - val_accuracy: 0.9569\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1192 - accuracy: 0.9695 - val_loss: 0.2949 - val_accuracy: 0.9630\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1124 - accuracy: 0.9741 - val_loss: 0.2488 - val_accuracy: 0.9637\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1136 - accuracy: 0.9725 - val_loss: 0.2396 - val_accuracy: 0.9716\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1133 - accuracy: 0.9718 - val_loss: 0.2286 - val_accuracy: 0.9727\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1056 - accuracy: 0.9762 - val_loss: 0.3281 - val_accuracy: 0.9545\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1035 - accuracy: 0.9758 - val_loss: 0.2310 - val_accuracy: 0.9699\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1086 - accuracy: 0.9737 - val_loss: 0.2327 - val_accuracy: 0.9626\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1058 - accuracy: 0.9750 - val_loss: 0.2474 - val_accuracy: 0.9707\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0970 - accuracy: 0.9772 - val_loss: 0.2187 - val_accuracy: 0.9771\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0966 - accuracy: 0.9766 - val_loss: 0.2388 - val_accuracy: 0.9685\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1003 - accuracy: 0.9750 - val_loss: 0.2162 - val_accuracy: 0.9736\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0896 - accuracy: 0.9778 - val_loss: 0.2264 - val_accuracy: 0.9787\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0912 - accuracy: 0.9771 - val_loss: 0.2179 - val_accuracy: 0.9712\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0990 - accuracy: 0.9770 - val_loss: 0.2181 - val_accuracy: 0.9707\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0937 - accuracy: 0.9773 - val_loss: 0.2590 - val_accuracy: 0.9721\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0869 - accuracy: 0.9795 - val_loss: 0.2286 - val_accuracy: 0.9747\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0971 - accuracy: 0.9749 - val_loss: 0.2046 - val_accuracy: 0.9767\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0860 - accuracy: 0.9777 - val_loss: 0.2170 - val_accuracy: 0.9622\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0799 - accuracy: 0.9803 - val_loss: 0.2254 - val_accuracy: 0.9727\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0884 - accuracy: 0.9777 - val_loss: 0.2106 - val_accuracy: 0.9767\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0834 - accuracy: 0.9795 - val_loss: 0.2246 - val_accuracy: 0.9736\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0780 - accuracy: 0.9820 - val_loss: 0.2184 - val_accuracy: 0.9762\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0879 - accuracy: 0.9792 - val_loss: 0.2132 - val_accuracy: 0.9762\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0876 - accuracy: 0.9780 - val_loss: 0.2219 - val_accuracy: 0.9692\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0805 - accuracy: 0.9816 - val_loss: 0.2009 - val_accuracy: 0.9813\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0735 - accuracy: 0.9824 - val_loss: 0.1977 - val_accuracy: 0.9820\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0837 - accuracy: 0.9791 - val_loss: 0.2125 - val_accuracy: 0.9710\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0811 - accuracy: 0.9822 - val_loss: 0.1979 - val_accuracy: 0.9839\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0747 - accuracy: 0.9816 - val_loss: 0.2263 - val_accuracy: 0.9705\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0776 - accuracy: 0.9820 - val_loss: 0.2420 - val_accuracy: 0.9657\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0769 - accuracy: 0.9812 - val_loss: 0.2236 - val_accuracy: 0.9793\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0750 - accuracy: 0.9818 - val_loss: 0.2083 - val_accuracy: 0.9787\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0780 - accuracy: 0.9799 - val_loss: 0.2165 - val_accuracy: 0.9745\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0682 - accuracy: 0.9835 - val_loss: 0.2157 - val_accuracy: 0.9705\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0728 - accuracy: 0.9827 - val_loss: 0.1884 - val_accuracy: 0.9822\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9811 - val_loss: 0.2199 - val_accuracy: 0.9714\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0731 - accuracy: 0.9825 - val_loss: 0.1829 - val_accuracy: 0.9850\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0688 - accuracy: 0.9845 - val_loss: 0.1913 - val_accuracy: 0.9835\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.5690 - accuracy: 0.3492 - val_loss: 2.3150 - val_accuracy: 0.6315\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4740 - accuracy: 0.7402 - val_loss: 1.3164 - val_accuracy: 0.8055\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7551 - accuracy: 0.8535 - val_loss: 0.8868 - val_accuracy: 0.8744\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4496 - accuracy: 0.9031 - val_loss: 0.6822 - val_accuracy: 0.8948\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3117 - accuracy: 0.9314 - val_loss: 0.5459 - val_accuracy: 0.9261\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2533 - accuracy: 0.9401 - val_loss: 0.4347 - val_accuracy: 0.9428\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2184 - accuracy: 0.9486 - val_loss: 0.3955 - val_accuracy: 0.9476\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1922 - accuracy: 0.9544 - val_loss: 0.3934 - val_accuracy: 0.9311\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1649 - accuracy: 0.9627 - val_loss: 0.3511 - val_accuracy: 0.9446\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1643 - accuracy: 0.9625 - val_loss: 0.3421 - val_accuracy: 0.9481\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1508 - accuracy: 0.9676 - val_loss: 0.2936 - val_accuracy: 0.9556\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1420 - accuracy: 0.9655 - val_loss: 0.3216 - val_accuracy: 0.9454\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1346 - accuracy: 0.9693 - val_loss: 0.2913 - val_accuracy: 0.9560\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1253 - accuracy: 0.9719 - val_loss: 0.2608 - val_accuracy: 0.9670\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1365 - accuracy: 0.9682 - val_loss: 0.2444 - val_accuracy: 0.9626\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1096 - accuracy: 0.9753 - val_loss: 0.2452 - val_accuracy: 0.9589\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1154 - accuracy: 0.9727 - val_loss: 0.2857 - val_accuracy: 0.9549\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1189 - accuracy: 0.9728 - val_loss: 0.2283 - val_accuracy: 0.9663\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1066 - accuracy: 0.9750 - val_loss: 0.2743 - val_accuracy: 0.9547\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1084 - accuracy: 0.9750 - val_loss: 0.2244 - val_accuracy: 0.9611\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0984 - accuracy: 0.9776 - val_loss: 0.2213 - val_accuracy: 0.9674\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1008 - accuracy: 0.9766 - val_loss: 0.2071 - val_accuracy: 0.9749\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0954 - accuracy: 0.9767 - val_loss: 0.2360 - val_accuracy: 0.9630\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0894 - accuracy: 0.9798 - val_loss: 0.2095 - val_accuracy: 0.9668\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0904 - accuracy: 0.9791 - val_loss: 0.2272 - val_accuracy: 0.9578\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0932 - accuracy: 0.9782 - val_loss: 0.2020 - val_accuracy: 0.9630\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0901 - accuracy: 0.9790 - val_loss: 0.2022 - val_accuracy: 0.9721\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0815 - accuracy: 0.9807 - val_loss: 0.1996 - val_accuracy: 0.9716\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0905 - accuracy: 0.9782 - val_loss: 0.2018 - val_accuracy: 0.9743\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0800 - accuracy: 0.9809 - val_loss: 0.1862 - val_accuracy: 0.9716\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0869 - accuracy: 0.9786 - val_loss: 0.2072 - val_accuracy: 0.9677\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0828 - accuracy: 0.9808 - val_loss: 0.1947 - val_accuracy: 0.9736\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0835 - accuracy: 0.9798 - val_loss: 0.1935 - val_accuracy: 0.9754\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0829 - accuracy: 0.9809 - val_loss: 0.1889 - val_accuracy: 0.9712\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0749 - accuracy: 0.9820 - val_loss: 0.2475 - val_accuracy: 0.9617\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0843 - accuracy: 0.9797 - val_loss: 0.2657 - val_accuracy: 0.9657\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0739 - accuracy: 0.9829 - val_loss: 0.1669 - val_accuracy: 0.9833\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0750 - accuracy: 0.9822 - val_loss: 0.2198 - val_accuracy: 0.9657\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0690 - accuracy: 0.9823 - val_loss: 0.1864 - val_accuracy: 0.9723\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0746 - accuracy: 0.9827 - val_loss: 0.2199 - val_accuracy: 0.9650\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0706 - accuracy: 0.9823 - val_loss: 0.2125 - val_accuracy: 0.9778\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0732 - accuracy: 0.9830 - val_loss: 0.1842 - val_accuracy: 0.9681\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0767 - accuracy: 0.9802 - val_loss: 0.1852 - val_accuracy: 0.9736\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0707 - accuracy: 0.9827 - val_loss: 0.1803 - val_accuracy: 0.9767\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0683 - accuracy: 0.9835 - val_loss: 0.1832 - val_accuracy: 0.9732\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0664 - accuracy: 0.9830 - val_loss: 0.1617 - val_accuracy: 0.9776\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0751 - accuracy: 0.9806 - val_loss: 0.1677 - val_accuracy: 0.9791\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0610 - accuracy: 0.9856 - val_loss: 0.1956 - val_accuracy: 0.9694\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0747 - accuracy: 0.9818 - val_loss: 0.1877 - val_accuracy: 0.9732\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0623 - accuracy: 0.9855 - val_loss: 0.1675 - val_accuracy: 0.9681\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0715 - accuracy: 0.9816 - val_loss: 0.1673 - val_accuracy: 0.9795\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0620 - accuracy: 0.9844 - val_loss: 0.1608 - val_accuracy: 0.9787\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0609 - accuracy: 0.9862 - val_loss: 0.1705 - val_accuracy: 0.9787\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0617 - accuracy: 0.9852 - val_loss: 0.1641 - val_accuracy: 0.9703\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0667 - accuracy: 0.9840 - val_loss: 0.1705 - val_accuracy: 0.9716\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0642 - accuracy: 0.9836 - val_loss: 0.1543 - val_accuracy: 0.9773\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0605 - accuracy: 0.9856 - val_loss: 0.1610 - val_accuracy: 0.9784\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0595 - accuracy: 0.9854 - val_loss: 0.1734 - val_accuracy: 0.9760\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0578 - accuracy: 0.9858 - val_loss: 0.1956 - val_accuracy: 0.9727\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0633 - accuracy: 0.9843 - val_loss: 0.1644 - val_accuracy: 0.9817\n","Average Validation Accuracy: 0.9868206083774567\n","Average Validation Loss: 0.09685415029525757\n","Average Test Accuracy: 0.9860322773456573\n","------------------------------------------------------------------------\n","\n","Number of input features: 8\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.9798 - accuracy: 0.2602 - val_loss: 2.7901 - val_accuracy: 0.5270\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8901 - accuracy: 0.6509 - val_loss: 1.5993 - val_accuracy: 0.7309\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0214 - accuracy: 0.8003 - val_loss: 1.0836 - val_accuracy: 0.8301\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6672 - accuracy: 0.8570 - val_loss: 0.8472 - val_accuracy: 0.8684\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5019 - accuracy: 0.8809 - val_loss: 0.7070 - val_accuracy: 0.8865\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4131 - accuracy: 0.9003 - val_loss: 0.6459 - val_accuracy: 0.8893\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3477 - accuracy: 0.9126 - val_loss: 0.5598 - val_accuracy: 0.9149\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2976 - accuracy: 0.9255 - val_loss: 0.5843 - val_accuracy: 0.8944\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2725 - accuracy: 0.9329 - val_loss: 0.5174 - val_accuracy: 0.9144\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2377 - accuracy: 0.9406 - val_loss: 0.4430 - val_accuracy: 0.9408\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2329 - accuracy: 0.9436 - val_loss: 0.4297 - val_accuracy: 0.9353\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2062 - accuracy: 0.9492 - val_loss: 0.4012 - val_accuracy: 0.9472\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1973 - accuracy: 0.9507 - val_loss: 0.4055 - val_accuracy: 0.9413\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1817 - accuracy: 0.9546 - val_loss: 0.3630 - val_accuracy: 0.9468\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1719 - accuracy: 0.9582 - val_loss: 0.3577 - val_accuracy: 0.9441\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1645 - accuracy: 0.9599 - val_loss: 0.3582 - val_accuracy: 0.9494\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1651 - accuracy: 0.9578 - val_loss: 0.3296 - val_accuracy: 0.9474\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1441 - accuracy: 0.9650 - val_loss: 0.3373 - val_accuracy: 0.9463\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1377 - accuracy: 0.9666 - val_loss: 0.3165 - val_accuracy: 0.9630\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1389 - accuracy: 0.9674 - val_loss: 0.2837 - val_accuracy: 0.9644\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1384 - accuracy: 0.9662 - val_loss: 0.2851 - val_accuracy: 0.9617\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1280 - accuracy: 0.9703 - val_loss: 0.2643 - val_accuracy: 0.9659\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1224 - accuracy: 0.9697 - val_loss: 0.2719 - val_accuracy: 0.9633\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1225 - accuracy: 0.9691 - val_loss: 0.2542 - val_accuracy: 0.9802\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1161 - accuracy: 0.9741 - val_loss: 0.2451 - val_accuracy: 0.9659\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1241 - accuracy: 0.9693 - val_loss: 0.2647 - val_accuracy: 0.9573\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1028 - accuracy: 0.9767 - val_loss: 0.2459 - val_accuracy: 0.9712\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1156 - accuracy: 0.9716 - val_loss: 0.2751 - val_accuracy: 0.9644\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1039 - accuracy: 0.9751 - val_loss: 0.2449 - val_accuracy: 0.9815\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1005 - accuracy: 0.9762 - val_loss: 0.2898 - val_accuracy: 0.9604\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1073 - accuracy: 0.9736 - val_loss: 0.2418 - val_accuracy: 0.9650\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1001 - accuracy: 0.9777 - val_loss: 0.3237 - val_accuracy: 0.9501\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0958 - accuracy: 0.9760 - val_loss: 0.2373 - val_accuracy: 0.9776\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1032 - accuracy: 0.9755 - val_loss: 0.2430 - val_accuracy: 0.9668\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0919 - accuracy: 0.9793 - val_loss: 0.2566 - val_accuracy: 0.9648\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0978 - accuracy: 0.9768 - val_loss: 0.2368 - val_accuracy: 0.9751\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0965 - accuracy: 0.9769 - val_loss: 0.3036 - val_accuracy: 0.9573\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0986 - accuracy: 0.9765 - val_loss: 0.2512 - val_accuracy: 0.9696\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0852 - accuracy: 0.9794 - val_loss: 0.2625 - val_accuracy: 0.9602\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9779 - val_loss: 0.2450 - val_accuracy: 0.9784\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0914 - accuracy: 0.9775 - val_loss: 0.2311 - val_accuracy: 0.9699\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0829 - accuracy: 0.9812 - val_loss: 0.2378 - val_accuracy: 0.9809\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0935 - accuracy: 0.9762 - val_loss: 0.2391 - val_accuracy: 0.9716\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0808 - accuracy: 0.9805 - val_loss: 0.2420 - val_accuracy: 0.9740\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9816 - val_loss: 0.2581 - val_accuracy: 0.9630\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0805 - accuracy: 0.9817 - val_loss: 0.2501 - val_accuracy: 0.9747\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0855 - accuracy: 0.9789 - val_loss: 0.2361 - val_accuracy: 0.9784\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0802 - accuracy: 0.9809 - val_loss: 0.2289 - val_accuracy: 0.9778\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0813 - accuracy: 0.9815 - val_loss: 0.2392 - val_accuracy: 0.9690\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0850 - accuracy: 0.9795 - val_loss: 0.2352 - val_accuracy: 0.9740\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0715 - accuracy: 0.9830 - val_loss: 0.2398 - val_accuracy: 0.9760\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0815 - accuracy: 0.9791 - val_loss: 0.2407 - val_accuracy: 0.9820\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0740 - accuracy: 0.9820 - val_loss: 0.2498 - val_accuracy: 0.9628\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0852 - accuracy: 0.9785 - val_loss: 0.2232 - val_accuracy: 0.9828\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0742 - accuracy: 0.9819 - val_loss: 0.2295 - val_accuracy: 0.9725\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0739 - accuracy: 0.9817 - val_loss: 0.2253 - val_accuracy: 0.9800\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0708 - accuracy: 0.9841 - val_loss: 0.2263 - val_accuracy: 0.9784\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0769 - accuracy: 0.9810 - val_loss: 0.2400 - val_accuracy: 0.9749\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0725 - accuracy: 0.9819 - val_loss: 0.2382 - val_accuracy: 0.9787\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0732 - accuracy: 0.9828 - val_loss: 0.2135 - val_accuracy: 0.9848\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.8979 - accuracy: 0.2589 - val_loss: 2.6723 - val_accuracy: 0.5362\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7097 - accuracy: 0.6883 - val_loss: 1.5309 - val_accuracy: 0.7604\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8982 - accuracy: 0.8211 - val_loss: 1.0907 - val_accuracy: 0.8308\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5707 - accuracy: 0.8851 - val_loss: 0.8246 - val_accuracy: 0.8836\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4150 - accuracy: 0.9148 - val_loss: 0.6596 - val_accuracy: 0.8988\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3203 - accuracy: 0.9349 - val_loss: 0.5673 - val_accuracy: 0.9195\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2632 - accuracy: 0.9426 - val_loss: 0.4722 - val_accuracy: 0.9399\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2195 - accuracy: 0.9501 - val_loss: 0.4101 - val_accuracy: 0.9327\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1929 - accuracy: 0.9553 - val_loss: 0.3813 - val_accuracy: 0.9373\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1693 - accuracy: 0.9596 - val_loss: 0.3821 - val_accuracy: 0.9360\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1580 - accuracy: 0.9652 - val_loss: 0.3239 - val_accuracy: 0.9503\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1388 - accuracy: 0.9691 - val_loss: 0.2985 - val_accuracy: 0.9567\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1446 - accuracy: 0.9681 - val_loss: 0.2789 - val_accuracy: 0.9639\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1244 - accuracy: 0.9723 - val_loss: 0.2418 - val_accuracy: 0.9688\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1196 - accuracy: 0.9712 - val_loss: 0.2241 - val_accuracy: 0.9688\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1093 - accuracy: 0.9757 - val_loss: 0.2487 - val_accuracy: 0.9547\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1146 - accuracy: 0.9734 - val_loss: 0.2301 - val_accuracy: 0.9641\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1018 - accuracy: 0.9766 - val_loss: 0.2057 - val_accuracy: 0.9679\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1027 - accuracy: 0.9765 - val_loss: 0.2064 - val_accuracy: 0.9670\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0988 - accuracy: 0.9762 - val_loss: 0.2179 - val_accuracy: 0.9699\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0953 - accuracy: 0.9791 - val_loss: 0.1900 - val_accuracy: 0.9707\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0959 - accuracy: 0.9785 - val_loss: 0.1913 - val_accuracy: 0.9685\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0901 - accuracy: 0.9783 - val_loss: 0.1881 - val_accuracy: 0.9703\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0915 - accuracy: 0.9772 - val_loss: 0.1810 - val_accuracy: 0.9633\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0870 - accuracy: 0.9795 - val_loss: 0.1988 - val_accuracy: 0.9615\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0875 - accuracy: 0.9795 - val_loss: 0.1703 - val_accuracy: 0.9745\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0832 - accuracy: 0.9818 - val_loss: 0.1876 - val_accuracy: 0.9600\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9810 - val_loss: 0.1801 - val_accuracy: 0.9670\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0777 - accuracy: 0.9816 - val_loss: 0.1958 - val_accuracy: 0.9696\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0818 - accuracy: 0.9818 - val_loss: 0.2158 - val_accuracy: 0.9644\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0778 - accuracy: 0.9830 - val_loss: 0.1600 - val_accuracy: 0.9723\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0819 - accuracy: 0.9801 - val_loss: 0.1695 - val_accuracy: 0.9769\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0720 - accuracy: 0.9828 - val_loss: 0.1668 - val_accuracy: 0.9681\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0759 - accuracy: 0.9819 - val_loss: 0.1933 - val_accuracy: 0.9694\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0719 - accuracy: 0.9843 - val_loss: 0.1619 - val_accuracy: 0.9802\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0750 - accuracy: 0.9821 - val_loss: 0.1801 - val_accuracy: 0.9718\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0680 - accuracy: 0.9837 - val_loss: 0.1654 - val_accuracy: 0.9699\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0745 - accuracy: 0.9833 - val_loss: 0.1682 - val_accuracy: 0.9718\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0679 - accuracy: 0.9843 - val_loss: 0.1600 - val_accuracy: 0.9705\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0687 - accuracy: 0.9837 - val_loss: 0.1535 - val_accuracy: 0.9714\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0690 - accuracy: 0.9842 - val_loss: 0.1627 - val_accuracy: 0.9754\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0651 - accuracy: 0.9850 - val_loss: 0.1714 - val_accuracy: 0.9745\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0630 - accuracy: 0.9855 - val_loss: 0.1963 - val_accuracy: 0.9685\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0701 - accuracy: 0.9833 - val_loss: 0.1569 - val_accuracy: 0.9771\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0618 - accuracy: 0.9848 - val_loss: 0.1642 - val_accuracy: 0.9705\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0614 - accuracy: 0.9861 - val_loss: 0.1515 - val_accuracy: 0.9738\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0688 - accuracy: 0.9839 - val_loss: 0.1547 - val_accuracy: 0.9787\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0588 - accuracy: 0.9868 - val_loss: 0.1533 - val_accuracy: 0.9800\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0624 - accuracy: 0.9854 - val_loss: 0.1766 - val_accuracy: 0.9762\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0652 - accuracy: 0.9836 - val_loss: 0.1576 - val_accuracy: 0.9734\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0595 - accuracy: 0.9868 - val_loss: 0.1797 - val_accuracy: 0.9705\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0625 - accuracy: 0.9850 - val_loss: 0.1515 - val_accuracy: 0.9824\n","Epoch 53/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0629 - accuracy: 0.9858 - val_loss: 0.1581 - val_accuracy: 0.9718\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0635 - accuracy: 0.9845 - val_loss: 0.2103 - val_accuracy: 0.9549\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0572 - accuracy: 0.9861 - val_loss: 0.1639 - val_accuracy: 0.9762\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0581 - accuracy: 0.9854 - val_loss: 0.1500 - val_accuracy: 0.9820\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0607 - accuracy: 0.9853 - val_loss: 0.1725 - val_accuracy: 0.9672\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0567 - accuracy: 0.9859 - val_loss: 0.1916 - val_accuracy: 0.9756\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0630 - accuracy: 0.9849 - val_loss: 0.1568 - val_accuracy: 0.9813\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0577 - accuracy: 0.9850 - val_loss: 0.1612 - val_accuracy: 0.9813\n","Average Validation Accuracy: 0.987183690071106\n","Average Validation Loss: 0.10011954605579376\n","Average Test Accuracy: 0.9859217405319214\n","------------------------------------------------------------------------\n","\n","Number of input features: 9\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.6857 - accuracy: 0.3291 - val_loss: 2.2412 - val_accuracy: 0.6136\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4381 - accuracy: 0.7374 - val_loss: 1.2066 - val_accuracy: 0.7996\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7417 - accuracy: 0.8462 - val_loss: 0.8140 - val_accuracy: 0.8629\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4734 - accuracy: 0.8932 - val_loss: 0.6101 - val_accuracy: 0.9014\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3512 - accuracy: 0.9184 - val_loss: 0.5034 - val_accuracy: 0.9175\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2789 - accuracy: 0.9336 - val_loss: 0.4716 - val_accuracy: 0.9206\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2384 - accuracy: 0.9393 - val_loss: 0.4138 - val_accuracy: 0.9364\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2046 - accuracy: 0.9501 - val_loss: 0.4338 - val_accuracy: 0.9234\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1862 - accuracy: 0.9545 - val_loss: 0.3418 - val_accuracy: 0.9496\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1740 - accuracy: 0.9588 - val_loss: 0.3042 - val_accuracy: 0.9560\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1560 - accuracy: 0.9652 - val_loss: 0.3049 - val_accuracy: 0.9487\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1530 - accuracy: 0.9628 - val_loss: 0.3262 - val_accuracy: 0.9437\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1337 - accuracy: 0.9691 - val_loss: 0.2732 - val_accuracy: 0.9714\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1369 - accuracy: 0.9664 - val_loss: 0.2808 - val_accuracy: 0.9569\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1206 - accuracy: 0.9725 - val_loss: 0.2602 - val_accuracy: 0.9648\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1153 - accuracy: 0.9737 - val_loss: 0.2567 - val_accuracy: 0.9696\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1152 - accuracy: 0.9728 - val_loss: 0.2422 - val_accuracy: 0.9681\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1118 - accuracy: 0.9737 - val_loss: 0.2350 - val_accuracy: 0.9655\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1056 - accuracy: 0.9742 - val_loss: 0.2495 - val_accuracy: 0.9615\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0998 - accuracy: 0.9751 - val_loss: 0.2345 - val_accuracy: 0.9795\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0980 - accuracy: 0.9762 - val_loss: 0.2461 - val_accuracy: 0.9681\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0895 - accuracy: 0.9788 - val_loss: 0.2202 - val_accuracy: 0.9703\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1018 - accuracy: 0.9744 - val_loss: 0.2388 - val_accuracy: 0.9685\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0876 - accuracy: 0.9785 - val_loss: 0.2167 - val_accuracy: 0.9751\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0862 - accuracy: 0.9796 - val_loss: 0.2316 - val_accuracy: 0.9787\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0859 - accuracy: 0.9792 - val_loss: 0.2261 - val_accuracy: 0.9712\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0874 - accuracy: 0.9782 - val_loss: 0.2465 - val_accuracy: 0.9674\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0799 - accuracy: 0.9809 - val_loss: 0.2364 - val_accuracy: 0.9705\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0783 - accuracy: 0.9810 - val_loss: 0.2118 - val_accuracy: 0.9745\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0824 - accuracy: 0.9797 - val_loss: 0.2253 - val_accuracy: 0.9734\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0774 - accuracy: 0.9818 - val_loss: 0.2154 - val_accuracy: 0.9793\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0776 - accuracy: 0.9798 - val_loss: 0.2149 - val_accuracy: 0.9747\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0717 - accuracy: 0.9830 - val_loss: 0.2777 - val_accuracy: 0.9602\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0749 - accuracy: 0.9824 - val_loss: 0.2244 - val_accuracy: 0.9646\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0716 - accuracy: 0.9827 - val_loss: 0.1975 - val_accuracy: 0.9789\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0762 - accuracy: 0.9805 - val_loss: 0.2076 - val_accuracy: 0.9732\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0652 - accuracy: 0.9832 - val_loss: 0.1871 - val_accuracy: 0.9844\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0678 - accuracy: 0.9842 - val_loss: 0.1917 - val_accuracy: 0.9839\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0644 - accuracy: 0.9841 - val_loss: 0.2191 - val_accuracy: 0.9760\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0613 - accuracy: 0.9858 - val_loss: 0.2054 - val_accuracy: 0.9802\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0617 - accuracy: 0.9863 - val_loss: 0.1961 - val_accuracy: 0.9842\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0626 - accuracy: 0.9850 - val_loss: 0.1943 - val_accuracy: 0.9793\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0644 - accuracy: 0.9844 - val_loss: 0.2236 - val_accuracy: 0.9795\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0604 - accuracy: 0.9859 - val_loss: 0.2156 - val_accuracy: 0.9782\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0559 - accuracy: 0.9884 - val_loss: 0.2035 - val_accuracy: 0.9773\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0553 - accuracy: 0.9879 - val_loss: 0.1855 - val_accuracy: 0.9835\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0616 - accuracy: 0.9860 - val_loss: 0.2166 - val_accuracy: 0.9782\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0570 - accuracy: 0.9874 - val_loss: 0.1875 - val_accuracy: 0.9837\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0563 - accuracy: 0.9870 - val_loss: 0.2107 - val_accuracy: 0.9833\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0562 - accuracy: 0.9876 - val_loss: 0.1948 - val_accuracy: 0.9776\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0554 - accuracy: 0.9880 - val_loss: 0.1902 - val_accuracy: 0.9861\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0512 - accuracy: 0.9880 - val_loss: 0.2026 - val_accuracy: 0.9789\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0544 - accuracy: 0.9874 - val_loss: 0.2021 - val_accuracy: 0.9839\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0525 - accuracy: 0.9873 - val_loss: 0.2019 - val_accuracy: 0.9729\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0526 - accuracy: 0.9879 - val_loss: 0.1947 - val_accuracy: 0.9859\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0465 - accuracy: 0.9899 - val_loss: 0.1866 - val_accuracy: 0.9870\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0563 - accuracy: 0.9860 - val_loss: 0.1942 - val_accuracy: 0.9868\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0494 - accuracy: 0.9882 - val_loss: 0.1908 - val_accuracy: 0.9864\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0506 - accuracy: 0.9887 - val_loss: 0.2083 - val_accuracy: 0.9771\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0510 - accuracy: 0.9867 - val_loss: 0.1968 - val_accuracy: 0.9850\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.8805 - accuracy: 0.2719 - val_loss: 2.5220 - val_accuracy: 0.6141\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5748 - accuracy: 0.7140 - val_loss: 1.3282 - val_accuracy: 0.7754\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7939 - accuracy: 0.8295 - val_loss: 0.9150 - val_accuracy: 0.8442\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5015 - accuracy: 0.8834 - val_loss: 0.7453 - val_accuracy: 0.8818\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3602 - accuracy: 0.9155 - val_loss: 0.6212 - val_accuracy: 0.8970\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2996 - accuracy: 0.9244 - val_loss: 0.4994 - val_accuracy: 0.9298\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2524 - accuracy: 0.9367 - val_loss: 0.4835 - val_accuracy: 0.9182\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2298 - accuracy: 0.9421 - val_loss: 0.4719 - val_accuracy: 0.9206\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1965 - accuracy: 0.9516 - val_loss: 0.4225 - val_accuracy: 0.9369\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1883 - accuracy: 0.9516 - val_loss: 0.3950 - val_accuracy: 0.9296\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1692 - accuracy: 0.9558 - val_loss: 0.3749 - val_accuracy: 0.9329\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1548 - accuracy: 0.9625 - val_loss: 0.3542 - val_accuracy: 0.9404\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1497 - accuracy: 0.9615 - val_loss: 0.3161 - val_accuracy: 0.9538\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1360 - accuracy: 0.9658 - val_loss: 0.2976 - val_accuracy: 0.9538\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1326 - accuracy: 0.9678 - val_loss: 0.2944 - val_accuracy: 0.9626\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1185 - accuracy: 0.9729 - val_loss: 0.3063 - val_accuracy: 0.9468\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1173 - accuracy: 0.9718 - val_loss: 0.2704 - val_accuracy: 0.9606\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9757 - val_loss: 0.2621 - val_accuracy: 0.9683\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1135 - accuracy: 0.9740 - val_loss: 0.2564 - val_accuracy: 0.9575\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1026 - accuracy: 0.9760 - val_loss: 0.2506 - val_accuracy: 0.9641\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0987 - accuracy: 0.9763 - val_loss: 0.2605 - val_accuracy: 0.9650\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0973 - accuracy: 0.9758 - val_loss: 0.2477 - val_accuracy: 0.9685\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.9806 - val_loss: 0.2938 - val_accuracy: 0.9492\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0930 - accuracy: 0.9781 - val_loss: 0.2418 - val_accuracy: 0.9705\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0863 - accuracy: 0.9803 - val_loss: 0.2500 - val_accuracy: 0.9659\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0857 - accuracy: 0.9809 - val_loss: 0.2682 - val_accuracy: 0.9683\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0752 - accuracy: 0.9837 - val_loss: 0.2281 - val_accuracy: 0.9758\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0830 - accuracy: 0.9805 - val_loss: 0.2503 - val_accuracy: 0.9646\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0782 - accuracy: 0.9824 - val_loss: 0.2377 - val_accuracy: 0.9637\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0791 - accuracy: 0.9821 - val_loss: 0.2278 - val_accuracy: 0.9721\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0767 - accuracy: 0.9820 - val_loss: 0.2253 - val_accuracy: 0.9778\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0694 - accuracy: 0.9843 - val_loss: 0.2142 - val_accuracy: 0.9758\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0753 - accuracy: 0.9828 - val_loss: 0.2272 - val_accuracy: 0.9685\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0697 - accuracy: 0.9842 - val_loss: 0.3465 - val_accuracy: 0.9366\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0737 - accuracy: 0.9829 - val_loss: 0.2509 - val_accuracy: 0.9611\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0659 - accuracy: 0.9850 - val_loss: 0.2382 - val_accuracy: 0.9626\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0681 - accuracy: 0.9834 - val_loss: 0.2062 - val_accuracy: 0.9767\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0677 - accuracy: 0.9855 - val_loss: 0.1997 - val_accuracy: 0.9820\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0691 - accuracy: 0.9840 - val_loss: 0.2535 - val_accuracy: 0.9600\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0600 - accuracy: 0.9868 - val_loss: 0.2250 - val_accuracy: 0.9705\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0716 - accuracy: 0.9831 - val_loss: 0.2614 - val_accuracy: 0.9551\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0613 - accuracy: 0.9850 - val_loss: 0.1941 - val_accuracy: 0.9828\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0643 - accuracy: 0.9855 - val_loss: 0.2273 - val_accuracy: 0.9795\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0611 - accuracy: 0.9858 - val_loss: 0.2123 - val_accuracy: 0.9703\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0652 - accuracy: 0.9845 - val_loss: 0.2003 - val_accuracy: 0.9773\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0575 - accuracy: 0.9869 - val_loss: 0.2134 - val_accuracy: 0.9710\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0608 - accuracy: 0.9873 - val_loss: 0.2076 - val_accuracy: 0.9789\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0605 - accuracy: 0.9858 - val_loss: 0.1930 - val_accuracy: 0.9837\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0588 - accuracy: 0.9863 - val_loss: 0.1916 - val_accuracy: 0.9773\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0538 - accuracy: 0.9879 - val_loss: 0.1877 - val_accuracy: 0.9859\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0585 - accuracy: 0.9859 - val_loss: 0.2350 - val_accuracy: 0.9710\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0513 - accuracy: 0.9880 - val_loss: 0.2192 - val_accuracy: 0.9707\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0635 - accuracy: 0.9854 - val_loss: 0.1925 - val_accuracy: 0.9762\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0511 - accuracy: 0.9878 - val_loss: 0.1896 - val_accuracy: 0.9804\n","Epoch 55/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0546 - accuracy: 0.9872 - val_loss: 0.2031 - val_accuracy: 0.9745\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0527 - accuracy: 0.9874 - val_loss: 0.1866 - val_accuracy: 0.9793\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0535 - accuracy: 0.9878 - val_loss: 0.1922 - val_accuracy: 0.9817\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0568 - accuracy: 0.9857 - val_loss: 0.1935 - val_accuracy: 0.9756\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0512 - accuracy: 0.9879 - val_loss: 0.1926 - val_accuracy: 0.9736\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0566 - accuracy: 0.9863 - val_loss: 0.1975 - val_accuracy: 0.9721\n","Average Validation Accuracy: 0.9854408502578735\n","Average Validation Loss: 0.097366563975811\n","Average Test Accuracy: 0.9847055375576019\n","------------------------------------------------------------------------\n","\n","Number of input features: 10\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.4605 - accuracy: 0.3839 - val_loss: 2.0490 - val_accuracy: 0.6537\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2272 - accuracy: 0.7716 - val_loss: 1.0266 - val_accuracy: 0.8229\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6062 - accuracy: 0.8739 - val_loss: 0.7020 - val_accuracy: 0.8779\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3877 - accuracy: 0.9160 - val_loss: 0.5930 - val_accuracy: 0.8961\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2955 - accuracy: 0.9332 - val_loss: 0.5845 - val_accuracy: 0.8997\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2388 - accuracy: 0.9448 - val_loss: 0.4253 - val_accuracy: 0.9314\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2088 - accuracy: 0.9494 - val_loss: 0.3813 - val_accuracy: 0.9494\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1880 - accuracy: 0.9537 - val_loss: 0.3925 - val_accuracy: 0.9485\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1671 - accuracy: 0.9596 - val_loss: 0.3331 - val_accuracy: 0.9580\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1522 - accuracy: 0.9646 - val_loss: 0.3473 - val_accuracy: 0.9481\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1392 - accuracy: 0.9664 - val_loss: 0.3292 - val_accuracy: 0.9496\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1377 - accuracy: 0.9687 - val_loss: 0.3102 - val_accuracy: 0.9591\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1212 - accuracy: 0.9723 - val_loss: 0.3084 - val_accuracy: 0.9611\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1167 - accuracy: 0.9732 - val_loss: 0.2928 - val_accuracy: 0.9699\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1147 - accuracy: 0.9734 - val_loss: 0.2871 - val_accuracy: 0.9683\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1086 - accuracy: 0.9742 - val_loss: 0.3121 - val_accuracy: 0.9622\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1015 - accuracy: 0.9776 - val_loss: 0.2820 - val_accuracy: 0.9666\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1066 - accuracy: 0.9750 - val_loss: 0.2838 - val_accuracy: 0.9683\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1000 - accuracy: 0.9773 - val_loss: 0.2728 - val_accuracy: 0.9769\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0942 - accuracy: 0.9770 - val_loss: 0.2958 - val_accuracy: 0.9571\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0979 - accuracy: 0.9764 - val_loss: 0.2592 - val_accuracy: 0.9789\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0847 - accuracy: 0.9809 - val_loss: 0.3948 - val_accuracy: 0.9432\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0917 - accuracy: 0.9786 - val_loss: 0.2677 - val_accuracy: 0.9696\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0835 - accuracy: 0.9795 - val_loss: 0.2665 - val_accuracy: 0.9791\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0851 - accuracy: 0.9799 - val_loss: 0.4071 - val_accuracy: 0.9446\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0791 - accuracy: 0.9828 - val_loss: 0.2600 - val_accuracy: 0.9714\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0819 - accuracy: 0.9798 - val_loss: 0.2642 - val_accuracy: 0.9692\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0793 - accuracy: 0.9814 - val_loss: 0.2833 - val_accuracy: 0.9692\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0739 - accuracy: 0.9840 - val_loss: 0.2537 - val_accuracy: 0.9688\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0763 - accuracy: 0.9824 - val_loss: 0.2344 - val_accuracy: 0.9868\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0820 - accuracy: 0.9808 - val_loss: 0.2422 - val_accuracy: 0.9817\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0688 - accuracy: 0.9850 - val_loss: 0.2406 - val_accuracy: 0.9826\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0758 - accuracy: 0.9819 - val_loss: 0.2533 - val_accuracy: 0.9820\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0662 - accuracy: 0.9858 - val_loss: 0.2484 - val_accuracy: 0.9795\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0709 - accuracy: 0.9835 - val_loss: 0.2325 - val_accuracy: 0.9853\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0758 - accuracy: 0.9822 - val_loss: 0.2378 - val_accuracy: 0.9877\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0605 - accuracy: 0.9871 - val_loss: 0.2273 - val_accuracy: 0.9877\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0715 - accuracy: 0.9839 - val_loss: 0.2655 - val_accuracy: 0.9767\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0586 - accuracy: 0.9876 - val_loss: 0.2507 - val_accuracy: 0.9718\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0739 - accuracy: 0.9827 - val_loss: 0.2240 - val_accuracy: 0.9861\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0592 - accuracy: 0.9867 - val_loss: 0.2369 - val_accuracy: 0.9822\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0676 - accuracy: 0.9842 - val_loss: 0.2377 - val_accuracy: 0.9793\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0592 - accuracy: 0.9867 - val_loss: 0.2299 - val_accuracy: 0.9835\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0637 - accuracy: 0.9856 - val_loss: 0.2225 - val_accuracy: 0.9859\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0676 - accuracy: 0.9832 - val_loss: 0.2262 - val_accuracy: 0.9833\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0519 - accuracy: 0.9889 - val_loss: 0.2222 - val_accuracy: 0.9837\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0622 - accuracy: 0.9857 - val_loss: 0.2466 - val_accuracy: 0.9767\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0547 - accuracy: 0.9880 - val_loss: 0.2208 - val_accuracy: 0.9879\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0619 - accuracy: 0.9848 - val_loss: 0.2102 - val_accuracy: 0.9870\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0525 - accuracy: 0.9889 - val_loss: 0.2273 - val_accuracy: 0.9815\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0679 - accuracy: 0.9833 - val_loss: 0.2264 - val_accuracy: 0.9866\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0519 - accuracy: 0.9892 - val_loss: 0.2146 - val_accuracy: 0.9835\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0609 - accuracy: 0.9854 - val_loss: 0.2116 - val_accuracy: 0.9839\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0602 - accuracy: 0.9865 - val_loss: 0.1994 - val_accuracy: 0.9872\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0550 - accuracy: 0.9882 - val_loss: 0.2158 - val_accuracy: 0.9837\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0573 - accuracy: 0.9872 - val_loss: 0.2015 - val_accuracy: 0.9866\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0574 - accuracy: 0.9867 - val_loss: 0.2378 - val_accuracy: 0.9718\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0525 - accuracy: 0.9879 - val_loss: 0.2013 - val_accuracy: 0.9877\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0531 - accuracy: 0.9887 - val_loss: 0.2011 - val_accuracy: 0.9857\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0508 - accuracy: 0.9889 - val_loss: 0.2189 - val_accuracy: 0.9789\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.2857 - accuracy: 0.4058 - val_loss: 2.0599 - val_accuracy: 0.6693\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2382 - accuracy: 0.7649 - val_loss: 1.1228 - val_accuracy: 0.8183\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6259 - accuracy: 0.8673 - val_loss: 0.7739 - val_accuracy: 0.8823\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4106 - accuracy: 0.9061 - val_loss: 0.6100 - val_accuracy: 0.9067\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3117 - accuracy: 0.9267 - val_loss: 0.5185 - val_accuracy: 0.9087\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2603 - accuracy: 0.9382 - val_loss: 0.4745 - val_accuracy: 0.9230\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2233 - accuracy: 0.9497 - val_loss: 0.4056 - val_accuracy: 0.9428\n","Epoch 8/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2031 - accuracy: 0.9509 - val_loss: 0.3537 - val_accuracy: 0.9490\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1780 - accuracy: 0.9584 - val_loss: 0.3289 - val_accuracy: 0.9516\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1717 - accuracy: 0.9602 - val_loss: 0.3607 - val_accuracy: 0.9329\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1607 - accuracy: 0.9621 - val_loss: 0.3087 - val_accuracy: 0.9567\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1501 - accuracy: 0.9652 - val_loss: 0.3038 - val_accuracy: 0.9553\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1433 - accuracy: 0.9669 - val_loss: 0.2990 - val_accuracy: 0.9547\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1286 - accuracy: 0.9705 - val_loss: 0.3082 - val_accuracy: 0.9549\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1336 - accuracy: 0.9689 - val_loss: 0.2760 - val_accuracy: 0.9580\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1226 - accuracy: 0.9723 - val_loss: 0.3116 - val_accuracy: 0.9512\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1151 - accuracy: 0.9734 - val_loss: 0.2633 - val_accuracy: 0.9538\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1121 - accuracy: 0.9749 - val_loss: 0.2468 - val_accuracy: 0.9663\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1095 - accuracy: 0.9770 - val_loss: 0.2700 - val_accuracy: 0.9575\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1023 - accuracy: 0.9769 - val_loss: 0.2390 - val_accuracy: 0.9696\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1003 - accuracy: 0.9784 - val_loss: 0.2357 - val_accuracy: 0.9670\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0984 - accuracy: 0.9790 - val_loss: 0.2379 - val_accuracy: 0.9696\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0925 - accuracy: 0.9803 - val_loss: 0.2510 - val_accuracy: 0.9584\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0908 - accuracy: 0.9814 - val_loss: 0.2392 - val_accuracy: 0.9624\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0867 - accuracy: 0.9801 - val_loss: 0.2421 - val_accuracy: 0.9551\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0832 - accuracy: 0.9823 - val_loss: 0.2013 - val_accuracy: 0.9727\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0867 - accuracy: 0.9818 - val_loss: 0.2331 - val_accuracy: 0.9672\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0811 - accuracy: 0.9840 - val_loss: 0.3439 - val_accuracy: 0.9516\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0839 - accuracy: 0.9821 - val_loss: 0.2330 - val_accuracy: 0.9703\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0769 - accuracy: 0.9826 - val_loss: 0.2103 - val_accuracy: 0.9648\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0777 - accuracy: 0.9836 - val_loss: 0.2746 - val_accuracy: 0.9611\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0725 - accuracy: 0.9856 - val_loss: 0.2176 - val_accuracy: 0.9591\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0740 - accuracy: 0.9839 - val_loss: 0.2011 - val_accuracy: 0.9760\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0773 - accuracy: 0.9845 - val_loss: 0.2100 - val_accuracy: 0.9745\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0693 - accuracy: 0.9846 - val_loss: 0.2098 - val_accuracy: 0.9736\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0771 - accuracy: 0.9827 - val_loss: 0.2067 - val_accuracy: 0.9745\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0616 - accuracy: 0.9868 - val_loss: 0.2065 - val_accuracy: 0.9661\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0672 - accuracy: 0.9858 - val_loss: 0.2008 - val_accuracy: 0.9725\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0740 - accuracy: 0.9837 - val_loss: 0.2000 - val_accuracy: 0.9723\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0651 - accuracy: 0.9865 - val_loss: 0.2253 - val_accuracy: 0.9725\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0627 - accuracy: 0.9867 - val_loss: 0.2159 - val_accuracy: 0.9703\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0662 - accuracy: 0.9853 - val_loss: 0.1881 - val_accuracy: 0.9740\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0659 - accuracy: 0.9850 - val_loss: 0.1891 - val_accuracy: 0.9782\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0558 - accuracy: 0.9881 - val_loss: 0.1943 - val_accuracy: 0.9725\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0670 - accuracy: 0.9861 - val_loss: 0.1777 - val_accuracy: 0.9813\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0562 - accuracy: 0.9878 - val_loss: 0.1738 - val_accuracy: 0.9751\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0637 - accuracy: 0.9854 - val_loss: 0.1854 - val_accuracy: 0.9767\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0590 - accuracy: 0.9859 - val_loss: 0.1749 - val_accuracy: 0.9802\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0568 - accuracy: 0.9870 - val_loss: 0.1801 - val_accuracy: 0.9809\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0527 - accuracy: 0.9876 - val_loss: 0.1655 - val_accuracy: 0.9855\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0608 - accuracy: 0.9858 - val_loss: 0.1750 - val_accuracy: 0.9787\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0549 - accuracy: 0.9879 - val_loss: 0.1656 - val_accuracy: 0.9780\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0561 - accuracy: 0.9876 - val_loss: 0.1882 - val_accuracy: 0.9738\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0569 - accuracy: 0.9865 - val_loss: 0.1716 - val_accuracy: 0.9791\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0482 - accuracy: 0.9887 - val_loss: 0.1690 - val_accuracy: 0.9751\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0614 - accuracy: 0.9869 - val_loss: 0.1699 - val_accuracy: 0.9745\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0532 - accuracy: 0.9870 - val_loss: 0.1709 - val_accuracy: 0.9824\n","Epoch 58/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0617 - accuracy: 0.9850 - val_loss: 0.1703 - val_accuracy: 0.9804\n","Epoch 59/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0454 - accuracy: 0.9895 - val_loss: 0.1819 - val_accuracy: 0.9740\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0614 - accuracy: 0.9861 - val_loss: 0.1888 - val_accuracy: 0.9701\n","Average Validation Accuracy: 0.9826089143753052\n","Average Validation Loss: 0.10468632355332375\n","Average Test Accuracy: 0.9844844043254852\n","------------------------------------------------------------------------\n","\n","Number of input features: 11\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7496 - accuracy: 0.3086 - val_loss: 2.3226 - val_accuracy: 0.6022\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4857 - accuracy: 0.7191 - val_loss: 1.2760 - val_accuracy: 0.7857\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7635 - accuracy: 0.8432 - val_loss: 0.8158 - val_accuracy: 0.8669\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4845 - accuracy: 0.8873 - val_loss: 0.6416 - val_accuracy: 0.8799\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3661 - accuracy: 0.9099 - val_loss: 0.5606 - val_accuracy: 0.9025\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3017 - accuracy: 0.9196 - val_loss: 0.4772 - val_accuracy: 0.9241\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2591 - accuracy: 0.9338 - val_loss: 0.4247 - val_accuracy: 0.9309\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2273 - accuracy: 0.9398 - val_loss: 0.3989 - val_accuracy: 0.9325\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2059 - accuracy: 0.9480 - val_loss: 0.3710 - val_accuracy: 0.9452\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1916 - accuracy: 0.9510 - val_loss: 0.3757 - val_accuracy: 0.9439\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1777 - accuracy: 0.9522 - val_loss: 0.3427 - val_accuracy: 0.9573\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1604 - accuracy: 0.9598 - val_loss: 0.3275 - val_accuracy: 0.9490\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1599 - accuracy: 0.9592 - val_loss: 0.3185 - val_accuracy: 0.9659\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1460 - accuracy: 0.9625 - val_loss: 0.3651 - val_accuracy: 0.9443\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1362 - accuracy: 0.9691 - val_loss: 0.3016 - val_accuracy: 0.9674\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1339 - accuracy: 0.9657 - val_loss: 0.3072 - val_accuracy: 0.9626\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1271 - accuracy: 0.9701 - val_loss: 0.2858 - val_accuracy: 0.9674\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1186 - accuracy: 0.9713 - val_loss: 0.2834 - val_accuracy: 0.9683\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1267 - accuracy: 0.9690 - val_loss: 0.2682 - val_accuracy: 0.9699\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1063 - accuracy: 0.9740 - val_loss: 0.2596 - val_accuracy: 0.9734\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1063 - accuracy: 0.9737 - val_loss: 0.2657 - val_accuracy: 0.9685\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1020 - accuracy: 0.9752 - val_loss: 0.2698 - val_accuracy: 0.9615\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1032 - accuracy: 0.9753 - val_loss: 0.2639 - val_accuracy: 0.9721\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0965 - accuracy: 0.9762 - val_loss: 0.2592 - val_accuracy: 0.9732\n","Epoch 25/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0982 - accuracy: 0.9760 - val_loss: 0.2480 - val_accuracy: 0.9738\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0879 - accuracy: 0.9788 - val_loss: 0.2527 - val_accuracy: 0.9721\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0927 - accuracy: 0.9775 - val_loss: 0.2665 - val_accuracy: 0.9637\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0876 - accuracy: 0.9781 - val_loss: 0.2552 - val_accuracy: 0.9740\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0845 - accuracy: 0.9795 - val_loss: 0.2389 - val_accuracy: 0.9806\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0915 - accuracy: 0.9772 - val_loss: 0.2635 - val_accuracy: 0.9690\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0771 - accuracy: 0.9806 - val_loss: 0.2540 - val_accuracy: 0.9729\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0796 - accuracy: 0.9805 - val_loss: 0.2514 - val_accuracy: 0.9767\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0789 - accuracy: 0.9805 - val_loss: 0.2455 - val_accuracy: 0.9813\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9803 - val_loss: 0.2426 - val_accuracy: 0.9791\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0699 - accuracy: 0.9832 - val_loss: 0.2517 - val_accuracy: 0.9815\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0781 - accuracy: 0.9809 - val_loss: 0.2376 - val_accuracy: 0.9831\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0728 - accuracy: 0.9830 - val_loss: 0.2486 - val_accuracy: 0.9749\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0723 - accuracy: 0.9816 - val_loss: 0.2427 - val_accuracy: 0.9824\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0747 - accuracy: 0.9822 - val_loss: 0.2356 - val_accuracy: 0.9833\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0672 - accuracy: 0.9843 - val_loss: 0.2730 - val_accuracy: 0.9765\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0762 - accuracy: 0.9806 - val_loss: 0.2322 - val_accuracy: 0.9835\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0636 - accuracy: 0.9855 - val_loss: 0.2452 - val_accuracy: 0.9833\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0682 - accuracy: 0.9831 - val_loss: 0.2399 - val_accuracy: 0.9857\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0726 - accuracy: 0.9841 - val_loss: 0.2419 - val_accuracy: 0.9824\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0677 - accuracy: 0.9840 - val_loss: 0.2418 - val_accuracy: 0.9811\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0667 - accuracy: 0.9842 - val_loss: 0.2312 - val_accuracy: 0.9857\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0642 - accuracy: 0.9853 - val_loss: 0.2503 - val_accuracy: 0.9784\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0692 - accuracy: 0.9843 - val_loss: 0.2366 - val_accuracy: 0.9826\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0599 - accuracy: 0.9867 - val_loss: 0.2483 - val_accuracy: 0.9729\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0641 - accuracy: 0.9852 - val_loss: 0.2301 - val_accuracy: 0.9857\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0642 - accuracy: 0.9846 - val_loss: 0.2619 - val_accuracy: 0.9824\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0587 - accuracy: 0.9867 - val_loss: 0.2366 - val_accuracy: 0.9864\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0576 - accuracy: 0.9876 - val_loss: 0.2474 - val_accuracy: 0.9802\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0607 - accuracy: 0.9867 - val_loss: 0.2472 - val_accuracy: 0.9857\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0626 - accuracy: 0.9846 - val_loss: 0.2489 - val_accuracy: 0.9864\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0526 - accuracy: 0.9887 - val_loss: 0.2554 - val_accuracy: 0.9747\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0624 - accuracy: 0.9846 - val_loss: 0.2578 - val_accuracy: 0.9833\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0540 - accuracy: 0.9875 - val_loss: 0.2500 - val_accuracy: 0.9824\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0562 - accuracy: 0.9874 - val_loss: 0.2529 - val_accuracy: 0.9806\n","Epoch 60/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0631 - accuracy: 0.9852 - val_loss: 0.2513 - val_accuracy: 0.9820\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 3ms/step - loss: 3.8539 - accuracy: 0.2810 - val_loss: 2.4636 - val_accuracy: 0.6299\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5176 - accuracy: 0.7262 - val_loss: 1.4379 - val_accuracy: 0.7890\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7932 - accuracy: 0.8495 - val_loss: 0.9978 - val_accuracy: 0.8739\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4826 - accuracy: 0.9046 - val_loss: 0.7898 - val_accuracy: 0.9096\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3418 - accuracy: 0.9298 - val_loss: 0.6711 - val_accuracy: 0.9267\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2605 - accuracy: 0.9461 - val_loss: 0.5649 - val_accuracy: 0.9362\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2124 - accuracy: 0.9543 - val_loss: 0.5016 - val_accuracy: 0.9307\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1891 - accuracy: 0.9582 - val_loss: 0.4611 - val_accuracy: 0.9443\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1687 - accuracy: 0.9621 - val_loss: 0.4333 - val_accuracy: 0.9441\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1490 - accuracy: 0.9669 - val_loss: 0.3876 - val_accuracy: 0.9597\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1356 - accuracy: 0.9704 - val_loss: 0.3743 - val_accuracy: 0.9545\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1347 - accuracy: 0.9708 - val_loss: 0.3530 - val_accuracy: 0.9567\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1165 - accuracy: 0.9754 - val_loss: 0.3403 - val_accuracy: 0.9571\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1134 - accuracy: 0.9755 - val_loss: 0.3006 - val_accuracy: 0.9703\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1108 - accuracy: 0.9740 - val_loss: 0.3069 - val_accuracy: 0.9648\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1073 - accuracy: 0.9749 - val_loss: 0.3010 - val_accuracy: 0.9639\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0942 - accuracy: 0.9797 - val_loss: 0.2821 - val_accuracy: 0.9661\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1005 - accuracy: 0.9759 - val_loss: 0.2848 - val_accuracy: 0.9670\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0892 - accuracy: 0.9805 - val_loss: 0.2835 - val_accuracy: 0.9694\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0891 - accuracy: 0.9804 - val_loss: 0.2476 - val_accuracy: 0.9729\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0827 - accuracy: 0.9816 - val_loss: 0.2382 - val_accuracy: 0.9745\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0918 - accuracy: 0.9790 - val_loss: 0.2981 - val_accuracy: 0.9551\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0770 - accuracy: 0.9829 - val_loss: 0.3213 - val_accuracy: 0.9523\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0799 - accuracy: 0.9821 - val_loss: 0.2698 - val_accuracy: 0.9628\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0893 - accuracy: 0.9789 - val_loss: 0.2548 - val_accuracy: 0.9677\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0695 - accuracy: 0.9853 - val_loss: 0.2288 - val_accuracy: 0.9740\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0736 - accuracy: 0.9837 - val_loss: 0.2345 - val_accuracy: 0.9694\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0813 - accuracy: 0.9813 - val_loss: 0.2398 - val_accuracy: 0.9723\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0648 - accuracy: 0.9866 - val_loss: 0.2657 - val_accuracy: 0.9635\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9817 - val_loss: 0.2219 - val_accuracy: 0.9760\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0701 - accuracy: 0.9839 - val_loss: 0.2341 - val_accuracy: 0.9685\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0689 - accuracy: 0.9849 - val_loss: 0.2309 - val_accuracy: 0.9659\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0712 - accuracy: 0.9836 - val_loss: 0.2104 - val_accuracy: 0.9802\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0597 - accuracy: 0.9863 - val_loss: 0.2075 - val_accuracy: 0.9778\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0708 - accuracy: 0.9834 - val_loss: 0.2071 - val_accuracy: 0.9762\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0596 - accuracy: 0.9865 - val_loss: 0.2189 - val_accuracy: 0.9674\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0671 - accuracy: 0.9846 - val_loss: 0.2021 - val_accuracy: 0.9828\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0596 - accuracy: 0.9867 - val_loss: 0.2395 - val_accuracy: 0.9685\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0610 - accuracy: 0.9873 - val_loss: 0.1912 - val_accuracy: 0.9817\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0593 - accuracy: 0.9856 - val_loss: 0.1859 - val_accuracy: 0.9800\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0552 - accuracy: 0.9873 - val_loss: 0.2005 - val_accuracy: 0.9762\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0552 - accuracy: 0.9880 - val_loss: 0.1728 - val_accuracy: 0.9850\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0625 - accuracy: 0.9857 - val_loss: 0.1892 - val_accuracy: 0.9844\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0494 - accuracy: 0.9896 - val_loss: 0.1755 - val_accuracy: 0.9804\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0578 - accuracy: 0.9869 - val_loss: 0.1908 - val_accuracy: 0.9743\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0657 - accuracy: 0.9858 - val_loss: 0.1902 - val_accuracy: 0.9784\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0486 - accuracy: 0.9900 - val_loss: 0.1810 - val_accuracy: 0.9817\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0578 - accuracy: 0.9881 - val_loss: 0.1955 - val_accuracy: 0.9780\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0544 - accuracy: 0.9881 - val_loss: 0.1910 - val_accuracy: 0.9776\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0579 - accuracy: 0.9870 - val_loss: 0.1927 - val_accuracy: 0.9802\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0509 - accuracy: 0.9892 - val_loss: 0.1858 - val_accuracy: 0.9795\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0479 - accuracy: 0.9894 - val_loss: 0.1753 - val_accuracy: 0.9806\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0550 - accuracy: 0.9871 - val_loss: 0.1932 - val_accuracy: 0.9758\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0527 - accuracy: 0.9883 - val_loss: 0.1836 - val_accuracy: 0.9789\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0501 - accuracy: 0.9876 - val_loss: 0.1756 - val_accuracy: 0.9828\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0553 - accuracy: 0.9871 - val_loss: 0.1683 - val_accuracy: 0.9839\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0478 - accuracy: 0.9884 - val_loss: 0.1665 - val_accuracy: 0.9839\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0476 - accuracy: 0.9901 - val_loss: 0.2066 - val_accuracy: 0.9723\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0480 - accuracy: 0.9892 - val_loss: 0.1877 - val_accuracy: 0.9795\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0525 - accuracy: 0.9883 - val_loss: 0.1713 - val_accuracy: 0.9773\n","Average Validation Accuracy: 0.9862760305404663\n","Average Validation Loss: 0.10257748514413834\n","Average Test Accuracy: 0.98455810546875\n","------------------------------------------------------------------------\n","\n","Number of input features: 12\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.5968 - accuracy: 0.3303 - val_loss: 2.2009 - val_accuracy: 0.5886\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2253 - accuracy: 0.7717 - val_loss: 0.9721 - val_accuracy: 0.8330\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5552 - accuracy: 0.8819 - val_loss: 0.7493 - val_accuracy: 0.8671\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3605 - accuracy: 0.9145 - val_loss: 0.5646 - val_accuracy: 0.9105\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2839 - accuracy: 0.9295 - val_loss: 0.4446 - val_accuracy: 0.9195\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2286 - accuracy: 0.9427 - val_loss: 0.4200 - val_accuracy: 0.9289\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2000 - accuracy: 0.9496 - val_loss: 0.3593 - val_accuracy: 0.9465\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1843 - accuracy: 0.9544 - val_loss: 0.3624 - val_accuracy: 0.9443\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1667 - accuracy: 0.9574 - val_loss: 0.3740 - val_accuracy: 0.9362\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1501 - accuracy: 0.9628 - val_loss: 0.3555 - val_accuracy: 0.9278\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1447 - accuracy: 0.9621 - val_loss: 0.2950 - val_accuracy: 0.9545\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1303 - accuracy: 0.9689 - val_loss: 0.3190 - val_accuracy: 0.9498\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1304 - accuracy: 0.9672 - val_loss: 0.3293 - val_accuracy: 0.9267\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1257 - accuracy: 0.9687 - val_loss: 0.2718 - val_accuracy: 0.9580\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1138 - accuracy: 0.9726 - val_loss: 0.2884 - val_accuracy: 0.9551\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1111 - accuracy: 0.9725 - val_loss: 0.2779 - val_accuracy: 0.9507\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1054 - accuracy: 0.9755 - val_loss: 0.2772 - val_accuracy: 0.9628\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1082 - accuracy: 0.9723 - val_loss: 0.2657 - val_accuracy: 0.9688\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1021 - accuracy: 0.9742 - val_loss: 0.2701 - val_accuracy: 0.9729\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0929 - accuracy: 0.9765 - val_loss: 0.2491 - val_accuracy: 0.9765\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0997 - accuracy: 0.9746 - val_loss: 0.2514 - val_accuracy: 0.9670\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0879 - accuracy: 0.9799 - val_loss: 0.2682 - val_accuracy: 0.9688\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0891 - accuracy: 0.9771 - val_loss: 0.2515 - val_accuracy: 0.9666\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0945 - accuracy: 0.9769 - val_loss: 0.2760 - val_accuracy: 0.9608\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0796 - accuracy: 0.9802 - val_loss: 0.2346 - val_accuracy: 0.9692\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0867 - accuracy: 0.9782 - val_loss: 0.2506 - val_accuracy: 0.9641\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0902 - accuracy: 0.9781 - val_loss: 0.2230 - val_accuracy: 0.9765\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0750 - accuracy: 0.9805 - val_loss: 0.2372 - val_accuracy: 0.9738\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0793 - accuracy: 0.9808 - val_loss: 0.2726 - val_accuracy: 0.9758\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0747 - accuracy: 0.9804 - val_loss: 0.2455 - val_accuracy: 0.9769\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0697 - accuracy: 0.9832 - val_loss: 0.2601 - val_accuracy: 0.9648\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0845 - accuracy: 0.9789 - val_loss: 0.2295 - val_accuracy: 0.9769\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0672 - accuracy: 0.9844 - val_loss: 0.2205 - val_accuracy: 0.9734\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0752 - accuracy: 0.9817 - val_loss: 0.2187 - val_accuracy: 0.9806\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0735 - accuracy: 0.9811 - val_loss: 0.2451 - val_accuracy: 0.9822\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0696 - accuracy: 0.9819 - val_loss: 0.2210 - val_accuracy: 0.9831\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0685 - accuracy: 0.9844 - val_loss: 0.2335 - val_accuracy: 0.9729\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0735 - accuracy: 0.9829 - val_loss: 0.2234 - val_accuracy: 0.9824\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0660 - accuracy: 0.9834 - val_loss: 0.2212 - val_accuracy: 0.9743\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0610 - accuracy: 0.9848 - val_loss: 0.2650 - val_accuracy: 0.9681\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0770 - accuracy: 0.9831 - val_loss: 0.2335 - val_accuracy: 0.9857\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0594 - accuracy: 0.9856 - val_loss: 0.2261 - val_accuracy: 0.9837\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0663 - accuracy: 0.9841 - val_loss: 0.2327 - val_accuracy: 0.9822\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0625 - accuracy: 0.9852 - val_loss: 0.2538 - val_accuracy: 0.9707\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0619 - accuracy: 0.9861 - val_loss: 0.2302 - val_accuracy: 0.9771\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0681 - accuracy: 0.9844 - val_loss: 0.2233 - val_accuracy: 0.9831\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0564 - accuracy: 0.9861 - val_loss: 0.2167 - val_accuracy: 0.9822\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0682 - accuracy: 0.9836 - val_loss: 0.2242 - val_accuracy: 0.9820\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0555 - accuracy: 0.9878 - val_loss: 0.2504 - val_accuracy: 0.9745\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0623 - accuracy: 0.9854 - val_loss: 0.2293 - val_accuracy: 0.9811\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0586 - accuracy: 0.9856 - val_loss: 0.2301 - val_accuracy: 0.9822\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0533 - accuracy: 0.9874 - val_loss: 0.2321 - val_accuracy: 0.9853\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0617 - accuracy: 0.9848 - val_loss: 0.2227 - val_accuracy: 0.9848\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0512 - accuracy: 0.9880 - val_loss: 0.2252 - val_accuracy: 0.9853\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0593 - accuracy: 0.9858 - val_loss: 0.2168 - val_accuracy: 0.9868\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0492 - accuracy: 0.9888 - val_loss: 0.2144 - val_accuracy: 0.9815\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0663 - accuracy: 0.9852 - val_loss: 0.2165 - val_accuracy: 0.9857\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0520 - accuracy: 0.9886 - val_loss: 0.2252 - val_accuracy: 0.9875\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0512 - accuracy: 0.9885 - val_loss: 0.2500 - val_accuracy: 0.9793\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0564 - accuracy: 0.9865 - val_loss: 0.2268 - val_accuracy: 0.9820\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.6587 - accuracy: 0.3013 - val_loss: 2.2100 - val_accuracy: 0.6130\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3055 - accuracy: 0.7609 - val_loss: 1.1967 - val_accuracy: 0.8004\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6578 - accuracy: 0.8632 - val_loss: 0.8338 - val_accuracy: 0.8785\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4399 - accuracy: 0.9016 - val_loss: 0.6926 - val_accuracy: 0.8924\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3294 - accuracy: 0.9237 - val_loss: 0.5476 - val_accuracy: 0.9186\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2693 - accuracy: 0.9357 - val_loss: 0.4947 - val_accuracy: 0.9289\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2234 - accuracy: 0.9482 - val_loss: 0.4488 - val_accuracy: 0.9212\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1999 - accuracy: 0.9521 - val_loss: 0.3754 - val_accuracy: 0.9472\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1772 - accuracy: 0.9586 - val_loss: 0.3789 - val_accuracy: 0.9375\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1702 - accuracy: 0.9602 - val_loss: 0.3339 - val_accuracy: 0.9358\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1478 - accuracy: 0.9650 - val_loss: 0.3370 - val_accuracy: 0.9362\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1480 - accuracy: 0.9650 - val_loss: 0.3155 - val_accuracy: 0.9492\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1316 - accuracy: 0.9705 - val_loss: 0.3039 - val_accuracy: 0.9514\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1264 - accuracy: 0.9713 - val_loss: 0.3301 - val_accuracy: 0.9448\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1173 - accuracy: 0.9744 - val_loss: 0.3085 - val_accuracy: 0.9520\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1202 - accuracy: 0.9705 - val_loss: 0.2539 - val_accuracy: 0.9637\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1132 - accuracy: 0.9728 - val_loss: 0.2665 - val_accuracy: 0.9617\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1026 - accuracy: 0.9771 - val_loss: 0.2885 - val_accuracy: 0.9516\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1028 - accuracy: 0.9744 - val_loss: 0.2458 - val_accuracy: 0.9696\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0920 - accuracy: 0.9781 - val_loss: 0.2355 - val_accuracy: 0.9659\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0931 - accuracy: 0.9785 - val_loss: 0.2251 - val_accuracy: 0.9745\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9800 - val_loss: 0.2533 - val_accuracy: 0.9622\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9796 - val_loss: 0.2766 - val_accuracy: 0.9549\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0869 - accuracy: 0.9794 - val_loss: 0.2416 - val_accuracy: 0.9648\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0810 - accuracy: 0.9803 - val_loss: 0.2205 - val_accuracy: 0.9743\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0863 - accuracy: 0.9800 - val_loss: 0.2245 - val_accuracy: 0.9657\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0778 - accuracy: 0.9822 - val_loss: 0.2089 - val_accuracy: 0.9778\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0747 - accuracy: 0.9816 - val_loss: 0.1964 - val_accuracy: 0.9736\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0762 - accuracy: 0.9826 - val_loss: 0.2436 - val_accuracy: 0.9661\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0744 - accuracy: 0.9823 - val_loss: 0.1938 - val_accuracy: 0.9773\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0724 - accuracy: 0.9845 - val_loss: 0.2023 - val_accuracy: 0.9692\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0666 - accuracy: 0.9863 - val_loss: 0.1947 - val_accuracy: 0.9699\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0691 - accuracy: 0.9844 - val_loss: 0.2052 - val_accuracy: 0.9703\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0695 - accuracy: 0.9843 - val_loss: 0.1951 - val_accuracy: 0.9769\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0734 - accuracy: 0.9833 - val_loss: 0.2540 - val_accuracy: 0.9553\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0600 - accuracy: 0.9875 - val_loss: 0.1828 - val_accuracy: 0.9811\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0686 - accuracy: 0.9842 - val_loss: 0.2275 - val_accuracy: 0.9608\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0585 - accuracy: 0.9872 - val_loss: 0.1748 - val_accuracy: 0.9804\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0732 - accuracy: 0.9830 - val_loss: 0.1793 - val_accuracy: 0.9831\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0597 - accuracy: 0.9869 - val_loss: 0.1834 - val_accuracy: 0.9789\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0632 - accuracy: 0.9860 - val_loss: 0.1792 - val_accuracy: 0.9791\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0608 - accuracy: 0.9865 - val_loss: 0.1823 - val_accuracy: 0.9734\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0578 - accuracy: 0.9865 - val_loss: 0.1838 - val_accuracy: 0.9688\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0627 - accuracy: 0.9862 - val_loss: 0.1907 - val_accuracy: 0.9780\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0567 - accuracy: 0.9871 - val_loss: 0.1840 - val_accuracy: 0.9751\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0605 - accuracy: 0.9871 - val_loss: 0.2164 - val_accuracy: 0.9692\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0551 - accuracy: 0.9872 - val_loss: 0.1729 - val_accuracy: 0.9828\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0644 - accuracy: 0.9857 - val_loss: 0.1812 - val_accuracy: 0.9749\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0502 - accuracy: 0.9891 - val_loss: 0.1709 - val_accuracy: 0.9793\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0575 - accuracy: 0.9868 - val_loss: 0.1882 - val_accuracy: 0.9749\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0546 - accuracy: 0.9876 - val_loss: 0.1722 - val_accuracy: 0.9782\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0505 - accuracy: 0.9892 - val_loss: 0.1754 - val_accuracy: 0.9762\n","Epoch 53/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0604 - accuracy: 0.9866 - val_loss: 0.1632 - val_accuracy: 0.9824\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0507 - accuracy: 0.9893 - val_loss: 0.2924 - val_accuracy: 0.9520\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0528 - accuracy: 0.9881 - val_loss: 0.1717 - val_accuracy: 0.9776\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0569 - accuracy: 0.9865 - val_loss: 0.1646 - val_accuracy: 0.9826\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0501 - accuracy: 0.9881 - val_loss: 0.1554 - val_accuracy: 0.9815\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0578 - accuracy: 0.9868 - val_loss: 0.1703 - val_accuracy: 0.9784\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0538 - accuracy: 0.9876 - val_loss: 0.1656 - val_accuracy: 0.9760\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0467 - accuracy: 0.9893 - val_loss: 0.1698 - val_accuracy: 0.9844\n","Average Validation Accuracy: 0.9875468015670776\n","Average Validation Loss: 0.0973563976585865\n","Average Test Accuracy: 0.9865482449531555\n","------------------------------------------------------------------------\n","\n","Number of input features: 13\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.4479 - accuracy: 0.3715 - val_loss: 2.1346 - val_accuracy: 0.6537\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3176 - accuracy: 0.7660 - val_loss: 1.1362 - val_accuracy: 0.8064\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6804 - accuracy: 0.8584 - val_loss: 0.7733 - val_accuracy: 0.8702\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4587 - accuracy: 0.8932 - val_loss: 0.5791 - val_accuracy: 0.8836\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3511 - accuracy: 0.9148 - val_loss: 0.5164 - val_accuracy: 0.8990\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2949 - accuracy: 0.9238 - val_loss: 0.4725 - val_accuracy: 0.9111\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2516 - accuracy: 0.9362 - val_loss: 0.4021 - val_accuracy: 0.9270\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2165 - accuracy: 0.9461 - val_loss: 0.3662 - val_accuracy: 0.9327\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1979 - accuracy: 0.9518 - val_loss: 0.3380 - val_accuracy: 0.9448\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1691 - accuracy: 0.9599 - val_loss: 0.3352 - val_accuracy: 0.9457\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1560 - accuracy: 0.9634 - val_loss: 0.3095 - val_accuracy: 0.9492\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1476 - accuracy: 0.9634 - val_loss: 0.2764 - val_accuracy: 0.9608\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1397 - accuracy: 0.9691 - val_loss: 0.2655 - val_accuracy: 0.9716\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1328 - accuracy: 0.9679 - val_loss: 0.2939 - val_accuracy: 0.9564\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1255 - accuracy: 0.9705 - val_loss: 0.2817 - val_accuracy: 0.9641\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1169 - accuracy: 0.9723 - val_loss: 0.2692 - val_accuracy: 0.9677\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1131 - accuracy: 0.9734 - val_loss: 0.2615 - val_accuracy: 0.9657\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1058 - accuracy: 0.9753 - val_loss: 0.2460 - val_accuracy: 0.9688\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1072 - accuracy: 0.9746 - val_loss: 0.2627 - val_accuracy: 0.9756\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0960 - accuracy: 0.9780 - val_loss: 0.2561 - val_accuracy: 0.9705\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1013 - accuracy: 0.9765 - val_loss: 0.2569 - val_accuracy: 0.9705\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0913 - accuracy: 0.9781 - val_loss: 0.2643 - val_accuracy: 0.9789\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0931 - accuracy: 0.9781 - val_loss: 0.2589 - val_accuracy: 0.9778\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0936 - accuracy: 0.9780 - val_loss: 0.2642 - val_accuracy: 0.9712\n","Epoch 25/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0901 - accuracy: 0.9794 - val_loss: 0.2585 - val_accuracy: 0.9644\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0851 - accuracy: 0.9802 - val_loss: 0.2532 - val_accuracy: 0.9745\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0882 - accuracy: 0.9801 - val_loss: 0.2485 - val_accuracy: 0.9683\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0754 - accuracy: 0.9829 - val_loss: 0.2565 - val_accuracy: 0.9712\n","Epoch 29/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0836 - accuracy: 0.9802 - val_loss: 0.2613 - val_accuracy: 0.9762\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0731 - accuracy: 0.9832 - val_loss: 0.2565 - val_accuracy: 0.9765\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0803 - accuracy: 0.9811 - val_loss: 0.2426 - val_accuracy: 0.9776\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0730 - accuracy: 0.9831 - val_loss: 0.2426 - val_accuracy: 0.9787\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0753 - accuracy: 0.9818 - val_loss: 0.2444 - val_accuracy: 0.9811\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0748 - accuracy: 0.9841 - val_loss: 0.2455 - val_accuracy: 0.9743\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0744 - accuracy: 0.9819 - val_loss: 0.2561 - val_accuracy: 0.9833\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0662 - accuracy: 0.9849 - val_loss: 0.2494 - val_accuracy: 0.9802\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0662 - accuracy: 0.9846 - val_loss: 0.2775 - val_accuracy: 0.9635\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0731 - accuracy: 0.9831 - val_loss: 0.2487 - val_accuracy: 0.9831\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0657 - accuracy: 0.9849 - val_loss: 0.2863 - val_accuracy: 0.9822\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0697 - accuracy: 0.9837 - val_loss: 0.2576 - val_accuracy: 0.9780\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0657 - accuracy: 0.9857 - val_loss: 0.2490 - val_accuracy: 0.9839\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0632 - accuracy: 0.9855 - val_loss: 0.3608 - val_accuracy: 0.9567\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0657 - accuracy: 0.9861 - val_loss: 0.2530 - val_accuracy: 0.9844\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0626 - accuracy: 0.9847 - val_loss: 0.2658 - val_accuracy: 0.9826\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0681 - accuracy: 0.9841 - val_loss: 0.2495 - val_accuracy: 0.9837\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0666 - accuracy: 0.9843 - val_loss: 0.2652 - val_accuracy: 0.9787\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0580 - accuracy: 0.9873 - val_loss: 0.2600 - val_accuracy: 0.9723\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0705 - accuracy: 0.9833 - val_loss: 0.2578 - val_accuracy: 0.9826\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0535 - accuracy: 0.9885 - val_loss: 0.2488 - val_accuracy: 0.9881\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0621 - accuracy: 0.9848 - val_loss: 0.2497 - val_accuracy: 0.9861\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0578 - accuracy: 0.9874 - val_loss: 0.2672 - val_accuracy: 0.9839\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0551 - accuracy: 0.9873 - val_loss: 0.2546 - val_accuracy: 0.9875\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0604 - accuracy: 0.9859 - val_loss: 0.3156 - val_accuracy: 0.9714\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0606 - accuracy: 0.9859 - val_loss: 0.2724 - val_accuracy: 0.9861\n","Epoch 55/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0543 - accuracy: 0.9875 - val_loss: 0.2738 - val_accuracy: 0.9870\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0525 - accuracy: 0.9887 - val_loss: 0.2684 - val_accuracy: 0.9866\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0627 - accuracy: 0.9855 - val_loss: 0.2768 - val_accuracy: 0.9846\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0512 - accuracy: 0.9888 - val_loss: 0.2843 - val_accuracy: 0.9745\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0585 - accuracy: 0.9863 - val_loss: 0.2753 - val_accuracy: 0.9866\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0499 - accuracy: 0.9899 - val_loss: 0.2577 - val_accuracy: 0.9877\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.5085 - accuracy: 0.3598 - val_loss: 2.1233 - val_accuracy: 0.6636\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2539 - accuracy: 0.7733 - val_loss: 1.1451 - val_accuracy: 0.8284\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6246 - accuracy: 0.8742 - val_loss: 0.8398 - val_accuracy: 0.8700\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4124 - accuracy: 0.9074 - val_loss: 0.6753 - val_accuracy: 0.9001\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3148 - accuracy: 0.9248 - val_loss: 0.5478 - val_accuracy: 0.9199\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2582 - accuracy: 0.9380 - val_loss: 0.5070 - val_accuracy: 0.9098\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2244 - accuracy: 0.9443 - val_loss: 0.4205 - val_accuracy: 0.9362\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2037 - accuracy: 0.9500 - val_loss: 0.3604 - val_accuracy: 0.9419\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1830 - accuracy: 0.9549 - val_loss: 0.3506 - val_accuracy: 0.9435\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1650 - accuracy: 0.9597 - val_loss: 0.3286 - val_accuracy: 0.9355\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1504 - accuracy: 0.9650 - val_loss: 0.3106 - val_accuracy: 0.9518\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1426 - accuracy: 0.9658 - val_loss: 0.3330 - val_accuracy: 0.9430\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1301 - accuracy: 0.9679 - val_loss: 0.2856 - val_accuracy: 0.9593\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1292 - accuracy: 0.9689 - val_loss: 0.2710 - val_accuracy: 0.9564\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1182 - accuracy: 0.9720 - val_loss: 0.2807 - val_accuracy: 0.9591\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1163 - accuracy: 0.9731 - val_loss: 0.2525 - val_accuracy: 0.9712\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1070 - accuracy: 0.9740 - val_loss: 0.2747 - val_accuracy: 0.9584\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1010 - accuracy: 0.9754 - val_loss: 0.2764 - val_accuracy: 0.9582\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0998 - accuracy: 0.9752 - val_loss: 0.2257 - val_accuracy: 0.9718\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0987 - accuracy: 0.9763 - val_loss: 0.2407 - val_accuracy: 0.9721\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0882 - accuracy: 0.9785 - val_loss: 0.2410 - val_accuracy: 0.9650\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0955 - accuracy: 0.9775 - val_loss: 0.3266 - val_accuracy: 0.9417\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0804 - accuracy: 0.9817 - val_loss: 0.2215 - val_accuracy: 0.9734\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0854 - accuracy: 0.9802 - val_loss: 0.2334 - val_accuracy: 0.9710\n","Epoch 25/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0810 - accuracy: 0.9805 - val_loss: 0.2162 - val_accuracy: 0.9723\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0892 - accuracy: 0.9784 - val_loss: 0.2301 - val_accuracy: 0.9696\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0754 - accuracy: 0.9819 - val_loss: 0.2153 - val_accuracy: 0.9721\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0760 - accuracy: 0.9821 - val_loss: 0.2424 - val_accuracy: 0.9690\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0773 - accuracy: 0.9821 - val_loss: 0.2172 - val_accuracy: 0.9648\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0688 - accuracy: 0.9837 - val_loss: 0.3738 - val_accuracy: 0.9355\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0767 - accuracy: 0.9821 - val_loss: 0.2050 - val_accuracy: 0.9771\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0721 - accuracy: 0.9832 - val_loss: 0.2061 - val_accuracy: 0.9769\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0648 - accuracy: 0.9856 - val_loss: 0.2184 - val_accuracy: 0.9716\n","Epoch 34/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0750 - accuracy: 0.9829 - val_loss: 0.2169 - val_accuracy: 0.9729\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0643 - accuracy: 0.9863 - val_loss: 0.2037 - val_accuracy: 0.9751\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0673 - accuracy: 0.9842 - val_loss: 0.2128 - val_accuracy: 0.9738\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0618 - accuracy: 0.9856 - val_loss: 0.1936 - val_accuracy: 0.9798\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0660 - accuracy: 0.9847 - val_loss: 0.2494 - val_accuracy: 0.9666\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0621 - accuracy: 0.9863 - val_loss: 0.2281 - val_accuracy: 0.9633\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0656 - accuracy: 0.9850 - val_loss: 0.1886 - val_accuracy: 0.9795\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0633 - accuracy: 0.9855 - val_loss: 0.1925 - val_accuracy: 0.9743\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0583 - accuracy: 0.9870 - val_loss: 0.2099 - val_accuracy: 0.9751\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0589 - accuracy: 0.9869 - val_loss: 0.1928 - val_accuracy: 0.9767\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0548 - accuracy: 0.9884 - val_loss: 0.1947 - val_accuracy: 0.9749\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0640 - accuracy: 0.9841 - val_loss: 0.1937 - val_accuracy: 0.9824\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0541 - accuracy: 0.9874 - val_loss: 0.1828 - val_accuracy: 0.9776\n","Epoch 47/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0594 - accuracy: 0.9870 - val_loss: 0.2324 - val_accuracy: 0.9578\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0548 - accuracy: 0.9874 - val_loss: 0.1843 - val_accuracy: 0.9784\n","Epoch 49/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0568 - accuracy: 0.9858 - val_loss: 0.1911 - val_accuracy: 0.9804\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0543 - accuracy: 0.9871 - val_loss: 0.1844 - val_accuracy: 0.9771\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0537 - accuracy: 0.9869 - val_loss: 0.1815 - val_accuracy: 0.9813\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0527 - accuracy: 0.9869 - val_loss: 0.1871 - val_accuracy: 0.9787\n","Epoch 53/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0495 - accuracy: 0.9878 - val_loss: 0.1871 - val_accuracy: 0.9793\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0532 - accuracy: 0.9881 - val_loss: 0.1907 - val_accuracy: 0.9736\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0540 - accuracy: 0.9874 - val_loss: 0.1817 - val_accuracy: 0.9826\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0497 - accuracy: 0.9887 - val_loss: 0.2031 - val_accuracy: 0.9743\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0511 - accuracy: 0.9887 - val_loss: 0.1814 - val_accuracy: 0.9833\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0444 - accuracy: 0.9901 - val_loss: 0.1858 - val_accuracy: 0.9743\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0558 - accuracy: 0.9866 - val_loss: 0.1862 - val_accuracy: 0.9813\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0463 - accuracy: 0.9891 - val_loss: 0.1763 - val_accuracy: 0.9802\n","Average Validation Accuracy: 0.9890716075897217\n","Average Validation Loss: 0.10268533602356911\n","Average Test Accuracy: 0.9884646832942963\n","------------------------------------------------------------------------\n","\n","Number of input features: 14\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.4961 - accuracy: 0.3479 - val_loss: 2.2089 - val_accuracy: 0.6143\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3845 - accuracy: 0.7488 - val_loss: 1.2230 - val_accuracy: 0.7804\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7376 - accuracy: 0.8463 - val_loss: 0.8499 - val_accuracy: 0.8440\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5015 - accuracy: 0.8849 - val_loss: 0.7059 - val_accuracy: 0.8638\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3806 - accuracy: 0.9097 - val_loss: 0.7133 - val_accuracy: 0.8772\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3147 - accuracy: 0.9254 - val_loss: 0.4805 - val_accuracy: 0.9164\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2668 - accuracy: 0.9357 - val_loss: 0.4560 - val_accuracy: 0.9219\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2405 - accuracy: 0.9397 - val_loss: 0.4102 - val_accuracy: 0.9459\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2106 - accuracy: 0.9488 - val_loss: 0.3996 - val_accuracy: 0.9393\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1996 - accuracy: 0.9520 - val_loss: 0.3637 - val_accuracy: 0.9465\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1712 - accuracy: 0.9601 - val_loss: 0.3425 - val_accuracy: 0.9551\n","Epoch 12/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1742 - accuracy: 0.9564 - val_loss: 0.3180 - val_accuracy: 0.9481\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1573 - accuracy: 0.9623 - val_loss: 0.3364 - val_accuracy: 0.9578\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1517 - accuracy: 0.9634 - val_loss: 0.2779 - val_accuracy: 0.9694\n","Epoch 15/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1384 - accuracy: 0.9657 - val_loss: 0.3048 - val_accuracy: 0.9426\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1351 - accuracy: 0.9679 - val_loss: 0.3189 - val_accuracy: 0.9459\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1375 - accuracy: 0.9673 - val_loss: 0.2797 - val_accuracy: 0.9641\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1169 - accuracy: 0.9726 - val_loss: 0.2590 - val_accuracy: 0.9659\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1196 - accuracy: 0.9715 - val_loss: 0.2879 - val_accuracy: 0.9578\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1139 - accuracy: 0.9726 - val_loss: 0.2600 - val_accuracy: 0.9668\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1122 - accuracy: 0.9759 - val_loss: 0.2684 - val_accuracy: 0.9670\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1067 - accuracy: 0.9743 - val_loss: 0.2615 - val_accuracy: 0.9578\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1040 - accuracy: 0.9759 - val_loss: 0.2326 - val_accuracy: 0.9765\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0966 - accuracy: 0.9772 - val_loss: 0.2401 - val_accuracy: 0.9729\n","Epoch 25/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1059 - accuracy: 0.9755 - val_loss: 0.2526 - val_accuracy: 0.9714\n","Epoch 26/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0899 - accuracy: 0.9797 - val_loss: 0.2376 - val_accuracy: 0.9762\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0940 - accuracy: 0.9795 - val_loss: 0.2412 - val_accuracy: 0.9760\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0873 - accuracy: 0.9812 - val_loss: 0.2175 - val_accuracy: 0.9831\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1021 - accuracy: 0.9768 - val_loss: 0.2214 - val_accuracy: 0.9793\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0803 - accuracy: 0.9815 - val_loss: 0.2141 - val_accuracy: 0.9826\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0878 - accuracy: 0.9796 - val_loss: 0.2407 - val_accuracy: 0.9784\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0850 - accuracy: 0.9809 - val_loss: 0.2210 - val_accuracy: 0.9745\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0759 - accuracy: 0.9841 - val_loss: 0.2076 - val_accuracy: 0.9771\n","Epoch 34/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0869 - accuracy: 0.9791 - val_loss: 0.2279 - val_accuracy: 0.9769\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0785 - accuracy: 0.9827 - val_loss: 0.2446 - val_accuracy: 0.9778\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0790 - accuracy: 0.9823 - val_loss: 0.2182 - val_accuracy: 0.9815\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0684 - accuracy: 0.9855 - val_loss: 0.2199 - val_accuracy: 0.9837\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0786 - accuracy: 0.9824 - val_loss: 0.2225 - val_accuracy: 0.9747\n","Epoch 39/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0662 - accuracy: 0.9854 - val_loss: 0.2264 - val_accuracy: 0.9736\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0816 - accuracy: 0.9803 - val_loss: 0.2169 - val_accuracy: 0.9802\n","Epoch 41/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0695 - accuracy: 0.9842 - val_loss: 0.2101 - val_accuracy: 0.9842\n","Epoch 42/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0713 - accuracy: 0.9832 - val_loss: 0.2131 - val_accuracy: 0.9736\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0654 - accuracy: 0.9859 - val_loss: 0.2211 - val_accuracy: 0.9817\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0758 - accuracy: 0.9831 - val_loss: 0.2091 - val_accuracy: 0.9846\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0727 - accuracy: 0.9831 - val_loss: 0.2171 - val_accuracy: 0.9817\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0633 - accuracy: 0.9860 - val_loss: 0.2101 - val_accuracy: 0.9861\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0680 - accuracy: 0.9834 - val_loss: 0.2017 - val_accuracy: 0.9802\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0704 - accuracy: 0.9835 - val_loss: 0.2685 - val_accuracy: 0.9637\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0600 - accuracy: 0.9868 - val_loss: 0.2032 - val_accuracy: 0.9837\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0651 - accuracy: 0.9849 - val_loss: 0.2258 - val_accuracy: 0.9822\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0616 - accuracy: 0.9873 - val_loss: 0.2018 - val_accuracy: 0.9864\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0612 - accuracy: 0.9856 - val_loss: 0.2082 - val_accuracy: 0.9837\n","Epoch 53/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0682 - accuracy: 0.9828 - val_loss: 0.2032 - val_accuracy: 0.9846\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0565 - accuracy: 0.9878 - val_loss: 0.1960 - val_accuracy: 0.9820\n","Epoch 55/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0623 - accuracy: 0.9863 - val_loss: 0.1930 - val_accuracy: 0.9809\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0640 - accuracy: 0.9846 - val_loss: 0.2150 - val_accuracy: 0.9833\n","Epoch 57/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0579 - accuracy: 0.9867 - val_loss: 0.2068 - val_accuracy: 0.9839\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0609 - accuracy: 0.9853 - val_loss: 0.2093 - val_accuracy: 0.9824\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0554 - accuracy: 0.9874 - val_loss: 0.2058 - val_accuracy: 0.9820\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0656 - accuracy: 0.9845 - val_loss: 0.2266 - val_accuracy: 0.9822\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.8398 - accuracy: 0.2879 - val_loss: 2.5427 - val_accuracy: 0.5725\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6539 - accuracy: 0.6918 - val_loss: 1.4667 - val_accuracy: 0.7525\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8681 - accuracy: 0.8235 - val_loss: 1.0225 - val_accuracy: 0.8515\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5801 - accuracy: 0.8699 - val_loss: 0.8707 - val_accuracy: 0.8634\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4452 - accuracy: 0.8952 - val_loss: 0.7086 - val_accuracy: 0.8882\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3638 - accuracy: 0.9097 - val_loss: 0.6523 - val_accuracy: 0.8814\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3194 - accuracy: 0.9209 - val_loss: 0.5646 - val_accuracy: 0.9188\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2788 - accuracy: 0.9298 - val_loss: 0.5321 - val_accuracy: 0.9186\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2580 - accuracy: 0.9344 - val_loss: 0.4739 - val_accuracy: 0.9243\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2309 - accuracy: 0.9415 - val_loss: 0.4325 - val_accuracy: 0.9476\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2136 - accuracy: 0.9451 - val_loss: 0.4628 - val_accuracy: 0.9173\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2008 - accuracy: 0.9495 - val_loss: 0.3967 - val_accuracy: 0.9452\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1797 - accuracy: 0.9559 - val_loss: 0.3969 - val_accuracy: 0.9384\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1817 - accuracy: 0.9533 - val_loss: 0.3748 - val_accuracy: 0.9507\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1604 - accuracy: 0.9589 - val_loss: 0.3760 - val_accuracy: 0.9419\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1609 - accuracy: 0.9604 - val_loss: 0.3507 - val_accuracy: 0.9523\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1462 - accuracy: 0.9642 - val_loss: 0.3320 - val_accuracy: 0.9613\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1452 - accuracy: 0.9648 - val_loss: 0.3786 - val_accuracy: 0.9457\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1380 - accuracy: 0.9655 - val_loss: 0.3458 - val_accuracy: 0.9602\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1234 - accuracy: 0.9695 - val_loss: 0.3407 - val_accuracy: 0.9547\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1291 - accuracy: 0.9682 - val_loss: 0.3139 - val_accuracy: 0.9602\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1239 - accuracy: 0.9690 - val_loss: 0.3035 - val_accuracy: 0.9582\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1148 - accuracy: 0.9720 - val_loss: 0.2969 - val_accuracy: 0.9615\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1160 - accuracy: 0.9725 - val_loss: 0.2983 - val_accuracy: 0.9602\n","Epoch 25/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1074 - accuracy: 0.9740 - val_loss: 0.3256 - val_accuracy: 0.9606\n","Epoch 26/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1157 - accuracy: 0.9717 - val_loss: 0.2903 - val_accuracy: 0.9749\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1016 - accuracy: 0.9762 - val_loss: 0.3128 - val_accuracy: 0.9584\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1083 - accuracy: 0.9725 - val_loss: 0.2854 - val_accuracy: 0.9721\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0991 - accuracy: 0.9762 - val_loss: 0.2879 - val_accuracy: 0.9672\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0979 - accuracy: 0.9758 - val_loss: 0.2991 - val_accuracy: 0.9644\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1016 - accuracy: 0.9754 - val_loss: 0.2866 - val_accuracy: 0.9679\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0915 - accuracy: 0.9769 - val_loss: 0.2725 - val_accuracy: 0.9771\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0897 - accuracy: 0.9770 - val_loss: 0.2681 - val_accuracy: 0.9734\n","Epoch 34/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0945 - accuracy: 0.9769 - val_loss: 0.2843 - val_accuracy: 0.9641\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0919 - accuracy: 0.9765 - val_loss: 0.3065 - val_accuracy: 0.9666\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0847 - accuracy: 0.9794 - val_loss: 0.2939 - val_accuracy: 0.9619\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0873 - accuracy: 0.9789 - val_loss: 0.2734 - val_accuracy: 0.9756\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0831 - accuracy: 0.9819 - val_loss: 0.3055 - val_accuracy: 0.9661\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0869 - accuracy: 0.9786 - val_loss: 0.2794 - val_accuracy: 0.9672\n","Epoch 40/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0836 - accuracy: 0.9789 - val_loss: 0.2908 - val_accuracy: 0.9648\n","Epoch 41/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0786 - accuracy: 0.9800 - val_loss: 0.2895 - val_accuracy: 0.9681\n","Epoch 42/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0826 - accuracy: 0.9795 - val_loss: 0.2735 - val_accuracy: 0.9725\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0800 - accuracy: 0.9805 - val_loss: 0.2609 - val_accuracy: 0.9723\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0751 - accuracy: 0.9819 - val_loss: 0.2680 - val_accuracy: 0.9776\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0847 - accuracy: 0.9793 - val_loss: 0.2896 - val_accuracy: 0.9690\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0754 - accuracy: 0.9831 - val_loss: 0.2514 - val_accuracy: 0.9743\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9824 - val_loss: 0.2949 - val_accuracy: 0.9604\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0722 - accuracy: 0.9822 - val_loss: 0.2635 - val_accuracy: 0.9758\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0743 - accuracy: 0.9827 - val_loss: 0.2670 - val_accuracy: 0.9699\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0662 - accuracy: 0.9857 - val_loss: 0.2552 - val_accuracy: 0.9707\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9807 - val_loss: 0.2539 - val_accuracy: 0.9831\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0670 - accuracy: 0.9842 - val_loss: 0.2612 - val_accuracy: 0.9740\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0761 - accuracy: 0.9823 - val_loss: 0.2770 - val_accuracy: 0.9657\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0648 - accuracy: 0.9855 - val_loss: 0.2525 - val_accuracy: 0.9802\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0696 - accuracy: 0.9841 - val_loss: 0.2905 - val_accuracy: 0.9705\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0669 - accuracy: 0.9843 - val_loss: 0.2599 - val_accuracy: 0.9787\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0726 - accuracy: 0.9829 - val_loss: 0.2619 - val_accuracy: 0.9734\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0617 - accuracy: 0.9869 - val_loss: 0.2624 - val_accuracy: 0.9754\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0746 - accuracy: 0.9817 - val_loss: 0.2481 - val_accuracy: 0.9793\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0583 - accuracy: 0.9866 - val_loss: 0.2463 - val_accuracy: 0.9723\n","Average Validation Accuracy: 0.983371376991272\n","Average Validation Loss: 0.11952678859233856\n","Average Test Accuracy: 0.9838578999042511\n","------------------------------------------------------------------------\n","\n","Number of input features: 15\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.0344 - accuracy: 0.2221 - val_loss: 2.9572 - val_accuracy: 0.4293\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1211 - accuracy: 0.5964 - val_loss: 1.7818 - val_accuracy: 0.6627\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2411 - accuracy: 0.7515 - val_loss: 1.1996 - val_accuracy: 0.7714\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8094 - accuracy: 0.8252 - val_loss: 0.9146 - val_accuracy: 0.8249\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5987 - accuracy: 0.8592 - val_loss: 0.7645 - val_accuracy: 0.8477\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4815 - accuracy: 0.8810 - val_loss: 0.6731 - val_accuracy: 0.8667\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4149 - accuracy: 0.8956 - val_loss: 0.6145 - val_accuracy: 0.8792\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3567 - accuracy: 0.9085 - val_loss: 0.6102 - val_accuracy: 0.8693\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3240 - accuracy: 0.9148 - val_loss: 0.4990 - val_accuracy: 0.9100\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2967 - accuracy: 0.9227 - val_loss: 0.5007 - val_accuracy: 0.9100\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2696 - accuracy: 0.9284 - val_loss: 0.4542 - val_accuracy: 0.9140\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2513 - accuracy: 0.9339 - val_loss: 0.4437 - val_accuracy: 0.9208\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2362 - accuracy: 0.9375 - val_loss: 0.3954 - val_accuracy: 0.9353\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2236 - accuracy: 0.9426 - val_loss: 0.4134 - val_accuracy: 0.9439\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2129 - accuracy: 0.9459 - val_loss: 0.3959 - val_accuracy: 0.9338\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2047 - accuracy: 0.9500 - val_loss: 0.3495 - val_accuracy: 0.9531\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1890 - accuracy: 0.9517 - val_loss: 0.3693 - val_accuracy: 0.9527\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1836 - accuracy: 0.9542 - val_loss: 0.3448 - val_accuracy: 0.9470\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1837 - accuracy: 0.9530 - val_loss: 0.3499 - val_accuracy: 0.9437\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1754 - accuracy: 0.9555 - val_loss: 0.4218 - val_accuracy: 0.9124\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1782 - accuracy: 0.9546 - val_loss: 0.3235 - val_accuracy: 0.9468\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1566 - accuracy: 0.9623 - val_loss: 0.2992 - val_accuracy: 0.9608\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1488 - accuracy: 0.9647 - val_loss: 0.4138 - val_accuracy: 0.9223\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1611 - accuracy: 0.9600 - val_loss: 0.3031 - val_accuracy: 0.9630\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1456 - accuracy: 0.9643 - val_loss: 0.3118 - val_accuracy: 0.9562\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1492 - accuracy: 0.9625 - val_loss: 0.2895 - val_accuracy: 0.9558\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1285 - accuracy: 0.9679 - val_loss: 0.2780 - val_accuracy: 0.9611\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1415 - accuracy: 0.9660 - val_loss: 0.3172 - val_accuracy: 0.9529\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1320 - accuracy: 0.9675 - val_loss: 0.3101 - val_accuracy: 0.9547\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1296 - accuracy: 0.9673 - val_loss: 0.2996 - val_accuracy: 0.9470\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1177 - accuracy: 0.9718 - val_loss: 0.2962 - val_accuracy: 0.9525\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1299 - accuracy: 0.9684 - val_loss: 0.2717 - val_accuracy: 0.9688\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1257 - accuracy: 0.9682 - val_loss: 0.2907 - val_accuracy: 0.9641\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1113 - accuracy: 0.9736 - val_loss: 0.2798 - val_accuracy: 0.9602\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1135 - accuracy: 0.9708 - val_loss: 0.2816 - val_accuracy: 0.9679\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1097 - accuracy: 0.9740 - val_loss: 0.2825 - val_accuracy: 0.9608\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1161 - accuracy: 0.9723 - val_loss: 0.2605 - val_accuracy: 0.9732\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1059 - accuracy: 0.9742 - val_loss: 0.2859 - val_accuracy: 0.9626\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1085 - accuracy: 0.9719 - val_loss: 0.2711 - val_accuracy: 0.9716\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1063 - accuracy: 0.9743 - val_loss: 0.3089 - val_accuracy: 0.9593\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1023 - accuracy: 0.9744 - val_loss: 0.2564 - val_accuracy: 0.9705\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0942 - accuracy: 0.9757 - val_loss: 0.2622 - val_accuracy: 0.9723\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1038 - accuracy: 0.9744 - val_loss: 0.2930 - val_accuracy: 0.9648\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0934 - accuracy: 0.9776 - val_loss: 0.2787 - val_accuracy: 0.9633\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1009 - accuracy: 0.9756 - val_loss: 0.3241 - val_accuracy: 0.9600\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0903 - accuracy: 0.9782 - val_loss: 0.2618 - val_accuracy: 0.9714\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0932 - accuracy: 0.9772 - val_loss: 0.2665 - val_accuracy: 0.9690\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0994 - accuracy: 0.9744 - val_loss: 0.2680 - val_accuracy: 0.9756\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9788 - val_loss: 0.2551 - val_accuracy: 0.9743\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0974 - accuracy: 0.9754 - val_loss: 0.2467 - val_accuracy: 0.9820\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0932 - accuracy: 0.9766 - val_loss: 0.2553 - val_accuracy: 0.9751\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9788 - val_loss: 0.2736 - val_accuracy: 0.9604\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0833 - accuracy: 0.9799 - val_loss: 0.2634 - val_accuracy: 0.9732\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9789 - val_loss: 0.2693 - val_accuracy: 0.9659\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0864 - accuracy: 0.9780 - val_loss: 0.2577 - val_accuracy: 0.9714\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0842 - accuracy: 0.9797 - val_loss: 0.2843 - val_accuracy: 0.9509\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9818 - val_loss: 0.2483 - val_accuracy: 0.9837\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0851 - accuracy: 0.9792 - val_loss: 0.2701 - val_accuracy: 0.9626\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9793 - val_loss: 0.2820 - val_accuracy: 0.9635\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9773 - val_loss: 0.3475 - val_accuracy: 0.9481\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.4573 - accuracy: 0.3741 - val_loss: 2.1422 - val_accuracy: 0.6436\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2791 - accuracy: 0.7644 - val_loss: 1.1880 - val_accuracy: 0.8198\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6566 - accuracy: 0.8662 - val_loss: 0.8032 - val_accuracy: 0.8601\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4384 - accuracy: 0.9001 - val_loss: 0.6792 - val_accuracy: 0.8981\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3346 - accuracy: 0.9207 - val_loss: 0.5439 - val_accuracy: 0.9065\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2858 - accuracy: 0.9309 - val_loss: 0.4873 - val_accuracy: 0.9179\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2509 - accuracy: 0.9332 - val_loss: 0.4572 - val_accuracy: 0.9331\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.2206 - accuracy: 0.9445 - val_loss: 0.4431 - val_accuracy: 0.9223\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.2012 - accuracy: 0.9494 - val_loss: 0.3715 - val_accuracy: 0.9474\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1907 - accuracy: 0.9552 - val_loss: 0.3691 - val_accuracy: 0.9382\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1670 - accuracy: 0.9593 - val_loss: 0.3578 - val_accuracy: 0.9336\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1581 - accuracy: 0.9629 - val_loss: 0.3440 - val_accuracy: 0.9457\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1488 - accuracy: 0.9650 - val_loss: 0.3099 - val_accuracy: 0.9525\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1376 - accuracy: 0.9672 - val_loss: 0.3707 - val_accuracy: 0.9393\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1333 - accuracy: 0.9679 - val_loss: 0.2954 - val_accuracy: 0.9503\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1278 - accuracy: 0.9682 - val_loss: 0.2919 - val_accuracy: 0.9630\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1196 - accuracy: 0.9712 - val_loss: 0.2836 - val_accuracy: 0.9602\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1100 - accuracy: 0.9751 - val_loss: 0.2812 - val_accuracy: 0.9611\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1099 - accuracy: 0.9739 - val_loss: 0.2824 - val_accuracy: 0.9564\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1068 - accuracy: 0.9757 - val_loss: 0.2552 - val_accuracy: 0.9688\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1091 - accuracy: 0.9739 - val_loss: 0.2706 - val_accuracy: 0.9701\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0923 - accuracy: 0.9795 - val_loss: 0.2540 - val_accuracy: 0.9659\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0950 - accuracy: 0.9781 - val_loss: 0.2695 - val_accuracy: 0.9606\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0915 - accuracy: 0.9786 - val_loss: 0.2760 - val_accuracy: 0.9688\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0941 - accuracy: 0.9796 - val_loss: 0.2833 - val_accuracy: 0.9580\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.0837 - accuracy: 0.9811 - val_loss: 0.2774 - val_accuracy: 0.9578\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0892 - accuracy: 0.9786 - val_loss: 0.2537 - val_accuracy: 0.9707\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0880 - accuracy: 0.9794 - val_loss: 0.2588 - val_accuracy: 0.9681\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0788 - accuracy: 0.9827 - val_loss: 0.2455 - val_accuracy: 0.9734\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0860 - accuracy: 0.9798 - val_loss: 0.2631 - val_accuracy: 0.9714\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0734 - accuracy: 0.9837 - val_loss: 0.2413 - val_accuracy: 0.9683\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0839 - accuracy: 0.9811 - val_loss: 0.2356 - val_accuracy: 0.9710\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0755 - accuracy: 0.9831 - val_loss: 0.2532 - val_accuracy: 0.9652\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0730 - accuracy: 0.9844 - val_loss: 0.2619 - val_accuracy: 0.9699\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0735 - accuracy: 0.9842 - val_loss: 0.2462 - val_accuracy: 0.9685\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0752 - accuracy: 0.9831 - val_loss: 0.2254 - val_accuracy: 0.9776\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0749 - accuracy: 0.9829 - val_loss: 0.2341 - val_accuracy: 0.9769\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0686 - accuracy: 0.9835 - val_loss: 0.2646 - val_accuracy: 0.9661\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0685 - accuracy: 0.9852 - val_loss: 0.2429 - val_accuracy: 0.9699\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0775 - accuracy: 0.9817 - val_loss: 0.2473 - val_accuracy: 0.9729\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0637 - accuracy: 0.9853 - val_loss: 0.2437 - val_accuracy: 0.9751\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0616 - accuracy: 0.9860 - val_loss: 0.2464 - val_accuracy: 0.9716\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.0694 - accuracy: 0.9856 - val_loss: 0.2520 - val_accuracy: 0.9721\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.0630 - accuracy: 0.9866 - val_loss: 0.2781 - val_accuracy: 0.9677\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0675 - accuracy: 0.9835 - val_loss: 0.2422 - val_accuracy: 0.9707\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0666 - accuracy: 0.9849 - val_loss: 0.2576 - val_accuracy: 0.9630\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.0624 - accuracy: 0.9850 - val_loss: 0.2430 - val_accuracy: 0.9712\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0659 - accuracy: 0.9850 - val_loss: 0.2224 - val_accuracy: 0.9822\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0541 - accuracy: 0.9883 - val_loss: 0.2441 - val_accuracy: 0.9626\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0654 - accuracy: 0.9850 - val_loss: 0.2177 - val_accuracy: 0.9771\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0593 - accuracy: 0.9861 - val_loss: 0.2445 - val_accuracy: 0.9727\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0562 - accuracy: 0.9876 - val_loss: 0.2241 - val_accuracy: 0.9747\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.0551 - accuracy: 0.9881 - val_loss: 0.2154 - val_accuracy: 0.9789\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0553 - accuracy: 0.9870 - val_loss: 0.2260 - val_accuracy: 0.9729\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0549 - accuracy: 0.9880 - val_loss: 0.2164 - val_accuracy: 0.9760\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0558 - accuracy: 0.9858 - val_loss: 0.3000 - val_accuracy: 0.9551\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0528 - accuracy: 0.9873 - val_loss: 0.2116 - val_accuracy: 0.9800\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0558 - accuracy: 0.9866 - val_loss: 0.2268 - val_accuracy: 0.9756\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0567 - accuracy: 0.9865 - val_loss: 0.2221 - val_accuracy: 0.9771\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0505 - accuracy: 0.9874 - val_loss: 0.2115 - val_accuracy: 0.9789\n","Average Validation Accuracy: 0.9728792905807495\n","Average Validation Loss: 0.15878944098949432\n","Average Test Accuracy: 0.9736124575138092\n","------------------------------------------------------------------------\n","\n","Number of input features: 16\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.3169 - accuracy: 0.3707 - val_loss: 1.8917 - val_accuracy: 0.6557\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1458 - accuracy: 0.7687 - val_loss: 0.9607 - val_accuracy: 0.8249\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6337 - accuracy: 0.8548 - val_loss: 0.7131 - val_accuracy: 0.8682\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4592 - accuracy: 0.8879 - val_loss: 0.6015 - val_accuracy: 0.8796\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3619 - accuracy: 0.9097 - val_loss: 0.5217 - val_accuracy: 0.9039\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3130 - accuracy: 0.9209 - val_loss: 0.4245 - val_accuracy: 0.9276\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2626 - accuracy: 0.9342 - val_loss: 0.3867 - val_accuracy: 0.9263\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2327 - accuracy: 0.9408 - val_loss: 0.3647 - val_accuracy: 0.9388\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2118 - accuracy: 0.9495 - val_loss: 0.3544 - val_accuracy: 0.9069\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1927 - accuracy: 0.9534 - val_loss: 0.3471 - val_accuracy: 0.9406\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1808 - accuracy: 0.9566 - val_loss: 0.2922 - val_accuracy: 0.9600\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1757 - accuracy: 0.9559 - val_loss: 0.3035 - val_accuracy: 0.9520\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1502 - accuracy: 0.9661 - val_loss: 0.3580 - val_accuracy: 0.9435\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1597 - accuracy: 0.9615 - val_loss: 0.3424 - val_accuracy: 0.9501\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1356 - accuracy: 0.9687 - val_loss: 0.3129 - val_accuracy: 0.9465\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.1371 - accuracy: 0.9667 - val_loss: 0.2704 - val_accuracy: 0.9580\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1323 - accuracy: 0.9707 - val_loss: 0.2566 - val_accuracy: 0.9538\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1357 - accuracy: 0.9664 - val_loss: 0.2487 - val_accuracy: 0.9562\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1187 - accuracy: 0.9723 - val_loss: 0.2262 - val_accuracy: 0.9743\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1161 - accuracy: 0.9729 - val_loss: 0.2475 - val_accuracy: 0.9617\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1185 - accuracy: 0.9719 - val_loss: 0.2466 - val_accuracy: 0.9619\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1070 - accuracy: 0.9742 - val_loss: 0.2336 - val_accuracy: 0.9635\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9743 - val_loss: 0.2222 - val_accuracy: 0.9723\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1062 - accuracy: 0.9752 - val_loss: 0.2197 - val_accuracy: 0.9650\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0963 - accuracy: 0.9768 - val_loss: 0.2115 - val_accuracy: 0.9758\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1173 - accuracy: 0.9720 - val_loss: 0.2149 - val_accuracy: 0.9732\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0866 - accuracy: 0.9795 - val_loss: 0.1960 - val_accuracy: 0.9791\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0931 - accuracy: 0.9768 - val_loss: 0.2710 - val_accuracy: 0.9520\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0966 - accuracy: 0.9772 - val_loss: 0.1969 - val_accuracy: 0.9765\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0917 - accuracy: 0.9795 - val_loss: 0.2140 - val_accuracy: 0.9685\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0906 - accuracy: 0.9791 - val_loss: 0.2146 - val_accuracy: 0.9714\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0888 - accuracy: 0.9781 - val_loss: 0.2142 - val_accuracy: 0.9743\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0960 - accuracy: 0.9767 - val_loss: 0.2427 - val_accuracy: 0.9725\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0887 - accuracy: 0.9784 - val_loss: 0.2072 - val_accuracy: 0.9754\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0759 - accuracy: 0.9827 - val_loss: 0.1962 - val_accuracy: 0.9760\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0910 - accuracy: 0.9784 - val_loss: 0.2187 - val_accuracy: 0.9751\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0769 - accuracy: 0.9825 - val_loss: 0.2029 - val_accuracy: 0.9754\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0829 - accuracy: 0.9823 - val_loss: 0.2240 - val_accuracy: 0.9705\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0829 - accuracy: 0.9801 - val_loss: 0.2028 - val_accuracy: 0.9732\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9824 - val_loss: 0.1943 - val_accuracy: 0.9751\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0788 - accuracy: 0.9814 - val_loss: 0.2175 - val_accuracy: 0.9756\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0691 - accuracy: 0.9848 - val_loss: 0.2251 - val_accuracy: 0.9712\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0825 - accuracy: 0.9796 - val_loss: 0.2057 - val_accuracy: 0.9782\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0669 - accuracy: 0.9844 - val_loss: 0.2207 - val_accuracy: 0.9828\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0772 - accuracy: 0.9816 - val_loss: 0.2056 - val_accuracy: 0.9765\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9822 - val_loss: 0.2147 - val_accuracy: 0.9831\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0701 - accuracy: 0.9845 - val_loss: 0.1997 - val_accuracy: 0.9791\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0669 - accuracy: 0.9862 - val_loss: 0.1923 - val_accuracy: 0.9806\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0676 - accuracy: 0.9844 - val_loss: 0.1994 - val_accuracy: 0.9773\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0708 - accuracy: 0.9823 - val_loss: 0.1952 - val_accuracy: 0.9780\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0732 - accuracy: 0.9816 - val_loss: 0.2054 - val_accuracy: 0.9749\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0591 - accuracy: 0.9873 - val_loss: 0.2017 - val_accuracy: 0.9780\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0680 - accuracy: 0.9834 - val_loss: 0.1991 - val_accuracy: 0.9791\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0676 - accuracy: 0.9857 - val_loss: 0.2115 - val_accuracy: 0.9765\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0616 - accuracy: 0.9860 - val_loss: 0.2566 - val_accuracy: 0.9718\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0642 - accuracy: 0.9854 - val_loss: 0.2024 - val_accuracy: 0.9842\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0668 - accuracy: 0.9844 - val_loss: 0.1911 - val_accuracy: 0.9795\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0550 - accuracy: 0.9880 - val_loss: 0.1996 - val_accuracy: 0.9795\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0626 - accuracy: 0.9857 - val_loss: 0.2281 - val_accuracy: 0.9738\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0602 - accuracy: 0.9868 - val_loss: 0.1936 - val_accuracy: 0.9826\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.4305 - accuracy: 0.3451 - val_loss: 2.0527 - val_accuracy: 0.6834\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2176 - accuracy: 0.7780 - val_loss: 1.0875 - val_accuracy: 0.8286\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6106 - accuracy: 0.8753 - val_loss: 0.7523 - val_accuracy: 0.8770\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3996 - accuracy: 0.9102 - val_loss: 0.5572 - val_accuracy: 0.9135\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2979 - accuracy: 0.9272 - val_loss: 0.4724 - val_accuracy: 0.9153\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2445 - accuracy: 0.9408 - val_loss: 0.4596 - val_accuracy: 0.9171\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2151 - accuracy: 0.9461 - val_loss: 0.3313 - val_accuracy: 0.9428\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1887 - accuracy: 0.9536 - val_loss: 0.3108 - val_accuracy: 0.9446\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1711 - accuracy: 0.9574 - val_loss: 0.2950 - val_accuracy: 0.9523\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1663 - accuracy: 0.9599 - val_loss: 0.2691 - val_accuracy: 0.9657\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1483 - accuracy: 0.9624 - val_loss: 0.2595 - val_accuracy: 0.9630\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1415 - accuracy: 0.9656 - val_loss: 0.2472 - val_accuracy: 0.9560\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1367 - accuracy: 0.9667 - val_loss: 0.2413 - val_accuracy: 0.9626\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1251 - accuracy: 0.9704 - val_loss: 0.2431 - val_accuracy: 0.9571\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1215 - accuracy: 0.9721 - val_loss: 0.2328 - val_accuracy: 0.9639\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1202 - accuracy: 0.9711 - val_loss: 0.2366 - val_accuracy: 0.9578\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1148 - accuracy: 0.9725 - val_loss: 0.2185 - val_accuracy: 0.9622\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1165 - accuracy: 0.9719 - val_loss: 0.2200 - val_accuracy: 0.9707\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1042 - accuracy: 0.9752 - val_loss: 0.2021 - val_accuracy: 0.9668\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1045 - accuracy: 0.9760 - val_loss: 0.2637 - val_accuracy: 0.9516\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0924 - accuracy: 0.9778 - val_loss: 0.2213 - val_accuracy: 0.9650\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1039 - accuracy: 0.9746 - val_loss: 0.2088 - val_accuracy: 0.9699\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0982 - accuracy: 0.9773 - val_loss: 0.2340 - val_accuracy: 0.9659\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0863 - accuracy: 0.9801 - val_loss: 0.2075 - val_accuracy: 0.9694\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9786 - val_loss: 0.1933 - val_accuracy: 0.9679\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0882 - accuracy: 0.9794 - val_loss: 0.2124 - val_accuracy: 0.9619\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0829 - accuracy: 0.9810 - val_loss: 0.2205 - val_accuracy: 0.9582\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0940 - accuracy: 0.9780 - val_loss: 0.2158 - val_accuracy: 0.9641\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0801 - accuracy: 0.9813 - val_loss: 0.3260 - val_accuracy: 0.9314\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0881 - accuracy: 0.9782 - val_loss: 0.2031 - val_accuracy: 0.9756\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9844 - val_loss: 0.1819 - val_accuracy: 0.9754\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0843 - accuracy: 0.9802 - val_loss: 0.1916 - val_accuracy: 0.9800\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0709 - accuracy: 0.9839 - val_loss: 0.2105 - val_accuracy: 0.9705\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0828 - accuracy: 0.9804 - val_loss: 0.1979 - val_accuracy: 0.9718\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0687 - accuracy: 0.9844 - val_loss: 0.1732 - val_accuracy: 0.9784\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0730 - accuracy: 0.9835 - val_loss: 0.1992 - val_accuracy: 0.9740\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0752 - accuracy: 0.9815 - val_loss: 0.2130 - val_accuracy: 0.9663\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0699 - accuracy: 0.9830 - val_loss: 0.1910 - val_accuracy: 0.9681\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0643 - accuracy: 0.9856 - val_loss: 0.1869 - val_accuracy: 0.9705\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0689 - accuracy: 0.9841 - val_loss: 0.1751 - val_accuracy: 0.9718\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0661 - accuracy: 0.9857 - val_loss: 0.1980 - val_accuracy: 0.9630\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0687 - accuracy: 0.9836 - val_loss: 0.2631 - val_accuracy: 0.9589\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0634 - accuracy: 0.9843 - val_loss: 0.1910 - val_accuracy: 0.9751\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0662 - accuracy: 0.9871 - val_loss: 0.1762 - val_accuracy: 0.9751\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0634 - accuracy: 0.9852 - val_loss: 0.1677 - val_accuracy: 0.9780\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0638 - accuracy: 0.9850 - val_loss: 0.2291 - val_accuracy: 0.9549\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0593 - accuracy: 0.9871 - val_loss: 0.1550 - val_accuracy: 0.9804\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0672 - accuracy: 0.9841 - val_loss: 0.2381 - val_accuracy: 0.9652\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0585 - accuracy: 0.9875 - val_loss: 0.1740 - val_accuracy: 0.9740\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0635 - accuracy: 0.9862 - val_loss: 0.1686 - val_accuracy: 0.9787\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0572 - accuracy: 0.9867 - val_loss: 0.1664 - val_accuracy: 0.9784\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0629 - accuracy: 0.9856 - val_loss: 0.1682 - val_accuracy: 0.9831\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0481 - accuracy: 0.9905 - val_loss: 0.1664 - val_accuracy: 0.9749\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0641 - accuracy: 0.9845 - val_loss: 0.1602 - val_accuracy: 0.9795\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0508 - accuracy: 0.9887 - val_loss: 0.1528 - val_accuracy: 0.9828\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0631 - accuracy: 0.9860 - val_loss: 0.1597 - val_accuracy: 0.9815\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0479 - accuracy: 0.9900 - val_loss: 0.1579 - val_accuracy: 0.9793\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0599 - accuracy: 0.9862 - val_loss: 0.1672 - val_accuracy: 0.9765\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0537 - accuracy: 0.9878 - val_loss: 0.1599 - val_accuracy: 0.9765\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0500 - accuracy: 0.9879 - val_loss: 0.1783 - val_accuracy: 0.9732\n","Average Validation Accuracy: 0.9845332205295563\n","Average Validation Loss: 0.09490707516670227\n","Average Test Accuracy: 0.9856269061565399\n","------------------------------------------------------------------------\n","\n","Number of input features: 17\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.7432 - accuracy: 0.2776 - val_loss: 2.5154 - val_accuracy: 0.5305\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6637 - accuracy: 0.6941 - val_loss: 1.4363 - val_accuracy: 0.7622\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9285 - accuracy: 0.8193 - val_loss: 0.9477 - val_accuracy: 0.8293\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6179 - accuracy: 0.8683 - val_loss: 0.7845 - val_accuracy: 0.8623\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4850 - accuracy: 0.8875 - val_loss: 0.6539 - val_accuracy: 0.8825\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4011 - accuracy: 0.9051 - val_loss: 0.6050 - val_accuracy: 0.8805\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3494 - accuracy: 0.9149 - val_loss: 0.4980 - val_accuracy: 0.9144\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3192 - accuracy: 0.9190 - val_loss: 0.4683 - val_accuracy: 0.9252\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2799 - accuracy: 0.9310 - val_loss: 0.4807 - val_accuracy: 0.9135\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2648 - accuracy: 0.9344 - val_loss: 0.4786 - val_accuracy: 0.9067\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2392 - accuracy: 0.9405 - val_loss: 0.4394 - val_accuracy: 0.9256\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2206 - accuracy: 0.9459 - val_loss: 0.4058 - val_accuracy: 0.9347\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2117 - accuracy: 0.9480 - val_loss: 0.3738 - val_accuracy: 0.9386\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1974 - accuracy: 0.9526 - val_loss: 0.4042 - val_accuracy: 0.9305\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1900 - accuracy: 0.9539 - val_loss: 0.3286 - val_accuracy: 0.9615\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1831 - accuracy: 0.9543 - val_loss: 0.3390 - val_accuracy: 0.9534\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1606 - accuracy: 0.9626 - val_loss: 0.3482 - val_accuracy: 0.9487\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1739 - accuracy: 0.9582 - val_loss: 0.3432 - val_accuracy: 0.9406\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1573 - accuracy: 0.9623 - val_loss: 0.3405 - val_accuracy: 0.9457\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1599 - accuracy: 0.9620 - val_loss: 0.3285 - val_accuracy: 0.9518\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1419 - accuracy: 0.9670 - val_loss: 0.2976 - val_accuracy: 0.9586\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1504 - accuracy: 0.9643 - val_loss: 0.2936 - val_accuracy: 0.9696\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1451 - accuracy: 0.9669 - val_loss: 0.3292 - val_accuracy: 0.9461\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1335 - accuracy: 0.9690 - val_loss: 0.2957 - val_accuracy: 0.9639\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1331 - accuracy: 0.9686 - val_loss: 0.2811 - val_accuracy: 0.9650\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1290 - accuracy: 0.9684 - val_loss: 0.2895 - val_accuracy: 0.9608\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1278 - accuracy: 0.9704 - val_loss: 0.2640 - val_accuracy: 0.9738\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1232 - accuracy: 0.9705 - val_loss: 0.2927 - val_accuracy: 0.9679\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1335 - accuracy: 0.9710 - val_loss: 0.2643 - val_accuracy: 0.9683\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1142 - accuracy: 0.9732 - val_loss: 0.2644 - val_accuracy: 0.9648\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1192 - accuracy: 0.9718 - val_loss: 0.2665 - val_accuracy: 0.9705\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1074 - accuracy: 0.9760 - val_loss: 0.3040 - val_accuracy: 0.9578\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1090 - accuracy: 0.9755 - val_loss: 0.2722 - val_accuracy: 0.9690\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1211 - accuracy: 0.9704 - val_loss: 0.2935 - val_accuracy: 0.9578\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1039 - accuracy: 0.9757 - val_loss: 0.2642 - val_accuracy: 0.9681\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1112 - accuracy: 0.9746 - val_loss: 0.2586 - val_accuracy: 0.9696\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1056 - accuracy: 0.9743 - val_loss: 0.2834 - val_accuracy: 0.9602\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0946 - accuracy: 0.9785 - val_loss: 0.2608 - val_accuracy: 0.9712\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1116 - accuracy: 0.9711 - val_loss: 0.2682 - val_accuracy: 0.9681\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0970 - accuracy: 0.9793 - val_loss: 0.2414 - val_accuracy: 0.9732\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0983 - accuracy: 0.9783 - val_loss: 0.2504 - val_accuracy: 0.9716\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1010 - accuracy: 0.9760 - val_loss: 0.2861 - val_accuracy: 0.9635\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0939 - accuracy: 0.9789 - val_loss: 0.3794 - val_accuracy: 0.9380\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0968 - accuracy: 0.9773 - val_loss: 0.3080 - val_accuracy: 0.9626\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0905 - accuracy: 0.9801 - val_loss: 0.2486 - val_accuracy: 0.9747\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1009 - accuracy: 0.9762 - val_loss: 0.2382 - val_accuracy: 0.9732\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0873 - accuracy: 0.9822 - val_loss: 0.2784 - val_accuracy: 0.9575\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0910 - accuracy: 0.9793 - val_loss: 0.2428 - val_accuracy: 0.9754\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0864 - accuracy: 0.9810 - val_loss: 0.2479 - val_accuracy: 0.9743\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9794 - val_loss: 0.2509 - val_accuracy: 0.9758\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0847 - accuracy: 0.9821 - val_loss: 0.2624 - val_accuracy: 0.9705\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0832 - accuracy: 0.9816 - val_loss: 0.2563 - val_accuracy: 0.9670\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0815 - accuracy: 0.9814 - val_loss: 0.2564 - val_accuracy: 0.9690\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0766 - accuracy: 0.9829 - val_loss: 0.2525 - val_accuracy: 0.9694\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0839 - accuracy: 0.9808 - val_loss: 0.2346 - val_accuracy: 0.9784\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0731 - accuracy: 0.9840 - val_loss: 0.2381 - val_accuracy: 0.9723\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0728 - accuracy: 0.9852 - val_loss: 0.2608 - val_accuracy: 0.9696\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0884 - accuracy: 0.9814 - val_loss: 0.2268 - val_accuracy: 0.9839\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0671 - accuracy: 0.9857 - val_loss: 0.2686 - val_accuracy: 0.9641\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9830 - val_loss: 0.2418 - val_accuracy: 0.9740\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.6699 - accuracy: 0.2719 - val_loss: 2.3315 - val_accuracy: 0.6057\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5237 - accuracy: 0.7063 - val_loss: 1.4568 - val_accuracy: 0.7591\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9100 - accuracy: 0.8038 - val_loss: 1.0902 - val_accuracy: 0.8101\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6328 - accuracy: 0.8543 - val_loss: 0.9029 - val_accuracy: 0.8614\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4780 - accuracy: 0.8844 - val_loss: 0.7463 - val_accuracy: 0.8902\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3872 - accuracy: 0.9047 - val_loss: 0.7260 - val_accuracy: 0.8845\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3337 - accuracy: 0.9160 - val_loss: 0.6225 - val_accuracy: 0.8895\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2917 - accuracy: 0.9252 - val_loss: 0.5897 - val_accuracy: 0.9098\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2746 - accuracy: 0.9278 - val_loss: 0.5087 - val_accuracy: 0.9261\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2444 - accuracy: 0.9355 - val_loss: 0.4732 - val_accuracy: 0.9289\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2299 - accuracy: 0.9368 - val_loss: 0.5217 - val_accuracy: 0.9186\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2142 - accuracy: 0.9433 - val_loss: 0.4514 - val_accuracy: 0.9289\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2029 - accuracy: 0.9457 - val_loss: 0.4292 - val_accuracy: 0.9369\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1835 - accuracy: 0.9499 - val_loss: 0.4205 - val_accuracy: 0.9417\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1861 - accuracy: 0.9517 - val_loss: 0.4063 - val_accuracy: 0.9424\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1621 - accuracy: 0.9571 - val_loss: 0.4101 - val_accuracy: 0.9463\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1628 - accuracy: 0.9560 - val_loss: 0.4052 - val_accuracy: 0.9410\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1511 - accuracy: 0.9599 - val_loss: 0.3830 - val_accuracy: 0.9501\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1460 - accuracy: 0.9624 - val_loss: 0.4825 - val_accuracy: 0.9270\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1379 - accuracy: 0.9639 - val_loss: 0.3422 - val_accuracy: 0.9635\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1375 - accuracy: 0.9660 - val_loss: 0.3461 - val_accuracy: 0.9591\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1292 - accuracy: 0.9672 - val_loss: 0.3610 - val_accuracy: 0.9514\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1233 - accuracy: 0.9687 - val_loss: 0.3767 - val_accuracy: 0.9545\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1186 - accuracy: 0.9716 - val_loss: 0.3072 - val_accuracy: 0.9670\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1178 - accuracy: 0.9726 - val_loss: 0.3100 - val_accuracy: 0.9604\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1185 - accuracy: 0.9688 - val_loss: 0.3089 - val_accuracy: 0.9584\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1144 - accuracy: 0.9716 - val_loss: 0.3113 - val_accuracy: 0.9639\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1157 - accuracy: 0.9733 - val_loss: 0.2965 - val_accuracy: 0.9639\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0937 - accuracy: 0.9792 - val_loss: 0.3044 - val_accuracy: 0.9670\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1055 - accuracy: 0.9741 - val_loss: 0.2831 - val_accuracy: 0.9685\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1139 - accuracy: 0.9715 - val_loss: 0.2811 - val_accuracy: 0.9657\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9784 - val_loss: 0.3450 - val_accuracy: 0.9540\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1090 - accuracy: 0.9731 - val_loss: 0.2915 - val_accuracy: 0.9615\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0874 - accuracy: 0.9810 - val_loss: 0.2733 - val_accuracy: 0.9721\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1083 - accuracy: 0.9753 - val_loss: 0.2795 - val_accuracy: 0.9617\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0976 - accuracy: 0.9767 - val_loss: 0.2559 - val_accuracy: 0.9725\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0954 - accuracy: 0.9778 - val_loss: 0.2493 - val_accuracy: 0.9688\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0793 - accuracy: 0.9829 - val_loss: 0.3094 - val_accuracy: 0.9571\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0972 - accuracy: 0.9764 - val_loss: 0.2764 - val_accuracy: 0.9650\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0908 - accuracy: 0.9781 - val_loss: 0.2672 - val_accuracy: 0.9628\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0861 - accuracy: 0.9801 - val_loss: 0.2422 - val_accuracy: 0.9692\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9782 - val_loss: 0.2547 - val_accuracy: 0.9655\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0896 - accuracy: 0.9797 - val_loss: 0.2471 - val_accuracy: 0.9732\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0791 - accuracy: 0.9819 - val_loss: 0.2355 - val_accuracy: 0.9747\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0826 - accuracy: 0.9793 - val_loss: 0.2285 - val_accuracy: 0.9714\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0839 - accuracy: 0.9806 - val_loss: 0.2362 - val_accuracy: 0.9707\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0809 - accuracy: 0.9815 - val_loss: 0.2467 - val_accuracy: 0.9652\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0878 - accuracy: 0.9798 - val_loss: 0.2735 - val_accuracy: 0.9622\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0720 - accuracy: 0.9834 - val_loss: 0.2203 - val_accuracy: 0.9734\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0836 - accuracy: 0.9788 - val_loss: 0.2282 - val_accuracy: 0.9811\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0715 - accuracy: 0.9843 - val_loss: 0.2387 - val_accuracy: 0.9751\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0733 - accuracy: 0.9832 - val_loss: 0.2254 - val_accuracy: 0.9782\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0814 - accuracy: 0.9815 - val_loss: 0.3436 - val_accuracy: 0.9443\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0701 - accuracy: 0.9843 - val_loss: 0.2083 - val_accuracy: 0.9765\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0721 - accuracy: 0.9840 - val_loss: 0.2203 - val_accuracy: 0.9760\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0751 - accuracy: 0.9835 - val_loss: 0.2185 - val_accuracy: 0.9778\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0675 - accuracy: 0.9855 - val_loss: 0.2604 - val_accuracy: 0.9670\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9823 - val_loss: 0.2230 - val_accuracy: 0.9738\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0683 - accuracy: 0.9843 - val_loss: 0.2046 - val_accuracy: 0.9824\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0792 - accuracy: 0.9824 - val_loss: 0.2280 - val_accuracy: 0.9685\n","Average Validation Accuracy: 0.9792687296867371\n","Average Validation Loss: 0.12947606295347214\n","Average Test Accuracy: 0.9806147217750549\n","------------------------------------------------------------------------\n","\n","Number of input features: 18\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.3927 - accuracy: 0.3672 - val_loss: 2.1959 - val_accuracy: 0.6180\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3898 - accuracy: 0.7444 - val_loss: 1.1593 - val_accuracy: 0.8134\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7176 - accuracy: 0.8586 - val_loss: 0.7752 - val_accuracy: 0.8647\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4503 - accuracy: 0.9017 - val_loss: 0.6037 - val_accuracy: 0.9023\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3223 - accuracy: 0.9266 - val_loss: 0.5067 - val_accuracy: 0.9274\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2557 - accuracy: 0.9372 - val_loss: 0.4560 - val_accuracy: 0.9226\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2103 - accuracy: 0.9517 - val_loss: 0.4254 - val_accuracy: 0.9318\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1866 - accuracy: 0.9574 - val_loss: 0.3976 - val_accuracy: 0.9470\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1638 - accuracy: 0.9623 - val_loss: 0.3434 - val_accuracy: 0.9562\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.1523 - accuracy: 0.9642 - val_loss: 0.3528 - val_accuracy: 0.9600\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1373 - accuracy: 0.9701 - val_loss: 0.4774 - val_accuracy: 0.9476\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1350 - accuracy: 0.9691 - val_loss: 0.3196 - val_accuracy: 0.9613\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1197 - accuracy: 0.9731 - val_loss: 0.3006 - val_accuracy: 0.9683\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1307 - accuracy: 0.9699 - val_loss: 0.2911 - val_accuracy: 0.9670\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1122 - accuracy: 0.9743 - val_loss: 0.3383 - val_accuracy: 0.9490\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1090 - accuracy: 0.9751 - val_loss: 0.2775 - val_accuracy: 0.9718\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1155 - accuracy: 0.9747 - val_loss: 0.2771 - val_accuracy: 0.9690\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1104 - accuracy: 0.9750 - val_loss: 0.2729 - val_accuracy: 0.9672\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0948 - accuracy: 0.9790 - val_loss: 0.2861 - val_accuracy: 0.9637\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0976 - accuracy: 0.9796 - val_loss: 0.2398 - val_accuracy: 0.9773\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1025 - accuracy: 0.9759 - val_loss: 0.2383 - val_accuracy: 0.9749\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0856 - accuracy: 0.9808 - val_loss: 0.2243 - val_accuracy: 0.9791\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0958 - accuracy: 0.9775 - val_loss: 0.2558 - val_accuracy: 0.9707\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9827 - val_loss: 0.2366 - val_accuracy: 0.9725\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0861 - accuracy: 0.9804 - val_loss: 0.2164 - val_accuracy: 0.9800\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0859 - accuracy: 0.9812 - val_loss: 0.2208 - val_accuracy: 0.9740\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0817 - accuracy: 0.9827 - val_loss: 0.2244 - val_accuracy: 0.9740\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0819 - accuracy: 0.9820 - val_loss: 0.2557 - val_accuracy: 0.9659\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0795 - accuracy: 0.9818 - val_loss: 0.2046 - val_accuracy: 0.9828\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0772 - accuracy: 0.9820 - val_loss: 0.2207 - val_accuracy: 0.9754\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0793 - accuracy: 0.9831 - val_loss: 0.2509 - val_accuracy: 0.9679\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9831 - val_loss: 0.2059 - val_accuracy: 0.9804\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9835 - val_loss: 0.2017 - val_accuracy: 0.9822\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0802 - accuracy: 0.9828 - val_loss: 0.2135 - val_accuracy: 0.9782\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0650 - accuracy: 0.9865 - val_loss: 0.2151 - val_accuracy: 0.9787\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0771 - accuracy: 0.9823 - val_loss: 0.2248 - val_accuracy: 0.9789\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0674 - accuracy: 0.9857 - val_loss: 0.2148 - val_accuracy: 0.9782\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0731 - accuracy: 0.9845 - val_loss: 0.2390 - val_accuracy: 0.9705\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0677 - accuracy: 0.9843 - val_loss: 0.2079 - val_accuracy: 0.9815\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0722 - accuracy: 0.9831 - val_loss: 0.1995 - val_accuracy: 0.9804\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0650 - accuracy: 0.9857 - val_loss: 0.2136 - val_accuracy: 0.9817\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0675 - accuracy: 0.9852 - val_loss: 0.2283 - val_accuracy: 0.9769\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0654 - accuracy: 0.9870 - val_loss: 0.2083 - val_accuracy: 0.9815\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0692 - accuracy: 0.9847 - val_loss: 0.2154 - val_accuracy: 0.9758\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0674 - accuracy: 0.9847 - val_loss: 0.2073 - val_accuracy: 0.9820\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0627 - accuracy: 0.9874 - val_loss: 0.2116 - val_accuracy: 0.9800\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0629 - accuracy: 0.9862 - val_loss: 0.2101 - val_accuracy: 0.9839\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0615 - accuracy: 0.9861 - val_loss: 0.2249 - val_accuracy: 0.9776\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0648 - accuracy: 0.9856 - val_loss: 0.2062 - val_accuracy: 0.9824\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0621 - accuracy: 0.9880 - val_loss: 0.2223 - val_accuracy: 0.9754\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0607 - accuracy: 0.9870 - val_loss: 0.2117 - val_accuracy: 0.9787\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0662 - accuracy: 0.9848 - val_loss: 0.2285 - val_accuracy: 0.9776\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0560 - accuracy: 0.9889 - val_loss: 0.2319 - val_accuracy: 0.9747\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0659 - accuracy: 0.9857 - val_loss: 0.2045 - val_accuracy: 0.9831\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0485 - accuracy: 0.9905 - val_loss: 0.2036 - val_accuracy: 0.9811\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0670 - accuracy: 0.9837 - val_loss: 0.2583 - val_accuracy: 0.9703\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0556 - accuracy: 0.9887 - val_loss: 0.2461 - val_accuracy: 0.9738\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0623 - accuracy: 0.9872 - val_loss: 0.2039 - val_accuracy: 0.9859\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0527 - accuracy: 0.9898 - val_loss: 0.2224 - val_accuracy: 0.9795\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0555 - accuracy: 0.9882 - val_loss: 0.2029 - val_accuracy: 0.9822\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.7195 - accuracy: 0.2769 - val_loss: 2.3937 - val_accuracy: 0.5784\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4805 - accuracy: 0.7274 - val_loss: 1.3141 - val_accuracy: 0.7703\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7715 - accuracy: 0.8429 - val_loss: 0.8848 - val_accuracy: 0.8442\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4938 - accuracy: 0.8903 - val_loss: 0.6616 - val_accuracy: 0.9006\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3695 - accuracy: 0.9135 - val_loss: 0.5729 - val_accuracy: 0.9063\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2949 - accuracy: 0.9303 - val_loss: 0.5105 - val_accuracy: 0.9215\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2483 - accuracy: 0.9378 - val_loss: 0.4616 - val_accuracy: 0.9267\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2226 - accuracy: 0.9465 - val_loss: 0.4239 - val_accuracy: 0.9285\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1978 - accuracy: 0.9517 - val_loss: 0.4012 - val_accuracy: 0.9322\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.1846 - accuracy: 0.9570 - val_loss: 0.3349 - val_accuracy: 0.9496\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1663 - accuracy: 0.9614 - val_loss: 0.3512 - val_accuracy: 0.9402\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1706 - accuracy: 0.9588 - val_loss: 0.3006 - val_accuracy: 0.9569\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1447 - accuracy: 0.9667 - val_loss: 0.3295 - val_accuracy: 0.9525\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1431 - accuracy: 0.9676 - val_loss: 0.2738 - val_accuracy: 0.9630\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1361 - accuracy: 0.9679 - val_loss: 0.2899 - val_accuracy: 0.9567\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1242 - accuracy: 0.9714 - val_loss: 0.2839 - val_accuracy: 0.9485\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1222 - accuracy: 0.9712 - val_loss: 0.3630 - val_accuracy: 0.9375\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1220 - accuracy: 0.9701 - val_loss: 0.2543 - val_accuracy: 0.9648\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1068 - accuracy: 0.9772 - val_loss: 0.2617 - val_accuracy: 0.9613\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1114 - accuracy: 0.9756 - val_loss: 0.2850 - val_accuracy: 0.9547\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1055 - accuracy: 0.9775 - val_loss: 0.3190 - val_accuracy: 0.9540\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1017 - accuracy: 0.9767 - val_loss: 0.2487 - val_accuracy: 0.9591\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0974 - accuracy: 0.9779 - val_loss: 0.2648 - val_accuracy: 0.9641\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0946 - accuracy: 0.9797 - val_loss: 0.2256 - val_accuracy: 0.9703\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0954 - accuracy: 0.9784 - val_loss: 0.2822 - val_accuracy: 0.9580\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0990 - accuracy: 0.9779 - val_loss: 0.2321 - val_accuracy: 0.9705\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0888 - accuracy: 0.9798 - val_loss: 0.2006 - val_accuracy: 0.9813\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0924 - accuracy: 0.9796 - val_loss: 0.2399 - val_accuracy: 0.9670\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0821 - accuracy: 0.9817 - val_loss: 0.2409 - val_accuracy: 0.9705\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0903 - accuracy: 0.9804 - val_loss: 0.2403 - val_accuracy: 0.9705\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0750 - accuracy: 0.9849 - val_loss: 0.2138 - val_accuracy: 0.9760\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0823 - accuracy: 0.9822 - val_loss: 0.2143 - val_accuracy: 0.9754\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9841 - val_loss: 0.2097 - val_accuracy: 0.9795\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0797 - accuracy: 0.9821 - val_loss: 0.2318 - val_accuracy: 0.9743\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0782 - accuracy: 0.9828 - val_loss: 0.2486 - val_accuracy: 0.9729\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0775 - accuracy: 0.9831 - val_loss: 0.2258 - val_accuracy: 0.9694\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0769 - accuracy: 0.9822 - val_loss: 0.2120 - val_accuracy: 0.9767\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0745 - accuracy: 0.9837 - val_loss: 0.3194 - val_accuracy: 0.9375\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0718 - accuracy: 0.9855 - val_loss: 0.1947 - val_accuracy: 0.9795\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0698 - accuracy: 0.9859 - val_loss: 0.1968 - val_accuracy: 0.9809\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0677 - accuracy: 0.9867 - val_loss: 0.2319 - val_accuracy: 0.9710\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0666 - accuracy: 0.9861 - val_loss: 0.4138 - val_accuracy: 0.9567\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0747 - accuracy: 0.9843 - val_loss: 0.1992 - val_accuracy: 0.9802\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0680 - accuracy: 0.9861 - val_loss: 0.2183 - val_accuracy: 0.9754\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0662 - accuracy: 0.9861 - val_loss: 0.1945 - val_accuracy: 0.9820\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0720 - accuracy: 0.9835 - val_loss: 0.2053 - val_accuracy: 0.9791\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0541 - accuracy: 0.9897 - val_loss: 0.2251 - val_accuracy: 0.9751\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0694 - accuracy: 0.9853 - val_loss: 0.2097 - val_accuracy: 0.9723\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0641 - accuracy: 0.9872 - val_loss: 0.2099 - val_accuracy: 0.9791\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0612 - accuracy: 0.9876 - val_loss: 0.2243 - val_accuracy: 0.9692\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0578 - accuracy: 0.9887 - val_loss: 0.2036 - val_accuracy: 0.9736\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0630 - accuracy: 0.9862 - val_loss: 0.2037 - val_accuracy: 0.9771\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0569 - accuracy: 0.9883 - val_loss: 0.1865 - val_accuracy: 0.9811\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0614 - accuracy: 0.9874 - val_loss: 0.1962 - val_accuracy: 0.9793\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0561 - accuracy: 0.9880 - val_loss: 0.1847 - val_accuracy: 0.9820\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0563 - accuracy: 0.9883 - val_loss: 0.2095 - val_accuracy: 0.9762\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0557 - accuracy: 0.9889 - val_loss: 0.2051 - val_accuracy: 0.9795\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0586 - accuracy: 0.9866 - val_loss: 0.2081 - val_accuracy: 0.9712\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0575 - accuracy: 0.9876 - val_loss: 0.2004 - val_accuracy: 0.9813\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0536 - accuracy: 0.9886 - val_loss: 0.1954 - val_accuracy: 0.9802\n","Average Validation Accuracy: 0.9868932366371155\n","Average Validation Loss: 0.10123884677886963\n","Average Test Accuracy: 0.9868799448013306\n","------------------------------------------------------------------------\n","\n","Number of input features: 19\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.8003 - accuracy: 0.2675 - val_loss: 2.5578 - val_accuracy: 0.4715\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6992 - accuracy: 0.6794 - val_loss: 1.3951 - val_accuracy: 0.7646\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9387 - accuracy: 0.8077 - val_loss: 0.9329 - val_accuracy: 0.8315\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6032 - accuracy: 0.8641 - val_loss: 0.7252 - val_accuracy: 0.8570\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4470 - accuracy: 0.8917 - val_loss: 0.5804 - val_accuracy: 0.8895\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3726 - accuracy: 0.9047 - val_loss: 0.4905 - val_accuracy: 0.9003\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3145 - accuracy: 0.9175 - val_loss: 0.4139 - val_accuracy: 0.9281\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2732 - accuracy: 0.9297 - val_loss: 0.4021 - val_accuracy: 0.9239\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2373 - accuracy: 0.9369 - val_loss: 0.4266 - val_accuracy: 0.9146\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2345 - accuracy: 0.9371 - val_loss: 0.3297 - val_accuracy: 0.9523\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2154 - accuracy: 0.9426 - val_loss: 0.3575 - val_accuracy: 0.9377\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2073 - accuracy: 0.9469 - val_loss: 0.4627 - val_accuracy: 0.9265\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1775 - accuracy: 0.9550 - val_loss: 0.3100 - val_accuracy: 0.9529\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1699 - accuracy: 0.9571 - val_loss: 0.3178 - val_accuracy: 0.9527\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1736 - accuracy: 0.9550 - val_loss: 0.3019 - val_accuracy: 0.9540\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1555 - accuracy: 0.9607 - val_loss: 0.3105 - val_accuracy: 0.9637\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1445 - accuracy: 0.9641 - val_loss: 0.3304 - val_accuracy: 0.9454\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1442 - accuracy: 0.9653 - val_loss: 0.4368 - val_accuracy: 0.9446\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1359 - accuracy: 0.9676 - val_loss: 0.2865 - val_accuracy: 0.9606\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1332 - accuracy: 0.9682 - val_loss: 0.3135 - val_accuracy: 0.9492\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1302 - accuracy: 0.9705 - val_loss: 0.2947 - val_accuracy: 0.9580\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1160 - accuracy: 0.9727 - val_loss: 0.2735 - val_accuracy: 0.9668\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1228 - accuracy: 0.9711 - val_loss: 0.2685 - val_accuracy: 0.9624\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1203 - accuracy: 0.9734 - val_loss: 0.2548 - val_accuracy: 0.9685\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1056 - accuracy: 0.9767 - val_loss: 0.2401 - val_accuracy: 0.9718\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1156 - accuracy: 0.9733 - val_loss: 0.2564 - val_accuracy: 0.9710\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1014 - accuracy: 0.9767 - val_loss: 0.2351 - val_accuracy: 0.9758\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1036 - accuracy: 0.9767 - val_loss: 0.2611 - val_accuracy: 0.9677\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0931 - accuracy: 0.9809 - val_loss: 0.2502 - val_accuracy: 0.9655\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1056 - accuracy: 0.9745 - val_loss: 0.2143 - val_accuracy: 0.9798\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0843 - accuracy: 0.9828 - val_loss: 0.2320 - val_accuracy: 0.9721\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1031 - accuracy: 0.9765 - val_loss: 0.2078 - val_accuracy: 0.9817\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0945 - accuracy: 0.9782 - val_loss: 0.2123 - val_accuracy: 0.9758\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0892 - accuracy: 0.9808 - val_loss: 0.2399 - val_accuracy: 0.9670\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0923 - accuracy: 0.9792 - val_loss: 0.2332 - val_accuracy: 0.9690\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0836 - accuracy: 0.9814 - val_loss: 0.2050 - val_accuracy: 0.9798\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0835 - accuracy: 0.9830 - val_loss: 0.1934 - val_accuracy: 0.9848\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1022 - accuracy: 0.9766 - val_loss: 0.1916 - val_accuracy: 0.9853\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0706 - accuracy: 0.9866 - val_loss: 0.2035 - val_accuracy: 0.9782\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0931 - accuracy: 0.9797 - val_loss: 0.2216 - val_accuracy: 0.9740\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0803 - accuracy: 0.9829 - val_loss: 0.2060 - val_accuracy: 0.9747\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0754 - accuracy: 0.9843 - val_loss: 0.1848 - val_accuracy: 0.9824\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0800 - accuracy: 0.9833 - val_loss: 0.2160 - val_accuracy: 0.9734\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0843 - accuracy: 0.9821 - val_loss: 0.2211 - val_accuracy: 0.9773\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0708 - accuracy: 0.9868 - val_loss: 0.2155 - val_accuracy: 0.9769\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0818 - accuracy: 0.9815 - val_loss: 0.1867 - val_accuracy: 0.9820\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0655 - accuracy: 0.9879 - val_loss: 0.2517 - val_accuracy: 0.9666\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0784 - accuracy: 0.9821 - val_loss: 0.1875 - val_accuracy: 0.9795\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0728 - accuracy: 0.9840 - val_loss: 0.1878 - val_accuracy: 0.9804\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0710 - accuracy: 0.9857 - val_loss: 0.1901 - val_accuracy: 0.9809\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0748 - accuracy: 0.9830 - val_loss: 0.1829 - val_accuracy: 0.9853\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0684 - accuracy: 0.9861 - val_loss: 0.1778 - val_accuracy: 0.9857\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0693 - accuracy: 0.9861 - val_loss: 0.1839 - val_accuracy: 0.9824\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0623 - accuracy: 0.9884 - val_loss: 0.1792 - val_accuracy: 0.9857\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0681 - accuracy: 0.9860 - val_loss: 0.2007 - val_accuracy: 0.9765\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0697 - accuracy: 0.9855 - val_loss: 0.2419 - val_accuracy: 0.9630\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0686 - accuracy: 0.9866 - val_loss: 0.2143 - val_accuracy: 0.9727\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0546 - accuracy: 0.9904 - val_loss: 0.2084 - val_accuracy: 0.9716\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0710 - accuracy: 0.9856 - val_loss: 0.1844 - val_accuracy: 0.9828\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0661 - accuracy: 0.9872 - val_loss: 0.1817 - val_accuracy: 0.9795\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.3227 - accuracy: 0.3621 - val_loss: 1.9445 - val_accuracy: 0.6856\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1613 - accuracy: 0.7750 - val_loss: 1.0450 - val_accuracy: 0.8409\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6169 - accuracy: 0.8673 - val_loss: 0.7314 - val_accuracy: 0.8761\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4120 - accuracy: 0.9073 - val_loss: 0.5937 - val_accuracy: 0.9140\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3185 - accuracy: 0.9235 - val_loss: 0.4832 - val_accuracy: 0.9303\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2605 - accuracy: 0.9363 - val_loss: 0.4227 - val_accuracy: 0.9382\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2190 - accuracy: 0.9481 - val_loss: 0.3908 - val_accuracy: 0.9316\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2015 - accuracy: 0.9491 - val_loss: 0.4153 - val_accuracy: 0.9333\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1791 - accuracy: 0.9581 - val_loss: 0.3448 - val_accuracy: 0.9399\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1632 - accuracy: 0.9608 - val_loss: 0.3194 - val_accuracy: 0.9523\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1559 - accuracy: 0.9619 - val_loss: 0.3646 - val_accuracy: 0.9523\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1482 - accuracy: 0.9655 - val_loss: 0.2973 - val_accuracy: 0.9573\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1340 - accuracy: 0.9694 - val_loss: 0.3203 - val_accuracy: 0.9534\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1226 - accuracy: 0.9725 - val_loss: 0.2960 - val_accuracy: 0.9626\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1359 - accuracy: 0.9699 - val_loss: 0.2842 - val_accuracy: 0.9624\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1080 - accuracy: 0.9752 - val_loss: 0.2687 - val_accuracy: 0.9611\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1172 - accuracy: 0.9745 - val_loss: 0.3153 - val_accuracy: 0.9573\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1116 - accuracy: 0.9755 - val_loss: 0.2892 - val_accuracy: 0.9591\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1130 - accuracy: 0.9749 - val_loss: 0.2826 - val_accuracy: 0.9659\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1009 - accuracy: 0.9762 - val_loss: 0.2401 - val_accuracy: 0.9721\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0979 - accuracy: 0.9797 - val_loss: 0.2860 - val_accuracy: 0.9703\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1043 - accuracy: 0.9754 - val_loss: 0.2444 - val_accuracy: 0.9745\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0893 - accuracy: 0.9831 - val_loss: 0.2680 - val_accuracy: 0.9657\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0959 - accuracy: 0.9785 - val_loss: 0.2647 - val_accuracy: 0.9696\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0841 - accuracy: 0.9817 - val_loss: 0.2880 - val_accuracy: 0.9602\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0897 - accuracy: 0.9811 - val_loss: 0.2444 - val_accuracy: 0.9732\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0872 - accuracy: 0.9818 - val_loss: 0.2113 - val_accuracy: 0.9787\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0801 - accuracy: 0.9823 - val_loss: 0.2493 - val_accuracy: 0.9692\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0793 - accuracy: 0.9841 - val_loss: 0.2181 - val_accuracy: 0.9806\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0848 - accuracy: 0.9826 - val_loss: 0.2402 - val_accuracy: 0.9723\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0753 - accuracy: 0.9849 - val_loss: 0.2514 - val_accuracy: 0.9734\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0791 - accuracy: 0.9826 - val_loss: 0.2392 - val_accuracy: 0.9734\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0768 - accuracy: 0.9845 - val_loss: 0.2580 - val_accuracy: 0.9633\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0719 - accuracy: 0.9847 - val_loss: 0.3016 - val_accuracy: 0.9589\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0717 - accuracy: 0.9854 - val_loss: 0.2307 - val_accuracy: 0.9738\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0759 - accuracy: 0.9841 - val_loss: 0.2340 - val_accuracy: 0.9721\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0668 - accuracy: 0.9859 - val_loss: 0.2393 - val_accuracy: 0.9705\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0663 - accuracy: 0.9854 - val_loss: 0.2071 - val_accuracy: 0.9828\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0684 - accuracy: 0.9867 - val_loss: 0.2109 - val_accuracy: 0.9791\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0689 - accuracy: 0.9850 - val_loss: 0.2162 - val_accuracy: 0.9793\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0584 - accuracy: 0.9884 - val_loss: 0.2098 - val_accuracy: 0.9839\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0613 - accuracy: 0.9866 - val_loss: 0.2129 - val_accuracy: 0.9824\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0554 - accuracy: 0.9898 - val_loss: 0.1958 - val_accuracy: 0.9822\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0654 - accuracy: 0.9857 - val_loss: 0.2063 - val_accuracy: 0.9795\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0594 - accuracy: 0.9879 - val_loss: 0.2255 - val_accuracy: 0.9751\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0594 - accuracy: 0.9869 - val_loss: 0.2289 - val_accuracy: 0.9707\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0599 - accuracy: 0.9878 - val_loss: 0.2099 - val_accuracy: 0.9789\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0641 - accuracy: 0.9862 - val_loss: 0.1928 - val_accuracy: 0.9824\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0609 - accuracy: 0.9869 - val_loss: 0.2739 - val_accuracy: 0.9729\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0558 - accuracy: 0.9883 - val_loss: 0.2123 - val_accuracy: 0.9817\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0577 - accuracy: 0.9873 - val_loss: 0.2024 - val_accuracy: 0.9853\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0524 - accuracy: 0.9898 - val_loss: 0.1917 - val_accuracy: 0.9844\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0529 - accuracy: 0.9891 - val_loss: 0.2223 - val_accuracy: 0.9800\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0607 - accuracy: 0.9863 - val_loss: 0.2190 - val_accuracy: 0.9732\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0550 - accuracy: 0.9885 - val_loss: 0.2588 - val_accuracy: 0.9685\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0502 - accuracy: 0.9901 - val_loss: 0.2263 - val_accuracy: 0.9758\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0511 - accuracy: 0.9898 - val_loss: 0.2110 - val_accuracy: 0.9795\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0555 - accuracy: 0.9881 - val_loss: 0.2129 - val_accuracy: 0.9802\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0567 - accuracy: 0.9874 - val_loss: 0.2052 - val_accuracy: 0.9784\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0549 - accuracy: 0.9885 - val_loss: 0.2058 - val_accuracy: 0.9835\n","Average Validation Accuracy: 0.9864213168621063\n","Average Validation Loss: 0.1005113236606121\n","Average Test Accuracy: 0.9865114092826843\n","------------------------------------------------------------------------\n","\n","Number of input features: 20\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.4055 - accuracy: 0.3491 - val_loss: 1.9672 - val_accuracy: 0.6345\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1832 - accuracy: 0.7683 - val_loss: 0.9937 - val_accuracy: 0.7967\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6212 - accuracy: 0.8633 - val_loss: 0.6440 - val_accuracy: 0.8832\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4100 - accuracy: 0.9029 - val_loss: 0.5276 - val_accuracy: 0.8964\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3140 - accuracy: 0.9226 - val_loss: 0.4356 - val_accuracy: 0.9263\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2556 - accuracy: 0.9380 - val_loss: 0.3533 - val_accuracy: 0.9424\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2182 - accuracy: 0.9480 - val_loss: 0.3683 - val_accuracy: 0.9384\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2020 - accuracy: 0.9500 - val_loss: 0.3235 - val_accuracy: 0.9439\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1883 - accuracy: 0.9533 - val_loss: 0.3098 - val_accuracy: 0.9494\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1582 - accuracy: 0.9639 - val_loss: 0.3110 - val_accuracy: 0.9494\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1562 - accuracy: 0.9626 - val_loss: 0.3460 - val_accuracy: 0.9349\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1506 - accuracy: 0.9646 - val_loss: 0.3041 - val_accuracy: 0.9531\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1434 - accuracy: 0.9651 - val_loss: 0.2410 - val_accuracy: 0.9679\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1301 - accuracy: 0.9693 - val_loss: 0.2327 - val_accuracy: 0.9663\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1339 - accuracy: 0.9661 - val_loss: 0.2833 - val_accuracy: 0.9534\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1262 - accuracy: 0.9713 - val_loss: 0.2356 - val_accuracy: 0.9690\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1265 - accuracy: 0.9704 - val_loss: 0.2402 - val_accuracy: 0.9624\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1097 - accuracy: 0.9753 - val_loss: 0.2287 - val_accuracy: 0.9670\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1163 - accuracy: 0.9711 - val_loss: 0.2160 - val_accuracy: 0.9685\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1140 - accuracy: 0.9725 - val_loss: 0.2135 - val_accuracy: 0.9707\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1083 - accuracy: 0.9739 - val_loss: 0.3209 - val_accuracy: 0.9408\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1032 - accuracy: 0.9751 - val_loss: 0.2194 - val_accuracy: 0.9725\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0942 - accuracy: 0.9794 - val_loss: 0.2044 - val_accuracy: 0.9760\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1018 - accuracy: 0.9768 - val_loss: 0.2700 - val_accuracy: 0.9553\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0949 - accuracy: 0.9780 - val_loss: 0.2221 - val_accuracy: 0.9655\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0958 - accuracy: 0.9769 - val_loss: 0.2064 - val_accuracy: 0.9723\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0901 - accuracy: 0.9799 - val_loss: 0.2116 - val_accuracy: 0.9663\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0876 - accuracy: 0.9803 - val_loss: 0.2104 - val_accuracy: 0.9758\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0898 - accuracy: 0.9806 - val_loss: 0.1932 - val_accuracy: 0.9758\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0864 - accuracy: 0.9808 - val_loss: 0.1850 - val_accuracy: 0.9778\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0837 - accuracy: 0.9804 - val_loss: 0.1918 - val_accuracy: 0.9795\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0829 - accuracy: 0.9808 - val_loss: 0.2056 - val_accuracy: 0.9756\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0804 - accuracy: 0.9823 - val_loss: 0.1800 - val_accuracy: 0.9826\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0736 - accuracy: 0.9831 - val_loss: 0.1897 - val_accuracy: 0.9749\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0822 - accuracy: 0.9827 - val_loss: 0.1997 - val_accuracy: 0.9767\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0732 - accuracy: 0.9855 - val_loss: 0.2059 - val_accuracy: 0.9740\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0737 - accuracy: 0.9845 - val_loss: 0.1872 - val_accuracy: 0.9758\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0687 - accuracy: 0.9841 - val_loss: 0.1948 - val_accuracy: 0.9760\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0739 - accuracy: 0.9840 - val_loss: 0.2181 - val_accuracy: 0.9725\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0736 - accuracy: 0.9828 - val_loss: 0.1722 - val_accuracy: 0.9842\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0665 - accuracy: 0.9854 - val_loss: 0.1855 - val_accuracy: 0.9800\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0738 - accuracy: 0.9835 - val_loss: 0.1754 - val_accuracy: 0.9844\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0611 - accuracy: 0.9874 - val_loss: 0.1796 - val_accuracy: 0.9820\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0703 - accuracy: 0.9854 - val_loss: 0.2123 - val_accuracy: 0.9736\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0673 - accuracy: 0.9867 - val_loss: 0.1857 - val_accuracy: 0.9780\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0683 - accuracy: 0.9846 - val_loss: 0.2133 - val_accuracy: 0.9773\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0617 - accuracy: 0.9876 - val_loss: 0.1648 - val_accuracy: 0.9864\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0692 - accuracy: 0.9849 - val_loss: 0.2242 - val_accuracy: 0.9718\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0556 - accuracy: 0.9884 - val_loss: 0.2399 - val_accuracy: 0.9648\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0654 - accuracy: 0.9863 - val_loss: 0.2783 - val_accuracy: 0.9545\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0577 - accuracy: 0.9875 - val_loss: 0.1916 - val_accuracy: 0.9804\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0647 - accuracy: 0.9857 - val_loss: 0.1946 - val_accuracy: 0.9787\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0590 - accuracy: 0.9883 - val_loss: 0.1792 - val_accuracy: 0.9811\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0641 - accuracy: 0.9854 - val_loss: 0.1801 - val_accuracy: 0.9835\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0501 - accuracy: 0.9896 - val_loss: 0.2034 - val_accuracy: 0.9813\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0592 - accuracy: 0.9869 - val_loss: 0.1806 - val_accuracy: 0.9839\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0562 - accuracy: 0.9880 - val_loss: 0.1763 - val_accuracy: 0.9855\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0515 - accuracy: 0.9892 - val_loss: 0.2081 - val_accuracy: 0.9729\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0589 - accuracy: 0.9870 - val_loss: 0.2526 - val_accuracy: 0.9652\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0500 - accuracy: 0.9898 - val_loss: 0.1822 - val_accuracy: 0.9802\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 3.1280 - accuracy: 0.4050 - val_loss: 1.9103 - val_accuracy: 0.6752\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1919 - accuracy: 0.7761 - val_loss: 1.1326 - val_accuracy: 0.8114\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7059 - accuracy: 0.8475 - val_loss: 0.9068 - val_accuracy: 0.8222\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4882 - accuracy: 0.8890 - val_loss: 0.6615 - val_accuracy: 0.8801\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3727 - accuracy: 0.9120 - val_loss: 0.5164 - val_accuracy: 0.9254\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2984 - accuracy: 0.9296 - val_loss: 0.5141 - val_accuracy: 0.9096\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2591 - accuracy: 0.9402 - val_loss: 0.4226 - val_accuracy: 0.9360\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2189 - accuracy: 0.9493 - val_loss: 0.3912 - val_accuracy: 0.9289\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2039 - accuracy: 0.9530 - val_loss: 0.3307 - val_accuracy: 0.9492\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1862 - accuracy: 0.9557 - val_loss: 0.3312 - val_accuracy: 0.9468\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1694 - accuracy: 0.9606 - val_loss: 0.3583 - val_accuracy: 0.9369\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1625 - accuracy: 0.9616 - val_loss: 0.3080 - val_accuracy: 0.9490\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1471 - accuracy: 0.9663 - val_loss: 0.3513 - val_accuracy: 0.9410\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1428 - accuracy: 0.9685 - val_loss: 0.3103 - val_accuracy: 0.9457\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1318 - accuracy: 0.9702 - val_loss: 0.2698 - val_accuracy: 0.9628\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1230 - accuracy: 0.9715 - val_loss: 0.2899 - val_accuracy: 0.9514\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1329 - accuracy: 0.9693 - val_loss: 0.2393 - val_accuracy: 0.9661\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1117 - accuracy: 0.9750 - val_loss: 0.2521 - val_accuracy: 0.9657\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1141 - accuracy: 0.9743 - val_loss: 0.2786 - val_accuracy: 0.9553\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1081 - accuracy: 0.9766 - val_loss: 0.2558 - val_accuracy: 0.9613\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1069 - accuracy: 0.9785 - val_loss: 0.2458 - val_accuracy: 0.9659\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1066 - accuracy: 0.9777 - val_loss: 0.2393 - val_accuracy: 0.9705\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1006 - accuracy: 0.9784 - val_loss: 0.2183 - val_accuracy: 0.9716\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0945 - accuracy: 0.9794 - val_loss: 0.2347 - val_accuracy: 0.9663\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0967 - accuracy: 0.9785 - val_loss: 0.2567 - val_accuracy: 0.9611\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0938 - accuracy: 0.9792 - val_loss: 0.2175 - val_accuracy: 0.9804\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0850 - accuracy: 0.9826 - val_loss: 0.2291 - val_accuracy: 0.9696\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0844 - accuracy: 0.9816 - val_loss: 0.2108 - val_accuracy: 0.9743\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0997 - accuracy: 0.9768 - val_loss: 0.2913 - val_accuracy: 0.9523\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0780 - accuracy: 0.9842 - val_loss: 0.2164 - val_accuracy: 0.9655\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0762 - accuracy: 0.9846 - val_loss: 0.2453 - val_accuracy: 0.9641\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9809 - val_loss: 0.1925 - val_accuracy: 0.9802\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0709 - accuracy: 0.9856 - val_loss: 0.1997 - val_accuracy: 0.9773\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0780 - accuracy: 0.9846 - val_loss: 0.2085 - val_accuracy: 0.9749\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0742 - accuracy: 0.9848 - val_loss: 0.2069 - val_accuracy: 0.9784\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0804 - accuracy: 0.9836 - val_loss: 0.2265 - val_accuracy: 0.9663\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0771 - accuracy: 0.9844 - val_loss: 0.2041 - val_accuracy: 0.9769\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0697 - accuracy: 0.9849 - val_loss: 0.2569 - val_accuracy: 0.9600\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0680 - accuracy: 0.9870 - val_loss: 0.2003 - val_accuracy: 0.9793\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0722 - accuracy: 0.9855 - val_loss: 0.2506 - val_accuracy: 0.9593\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0632 - accuracy: 0.9891 - val_loss: 0.2092 - val_accuracy: 0.9776\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0666 - accuracy: 0.9862 - val_loss: 0.2259 - val_accuracy: 0.9685\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0669 - accuracy: 0.9866 - val_loss: 0.2159 - val_accuracy: 0.9725\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0660 - accuracy: 0.9859 - val_loss: 0.1786 - val_accuracy: 0.9787\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0622 - accuracy: 0.9875 - val_loss: 0.2120 - val_accuracy: 0.9692\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0622 - accuracy: 0.9870 - val_loss: 0.1816 - val_accuracy: 0.9780\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0628 - accuracy: 0.9882 - val_loss: 0.2625 - val_accuracy: 0.9613\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0568 - accuracy: 0.9892 - val_loss: 0.1773 - val_accuracy: 0.9822\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0619 - accuracy: 0.9868 - val_loss: 0.1850 - val_accuracy: 0.9798\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0633 - accuracy: 0.9872 - val_loss: 0.1786 - val_accuracy: 0.9826\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0532 - accuracy: 0.9899 - val_loss: 0.1891 - val_accuracy: 0.9826\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0580 - accuracy: 0.9889 - val_loss: 0.1858 - val_accuracy: 0.9787\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0599 - accuracy: 0.9876 - val_loss: 0.1761 - val_accuracy: 0.9811\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0526 - accuracy: 0.9901 - val_loss: 0.1708 - val_accuracy: 0.9857\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0580 - accuracy: 0.9874 - val_loss: 0.1851 - val_accuracy: 0.9769\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0544 - accuracy: 0.9894 - val_loss: 0.1975 - val_accuracy: 0.9804\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0543 - accuracy: 0.9880 - val_loss: 0.1844 - val_accuracy: 0.9776\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0553 - accuracy: 0.9878 - val_loss: 0.2158 - val_accuracy: 0.9749\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0527 - accuracy: 0.9881 - val_loss: 0.1748 - val_accuracy: 0.9842\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0460 - accuracy: 0.9910 - val_loss: 0.1880 - val_accuracy: 0.9831\n","Average Validation Accuracy: 0.9883092641830444\n","Average Validation Loss: 0.09394622221589088\n","Average Test Accuracy: 0.9892017245292664\n","------------------------------------------------------------------------\n"]}],"source":["# Define the number of folds for k-fold cross-validation\n","k = 2\n","\n","# Define the cross-validation method\n","cv_method = StratifiedKFold(n_splits=k)\n","\n","# Initialize the list to store the history, train & validation(accuracy & loss) for each model\n","models = []\n","model_history = []\n","model_accuracy = []\n","model_train_acc = []\n","model_train_loss = []\n","model_val_acc = []\n","model_val_loss = []\n","\n","for i in range(1, 21):\n","\n","  models_fold = []\n","  hist = []\n","  train_accuracy = []\n","  train_loss = []\n","  val_accuracy = []\n","  val_loss = []\n","  test_accuracy = []\n","\n","  print(\"\\nNumber of input features:\", i)\n","\n","  # Select the input features from the input data\n","  X_train_selected = X_train[:, :i]\n","  X_test_selected = X_test[:, :i]\n","\n","  X_train_selected = X_train_selected.reshape(27543, i, 1, 1)\n","  X_test_selected = X_test_selected.reshape(13567, i, 1, 1)\n","\n","  # Loop over the folds\n","  for fold, (train_index, val_index) in enumerate(cv_method.split(X_train_selected, y_train)):\n","\n","    print(\"Fold:\", fold+1)\n","\n","    # Build the model\n","    model = Sequential()\n","    model.add(Conv2D(60, kernel_size=(5,5), activation='relu',bias_initializer='normal', input_shape=X_train_selected.shape[1:], padding= \"same\")) #keeps the output size same as input size (prevent down or upsampling)\n","    model.add(MaxPooling2D(pool_size=(1,1))) #pool size 2 error, because 1 (1 feature) minus 2 (pool size) is negative)\n","    model.add(Flatten())\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(373, kernel_initializer='normal', activation='softmax'))\n","\n","    # compile model\n","    model.compile(loss = \"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy']) \n","\n","    # # Fit the model to the training data for the current fold\n","    history = model.fit(X_train_selected[train_index], to_categorical(y_train_enc[train_index], num_classes=373), batch_size = 5, epochs = 60, verbose = 1, validation_split = 0.33)\n","\n","    # Evaluate the model on the validation data for the current fold\n","    val_scores = model.evaluate(X_train_selected[val_index], to_categorical(y_train_enc[val_index],num_classes=373), verbose=0)\n","    val_accuracy.append(val_scores[1])\n","    val_loss.append(val_scores[0])\n","\n","    # Evaluate the model on the test data for the current fold\n","    test_scores = model.evaluate(X_test_selected, to_categorical(y_test_enc, num_classes=373), verbose=0)\n","    test_accuracy.append(test_scores[1])\n","\n","    # add the model to the list of models\n","    models_fold.append(model)\n","    hist.append(history)\n","\n","    # store the training accuracy and loss for each fold\n","    train_accuracy.append(history.history['accuracy'])\n","    train_loss.append(history.history['loss'])\n","  \n","  # Calculate the average test and validation accuracy and loss across all folds\n","  avg_test_acc = sum(test_accuracy) / len(test_accuracy)\n","  avg_val_acc = sum(val_accuracy) / len(val_accuracy)\n","  avg_val_loss = sum(val_loss) / len(val_loss)\n","\n","  # Print the average validation and test accuracy and loss\n","  print(\"Average Validation Accuracy:\", avg_val_acc)\n","  print(\"Average Validation Loss:\",avg_val_loss)\n","  print(\"Average Test Accuracy:\", avg_test_acc)\n","\n","  best_fold_index = test_accuracy.index(max(test_accuracy))\n","  model_accuracy.append(test_accuracy[best_fold_index])\n","  models.append(models_fold[best_fold_index])\n","  model_history.append(hist[best_fold_index])\n","  model_train_acc.append(train_accuracy[best_fold_index])\n","  model_train_loss.append(train_loss[best_fold_index])\n","  model_val_acc.append(val_accuracy[best_fold_index])\n","  model_val_loss.append(val_loss[best_fold_index])\n","  print('------------------------------------------------------------------------')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZG29fO-C4TJH"},"outputs":[],"source":["#to show the no of input features and its corresponding model accuracy\n","model_list = []\n","\n","#Iterate through each model's accuracy \n","for i in range (len(model_accuracy)):\n","    #get the number of input features for the current model\n","    no_features = i + 1\n","\n","    #round the model accuries to 3 d.p.\n","    rounded_model_acc = round(model_accuracy[i], 3)\n","    \n","    model_list.append([no_features, rounded_model_acc])\n","\n","models_df = pd.DataFrame(model_list, columns=[\"No of input features\", \"Model accuracy\"])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"M1aBlP3GmZ9o"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Final Test Accuracy: 0.9904916286468506\n"]}],"source":["# Select the final model based on the max test accuracy across all models\n","\n","best_model_index = model_accuracy.index(max(model_accuracy))\n","\n","best_model = models[best_model_index]\n","best_model_history = model_history[best_model_index]\n","best_model_train_acc = model_train_acc[best_model_index]\n","best_model_train_loss = model_train_loss[best_model_index]\n","best_model_val_acc = model_val_acc[best_model_index]\n","best_model_val_loss = model_val_loss[best_model_index]\n","\n","# summarize history for accuracy  \n","plt.subplot(211)  \n","plt.plot(best_model_history.history['accuracy'])  \n","plt.plot(best_model_history.history['val_accuracy'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='lower right')  \n","\n","# summarize history for loss\n","plt.subplot(212)  \n","plt.plot(best_model_history.history['loss'])  \n","plt.plot(best_model_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='upper right')  \n","plt.subplots_adjust(hspace=0.7)\n","\n","plt.show() \n","\n","print(\"Final Test Accuracy:\", model_accuracy[best_model_index])"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"RMkWBkrYmZ9s"},"outputs":[{"name":"stdout","output_type":"stream","text":["424/424 [==============================] - 1s 2ms/step\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       591\n","           1       1.00      1.00      1.00       430\n","           2       1.00      1.00      1.00       419\n","           3       1.00      1.00      1.00       384\n","           4       1.00      1.00      1.00       339\n","           5       1.00      1.00      1.00       342\n","           6       1.00      1.00      1.00       310\n","           7       1.00      1.00      1.00       325\n","           8       1.00      1.00      1.00       294\n","           9       1.00      1.00      1.00       269\n","          10       1.00      1.00      1.00       296\n","          11       0.99      1.00      0.99       258\n","          12       1.00      1.00      1.00       247\n","          13       1.00      1.00      1.00       237\n","          14       0.99      1.00      0.99       239\n","          15       1.00      1.00      1.00       235\n","          16       1.00      1.00      1.00       213\n","          17       1.00      1.00      1.00       202\n","          18       1.00      1.00      1.00       196\n","          19       1.00      1.00      1.00       181\n","          20       1.00      1.00      1.00       177\n","          21       1.00      1.00      1.00       177\n","          22       1.00      1.00      1.00       155\n","          23       1.00      1.00      1.00       155\n","          24       1.00      1.00      1.00       144\n","          25       1.00      1.00      1.00       126\n","          26       1.00      1.00      1.00       121\n","          27       1.00      1.00      1.00       108\n","          28       1.00      1.00      1.00        95\n","          29       1.00      1.00      1.00       102\n","          30       1.00      1.00      1.00       106\n","          31       1.00      1.00      1.00        86\n","          32       1.00      1.00      1.00       108\n","          33       0.98      1.00      0.99        88\n","          34       1.00      1.00      1.00       102\n","          35       1.00      1.00      1.00        88\n","          36       1.00      1.00      1.00        83\n","          37       1.00      1.00      1.00        93\n","          38       1.00      1.00      1.00        76\n","          39       1.00      1.00      1.00        85\n","          40       1.00      1.00      1.00        86\n","          41       1.00      1.00      1.00        85\n","          42       1.00      1.00      1.00        68\n","          43       1.00      1.00      1.00        75\n","          44       1.00      1.00      1.00        71\n","          45       0.85      1.00      0.92        58\n","          46       1.00      1.00      1.00        71\n","          47       0.93      0.74      0.82        57\n","          48       1.00      1.00      1.00        67\n","          49       0.84      1.00      0.91        47\n","          50       1.00      1.00      1.00        47\n","          51       1.00      1.00      1.00        48\n","          52       0.96      1.00      0.98        43\n","          53       1.00      1.00      1.00        51\n","          54       1.00      1.00      1.00        44\n","          55       0.98      1.00      0.99        51\n","          56       1.00      1.00      1.00        45\n","          57       1.00      1.00      1.00        44\n","          58       1.00      1.00      1.00        41\n","          59       1.00      1.00      1.00        52\n","          60       1.00      1.00      1.00        41\n","          61       1.00      1.00      1.00        37\n","          62       1.00      1.00      1.00        43\n","          63       1.00      1.00      1.00        43\n","          64       1.00      1.00      1.00        42\n","          65       1.00      1.00      1.00        46\n","          66       1.00      1.00      1.00        43\n","          67       1.00      1.00      1.00        44\n","          68       0.93      1.00      0.97        43\n","          69       1.00      1.00      1.00        40\n","          70       1.00      1.00      1.00        38\n","          71       1.00      1.00      1.00        33\n","          72       1.00      1.00      1.00        45\n","          73       1.00      1.00      1.00        38\n","          74       1.00      1.00      1.00        42\n","          75       1.00      1.00      1.00        39\n","          76       0.94      1.00      0.97        30\n","          77       1.00      1.00      1.00        28\n","          78       1.00      0.96      0.98        28\n","          79       1.00      1.00      1.00        32\n","          80       1.00      1.00      1.00        35\n","          81       1.00      1.00      1.00        33\n","          82       1.00      1.00      1.00        31\n","          83       1.00      1.00      1.00        39\n","          84       1.00      1.00      1.00        27\n","          85       1.00      1.00      1.00        36\n","          86       1.00      1.00      1.00        31\n","          87       1.00      1.00      1.00        20\n","          88       1.00      1.00      1.00        28\n","          89       1.00      1.00      1.00        33\n","          90       1.00      1.00      1.00        24\n","          91       1.00      1.00      1.00        22\n","          92       1.00      1.00      1.00        26\n","          93       1.00      1.00      1.00        35\n","          94       1.00      1.00      1.00        23\n","          95       1.00      1.00      1.00        27\n","          96       0.87      1.00      0.93        27\n","          97       1.00      1.00      1.00        28\n","          98       0.89      1.00      0.94        16\n","          99       1.00      1.00      1.00        35\n","         100       1.00      1.00      1.00        28\n","         101       1.00      1.00      1.00        25\n","         102       1.00      1.00      1.00        26\n","         103       1.00      1.00      1.00        26\n","         104       1.00      1.00      1.00        33\n","         105       0.67      1.00      0.80        24\n","         106       1.00      1.00      1.00        22\n","         107       0.90      1.00      0.95        26\n","         108       1.00      1.00      1.00        25\n","         109       1.00      1.00      1.00        18\n","         110       1.00      1.00      1.00        20\n","         111       0.68      1.00      0.81        23\n","         112       1.00      1.00      1.00        26\n","         113       1.00      1.00      1.00        16\n","         114       1.00      1.00      1.00        25\n","         115       1.00      1.00      1.00        18\n","         116       1.00      1.00      1.00        16\n","         117       1.00      1.00      1.00        19\n","         118       1.00      1.00      1.00        26\n","         119       1.00      1.00      1.00        22\n","         120       1.00      1.00      1.00        19\n","         121       1.00      1.00      1.00        20\n","         122       1.00      1.00      1.00        18\n","         123       1.00      1.00      1.00        21\n","         124       1.00      1.00      1.00        15\n","         125       1.00      1.00      1.00        14\n","         126       1.00      1.00      1.00        22\n","         127       1.00      1.00      1.00        26\n","         128       1.00      1.00      1.00        27\n","         129       1.00      1.00      1.00        17\n","         130       1.00      1.00      1.00        18\n","         131       1.00      1.00      1.00        18\n","         132       1.00      1.00      1.00        20\n","         133       1.00      1.00      1.00        11\n","         134       1.00      1.00      1.00        23\n","         135       1.00      1.00      1.00        14\n","         136       1.00      1.00      1.00        14\n","         137       1.00      1.00      1.00        20\n","         138       1.00      1.00      1.00        14\n","         139       1.00      1.00      1.00        19\n","         140       1.00      1.00      1.00        23\n","         141       1.00      1.00      1.00        16\n","         142       1.00      1.00      1.00        23\n","         143       1.00      1.00      1.00        13\n","         144       1.00      1.00      1.00        22\n","         145       1.00      1.00      1.00        17\n","         146       1.00      1.00      1.00        16\n","         147       1.00      1.00      1.00        24\n","         148       1.00      1.00      1.00        19\n","         149       1.00      1.00      1.00        15\n","         150       1.00      1.00      1.00        24\n","         151       1.00      1.00      1.00        20\n","         152       1.00      1.00      1.00        11\n","         153       1.00      1.00      1.00        19\n","         154       1.00      1.00      1.00        11\n","         155       1.00      1.00      1.00        17\n","         156       1.00      1.00      1.00        12\n","         157       1.00      1.00      1.00        18\n","         158       1.00      1.00      1.00        20\n","         159       1.00      1.00      1.00        20\n","         160       1.00      1.00      1.00        18\n","         161       1.00      1.00      1.00        16\n","         162       1.00      1.00      1.00        15\n","         163       1.00      1.00      1.00        15\n","         164       1.00      1.00      1.00        13\n","         165       1.00      0.84      0.91        19\n","         166       1.00      1.00      1.00        11\n","         167       1.00      1.00      1.00        15\n","         168       1.00      1.00      1.00        18\n","         169       1.00      1.00      1.00        21\n","         170       1.00      1.00      1.00        11\n","         171       1.00      1.00      1.00         9\n","         172       1.00      1.00      1.00        11\n","         173       1.00      1.00      1.00        16\n","         174       1.00      1.00      1.00        10\n","         175       1.00      1.00      1.00        10\n","         176       1.00      1.00      1.00        11\n","         177       0.00      0.00      0.00        15\n","         178       1.00      1.00      1.00        11\n","         179       1.00      1.00      1.00        15\n","         180       1.00      1.00      1.00        13\n","         181       1.00      1.00      1.00        15\n","         182       1.00      1.00      1.00         9\n","         183       0.69      0.92      0.79        12\n","         184       1.00      1.00      1.00        16\n","         185       1.00      1.00      1.00         8\n","         186       1.00      1.00      1.00        15\n","         187       1.00      1.00      1.00        15\n","         188       1.00      0.85      0.92        13\n","         189       1.00      1.00      1.00        14\n","         190       1.00      1.00      1.00         9\n","         191       1.00      1.00      1.00         4\n","         192       1.00      1.00      1.00         9\n","         193       1.00      1.00      1.00        11\n","         194       1.00      1.00      1.00        10\n","         195       1.00      1.00      1.00        17\n","         196       1.00      1.00      1.00        12\n","         197       1.00      1.00      1.00        14\n","         198       1.00      1.00      1.00         7\n","         199       1.00      1.00      1.00         7\n","         200       1.00      1.00      1.00         9\n","         201       1.00      1.00      1.00         6\n","         202       1.00      1.00      1.00        14\n","         203       1.00      1.00      1.00        11\n","         204       1.00      1.00      1.00        12\n","         205       1.00      1.00      1.00        14\n","         206       0.67      0.33      0.44         6\n","         207       1.00      1.00      1.00        12\n","         208       1.00      1.00      1.00         7\n","         209       1.00      0.86      0.92         7\n","         210       1.00      1.00      1.00        19\n","         211       1.00      1.00      1.00         7\n","         212       1.00      1.00      1.00         6\n","         213       1.00      1.00      1.00        11\n","         214       1.00      1.00      1.00        12\n","         215       1.00      1.00      1.00         7\n","         216       1.00      1.00      1.00         9\n","         217       1.00      1.00      1.00         5\n","         218       1.00      1.00      1.00         6\n","         219       1.00      1.00      1.00        12\n","         220       1.00      1.00      1.00         8\n","         221       0.50      0.22      0.31         9\n","         222       0.22      0.50      0.31         4\n","         223       1.00      1.00      1.00        14\n","         224       1.00      1.00      1.00        10\n","         225       1.00      1.00      1.00        12\n","         226       1.00      1.00      1.00         4\n","         227       1.00      1.00      1.00        13\n","         228       0.00      0.00      0.00         5\n","         229       1.00      1.00      1.00        11\n","         230       1.00      1.00      1.00         6\n","         231       1.00      1.00      1.00        13\n","         232       0.75      0.38      0.50         8\n","         233       0.35      1.00      0.51         9\n","         234       0.00      0.00      0.00         6\n","         235       1.00      1.00      1.00         9\n","         236       1.00      1.00      1.00         7\n","         237       1.00      0.80      0.89        10\n","         238       1.00      1.00      1.00        10\n","         239       1.00      1.00      1.00         8\n","         240       1.00      1.00      1.00         8\n","         241       1.00      1.00      1.00         8\n","         242       1.00      1.00      1.00         7\n","         243       1.00      1.00      1.00         4\n","         244       1.00      1.00      1.00         9\n","         245       1.00      1.00      1.00         7\n","         246       1.00      1.00      1.00         5\n","         247       1.00      1.00      1.00        12\n","         248       1.00      1.00      1.00        10\n","         249       1.00      1.00      1.00         5\n","         250       1.00      1.00      1.00        11\n","         251       0.88      1.00      0.93         7\n","         252       1.00      1.00      1.00         6\n","         253       1.00      1.00      1.00         2\n","         254       1.00      1.00      1.00         6\n","         255       1.00      1.00      1.00         7\n","         256       1.00      1.00      1.00         7\n","         257       0.80      1.00      0.89         4\n","         258       1.00      0.33      0.50         3\n","         259       1.00      1.00      1.00        10\n","         260       1.00      1.00      1.00         8\n","         261       1.00      0.67      0.80         9\n","         262       1.00      1.00      1.00         7\n","         263       1.00      1.00      1.00         9\n","         264       1.00      1.00      1.00         5\n","         265       0.00      0.00      0.00         9\n","         266       0.62      1.00      0.77        10\n","         267       1.00      1.00      1.00         7\n","         268       1.00      1.00      1.00         8\n","         269       1.00      1.00      1.00         6\n","         270       1.00      1.00      1.00         6\n","         271       1.00      1.00      1.00         3\n","         272       1.00      1.00      1.00         9\n","         273       0.44      1.00      0.62         4\n","         274       1.00      1.00      1.00         5\n","         275       1.00      1.00      1.00        10\n","         276       1.00      1.00      1.00         4\n","         277       1.00      1.00      1.00         7\n","         278       0.00      0.00      0.00         4\n","         279       1.00      1.00      1.00         3\n","         280       1.00      1.00      1.00        11\n","         281       0.00      0.00      0.00         5\n","         282       1.00      1.00      1.00         6\n","         283       1.00      1.00      1.00         9\n","         284       1.00      1.00      1.00         7\n","         285       1.00      1.00      1.00         6\n","         286       1.00      1.00      1.00         7\n","         287       1.00      1.00      1.00         2\n","         288       1.00      1.00      1.00         6\n","         289       1.00      1.00      1.00         4\n","         290       1.00      1.00      1.00         7\n","         291       1.00      1.00      1.00         5\n","         292       0.67      1.00      0.80         6\n","         293       1.00      1.00      1.00         8\n","         294       0.55      1.00      0.71         6\n","         295       1.00      0.88      0.93         8\n","         296       0.67      0.67      0.67         3\n","         297       1.00      1.00      1.00         7\n","         298       1.00      1.00      1.00         8\n","         299       1.00      1.00      1.00         5\n","         300       1.00      1.00      1.00         6\n","         301       1.00      1.00      1.00         4\n","         302       1.00      1.00      1.00         3\n","         303       0.83      1.00      0.91         5\n","         304       1.00      1.00      1.00         2\n","         305       0.00      0.00      0.00         5\n","         306       1.00      1.00      1.00         4\n","         307       1.00      1.00      1.00         4\n","         308       1.00      1.00      1.00         9\n","         309       1.00      1.00      1.00         7\n","         310       1.00      1.00      1.00         6\n","         311       1.00      1.00      1.00         8\n","         312       1.00      1.00      1.00        10\n","         313       1.00      1.00      1.00         6\n","         314       1.00      1.00      1.00         4\n","         315       1.00      1.00      1.00         6\n","         316       1.00      1.00      1.00         8\n","         317       0.00      0.00      0.00         8\n","         318       1.00      1.00      1.00         6\n","         319       1.00      1.00      1.00         7\n","         320       1.00      1.00      1.00         7\n","         321       1.00      1.00      1.00         4\n","         322       1.00      1.00      1.00         4\n","         323       1.00      1.00      1.00         4\n","         324       1.00      1.00      1.00         3\n","         325       1.00      1.00      1.00         2\n","         326       1.00      1.00      1.00         7\n","         327       1.00      1.00      1.00         6\n","         328       1.00      1.00      1.00         1\n","         329       0.00      0.00      0.00         6\n","         330       1.00      1.00      1.00         3\n","         331       1.00      1.00      1.00         6\n","         332       1.00      1.00      1.00         3\n","         333       0.00      0.00      0.00         3\n","         334       1.00      0.62      0.77         8\n","         335       1.00      1.00      1.00         4\n","         336       1.00      1.00      1.00         4\n","         337       1.00      1.00      1.00         7\n","         338       1.00      1.00      1.00         7\n","         339       1.00      1.00      1.00         6\n","         340       1.00      1.00      1.00         2\n","         341       0.57      1.00      0.73         4\n","         342       1.00      1.00      1.00         7\n","         343       1.00      1.00      1.00         2\n","         344       1.00      1.00      1.00         2\n","         345       1.00      1.00      1.00         4\n","         346       1.00      1.00      1.00         4\n","         347       1.00      1.00      1.00         3\n","         348       1.00      1.00      1.00         4\n","         349       1.00      1.00      1.00         4\n","         350       1.00      1.00      1.00         5\n","         351       1.00      1.00      1.00         5\n","         352       1.00      1.00      1.00         4\n","         353       0.00      0.00      0.00         1\n","         354       1.00      1.00      1.00         6\n","         355       1.00      1.00      1.00         1\n","         356       1.00      1.00      1.00         4\n","         357       1.00      1.00      1.00         1\n","         358       1.00      1.00      1.00         3\n","         359       1.00      1.00      1.00         4\n","         360       1.00      1.00      1.00         3\n","         361       1.00      1.00      1.00         2\n","         362       1.00      1.00      1.00         3\n","         363       1.00      1.00      1.00         1\n","         364       1.00      1.00      1.00         2\n","         365       0.00      0.00      0.00         3\n","         367       1.00      1.00      1.00         2\n","         368       1.00      1.00      1.00         3\n","         369       0.00      0.00      0.00         4\n","         370       1.00      1.00      1.00         3\n","         371       0.00      0.00      0.00         2\n","         372       1.00      1.00      1.00         3\n","\n","    accuracy                           0.99     13567\n","   macro avg       0.94      0.95      0.94     13567\n","weighted avg       0.99      0.99      0.99     13567\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["#Select only the optimal number of input features for X_test\n","X_test = X_test[:,:(best_model_index+1)]\n","\n","X_test = X_test.reshape(13567, best_model_index+1, 1, 1)\n","\n","# Evaluate the best model on the test data\n","y_pred = best_model.predict(X_test)\n","\n","# np.argmax() is used to convert the one-hot encoded predictions and test labels to class labels.\n","y_pred_label = np.argmax(y_pred, axis = 1)\n","\n","# Print the classification report\n","print(\"Classification report:\\n\", classification_report(y_test_enc, y_pred_label))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"FeifaQpJmZ9u"},"outputs":[{"name":"stdout","output_type":"stream","text":["           OsID  True Class  Predicted Class  True/False\n","0  Os07g0476500         331              331        True\n","1  Os01g0173100         161              161        True\n","2  Os01g0686800          17               17        True\n","3  Os04g0107900          34               34        True\n","4  Os04g0517100           7                7        True\n"]}],"source":["# extract class labels from test data\n","class_test = y_test_enc\n","\n","# Invert OsID_labels dictionary\n","inv_OsID_labels = {v: k for k, v in OsID_labels.items()}\n","\n","# map OsID values to the class labels\n","OsID_test = [inv_OsID_labels.get(value, 'Unknown') for value in class_test]\n","\n","# create dataframe with OsID, true class, predicted class, and true/false columns\n","results = pd.DataFrame({\n","    'OsID': OsID_test,\n","    'True Class': y_test_enc,\n","    'Predicted Class': y_pred_label,\n","    'True/False': class_test == y_pred_label\n","})\n","\n","# display dataframe\n","print(results.head())\n","\n","# save results_df to a CSV file\n","results.to_csv('MLP_gene classification.csv', index=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"HcBceHUp0-TI"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>No of input features</th>\n","      <th>Model accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.484</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.853</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.916</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.960</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.970</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.987</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.987</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>0.987</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>0.988</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0.985</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>0.987</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0.990</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.987</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>0.986</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>0.986</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>0.987</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>0.988</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>0.990</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    No of input features  Model accuracy\n","0                      1           0.484\n","1                      2           0.853\n","2                      3           0.916\n","3                      4           0.960\n","4                      5           0.970\n","5                      6           0.981\n","6                      7           0.987\n","7                      8           0.987\n","8                      9           0.987\n","9                     10           0.988\n","10                    11           0.985\n","11                    12           0.987\n","12                    13           0.990\n","13                    14           0.987\n","14                    15           0.986\n","15                    16           0.986\n","16                    17           0.981\n","17                    18           0.987\n","18                    19           0.988\n","19                    20           0.990"]},"metadata":{},"output_type":"display_data"}],"source":["display(models_df)"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
