{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8877,"status":"ok","timestamp":1682739001121,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"UsLpi_0MmZ9Z"},"outputs":[],"source":["from itertools import cycle\n","\n","import numpy as np\n","import pandas as pd \n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Model ,Sequential #for CNN\n","from keras.layers import Dense \n","from sklearn.model_selection import KFold\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from keras.layers import Conv2D, Input, MaxPooling2D, Dropout, Flatten, Dense, Activation\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.model_selection import StratifiedKFold\n","from keras import regularizers"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1682739001122,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"B95hUV4pmZ9g"},"outputs":[],"source":["#fixed random seed for reproducibility \n","np.random.seed(0)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":347489,"status":"ok","timestamp":1682739348597,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"EECGNCI3mZ9i","outputId":"3496a6d0-00a0-4c09-e18a-771b7fc724a0"},"outputs":[],"source":["# load dataset (input variables = X, output variables = Y)\n","df = pd.read_csv(\"TrainingData.csv\")\n","\n","#count the number of occurances for each osID\n","OsID_counts = df['OsID'].value_counts()\n","\n","#filter for osIDs that have 10 or more occurances\n","OsID_counts_filtered = OsID_counts[OsID_counts >= 10]\n","\n","#assign a label for each osID \n","OsID_labels = {}\n","class_no = 1\n","for osID in OsID_counts_filtered.index:\n","    OsID_labels[osID] = class_no\n","    class_no +=1\n","\n","#filter the dataset with osID that contain 10 or more occurances\n","dataGene = df[df['OsID'].isin(OsID_counts_filtered.index)]\n","\n","dataGene = dataGene.drop(['Class', 'Trait'],axis=1)\n","\n","# Add a new column 'class' to the filtered dataset\n","dataGene['class'] = dataGene['OsID'].map(OsID_labels)\n","\n","#print(\"Summary of dataGene:\\n\",dataGene.describe())"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":21,"status":"ok","timestamp":1682739348598,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"Vuf_bBJBUC1h","outputId":"1241a9b0-655f-41d7-e7c7-2a75b47ca6af"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X:\n"," (41110, 20)\n","Shape of Y:\n"," (41110,)\n","class\n","1.0      1800\n","2.0      1296\n","3.0      1260\n","4.0      1218\n","5.0      1026\n","6.0      1008\n","7.0       930\n","8.0       912\n","9.0       880\n","10.0      798\n","11.0      792\n","12.0      759\n","13.0      729\n","14.0      720\n","15.0      702\n","16.0      693\n","17.0      672\n","18.0      640\n","19.0      625\n","20.0      570\n","21.0      546\n","22.0      506\n","23.0      483\n","24.0      448\n","25.0      432\n","26.0      384\n","27.0      360\n","28.0      360\n","29.0      320\n","30.0      312\n","         ... \n","344.0      12\n","345.0      12\n","346.0      12\n","347.0      12\n","348.0      12\n","349.0      12\n","350.0      12\n","351.0      12\n","352.0      12\n","353.0      12\n","354.0      12\n","355.0      12\n","356.0      11\n","357.0      11\n","358.0      11\n","359.0      11\n","360.0      11\n","361.0      11\n","362.0      10\n","363.0      10\n","364.0      10\n","365.0      10\n","366.0      10\n","367.0      10\n","368.0      10\n","369.0      10\n","370.0      10\n","371.0      10\n","372.0      10\n","373.0      10\n","Length: 373, dtype: int64\n"]}],"source":["X = dataGene.drop(['class','OsID'], axis=1) # exclude class & OsID column\n","Y = dataGene['class']\n","\n","#input feature names in order of descending importance scores in MI feature selection method\n","feature_names = ['CoExpression', 'PCC', 'PPI', 'Root10DaysSeedling', 'Leaf21DaysSeedling', \n","                 'Leaf45DaysOldPlant', 'log_2FoldChange', 'ET', 'Shoot10DaysSeedling', 'Shoot3DaysSeedling', \n","                 'Shoot35DaysSeedling', 'Shoot14DaysSeedling', 'Root17DaysSeedling', 'Shoot17DaysSeedling', 'Shoot21DaysSeedling', \n","                 'Root24DaysSeedling', 'Root14DaysSeedling', 'Root21DaysSeedling', 'Root52DaysSeedling', 'Root35DaysSeedling']\n","\n","X_fs = X.reindex(columns=feature_names)\n","\n","print(\"Shape of X:\\n\",X_fs.shape)\n","print(\"Shape of Y:\\n\",Y.shape)\n","\n","# Statistical summary of the variables\n","#print(\"Summary of X:\\n\",X_fs.describe())\n","#print(\"Summary of Y:\\n\",Y.describe())\n","\n","# Check for class imbalance\n","print(df.groupby(Y).size())\n","\n","# change both input and target variables datatype to ndarray\n","X_fs = X_fs.values # 2-D array\n","\n","# select target variable \n","\n","Y = Y.values #1-D array\n","Y = Y.reshape(-1, 1)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":858,"status":"ok","timestamp":1682739349443,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"W5zIyx8RVDJu","outputId":"80dbefb5-e549-4900-b72d-18b5ec6be821"},"outputs":[{"name":"stdout","output_type":"stream","text":["Class=0, n=1800 (4.378%)\n","Class=1, n=1296 (3.153%)\n","Class=2, n=1260 (3.065%)\n","Class=3, n=1218 (2.963%)\n","Class=4, n=1026 (2.496%)\n","Class=5, n=1008 (2.452%)\n","Class=6, n=930 (2.262%)\n","Class=7, n=912 (2.218%)\n","Class=8, n=880 (2.141%)\n","Class=9, n=798 (1.941%)\n","Class=10, n=792 (1.927%)\n","Class=11, n=759 (1.846%)\n","Class=12, n=729 (1.773%)\n","Class=13, n=720 (1.751%)\n","Class=14, n=702 (1.708%)\n","Class=15, n=693 (1.686%)\n","Class=16, n=672 (1.635%)\n","Class=17, n=640 (1.557%)\n","Class=18, n=625 (1.520%)\n","Class=19, n=570 (1.387%)\n","Class=20, n=546 (1.328%)\n","Class=21, n=506 (1.231%)\n","Class=22, n=483 (1.175%)\n","Class=23, n=448 (1.090%)\n","Class=24, n=432 (1.051%)\n","Class=25, n=384 (0.934%)\n","Class=26, n=360 (0.876%)\n","Class=27, n=360 (0.876%)\n","Class=28, n=320 (0.778%)\n","Class=29, n=312 (0.759%)\n","Class=30, n=312 (0.759%)\n","Class=31, n=306 (0.744%)\n","Class=32, n=304 (0.739%)\n","Class=33, n=299 (0.727%)\n","Class=34, n=297 (0.722%)\n","Class=35, n=296 (0.720%)\n","Class=36, n=280 (0.681%)\n","Class=37, n=264 (0.642%)\n","Class=38, n=260 (0.632%)\n","Class=39, n=253 (0.615%)\n","Class=40, n=252 (0.613%)\n","Class=41, n=248 (0.603%)\n","Class=42, n=242 (0.589%)\n","Class=43, n=228 (0.555%)\n","Class=44, n=216 (0.525%)\n","Class=45, n=210 (0.511%)\n","Class=46, n=200 (0.486%)\n","Class=47, n=192 (0.467%)\n","Class=48, n=180 (0.438%)\n","Class=49, n=171 (0.416%)\n","Class=50, n=168 (0.409%)\n","Class=51, n=168 (0.409%)\n","Class=52, n=162 (0.394%)\n","Class=53, n=150 (0.365%)\n","Class=54, n=148 (0.360%)\n","Class=55, n=138 (0.336%)\n","Class=56, n=135 (0.328%)\n","Class=57, n=135 (0.328%)\n","Class=58, n=133 (0.324%)\n","Class=59, n=132 (0.321%)\n","Class=60, n=132 (0.321%)\n","Class=61, n=130 (0.316%)\n","Class=62, n=130 (0.316%)\n","Class=63, n=130 (0.316%)\n","Class=64, n=128 (0.311%)\n","Class=65, n=128 (0.311%)\n","Class=66, n=126 (0.306%)\n","Class=67, n=124 (0.302%)\n","Class=68, n=124 (0.302%)\n","Class=69, n=124 (0.302%)\n","Class=70, n=120 (0.292%)\n","Class=71, n=120 (0.292%)\n","Class=72, n=118 (0.287%)\n","Class=73, n=116 (0.282%)\n","Class=74, n=114 (0.277%)\n","Class=75, n=105 (0.255%)\n","Class=76, n=104 (0.253%)\n","Class=77, n=102 (0.248%)\n","Class=78, n=99 (0.241%)\n","Class=79, n=98 (0.238%)\n","Class=80, n=98 (0.238%)\n","Class=81, n=98 (0.238%)\n","Class=82, n=98 (0.238%)\n","Class=83, n=96 (0.234%)\n","Class=84, n=96 (0.234%)\n","Class=85, n=96 (0.234%)\n","Class=86, n=93 (0.226%)\n","Class=87, n=92 (0.224%)\n","Class=88, n=92 (0.224%)\n","Class=89, n=91 (0.221%)\n","Class=90, n=88 (0.214%)\n","Class=91, n=88 (0.214%)\n","Class=92, n=86 (0.209%)\n","Class=93, n=86 (0.209%)\n","Class=94, n=84 (0.204%)\n","Class=95, n=84 (0.204%)\n","Class=96, n=84 (0.204%)\n","Class=97, n=78 (0.190%)\n","Class=98, n=78 (0.190%)\n","Class=99, n=76 (0.185%)\n","Class=100, n=75 (0.182%)\n","Class=101, n=75 (0.182%)\n","Class=102, n=73 (0.178%)\n","Class=103, n=72 (0.175%)\n","Class=104, n=72 (0.175%)\n","Class=105, n=70 (0.170%)\n","Class=106, n=69 (0.168%)\n","Class=107, n=68 (0.165%)\n","Class=108, n=67 (0.163%)\n","Class=109, n=66 (0.161%)\n","Class=110, n=66 (0.161%)\n","Class=111, n=66 (0.161%)\n","Class=112, n=66 (0.161%)\n","Class=113, n=66 (0.161%)\n","Class=114, n=65 (0.158%)\n","Class=115, n=64 (0.156%)\n","Class=116, n=63 (0.153%)\n","Class=117, n=63 (0.153%)\n","Class=118, n=62 (0.151%)\n","Class=119, n=61 (0.148%)\n","Class=120, n=60 (0.146%)\n","Class=121, n=60 (0.146%)\n","Class=122, n=60 (0.146%)\n","Class=123, n=60 (0.146%)\n","Class=124, n=60 (0.146%)\n","Class=125, n=60 (0.146%)\n","Class=126, n=60 (0.146%)\n","Class=127, n=60 (0.146%)\n","Class=128, n=60 (0.146%)\n","Class=129, n=60 (0.146%)\n","Class=130, n=59 (0.144%)\n","Class=131, n=59 (0.144%)\n","Class=132, n=58 (0.141%)\n","Class=133, n=56 (0.136%)\n","Class=134, n=56 (0.136%)\n","Class=135, n=56 (0.136%)\n","Class=136, n=56 (0.136%)\n","Class=137, n=56 (0.136%)\n","Class=138, n=56 (0.136%)\n","Class=139, n=56 (0.136%)\n","Class=140, n=56 (0.136%)\n","Class=141, n=56 (0.136%)\n","Class=142, n=55 (0.134%)\n","Class=143, n=55 (0.134%)\n","Class=144, n=54 (0.131%)\n","Class=145, n=54 (0.131%)\n","Class=146, n=54 (0.131%)\n","Class=147, n=54 (0.131%)\n","Class=148, n=54 (0.131%)\n","Class=149, n=53 (0.129%)\n","Class=150, n=52 (0.126%)\n","Class=151, n=52 (0.126%)\n","Class=152, n=52 (0.126%)\n","Class=153, n=52 (0.126%)\n","Class=154, n=50 (0.122%)\n","Class=155, n=50 (0.122%)\n","Class=156, n=49 (0.119%)\n","Class=157, n=49 (0.119%)\n","Class=158, n=48 (0.117%)\n","Class=159, n=48 (0.117%)\n","Class=160, n=48 (0.117%)\n","Class=161, n=46 (0.112%)\n","Class=162, n=45 (0.109%)\n","Class=163, n=44 (0.107%)\n","Class=164, n=44 (0.107%)\n","Class=165, n=44 (0.107%)\n","Class=166, n=42 (0.102%)\n","Class=167, n=42 (0.102%)\n","Class=168, n=42 (0.102%)\n","Class=169, n=42 (0.102%)\n","Class=170, n=42 (0.102%)\n","Class=171, n=42 (0.102%)\n","Class=172, n=42 (0.102%)\n","Class=173, n=41 (0.100%)\n","Class=174, n=41 (0.100%)\n","Class=175, n=40 (0.097%)\n","Class=176, n=40 (0.097%)\n","Class=177, n=39 (0.095%)\n","Class=178, n=39 (0.095%)\n","Class=179, n=38 (0.092%)\n","Class=180, n=37 (0.090%)\n","Class=181, n=36 (0.088%)\n","Class=182, n=35 (0.085%)\n","Class=183, n=35 (0.085%)\n","Class=184, n=35 (0.085%)\n","Class=185, n=35 (0.085%)\n","Class=186, n=34 (0.083%)\n","Class=187, n=34 (0.083%)\n","Class=188, n=34 (0.083%)\n","Class=189, n=34 (0.083%)\n","Class=190, n=32 (0.078%)\n","Class=191, n=32 (0.078%)\n","Class=192, n=32 (0.078%)\n","Class=193, n=32 (0.078%)\n","Class=194, n=32 (0.078%)\n","Class=195, n=32 (0.078%)\n","Class=196, n=31 (0.075%)\n","Class=197, n=31 (0.075%)\n","Class=198, n=31 (0.075%)\n","Class=199, n=31 (0.075%)\n","Class=200, n=30 (0.073%)\n","Class=201, n=30 (0.073%)\n","Class=202, n=30 (0.073%)\n","Class=203, n=30 (0.073%)\n","Class=204, n=30 (0.073%)\n","Class=205, n=30 (0.073%)\n","Class=206, n=30 (0.073%)\n","Class=207, n=30 (0.073%)\n","Class=208, n=30 (0.073%)\n","Class=209, n=29 (0.071%)\n","Class=210, n=29 (0.071%)\n","Class=211, n=28 (0.068%)\n","Class=212, n=28 (0.068%)\n","Class=213, n=28 (0.068%)\n","Class=214, n=28 (0.068%)\n","Class=215, n=28 (0.068%)\n","Class=216, n=28 (0.068%)\n","Class=217, n=27 (0.066%)\n","Class=218, n=27 (0.066%)\n","Class=219, n=27 (0.066%)\n","Class=220, n=27 (0.066%)\n","Class=221, n=27 (0.066%)\n","Class=222, n=27 (0.066%)\n","Class=223, n=26 (0.063%)\n","Class=224, n=26 (0.063%)\n","Class=225, n=26 (0.063%)\n","Class=226, n=26 (0.063%)\n","Class=227, n=26 (0.063%)\n","Class=228, n=25 (0.061%)\n","Class=229, n=25 (0.061%)\n","Class=230, n=25 (0.061%)\n","Class=231, n=25 (0.061%)\n","Class=232, n=24 (0.058%)\n","Class=233, n=24 (0.058%)\n","Class=234, n=24 (0.058%)\n","Class=235, n=24 (0.058%)\n","Class=236, n=24 (0.058%)\n","Class=237, n=24 (0.058%)\n","Class=238, n=24 (0.058%)\n","Class=239, n=24 (0.058%)\n","Class=240, n=24 (0.058%)\n","Class=241, n=24 (0.058%)\n","Class=242, n=24 (0.058%)\n","Class=243, n=24 (0.058%)\n","Class=244, n=23 (0.056%)\n","Class=245, n=23 (0.056%)\n","Class=246, n=22 (0.054%)\n","Class=247, n=22 (0.054%)\n","Class=248, n=22 (0.054%)\n","Class=249, n=22 (0.054%)\n","Class=250, n=22 (0.054%)\n","Class=251, n=22 (0.054%)\n","Class=252, n=22 (0.054%)\n","Class=253, n=22 (0.054%)\n","Class=254, n=22 (0.054%)\n","Class=255, n=22 (0.054%)\n","Class=256, n=22 (0.054%)\n","Class=257, n=22 (0.054%)\n","Class=258, n=22 (0.054%)\n","Class=259, n=22 (0.054%)\n","Class=260, n=22 (0.054%)\n","Class=261, n=22 (0.054%)\n","Class=262, n=22 (0.054%)\n","Class=263, n=22 (0.054%)\n","Class=264, n=21 (0.051%)\n","Class=265, n=21 (0.051%)\n","Class=266, n=21 (0.051%)\n","Class=267, n=21 (0.051%)\n","Class=268, n=21 (0.051%)\n","Class=269, n=20 (0.049%)\n","Class=270, n=20 (0.049%)\n","Class=271, n=20 (0.049%)\n","Class=272, n=20 (0.049%)\n","Class=273, n=20 (0.049%)\n","Class=274, n=20 (0.049%)\n","Class=275, n=20 (0.049%)\n","Class=276, n=20 (0.049%)\n","Class=277, n=20 (0.049%)\n","Class=278, n=20 (0.049%)\n","Class=279, n=20 (0.049%)\n","Class=280, n=19 (0.046%)\n","Class=281, n=19 (0.046%)\n","Class=282, n=19 (0.046%)\n","Class=283, n=18 (0.044%)\n","Class=284, n=18 (0.044%)\n","Class=285, n=18 (0.044%)\n","Class=286, n=18 (0.044%)\n","Class=287, n=18 (0.044%)\n","Class=288, n=18 (0.044%)\n","Class=289, n=18 (0.044%)\n","Class=290, n=18 (0.044%)\n","Class=291, n=18 (0.044%)\n","Class=292, n=17 (0.041%)\n","Class=293, n=17 (0.041%)\n","Class=294, n=17 (0.041%)\n","Class=295, n=17 (0.041%)\n","Class=296, n=17 (0.041%)\n","Class=297, n=17 (0.041%)\n","Class=298, n=16 (0.039%)\n","Class=299, n=16 (0.039%)\n","Class=300, n=16 (0.039%)\n","Class=301, n=16 (0.039%)\n","Class=302, n=16 (0.039%)\n","Class=303, n=16 (0.039%)\n","Class=304, n=16 (0.039%)\n","Class=305, n=16 (0.039%)\n","Class=306, n=15 (0.036%)\n","Class=307, n=15 (0.036%)\n","Class=308, n=15 (0.036%)\n","Class=309, n=15 (0.036%)\n","Class=310, n=15 (0.036%)\n","Class=311, n=14 (0.034%)\n","Class=312, n=14 (0.034%)\n","Class=313, n=14 (0.034%)\n","Class=314, n=14 (0.034%)\n","Class=315, n=14 (0.034%)\n","Class=316, n=14 (0.034%)\n","Class=317, n=14 (0.034%)\n","Class=318, n=14 (0.034%)\n","Class=319, n=14 (0.034%)\n","Class=320, n=14 (0.034%)\n","Class=321, n=14 (0.034%)\n","Class=322, n=14 (0.034%)\n","Class=323, n=14 (0.034%)\n","Class=324, n=14 (0.034%)\n","Class=325, n=14 (0.034%)\n","Class=326, n=14 (0.034%)\n","Class=327, n=14 (0.034%)\n","Class=328, n=13 (0.032%)\n","Class=329, n=13 (0.032%)\n","Class=330, n=13 (0.032%)\n","Class=331, n=13 (0.032%)\n","Class=332, n=13 (0.032%)\n","Class=333, n=13 (0.032%)\n","Class=334, n=13 (0.032%)\n","Class=335, n=13 (0.032%)\n","Class=336, n=13 (0.032%)\n","Class=337, n=12 (0.029%)\n","Class=338, n=12 (0.029%)\n","Class=339, n=12 (0.029%)\n","Class=340, n=12 (0.029%)\n","Class=341, n=12 (0.029%)\n","Class=342, n=12 (0.029%)\n","Class=343, n=12 (0.029%)\n","Class=344, n=12 (0.029%)\n","Class=345, n=12 (0.029%)\n","Class=346, n=12 (0.029%)\n","Class=347, n=12 (0.029%)\n","Class=348, n=12 (0.029%)\n","Class=349, n=12 (0.029%)\n","Class=350, n=12 (0.029%)\n","Class=351, n=12 (0.029%)\n","Class=352, n=12 (0.029%)\n","Class=353, n=12 (0.029%)\n","Class=354, n=12 (0.029%)\n","Class=355, n=11 (0.027%)\n","Class=356, n=11 (0.027%)\n","Class=357, n=11 (0.027%)\n","Class=358, n=11 (0.027%)\n","Class=359, n=11 (0.027%)\n","Class=360, n=11 (0.027%)\n","Class=361, n=10 (0.024%)\n","Class=362, n=10 (0.024%)\n","Class=363, n=10 (0.024%)\n","Class=364, n=10 (0.024%)\n","Class=365, n=10 (0.024%)\n","Class=366, n=10 (0.024%)\n","Class=367, n=10 (0.024%)\n","Class=368, n=10 (0.024%)\n","Class=369, n=10 (0.024%)\n","Class=370, n=10 (0.024%)\n","Class=371, n=10 (0.024%)\n","Class=372, n=10 (0.024%)\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZhcVZnH8e+PsMm+JGJIgCQYdpkALTKDIgpoABWZQQzDEhEm4oCMwDxjEARGZWQc0QEXGJCwiewgIKAssriwJIEQwp6EKCEhCSCENZLwzh/nFKl0quveJF1Ld/8+z1NP3Xvu9tbtrnrrLHWvIgIzM7N6Vmp1AGZm1v6cLMzMrJCThZmZFXKyMDOzQk4WZmZWyMnCzMwKOVn0AZLOlfStbtrXppJel9Qvz98t6cju2Hfe362SRnfX/pbhuN+V9KKkF5p97GaTdJSkO1odRxEl4yVt06LjryHpKUnrt+L47cbJooeTNEPSW5Jek/SKpD/lD4P3/rYRcVREfKfkvvast05E/CUi1oqIRd0Q+2mSftFp/3tHxMUruu9ljGMT4ARgm4j4QKdlB+fk+Ho+z+9Wzb/ezDhzPKU+6CXtK+kP+f9irqTfSdq7GTF2owOA5yPi8UqBpO0l3Sxpfn5td0j6cJmdSbpf0iF5emSnv+Vzki6XtENl/Yh4E7gM+Pdufl09kpNF7/DZiFgb2Aw4A/gGcEF3H0TSyt29zzaxGfBSRMztvCAiLsvJcS1gb2BWZT6XLZNmnENJBwO/BM4HBgEDgdOB/Rp97G52FHBpZUbSVsDvgQdJf7NBwK3AXZJ2Wo79T89/w3WAfwCeBf4k6WNV61wGHNGL//fLiwg/evADmAHs2alsZ+BdYLs8fxHw3TzdH/g18ArwMunNtxLpTfku8BbwOvAfwBAggCOAvwD3VpWtnPd3N/A90hv4VeAGYIO8bHdgZq14gZHA34B38vEeqdrfkXl6JeBk4M/AXOASYN28rBLH6Bzbi8BJdc7Tunn7eXl/J+f975lf87s5jovq7GOp15PLTyF90LwGTAH2rVp2FPA74KfAX/NxVwbOBl4CpgHHAgurttkgx/oC8Bxwao51B+BtYGGO9YUasayct/tanddxFHBH1fw5wExgfv477lK1bFfg4bzsBeB7uXxN4Ir8P/QK8ACwfr3487KtgD/k/5V5wCVdxLhG/t/oX1V2NXBdjXUvBG4rEdf9wCF5eiQwtca+fg78oVPZc8BHWv1eb/XDNYteKCIeJL35P1Zj8Ql52QBgI+CbaZM4lPSh+9lI35q/X7XNx4GtgU93ccjDgC8DG5M+yM4uEeNvgP8CrszH+7saq30pPz4BDAPWAn7SaZ2PAlsCewCnSNq6i0P+mJQwhuXXcxhweETcwZI1hi8VxV7DU6RvpusC/w1cIal/1fLdgEmkRH0mcEyOYTtSYj+g0/4uI32YDsvLPw8cGhEPA18H7s6xfoClbUf6u16zDPHfB3wI2JCU7K+WtEpe9hPgvyJiHWA48KtcfiQpMQ3Kr+sYUvLvMv687Ht5H+sBmwL/10VMWwPzI+LFqrK9SAmjs6uA3fO3/3pxlXEdsEvV6wd4Aqj1/9mnOFn0XrNI3/A6e4fULLFZRLwTEb+P/PWpjtMi4o2IeKuL5ZdGxJSIeAP4FnBgpQN8BR0M/DAipkfE68CJwKhOTQL/GRFvRcQjwCPUeFPnWL4InBgRr0XEDNKH9qGd110eEXFlRMyOiHcj4lLgeaC6WWR6RJwfEYvyOTwwv67ZEfES8F5ilrQZKbkcHxFvRsRsUvIdVTKcDUk1rjnLEP8lEfHXiHiHlMA3JH3QQ/p/2ULShvncPVBVPgDYPCIWRsT4iHijRPzvkGqFH8h/tz92EdZ6pJoa8N7fcF1gdo11ZwOr5OU14yp7Lkjvm36kpqmK13I8fZqTRe81iFQV7+x/gKnAbZKmSxpbYl/PLcPyP5PeuP27WHdZbJz3V73vlUnfnCuqRy+9Sap9dNYfWLXGvgZ1Q4xIOkLS5DzA4BXggyz5+jufv407lVVPbwasDsyr2t9ZLPma63kJ0DKsj6QT86ifV0lNZatXxT8a2B54WtIDkiq1ywuAe4BrJM2U9F/5A70o/uNITUwP53N2SBdh/RVYuzITaUDFq6QvOp0NJCWJ+XXiKmsQsCjvq2JtUpNWn+Zk0Qvl0SGDSG3DS8jfDk+IiGHAZ4HjJe1RWdzFLotqHptUTW9KeuO+CLxB+mCoxNWP9K2v7H5nkT58qve9kGX41py9mGPqvK/nl3E/S5G0BamJawypr2Y9UjJW1WqdX+dsYHDVfPX5e47UH7F+RKyXH+tExI5d7KuzKaTz808l498L+BqwP+nb8wakPhwBRMQTEfFF4P2kGsJ1klaNiAURcUpEbEWqSXyBVHuoG39EPB8RXyZ9wB8LjJO0aY3QngDW7tScd0c+TmcHAvfmmnJXcZW1P3B/rmVVbE2qtfZpTha9iKR1JH2G1MH3i4h4tMY6n5H0QUkifXtalB+QPmSGdd6mhEMkbSNpDeDbwDX5m+DTwOp5GOcqpM7d1aq2mwMMqR7m28nlwHGShkpai8V9HAuXJbgcy1XA6ZLWzk0lxwO/qL9lKWuROsfnAStJOopUs6jnKtLr+oCkDakamhkRz5I6Yr+fY11J0nBJH82rzAE26dSmTtX2C/P+vivp0Kp9fFzSz2pssjYpkc4j1b6+TaoZACDpsNwEVflmH8C7kvbMf/OVSP9HC4FFRfFL+qKkjXPTZ+Xb+lJ/z9xcdzfpA7/iFGBPSadKWi//v59AShYn5v3XjKvWuap6jZI0WNJ3gEOAk6qWDcvnZWK9ffQFTha9w02SXiN9qzsJ+CFweBfrDid9Q3ud1LH5s4i4Oy/7HnBybj5YlrHll5JGXL1A+qA5FiAiXgX+lTTC5HlSTWNm1XaVzsqXJD1UY7/j8r7vJY02epv0LXh5fC0ffzqpxvXLvP8VEhEPAecCE0g1hqF5up6fAH8CHgfGk0anLahafhDpW/6TpKbEK1ncjPMb0oiyuZKqz2V1TL8gfegdlWN6gTQi6YYaq99EOr/TSOfmRVLiqPgM8FT+//oecGBOSIPy/iojwG4hJcGi+P8emKj0G5WrgTERMavmWUqd3+/1K0X6vcVuwC6k//XngX2BPSJifF6tXlydDctxvE4aNbUl8NGIuKdqnYOBC5b1C0pvpOK+TTNrJEn7A2dExJatjqWd5NrvA8CXouqHeU08/hqkYcN/HxG1+v/6FCcLsyaTtDbpG/adpG/C1wO3R0SZwQZmLeFkYdZkktYF7gK2IDWN3Qgcl4cHm7UlJwszMyvkDm4zMyvUay+O1b9//xgyZEirwzAz6zEmTpz4YkQMqLWs1yaLIUOGMGFC0QhGMzOrkPTnrpa5GcrMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK9SwZCFpnKS5kqZUlV0paVJ+zJA0KZcPkfRW1bJzq7bZSdKjkqZKOjvfPcvMzJqokRcSvIh0r+FLKgUR8cXKtKQzSTeAr5gWESNq7OccYAzpJvC3ACOBWxsQr5mZdaFhNYuIuJd0s/al5NrBgcDl9fYhaSCwTkTcF+kuTZcAn+/uWM3MrL5W9Vl8DJgTEc9UlQ2V9LCkeyR9LJcNAmZWrTMzl9UkaYykCZImzJs3r/ujNjPro1qVLA5iyVrFbGDTiNgBOB74paR1gFr9E13eBzYizouIjojoGDCg5v07zMxsOTT95keSVgb+EdipUhYRC4AFeXqipGmkm9nPBAZXbT4YmNW8aM3MDFpTs9gTeDIi3mtekjRAUr88PQwYDkyPiNnAa5J2yf0chwE3tCBmM7M+rZFDZy8H7gO2lDRT0hF50SiW7tjeDZgs6RHgGuCoiKh0jn8V+DkwFZiGR0KZmTWd0iCj3qejoyN8D24zs/IkTYyIjlrL/AtuMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFnCzMzKyQk4WZmRVqWLKQNE7SXElTqspOk/S8pEn5sU/VshMlTZX0lKRPV5WPzGVTJY1tVLxmZta1RtYsLgJG1ij/UUSMyI9bACRtA4wCts3b/ExSP0n9gJ8CewPbAAfldc3MrIlWbtSOI+JeSUNKrr4fcEVELACelTQV2DkvmxoR0wEkXZHXfbybwzUzszpa0WdxjKTJuZlq/Vw2CHiuap2Zuayr8pokjZE0QdKEefPmdXfcZmZ9VrOTxTnA5sAIYDZwZi5XjXWjTnlNEXFeRHRERMeAAQNWNFYzM8sa1gxVS0TMqUxLOh/4dZ6dCWxStepgYFae7qrczMyapKk1C0kDq2b3ByojpW4ERklaTdJQYDjwIDAeGC5pqKRVSZ3gNzYzZjMza2DNQtLlwO5Af0kzgVOB3SWNIDUlzQC+AhARj0m6itRxvRA4OiIW5f0cA/wW6AeMi4jHGhWzmZnVpoguuwB6tI6OjpgwYUKrwzAz6zEkTYyIjlrL/AtuMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFCpOFpM0lrZand5d0rKT1Gh+amZm1izI1i2uBRZI+CFwADAV+2dCozMysrZRJFu9GxELSJcX/NyKOAwYWbGNmZr1ImWTxjqSDgNEsvlnRKo0LyczM2k2ZZHE48PfA6RHxbL450S8aG5aZmbWTwpsfRcTjkr4BbJrnnwXOaHRgZmbWPsqMhvosMAn4TZ4fIcm3NjUz60PKNEOdBuwMvAIQEZNII6LMzKyPKJMsFkbEq53Keue9WM3MrKbCPgtgiqR/BvpJGg4cC/ypsWGZmVk7KVOz+BqwLbAAuByYD3y9aCNJ4yTNlTSlqux/JD0pabKk6yu/BJc0RNJbkiblx7lV2+wk6VFJUyWdLUnL+iLNzGzFFCaLiHgzIk6KiA9HREeefrvEvi8CRnYqux3YLiK2B54GTqxaNi0iRuTHUVXl5wBjgOH50XmfZmbWYF02Q0m6iTp9ExHxuXo7joh7JQ3pVHZb1ez9wAH19iFpILBORNyX5y8BPg/cWm+77jBk7M3MOGPfRh/GzKxHqNdn8YMGH/vLwJVV80MlPUxq5jo5In4PDAJmVq0zM5fVJGkMqRbCpptu2u0Bm5n1VV0mi4i4pzItaVVgK1JN46mI+NuKHFTSScBC4LJcNBvYNCJekrQT8CtJ2wK1+ifq1XbOA84D6Ojo8IgtM7NuUjgaStK+wLnANNKH91BJX4mI5WoKkjQa+AywR0QEQEQsIHWgExETJU0DtiDVJAZXbT4YmLU8xzUzs+VXZujsmcAnImIqpPtbADezHP0GkkYC3wA+HhFvVpUPAF6OiEWShpE6sqdHxMuSXpO0C/AAcBjw42U9rpmZrZgyQ2fnVhJFNh2YW7SRpMuB+4AtJc2UdATwE2Bt4PZOQ2R3AyZLegS4BjgqIl7Oy74K/ByYSqrdNLxzu2LI2JubdSgzs7ZWpmbxmKRbgKtI/QVfAMZL+keAiLiu1kYRcVCN4gu6WPda0k2Wai2bAGxXIk4zM2uQMslidWAO8PE8Pw/YAPgsKXnUTBZmZtZ7lLlE+eHNCMTMzNpXmdFQQ0mX/BhSvX7Rj/LMzKz3KNMM9StSX8NNwLuNDcfMzNpRmWTxdkSc3fBIzMysbZVJFmdJOhW4jfzDOYCIeKhhUZmZWVspkyw+BBwKfJLFzVCR583MrA8okyz2B4at6PWgzMys5yrzC+5HgPUaHYiZmbWvMjWLjYAnJY1nyT4LD501M+sjyiSLUxsehZmZtbUyv+C+p2gdMzPr3Qr7LCTtImm8pNcl/U3SIknzmxGcmZm1hzId3D8BDgKeAd4HHJnLzMysjyjTZ0FETJXULyIWARdK+lOD4zIzszZSJlm8me/BPUnS90n3y16zsWGZmVk7KdMMdWhe7xjgDWAT4J8aGZSZmbWXMqOh/pwn35Z0NrBJp9usmplZL1dmNNTdktaRtAHp19wXSvph40MzM7N2UaYZat2ImA/8I3BhROwE7NnYsMzMrJ2USRYrSxoIHAj8ell2LmmcpLmSplSVbSDpdknP5Of1c7kknS1pqqTJknas2mZ0Xv8ZSaOXJYYVNWTszc08nJlZWyqTLL4N/BaYGhHjJQ0j/eaijIuAkZ3KxgJ3RsRw4M48D7A3MDw/xgDnQEoupEuOfATYGTi1kmDMzKw5CpNFRFwdEdtHxL/m+ekRUWo0VETcC7zcqXg/4OI8fTHw+arySyK5H1gv12g+DdweES9HxF+B21k6ATWUaxdm1teVqVl0t40iYjZAfn5/Lh8EPFe13sxc1lX5UiSNkTRB0oR58+Z1e+BmZn1VK5JFV1SjLOqUL10YcV5EdEREx4ABA7o1ODOzvqwVyWJObl4iP8/N5TNJP/irGAzMqlNuZmZNUuZ3FhtJukDSrXl+G0lHrMAxbwQqI5pGAzdUlR+WR0XtAryam6l+C3xK0vq5Y/tTuczMzJqkTM3iItKH88Z5/mng62V2Luly4D5gS0kzc5I5A9hL0jPAXnke4BZgOjAVOB+odKi/DHwHGJ8f385lZmbWJGUuJNg/Iq6SdCJARCyUtKjMziPioC4W7VFj3QCO7mI/44BxZY5pZmbdr0zN4g1JG5I7lStNRA2NyszM2kqZmsXxpP6EzSX9ERgAHNDQqMzMrK2UuersQ5I+DmxJGsb6VES80/DIzMysbZS6Ux7pMhtD8vo7SiIiLmlYVGZm1lYKk4WkS4HNgUlApWM7ACcLM7M+okzNogPYJo9WMjOzPqjMaKgpwAcaHYiZmbWvUr+zAB6X9CCwoFIYEZ9rWFRmZtZWyiSL0xodRE8xZOzNzDhj31aHYWbWdGWGzt4jaTNgeETcIWkNoF/jQzMzs3ZR5kKC/wJcA/xfLhoE/KqRQZmZWXsp08F9NLArMB8gIp5h8Q2LzMysDyiTLBZExN8qM5JWpoubD5mZWe9UJlncI+mbwPsk7QVcDdzU2LDMzKydlEkWY4F5wKPAV0j3nTi5kUGZmVl7KTMa6l3SzYjOb3w4ZmbWjspcG+pRlu6jeBWYAHw3Il5qRGBmZtY+yjRD3QrcDBycHzcB9wIvkG652qcMGXtzq0MwM2u6Mr/g3jUidq2af1TSHyNiV0mHNCqwduZfcptZX1OmZrGWpI9UZiTtDKyVZxcu6wElbSlpUtVjvqSvSzpN0vNV5ftUbXOipKmSnpL06WU9ppmZrZgyNYsjgXGSKgniNeAISWsC31vWA0bEU8AIAEn9gOeB64HDgR9FxA+q15e0DTAK2BbYGLhD0hYRsQgzM2uKMqOhxgMfkrQuoIh4pWrxVSt4/D2AaRHxZ0ldrbMfcEVELACelTSVdOe++1bw2GZmVlKZZigAIuLVTomiO4wCLq+aP0bSZEnjJK2fywYBz1WtMzOXmZlZk5ROFt1N0qrA50i/CAc4h3T71hHAbODMyqo1Nq95uRFJYyRNkDRh3rx53RyxmVnf1WWykPSF/Dy0QcfeG3goIuYARMSciFhU9SPAnfN6M4FNqrYbDMyqtcOIOC8iOiKiY8CAAQ0K28ys76lXszgxP1/boGMfRFUTlKSBVcv2J93OFeBGYJSk1XLiGg482KCYzMyshnod3C9JugsYKunGzgtX5Laq+QZKe5GuNVXxfUkjSE1MMyrLIuIxSVcBj5OG6h7dLiOh/HsLM+sr6iWLfYEdgUtZ3H/QLSLiTWDDTmWH1ln/dOD07ozBzMzK6zJZ5HtY3C/pHyJinqS1U3G83rzw2p9rF2bWF5QZDbWRpIdJfQiPS5ooabsGx9Wj+HpRZtbblUkW5wHHR8RmEbEpcEIuMzOzPqJMslgzIu6qzETE3cCaDYuoh3Ltwsx6szLXhpou6Vukjm6AQ4BnGxeSmZm1mzI1iy8DA4Dr8qM/6aJ/ZmbWR5S5kOBfgWObEIuZmbWpll0byszMeg4nCzMzK+Rk0Y08IsrMeqvCZCFpsKTrJc2TNEfStZIGNyM4MzNrD2VqFheSrvw6kHTToZtymZmZ9RFlksWAiLgwIhbmx0WkobRmZtZHlEkWL0o6RFK//DgEeKnRgZmZWfso+6O8A4EXSLc7PSCXmZlZH1GYLCLiLxHxuYgYEBHvj4jPR8SfmxFcT+QRUWbWG3X5C25Jp9TZLiLiOw2Ix8zM2lC9y328UaNsTeAI0l3unCzMzPqILpuhIuLMyoN0/4r3kS4geAUwrEnx9UhuijKz3qbuhQQlbQAcDxwMXAzsmC8saGZmfUiXNQtJ/wOMB14DPhQRp3VnopA0Q9KjkiZJmpDLNpB0u6Rn8vP6uVySzpY0VdJkSTt2VxxmZlas3mioE4CNgZOBWZLm58drkuZ30/E/EREjIqIjz48F7oyI4cCdeR5gb2B4fowBzumm45uZWQldNkNFRCsuMrgfsHuevhi4G/hGLr8kIgK4X9J6kgZGxOwWxGhm1ue08qqzAdwmaaKkMblso0oCyM/vz+WDgOeqtp2Zy5YgaYykCZImzJs3r4GhF3Mnt5n1JmXuwd0ou0bELEnvB26X9GSddVWjLJYqiDiPNHKLjo6OpZabmdnyaVnNIiJm5ee5wPXAzsAcSQMB8vPcvPpMYJOqzQcDs5oXrZlZ39aSZCFpTUlrV6aBTwFTSJdCH51XGw3ckKdvBA7Lo6J2AV51f4WZWfO0qhlqI+B6SZUYfhkRv5E0HrhK0hHAX4Av5PVvAfYBpgJvkn4caGZmTdKSZBER04G/q1H+ErBHjfIAjm5CaGZmVoPvwW1mZoWcLMzMrJCTRYP59xZm1hs4WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrJoAo+IMrOezsnCzMwKOVk0iWsXZtaTOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFXKyaLIhY2/2yCgz63GcLFrEScPMehInizbgpGFm7c7JwszMCjU9WUjaRNJdkp6Q9Jikf8vlp0l6XtKk/NinapsTJU2V9JSkTzc75mZw7cLM2lkrahYLgRMiYmtgF+BoSdvkZT+KiBH5cQtAXjYK2BYYCfxMUr8WxN1wThhm1q6aniwiYnZEPJSnXwOeAAbV2WQ/4IqIWBARzwJTgZ0bH6mZmVW0tM9C0hBgB+CBXHSMpMmSxklaP5cNAp6r2mwmXSQXSWMkTZA0Yd68eQ2KuvE8UsrM2k3LkoWktYBrga9HxHzgHGBzYAQwGzizsmqNzaPWPiPivIjoiIiOAQMGNCDq5nLCMLN20ZJkIWkVUqK4LCKuA4iIORGxKCLeBc5ncVPTTGCTqs0HA7OaGa+ZWV/XitFQAi4AnoiIH1aVD6xabX9gSp6+ERglaTVJQ4HhwIPNirfVXLsws3awcguOuStwKPCopEm57JvAQZJGkJqYZgBfAYiIxyRdBTxOGkl1dEQsanrUZmZ9WNOTRUT8gdr9ELfU2eZ04PSGBWVmZnX5F9w9hJujzKyVnCx6ECcMM2sVJ4sexgnDzFrByaKHctIws2ZysujBnDDMrFmcLMzMrJCTRQ/n60iZWTM4WfQiThxm1iit+AW3NdiQsTcz44x9l0ocM87Yt0URmVlP52TRh9RKHpXEYmZWj5uhzE1XZlbIycKAxQnDicPManEzlC2lOmF07vtw05VZ3+RkYculq4TiJGLWO7kZyrpVdXOWh/Ka9R6uWVjD1RrK66G9Zj2Lk4W1ja6G9nY1vyzrmNmKcbKwPmF5k44TjVniZGFWR5mRYfU42Vhv4WRh1mDd1ZTmEWjWSj0mWUgaCZwF9AN+HhFntDgks7ZQnTSWp+bT6GS2LOvUis/aQ49IFpL6AT8F9gJmAuMl3RgRj7c2MjNrtHZPZo06drvpEckC2BmYGhHTASRdAewHOFmYWa/UbiP/FBEN23l3kXQAMDIijszzhwIfiYhjOq03BhiTZ7cEnlrOQ/YHXlzObZvFMXaPdo+x3eMDx9hd2iHGzSJiQK0FPaVmoRplS2W5iDgPOG+FDyZNiIiOFd1PIznG7tHuMbZ7fOAYu0u7x9hTLvcxE9ikan4wMKtFsZiZ9Tk9JVmMB4ZLGippVWAUcGOLYzIz6zN6RDNURCyUdAzwW9LQ2XER8VgDD7nCTVlN4Bi7R7vH2O7xgWPsLm0dY4/o4DYzs9bqKc1QZmbWQk4WZmZWyMmiE0kjJT0laaqksa2OB0DSDEmPSpokaUIu20DS7ZKeyc/rNzmmcZLmSppSVVYzJiVn53M6WdKOLYzxNEnP53M5SdI+VctOzDE+JenTTYpxE0l3SXpC0mOS/i2Xt8W5rBNf25xHSatLelDSIznG/8zlQyU9kM/hlXlwDJJWy/NT8/IhLYzxIknPVp3HEbm8Je+ZuiLCj/wgdZ5PA4YBqwKPANu0QVwzgP6dyr4PjM3TY4H/bnJMuwE7AlOKYgL2AW4l/V5mF+CBFsZ4GvDvNdbdJv+9VwOG5v+Dfk2IcSCwY55eG3g6x9IW57JOfG1zHvO5WCtPrwI8kM/NVcCoXH4u8NU8/a/AuXl6FHBlE/7OXcV4EXBAjfVb8p6p93DNYknvXVYkIv4GVC4r0o72Ay7O0xcDn2/mwSPiXuDlkjHtB1wSyf3AepIGtijGruwHXBERCyLiWWAq6f+hoSJidkQ8lKdfA54ABtEm57JOfF1p+nnM5+L1PLtKfgTwSeCaXN75HFbO7TXAHpJq/fC3GTF2pSXvmXqcLJY0CHiuan4m9d8YzRLAbZIm5kuaAGwUEbMhvaGB97csusW6iqndzusxuWo/rqr5ruUx5uaQHUjfOtvuXHaKD9roPErqJ2kSMBe4nVSjeSUiFtaI470Y8/JXgQ2bHWNEVM7j6fk8/kjSap1jrBF/SzhZLKnUZUVaYNeI2BHYGzha0m6tDmgZtdN5PQfYHBgBzAbOzOUtjVHSWsC1wNcjYn69VWuUNTzOGvG11XmMiEURMYJ0dYedga3rxNEWMfLiIjYAAAXTSURBVEraDjgR2Ar4MLAB8I1WxliPk8WS2vKyIhExKz/PBa4nvRnmVKql+Xlu6yJ8T1cxtc15jYg5+U37LnA+i5tIWhajpFVIH8SXRcR1ubhtzmWt+NrxPOa4XgHuJrXzryep8sPj6jjeizEvX5fyzZXdGePI3MwXEbEAuJA2OY+1OFksqe0uKyJpTUlrV6aBTwFTclyj82qjgRtaE+ESuorpRuCwPMJjF+DVShNLs3Vq992fdC4hxTgqj5QZCgwHHmxCPAIuAJ6IiB9WLWqLc9lVfO10HiUNkLRenn4fsCepb+Uu4IC8WudzWDm3BwC/i9yr3OQYn6z6QiBSn0r1eWyL98x7Wt3D3m4P0iiEp0ltnie1QTzDSKNLHgEeq8REamO9E3gmP2/Q5LguJzU/vEP6FnREVzGRqtQ/zef0UaCjhTFemmOYTHpDDqxa/6Qc41PA3k2K8aOk5oXJwKT82KddzmWd+NrmPALbAw/nWKYAp+TyYaRENRW4Glgtl6+e56fm5cNaGOPv8nmcAvyCxSOmWvKeqffw5T7MzKyQm6HMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZWI8k6QOSrpA0TdLjkm6RtIWkIaq6ymw3H/M0Sf++jNvcLamjEfHk/X8sX8V0Uh6/X71ssKQb8lVXp0k6q3Ll1Tr7ez0/D5H0lqSHla44+6Ck0fW2td7NycJ6nPwDpuuBuyNi84jYBvgmsFFrI2uJg4EfRMSIiHirUpjP0XXAryJiOLAFsBZw+jLse1pE7BARW5N+oHqcpMO7MXbrQZwsrCf6BPBORJxbKYiISRHx++qV8rfj30t6KD/+IZcPlHRv/jY+JX8776d0b4EpSvcOOa5eALnG8N/5G/fTkj6Wy9+XazyTJV0JvK9qm09Jui/HcrWktSStq3Tfhy3zOpdL+pcax9sjf8t/VOnCfatJOhI4EDhF0mWdNvkk8HZEXJjPzyLgOODLktaQtG2OfVKOdXi91xsR04HjgWPrrWe918rFq5i1ne2AiSXWmwvsFRFv5w/Dy4EO4J+B30bE6ZL6AWuQLog3KCK2A6hcmqHAyhGxs9KNf04lXcLhq8CbEbG9pO2Bh/L++gMnA3tGxBuSvgEcHxHflnQMcJGks4D1I+L86oNIWp1034M9IuJpSZeQ7s3wv5I+Cvw6Iq5hSdt2PkcRMV/SX4APAv8CnBURl+WmqX4lXu9DpIveWR/kZGG92SrAT5TuPraI1BQD6Rpg45QukPeriJgkaTowTNKPgZuB20rsv3LRv4nAkDy9G3A2QERMljQ5l+9CujHQH1MLEasC9+X1bpf0BdLlHf6uxnG2BJ6NiKfz/MXA0cD/1olN1L5KaaX8PuAkSYOB6yLimbqvdPG21ke5Gcp6oseAnUqsdxwwh/QB3EH6gCbSTZF2A54HLpV0WET8Na93N+mD+Ocl9r8gPy9iyS9eXX1I3577FkZExDYRcQSApJVIl9R+i3SZ6lrbLqvHSK958U6kdUhXMp0WEb8EPpeP+VtJnyyxzx1IF+izPsjJwnqi3wGrVbftS/qwpI93Wm9dYHaky2gfSm5qkbQZMDc391wA7JibiVaKiGuBb5Fux7o87iV1OqN0v4Ltc/n9wK6SPpiXrSGpUtM5jvQhfBCLazzVngSGVLbNr+WegjjuBNaQdFg+Xj/SPScuiog3JQ0DpkfE2aQLAW7f9a7eu/HRD4AfFxzXeiknC+txIl39cn9grzwk9DHSPaE7X+//Z8BoSfeTmqDeyOW7A5MkPQz8E3AW6S5kdyvdyewi0k1plsc5wFq5+ek/yJfnjoh5wJeAy/Oy+4GtcsI4Ejghd9DfS+rbqH69bwOHA1dLehR4l3RP6S5VnaMvSHqGdCXlt0mjxgC+CEzJr3cr4JIau9m8MnSWdD/rH1c6zK3v8VVnzcyskGsWZmZWyMnCzMwKOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFfp/04duEU3GcywAAAAASUVORK5CYII=","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["y_labelenc = LabelEncoder().fit_transform(Y)\n","\n","from collections import Counter\n","# summarize distribution\n","counter = Counter(y_labelenc)\n","\n","# sort counter by keys\n","counter = dict(sorted(counter.items()))\n","\n","\n","for k,v in counter.items():\n"," per = v / len(y_labelenc) * 100\n"," print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n","# plot the distribution\n","plt.bar( counter.keys(), counter.values())\n","\n","plt.ylabel('No of gene samples')\n","plt.xlabel('Class Index of OsID')\n","plt.title('Distribution of Target Classes (OsID)')\n","plt.show()"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":326,"status":"ok","timestamp":1682739349761,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"W1WdWupjmZ9l"},"outputs":[],"source":["# prepare target data\n","def prepare_targets(y_train, y_test):\n","\tle = LabelEncoder()\n","\t\n","\t#fit the encoders only to the training data and then transform both train and test data\n","\ty_train_enc = le.fit_transform(y_train)\n","\ty_test_enc = le.transform(y_test)\n","\n","\treturn y_train_enc, y_test_enc"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":14,"status":"ok","timestamp":1682739349762,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"JjjBaPUOtmlx","outputId":"8fa71542-ef6a-49cf-832b-cc4142b13516"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_fs, Y, test_size=0.33, random_state=1)\n","\n","# prepare output data\n","y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POiHy56emZ9m","outputId":"9ebb4441-027a-46b2-ce90-02a57e4299fd"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of input features: 1\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 5.0884 - accuracy: 0.0397 - val_loss: 5.0440 - val_accuracy: 0.0436\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.9684 - accuracy: 0.0437 - val_loss: 5.0204 - val_accuracy: 0.0436\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9558 - accuracy: 0.0441 - val_loss: 5.0134 - val_accuracy: 0.0444\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9432 - accuracy: 0.0451 - val_loss: 5.0012 - val_accuracy: 0.0444\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9321 - accuracy: 0.0445 - val_loss: 5.0005 - val_accuracy: 0.0451\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9291 - accuracy: 0.0453 - val_loss: 5.0020 - val_accuracy: 0.0451\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9263 - accuracy: 0.0451 - val_loss: 5.0027 - val_accuracy: 0.0451\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9246 - accuracy: 0.0454 - val_loss: 5.0012 - val_accuracy: 0.0451\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9231 - accuracy: 0.0454 - val_loss: 5.0041 - val_accuracy: 0.0451\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9219 - accuracy: 0.0451 - val_loss: 5.0040 - val_accuracy: 0.0451\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9207 - accuracy: 0.0454 - val_loss: 5.0072 - val_accuracy: 0.0451\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9199 - accuracy: 0.0453 - val_loss: 5.0123 - val_accuracy: 0.0451\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9202 - accuracy: 0.0454 - val_loss: 5.0068 - val_accuracy: 0.0451\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9196 - accuracy: 0.0453 - val_loss: 5.0048 - val_accuracy: 0.0451\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9189 - accuracy: 0.0454 - val_loss: 5.0077 - val_accuracy: 0.0451\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9180 - accuracy: 0.0450 - val_loss: 5.0059 - val_accuracy: 0.0451\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9172 - accuracy: 0.0454 - val_loss: 5.0066 - val_accuracy: 0.0451\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9167 - accuracy: 0.0453 - val_loss: 5.0147 - val_accuracy: 0.0451\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9166 - accuracy: 0.0454 - val_loss: 5.0095 - val_accuracy: 0.0451\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9164 - accuracy: 0.0454 - val_loss: 5.0249 - val_accuracy: 0.0451\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9161 - accuracy: 0.0454 - val_loss: 5.0133 - val_accuracy: 0.0451\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9164 - accuracy: 0.0454 - val_loss: 5.0106 - val_accuracy: 0.0451\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9162 - accuracy: 0.0454 - val_loss: 5.0093 - val_accuracy: 0.0451\n","Epoch 24/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 4.9146 - accuracy: 0.0452 - val_loss: 5.0202 - val_accuracy: 0.0451\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9152 - accuracy: 0.0453 - val_loss: 5.0089 - val_accuracy: 0.0451\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9145 - accuracy: 0.0454 - val_loss: 5.0092 - val_accuracy: 0.0451\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9140 - accuracy: 0.0454 - val_loss: 5.0092 - val_accuracy: 0.0451\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9138 - accuracy: 0.0454 - val_loss: 5.0091 - val_accuracy: 0.0451\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9133 - accuracy: 0.0452 - val_loss: 5.0092 - val_accuracy: 0.0451\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9131 - accuracy: 0.0453 - val_loss: 5.0113 - val_accuracy: 0.0451\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9130 - accuracy: 0.0454 - val_loss: 5.0119 - val_accuracy: 0.0451\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9129 - accuracy: 0.0454 - val_loss: 5.0123 - val_accuracy: 0.0451\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9130 - accuracy: 0.0454 - val_loss: 5.0118 - val_accuracy: 0.0451\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9127 - accuracy: 0.0453 - val_loss: 5.0120 - val_accuracy: 0.0451\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9123 - accuracy: 0.0453 - val_loss: 5.0155 - val_accuracy: 0.0451\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9123 - accuracy: 0.0454 - val_loss: 5.0129 - val_accuracy: 0.0451\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9121 - accuracy: 0.0454 - val_loss: 5.0106 - val_accuracy: 0.0451\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9117 - accuracy: 0.0451 - val_loss: 5.0156 - val_accuracy: 0.0451\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9113 - accuracy: 0.0454 - val_loss: 5.0163 - val_accuracy: 0.0451\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9117 - accuracy: 0.0454 - val_loss: 5.0130 - val_accuracy: 0.0451\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 5.0802 - accuracy: 0.0422 - val_loss: 5.0462 - val_accuracy: 0.0440\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9676 - accuracy: 0.0435 - val_loss: 5.0463 - val_accuracy: 0.0440\n","Epoch 3/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 4.9604 - accuracy: 0.0439 - val_loss: 5.0183 - val_accuracy: 0.0440\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9555 - accuracy: 0.0449 - val_loss: 5.0241 - val_accuracy: 0.0460\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9549 - accuracy: 0.0451 - val_loss: 5.0199 - val_accuracy: 0.0460\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9537 - accuracy: 0.0451 - val_loss: 5.0317 - val_accuracy: 0.0460\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9520 - accuracy: 0.0451 - val_loss: 5.0203 - val_accuracy: 0.0460\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9494 - accuracy: 0.0451 - val_loss: 5.0324 - val_accuracy: 0.0460\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9469 - accuracy: 0.0451 - val_loss: 5.0240 - val_accuracy: 0.0460\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9460 - accuracy: 0.0451 - val_loss: 5.0480 - val_accuracy: 0.0460\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9460 - accuracy: 0.0451 - val_loss: 5.0195 - val_accuracy: 0.0460\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9437 - accuracy: 0.0451 - val_loss: 5.0264 - val_accuracy: 0.0460\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9417 - accuracy: 0.0451 - val_loss: 5.0245 - val_accuracy: 0.0460\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9409 - accuracy: 0.0451 - val_loss: 5.0198 - val_accuracy: 0.0460\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9399 - accuracy: 0.0451 - val_loss: 5.0185 - val_accuracy: 0.0460\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9389 - accuracy: 0.0451 - val_loss: 5.0167 - val_accuracy: 0.0460\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9371 - accuracy: 0.0451 - val_loss: 5.0207 - val_accuracy: 0.0460\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9368 - accuracy: 0.0451 - val_loss: 5.0160 - val_accuracy: 0.0460\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9354 - accuracy: 0.0451 - val_loss: 5.0221 - val_accuracy: 0.0460\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9349 - accuracy: 0.0451 - val_loss: 5.0175 - val_accuracy: 0.0460\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9335 - accuracy: 0.0451 - val_loss: 5.0178 - val_accuracy: 0.0460\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9326 - accuracy: 0.0451 - val_loss: 5.0158 - val_accuracy: 0.0460\n","Epoch 23/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 4.9318 - accuracy: 0.0451 - val_loss: 5.0176 - val_accuracy: 0.0460\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9313 - accuracy: 0.0451 - val_loss: 5.0168 - val_accuracy: 0.0460\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9306 - accuracy: 0.0451 - val_loss: 5.0145 - val_accuracy: 0.0460\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9296 - accuracy: 0.0451 - val_loss: 5.0235 - val_accuracy: 0.0460\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9286 - accuracy: 0.0451 - val_loss: 5.0173 - val_accuracy: 0.0460\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9285 - accuracy: 0.0451 - val_loss: 5.0156 - val_accuracy: 0.0460\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9276 - accuracy: 0.0451 - val_loss: 5.0132 - val_accuracy: 0.0460\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9267 - accuracy: 0.0451 - val_loss: 5.0124 - val_accuracy: 0.0460\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9265 - accuracy: 0.0451 - val_loss: 5.0125 - val_accuracy: 0.0460\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9258 - accuracy: 0.0451 - val_loss: 5.0124 - val_accuracy: 0.0460\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9253 - accuracy: 0.0451 - val_loss: 5.0126 - val_accuracy: 0.0460\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9245 - accuracy: 0.0451 - val_loss: 5.0122 - val_accuracy: 0.0460\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9242 - accuracy: 0.0451 - val_loss: 5.0113 - val_accuracy: 0.0460\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9239 - accuracy: 0.0451 - val_loss: 5.0120 - val_accuracy: 0.0460\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9235 - accuracy: 0.0451 - val_loss: 5.0141 - val_accuracy: 0.0460\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9228 - accuracy: 0.0451 - val_loss: 5.0159 - val_accuracy: 0.0460\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9228 - accuracy: 0.0451 - val_loss: 5.0195 - val_accuracy: 0.0460\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9224 - accuracy: 0.0451 - val_loss: 5.0105 - val_accuracy: 0.0460\n","Average Validation Accuracy: 0.04534727334976196\n","Average Validation Loss: 4.942664861679077\n","Average Test Accuracy: 0.045035749673843384\n","------------------------------------------------------------------------\n","\n","Number of input features: 2\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 5.0692 - accuracy: 0.0454 - val_loss: 4.9966 - val_accuracy: 0.0517\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.9003 - accuracy: 0.0506 - val_loss: 4.9347 - val_accuracy: 0.0530\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8543 - accuracy: 0.0520 - val_loss: 4.9231 - val_accuracy: 0.0524\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8361 - accuracy: 0.0540 - val_loss: 4.9164 - val_accuracy: 0.0530\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8244 - accuracy: 0.0538 - val_loss: 4.9264 - val_accuracy: 0.0524\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8120 - accuracy: 0.0551 - val_loss: 4.9069 - val_accuracy: 0.0530\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8009 - accuracy: 0.0592 - val_loss: 4.8974 - val_accuracy: 0.0530\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7882 - accuracy: 0.0571 - val_loss: 4.9041 - val_accuracy: 0.0585\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7764 - accuracy: 0.0594 - val_loss: 4.8970 - val_accuracy: 0.0579\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7648 - accuracy: 0.0587 - val_loss: 4.9537 - val_accuracy: 0.0563\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7550 - accuracy: 0.0612 - val_loss: 4.9045 - val_accuracy: 0.0568\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7471 - accuracy: 0.0620 - val_loss: 4.9080 - val_accuracy: 0.0616\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7390 - accuracy: 0.0609 - val_loss: 4.9125 - val_accuracy: 0.0590\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7295 - accuracy: 0.0612 - val_loss: 4.9129 - val_accuracy: 0.0587\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7224 - accuracy: 0.0644 - val_loss: 4.9376 - val_accuracy: 0.0524\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7153 - accuracy: 0.0618 - val_loss: 4.9229 - val_accuracy: 0.0631\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7090 - accuracy: 0.0625 - val_loss: 4.9299 - val_accuracy: 0.0526\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7058 - accuracy: 0.0630 - val_loss: 4.9297 - val_accuracy: 0.0552\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7005 - accuracy: 0.0624 - val_loss: 4.9451 - val_accuracy: 0.0570\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6963 - accuracy: 0.0629 - val_loss: 4.9550 - val_accuracy: 0.0568\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6927 - accuracy: 0.0626 - val_loss: 4.9558 - val_accuracy: 0.0647\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6883 - accuracy: 0.0650 - val_loss: 4.9720 - val_accuracy: 0.0548\n","Epoch 23/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 4.6863 - accuracy: 0.0634 - val_loss: 4.9740 - val_accuracy: 0.0570\n","Epoch 24/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 4.6822 - accuracy: 0.0656 - val_loss: 4.9847 - val_accuracy: 0.0574\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6791 - accuracy: 0.0634 - val_loss: 4.9868 - val_accuracy: 0.0590\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6765 - accuracy: 0.0642 - val_loss: 4.9998 - val_accuracy: 0.0612\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6738 - accuracy: 0.0653 - val_loss: 5.0036 - val_accuracy: 0.0642\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6717 - accuracy: 0.0650 - val_loss: 5.0159 - val_accuracy: 0.0686\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 4.6691 - accuracy: 0.0655 - val_loss: 5.0687 - val_accuracy: 0.0543\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6670 - accuracy: 0.0637 - val_loss: 5.0197 - val_accuracy: 0.0631\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6641 - accuracy: 0.0657 - val_loss: 5.0610 - val_accuracy: 0.0607\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6592 - accuracy: 0.0666 - val_loss: 5.0482 - val_accuracy: 0.0620\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6578 - accuracy: 0.0677 - val_loss: 5.0757 - val_accuracy: 0.0598\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6547 - accuracy: 0.0650 - val_loss: 5.0419 - val_accuracy: 0.0662\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6506 - accuracy: 0.0667 - val_loss: 5.0719 - val_accuracy: 0.0583\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6494 - accuracy: 0.0670 - val_loss: 5.0629 - val_accuracy: 0.0598\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6460 - accuracy: 0.0698 - val_loss: 5.0997 - val_accuracy: 0.0596\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6415 - accuracy: 0.0673 - val_loss: 5.0855 - val_accuracy: 0.0640\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6388 - accuracy: 0.0675 - val_loss: 5.0869 - val_accuracy: 0.0634\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6361 - accuracy: 0.0685 - val_loss: 5.0742 - val_accuracy: 0.0653\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 5.0664 - accuracy: 0.0442 - val_loss: 4.9862 - val_accuracy: 0.0535\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8845 - accuracy: 0.0552 - val_loss: 4.9440 - val_accuracy: 0.0480\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8414 - accuracy: 0.0541 - val_loss: 4.9178 - val_accuracy: 0.0510\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8199 - accuracy: 0.0559 - val_loss: 4.9202 - val_accuracy: 0.0535\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.8007 - accuracy: 0.0577 - val_loss: 4.9183 - val_accuracy: 0.0554\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7821 - accuracy: 0.0588 - val_loss: 4.9053 - val_accuracy: 0.0625\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7651 - accuracy: 0.0604 - val_loss: 4.8977 - val_accuracy: 0.0570\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7528 - accuracy: 0.0625 - val_loss: 4.8943 - val_accuracy: 0.0552\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7400 - accuracy: 0.0604 - val_loss: 4.9200 - val_accuracy: 0.0526\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7260 - accuracy: 0.0628 - val_loss: 4.9179 - val_accuracy: 0.0603\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7169 - accuracy: 0.0630 - val_loss: 4.9237 - val_accuracy: 0.0601\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.7068 - accuracy: 0.0615 - val_loss: 4.9174 - val_accuracy: 0.0631\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6988 - accuracy: 0.0623 - val_loss: 4.9272 - val_accuracy: 0.0524\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.6879 - accuracy: 0.0626 - val_loss: 4.9502 - val_accuracy: 0.0548\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6796 - accuracy: 0.0607 - val_loss: 4.9522 - val_accuracy: 0.0603\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6750 - accuracy: 0.0622 - val_loss: 4.9516 - val_accuracy: 0.0638\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6676 - accuracy: 0.0661 - val_loss: 4.9773 - val_accuracy: 0.0660\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6586 - accuracy: 0.0661 - val_loss: 4.9880 - val_accuracy: 0.0609\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6545 - accuracy: 0.0655 - val_loss: 5.0058 - val_accuracy: 0.0609\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6490 - accuracy: 0.0661 - val_loss: 5.0246 - val_accuracy: 0.0700\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6440 - accuracy: 0.0670 - val_loss: 5.0489 - val_accuracy: 0.0702\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6389 - accuracy: 0.0685 - val_loss: 5.0596 - val_accuracy: 0.0629\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6336 - accuracy: 0.0661 - val_loss: 5.0699 - val_accuracy: 0.0673\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6289 - accuracy: 0.0696 - val_loss: 5.0593 - val_accuracy: 0.0686\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6250 - accuracy: 0.0678 - val_loss: 5.1006 - val_accuracy: 0.0638\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6186 - accuracy: 0.0686 - val_loss: 5.1059 - val_accuracy: 0.0634\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6136 - accuracy: 0.0696 - val_loss: 5.1234 - val_accuracy: 0.0702\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6056 - accuracy: 0.0732 - val_loss: 5.1666 - val_accuracy: 0.0607\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6021 - accuracy: 0.0721 - val_loss: 5.1516 - val_accuracy: 0.0636\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5964 - accuracy: 0.0701 - val_loss: 5.1903 - val_accuracy: 0.0627\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5934 - accuracy: 0.0715 - val_loss: 5.1910 - val_accuracy: 0.0675\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5866 - accuracy: 0.0717 - val_loss: 5.2327 - val_accuracy: 0.0645\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.5829 - accuracy: 0.0748 - val_loss: 5.2237 - val_accuracy: 0.0642\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5800 - accuracy: 0.0714 - val_loss: 5.2096 - val_accuracy: 0.0634\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5732 - accuracy: 0.0701 - val_loss: 5.2076 - val_accuracy: 0.0684\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5698 - accuracy: 0.0716 - val_loss: 5.2350 - val_accuracy: 0.0640\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5675 - accuracy: 0.0737 - val_loss: 5.2779 - val_accuracy: 0.0627\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 4.5634 - accuracy: 0.0728 - val_loss: 5.2641 - val_accuracy: 0.0649\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5595 - accuracy: 0.0725 - val_loss: 5.2903 - val_accuracy: 0.0708\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5547 - accuracy: 0.0724 - val_loss: 5.2467 - val_accuracy: 0.0686\n","Average Validation Accuracy: 0.06713143363595009\n","Average Validation Loss: 4.977795600891113\n","Average Test Accuracy: 0.06781160086393356\n","------------------------------------------------------------------------\n","\n","Number of input features: 3\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 7s 3ms/step - loss: 5.0288 - accuracy: 0.0551 - val_loss: 4.8403 - val_accuracy: 0.0728\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6860 - accuracy: 0.0832 - val_loss: 4.7218 - val_accuracy: 0.0779\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5980 - accuracy: 0.0842 - val_loss: 4.6779 - val_accuracy: 0.0785\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5555 - accuracy: 0.0857 - val_loss: 4.6561 - val_accuracy: 0.0722\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5252 - accuracy: 0.0849 - val_loss: 4.6521 - val_accuracy: 0.0781\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.5030 - accuracy: 0.0882 - val_loss: 4.6465 - val_accuracy: 0.0790\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4837 - accuracy: 0.0891 - val_loss: 4.6508 - val_accuracy: 0.0774\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4740 - accuracy: 0.0907 - val_loss: 4.6578 - val_accuracy: 0.0807\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4613 - accuracy: 0.0909 - val_loss: 4.6482 - val_accuracy: 0.0807\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4520 - accuracy: 0.0920 - val_loss: 4.6553 - val_accuracy: 0.0785\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4433 - accuracy: 0.0920 - val_loss: 4.6492 - val_accuracy: 0.0832\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4332 - accuracy: 0.0931 - val_loss: 4.6599 - val_accuracy: 0.0832\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4252 - accuracy: 0.0977 - val_loss: 4.6700 - val_accuracy: 0.0860\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4197 - accuracy: 0.0980 - val_loss: 4.6754 - val_accuracy: 0.0840\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4114 - accuracy: 0.0956 - val_loss: 4.7152 - val_accuracy: 0.0860\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4071 - accuracy: 0.0976 - val_loss: 4.6962 - val_accuracy: 0.0878\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4025 - accuracy: 0.0970 - val_loss: 4.7075 - val_accuracy: 0.0884\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3967 - accuracy: 0.0986 - val_loss: 4.7032 - val_accuracy: 0.0922\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3910 - accuracy: 0.0984 - val_loss: 4.7120 - val_accuracy: 0.0902\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3865 - accuracy: 0.0977 - val_loss: 4.7373 - val_accuracy: 0.0869\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3823 - accuracy: 0.0991 - val_loss: 4.7390 - val_accuracy: 0.0922\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3766 - accuracy: 0.0977 - val_loss: 4.7686 - val_accuracy: 0.0893\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3719 - accuracy: 0.1003 - val_loss: 4.7650 - val_accuracy: 0.0924\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3658 - accuracy: 0.0984 - val_loss: 4.7532 - val_accuracy: 0.0862\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 4.3623 - accuracy: 0.1010 - val_loss: 4.8216 - val_accuracy: 0.0834\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3592 - accuracy: 0.0997 - val_loss: 4.7811 - val_accuracy: 0.0878\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 4.3562 - accuracy: 0.0999 - val_loss: 4.7742 - val_accuracy: 0.0867\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3530 - accuracy: 0.0996 - val_loss: 4.8254 - val_accuracy: 0.0832\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3488 - accuracy: 0.0982 - val_loss: 4.8175 - val_accuracy: 0.0891\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3448 - accuracy: 0.0982 - val_loss: 4.7990 - val_accuracy: 0.0884\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3444 - accuracy: 0.0973 - val_loss: 4.8256 - val_accuracy: 0.0880\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3411 - accuracy: 0.0993 - val_loss: 4.8643 - val_accuracy: 0.0845\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3381 - accuracy: 0.0979 - val_loss: 4.8368 - val_accuracy: 0.0862\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3348 - accuracy: 0.0997 - val_loss: 4.8395 - val_accuracy: 0.0847\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3322 - accuracy: 0.0997 - val_loss: 4.8421 - val_accuracy: 0.0900\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3300 - accuracy: 0.0999 - val_loss: 4.8632 - val_accuracy: 0.0860\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3264 - accuracy: 0.0992 - val_loss: 4.9001 - val_accuracy: 0.0840\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3232 - accuracy: 0.0987 - val_loss: 4.8922 - val_accuracy: 0.0922\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3199 - accuracy: 0.1004 - val_loss: 4.9001 - val_accuracy: 0.0955\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3190 - accuracy: 0.0993 - val_loss: 4.8612 - val_accuracy: 0.0939\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.9761 - accuracy: 0.0623 - val_loss: 4.7701 - val_accuracy: 0.0796\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.6416 - accuracy: 0.0828 - val_loss: 4.7175 - val_accuracy: 0.0799\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5917 - accuracy: 0.0840 - val_loss: 4.6854 - val_accuracy: 0.0781\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5653 - accuracy: 0.0845 - val_loss: 4.6534 - val_accuracy: 0.0876\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5346 - accuracy: 0.0849 - val_loss: 4.6384 - val_accuracy: 0.0862\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5070 - accuracy: 0.0850 - val_loss: 4.6406 - val_accuracy: 0.0821\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4847 - accuracy: 0.0846 - val_loss: 4.6163 - val_accuracy: 0.0882\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4708 - accuracy: 0.0842 - val_loss: 4.6205 - val_accuracy: 0.0895\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4569 - accuracy: 0.0877 - val_loss: 4.6190 - val_accuracy: 0.0871\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4470 - accuracy: 0.0872 - val_loss: 4.6390 - val_accuracy: 0.0860\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4400 - accuracy: 0.0898 - val_loss: 4.6644 - val_accuracy: 0.0876\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4325 - accuracy: 0.0880 - val_loss: 4.6345 - val_accuracy: 0.0827\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4251 - accuracy: 0.0896 - val_loss: 4.6367 - val_accuracy: 0.0937\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.4208 - accuracy: 0.0879 - val_loss: 4.6516 - val_accuracy: 0.0851\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4156 - accuracy: 0.0909 - val_loss: 4.6776 - val_accuracy: 0.0799\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4104 - accuracy: 0.0879 - val_loss: 4.6588 - val_accuracy: 0.0904\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.4057 - accuracy: 0.0915 - val_loss: 4.7154 - val_accuracy: 0.0832\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3997 - accuracy: 0.0880 - val_loss: 4.7209 - val_accuracy: 0.0891\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3987 - accuracy: 0.0897 - val_loss: 4.7015 - val_accuracy: 0.0832\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3920 - accuracy: 0.0894 - val_loss: 4.7237 - val_accuracy: 0.0867\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3879 - accuracy: 0.0924 - val_loss: 4.7791 - val_accuracy: 0.0856\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3851 - accuracy: 0.0892 - val_loss: 4.7249 - val_accuracy: 0.0917\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3793 - accuracy: 0.0926 - val_loss: 4.7539 - val_accuracy: 0.0823\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3733 - accuracy: 0.0905 - val_loss: 4.7540 - val_accuracy: 0.0818\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3682 - accuracy: 0.0913 - val_loss: 4.7709 - val_accuracy: 0.0876\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3647 - accuracy: 0.0908 - val_loss: 4.7718 - val_accuracy: 0.0924\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3598 - accuracy: 0.0920 - val_loss: 4.7755 - val_accuracy: 0.0898\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3562 - accuracy: 0.0973 - val_loss: 4.7990 - val_accuracy: 0.0931\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3557 - accuracy: 0.0932 - val_loss: 4.8242 - val_accuracy: 0.0904\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3516 - accuracy: 0.0946 - val_loss: 4.7888 - val_accuracy: 0.0906\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3491 - accuracy: 0.0981 - val_loss: 4.7895 - val_accuracy: 0.0904\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3445 - accuracy: 0.0952 - val_loss: 4.7888 - val_accuracy: 0.0856\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3398 - accuracy: 0.0922 - val_loss: 4.8217 - val_accuracy: 0.0902\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3375 - accuracy: 0.0948 - val_loss: 4.8553 - val_accuracy: 0.0931\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3345 - accuracy: 0.0947 - val_loss: 4.8441 - val_accuracy: 0.0933\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3327 - accuracy: 0.0954 - val_loss: 4.8258 - val_accuracy: 0.0935\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3285 - accuracy: 0.0971 - val_loss: 4.8379 - val_accuracy: 0.0898\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3269 - accuracy: 0.0963 - val_loss: 4.8749 - val_accuracy: 0.0904\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.3224 - accuracy: 0.0981 - val_loss: 4.8730 - val_accuracy: 0.0935\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.3195 - accuracy: 0.0937 - val_loss: 4.8503 - val_accuracy: 0.0871\n","Average Validation Accuracy: 0.09229183942079544\n","Average Validation Loss: 4.681270599365234\n","Average Test Accuracy: 0.09206162020564079\n","------------------------------------------------------------------------\n","\n","Number of input features: 4\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.5953 - accuracy: 0.0978 - val_loss: 4.1247 - val_accuracy: 0.1417\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.7193 - accuracy: 0.1826 - val_loss: 3.6497 - val_accuracy: 0.2057\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.3433 - accuracy: 0.2398 - val_loss: 3.4146 - val_accuracy: 0.2594\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.0887 - accuracy: 0.2779 - val_loss: 3.2095 - val_accuracy: 0.2686\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.8911 - accuracy: 0.3012 - val_loss: 3.1083 - val_accuracy: 0.3259\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7321 - accuracy: 0.3317 - val_loss: 3.0918 - val_accuracy: 0.2865\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.6132 - accuracy: 0.3467 - val_loss: 2.9196 - val_accuracy: 0.3314\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.5234 - accuracy: 0.3554 - val_loss: 2.8674 - val_accuracy: 0.3215\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4593 - accuracy: 0.3659 - val_loss: 2.7960 - val_accuracy: 0.3371\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4087 - accuracy: 0.3733 - val_loss: 2.7437 - val_accuracy: 0.3699\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.3754 - accuracy: 0.3790 - val_loss: 2.7220 - val_accuracy: 0.3696\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.3352 - accuracy: 0.3853 - val_loss: 2.7006 - val_accuracy: 0.3710\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.3112 - accuracy: 0.3894 - val_loss: 2.6556 - val_accuracy: 0.4143\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2746 - accuracy: 0.3958 - val_loss: 2.6333 - val_accuracy: 0.3771\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2514 - accuracy: 0.4023 - val_loss: 2.7097 - val_accuracy: 0.3663\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2344 - accuracy: 0.3992 - val_loss: 2.6654 - val_accuracy: 0.3795\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2104 - accuracy: 0.4074 - val_loss: 2.5716 - val_accuracy: 0.4086\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1973 - accuracy: 0.4101 - val_loss: 2.4817 - val_accuracy: 0.4205\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1779 - accuracy: 0.4124 - val_loss: 2.5643 - val_accuracy: 0.3826\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1701 - accuracy: 0.4189 - val_loss: 2.5704 - val_accuracy: 0.3553\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1573 - accuracy: 0.4168 - val_loss: 2.5991 - val_accuracy: 0.3833\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1408 - accuracy: 0.4204 - val_loss: 2.4936 - val_accuracy: 0.4356\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1313 - accuracy: 0.4229 - val_loss: 2.4640 - val_accuracy: 0.3855\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1175 - accuracy: 0.4275 - val_loss: 2.4652 - val_accuracy: 0.4156\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1062 - accuracy: 0.4274 - val_loss: 2.4532 - val_accuracy: 0.4196\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1042 - accuracy: 0.4304 - val_loss: 2.3821 - val_accuracy: 0.4356\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0907 - accuracy: 0.4306 - val_loss: 2.5008 - val_accuracy: 0.4185\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0894 - accuracy: 0.4290 - val_loss: 2.4471 - val_accuracy: 0.4493\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0767 - accuracy: 0.4330 - val_loss: 2.5076 - val_accuracy: 0.4132\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0687 - accuracy: 0.4349 - val_loss: 2.3981 - val_accuracy: 0.4251\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0576 - accuracy: 0.4393 - val_loss: 2.4377 - val_accuracy: 0.4297\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0487 - accuracy: 0.4455 - val_loss: 2.3979 - val_accuracy: 0.4220\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0467 - accuracy: 0.4440 - val_loss: 2.3934 - val_accuracy: 0.3954\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0380 - accuracy: 0.4426 - val_loss: 2.3793 - val_accuracy: 0.4290\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0410 - accuracy: 0.4427 - val_loss: 2.6797 - val_accuracy: 0.3749\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0196 - accuracy: 0.4485 - val_loss: 2.3200 - val_accuracy: 0.4691\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0250 - accuracy: 0.4475 - val_loss: 2.3661 - val_accuracy: 0.4367\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0181 - accuracy: 0.4481 - val_loss: 2.4043 - val_accuracy: 0.3776\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0074 - accuracy: 0.4481 - val_loss: 2.3510 - val_accuracy: 0.4323\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0016 - accuracy: 0.4543 - val_loss: 2.3809 - val_accuracy: 0.4403\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 7s 3ms/step - loss: 4.6044 - accuracy: 0.0936 - val_loss: 4.1449 - val_accuracy: 0.1692\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.7399 - accuracy: 0.1772 - val_loss: 3.7613 - val_accuracy: 0.2453\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.3240 - accuracy: 0.2452 - val_loss: 3.4955 - val_accuracy: 0.2433\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.0265 - accuracy: 0.2882 - val_loss: 3.3673 - val_accuracy: 0.2711\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.8061 - accuracy: 0.3225 - val_loss: 3.1643 - val_accuracy: 0.3443\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.6404 - accuracy: 0.3455 - val_loss: 3.1196 - val_accuracy: 0.3410\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.5329 - accuracy: 0.3632 - val_loss: 3.0098 - val_accuracy: 0.3723\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4413 - accuracy: 0.3742 - val_loss: 2.9609 - val_accuracy: 0.3635\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3725 - accuracy: 0.3831 - val_loss: 2.8853 - val_accuracy: 0.3833\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3237 - accuracy: 0.3909 - val_loss: 2.8791 - val_accuracy: 0.3927\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2802 - accuracy: 0.3990 - val_loss: 2.7898 - val_accuracy: 0.3936\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2332 - accuracy: 0.4090 - val_loss: 2.7792 - val_accuracy: 0.4216\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1949 - accuracy: 0.4092 - val_loss: 2.6904 - val_accuracy: 0.3965\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1881 - accuracy: 0.4141 - val_loss: 2.6771 - val_accuracy: 0.3795\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1523 - accuracy: 0.4174 - val_loss: 2.6801 - val_accuracy: 0.4301\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1387 - accuracy: 0.4173 - val_loss: 2.6080 - val_accuracy: 0.4288\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1218 - accuracy: 0.4248 - val_loss: 2.5837 - val_accuracy: 0.4117\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1037 - accuracy: 0.4165 - val_loss: 2.6243 - val_accuracy: 0.3914\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0810 - accuracy: 0.4299 - val_loss: 2.5959 - val_accuracy: 0.4101\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0610 - accuracy: 0.4320 - val_loss: 2.5748 - val_accuracy: 0.4238\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0634 - accuracy: 0.4267 - val_loss: 2.5393 - val_accuracy: 0.4427\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0528 - accuracy: 0.4321 - val_loss: 2.5884 - val_accuracy: 0.4114\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0231 - accuracy: 0.4336 - val_loss: 2.5522 - val_accuracy: 0.4403\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0085 - accuracy: 0.4376 - val_loss: 2.5548 - val_accuracy: 0.4068\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9986 - accuracy: 0.4419 - val_loss: 2.5206 - val_accuracy: 0.4508\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9942 - accuracy: 0.4414 - val_loss: 2.4600 - val_accuracy: 0.4334\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9878 - accuracy: 0.4432 - val_loss: 2.4579 - val_accuracy: 0.4282\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9768 - accuracy: 0.4415 - val_loss: 2.4353 - val_accuracy: 0.4367\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9556 - accuracy: 0.4462 - val_loss: 2.4656 - val_accuracy: 0.4510\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9593 - accuracy: 0.4499 - val_loss: 2.5723 - val_accuracy: 0.4097\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9451 - accuracy: 0.4520 - val_loss: 2.4477 - val_accuracy: 0.4605\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9451 - accuracy: 0.4485 - val_loss: 2.4858 - val_accuracy: 0.4251\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9293 - accuracy: 0.4588 - val_loss: 2.4243 - val_accuracy: 0.4515\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9213 - accuracy: 0.4532 - val_loss: 2.3856 - val_accuracy: 0.4900\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9113 - accuracy: 0.4570 - val_loss: 2.4529 - val_accuracy: 0.4695\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8947 - accuracy: 0.4610 - val_loss: 2.4301 - val_accuracy: 0.4697\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8877 - accuracy: 0.4683 - val_loss: 2.4258 - val_accuracy: 0.4651\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8881 - accuracy: 0.4622 - val_loss: 2.3990 - val_accuracy: 0.4689\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8795 - accuracy: 0.4680 - val_loss: 2.4379 - val_accuracy: 0.4409\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8821 - accuracy: 0.4634 - val_loss: 2.3926 - val_accuracy: 0.4473\n","Average Validation Accuracy: 0.4540899991989136\n","Average Validation Loss: 2.1163944005966187\n","Average Test Accuracy: 0.4527898579835892\n","------------------------------------------------------------------------\n","\n","Number of input features: 5\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.4202 - accuracy: 0.1269 - val_loss: 3.8777 - val_accuracy: 0.2051\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.3513 - accuracy: 0.2759 - val_loss: 3.1268 - val_accuracy: 0.3234\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.7091 - accuracy: 0.3671 - val_loss: 2.6597 - val_accuracy: 0.3859\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2777 - accuracy: 0.4260 - val_loss: 2.3985 - val_accuracy: 0.4458\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0139 - accuracy: 0.4653 - val_loss: 2.1513 - val_accuracy: 0.4898\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.8147 - accuracy: 0.5008 - val_loss: 2.0291 - val_accuracy: 0.4990\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6764 - accuracy: 0.5267 - val_loss: 1.9168 - val_accuracy: 0.5270\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5613 - accuracy: 0.5596 - val_loss: 1.8699 - val_accuracy: 0.5448\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4704 - accuracy: 0.5800 - val_loss: 1.7648 - val_accuracy: 0.5842\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4219 - accuracy: 0.5905 - val_loss: 1.6696 - val_accuracy: 0.6392\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3549 - accuracy: 0.6085 - val_loss: 1.6654 - val_accuracy: 0.5921\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3213 - accuracy: 0.6087 - val_loss: 1.6561 - val_accuracy: 0.6119\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2984 - accuracy: 0.6114 - val_loss: 1.5911 - val_accuracy: 0.5716\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2734 - accuracy: 0.6191 - val_loss: 1.6142 - val_accuracy: 0.5888\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2452 - accuracy: 0.6288 - val_loss: 1.6030 - val_accuracy: 0.5879\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2421 - accuracy: 0.6246 - val_loss: 1.5230 - val_accuracy: 0.6273\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1906 - accuracy: 0.6457 - val_loss: 1.5352 - val_accuracy: 0.6033\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1889 - accuracy: 0.6352 - val_loss: 1.5470 - val_accuracy: 0.6062\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1757 - accuracy: 0.6515 - val_loss: 1.7149 - val_accuracy: 0.5795\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1634 - accuracy: 0.6474 - val_loss: 1.5277 - val_accuracy: 0.6180\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1358 - accuracy: 0.6591 - val_loss: 1.4070 - val_accuracy: 0.6631\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1355 - accuracy: 0.6553 - val_loss: 1.4886 - val_accuracy: 0.6007\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1129 - accuracy: 0.6572 - val_loss: 1.4781 - val_accuracy: 0.6275\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1055 - accuracy: 0.6637 - val_loss: 1.4159 - val_accuracy: 0.6392\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0961 - accuracy: 0.6588 - val_loss: 1.3854 - val_accuracy: 0.6539\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0789 - accuracy: 0.6662 - val_loss: 1.3497 - val_accuracy: 0.6473\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0751 - accuracy: 0.6682 - val_loss: 1.3696 - val_accuracy: 0.6455\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0691 - accuracy: 0.6702 - val_loss: 1.3785 - val_accuracy: 0.6528\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0481 - accuracy: 0.6766 - val_loss: 1.4228 - val_accuracy: 0.6359\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0405 - accuracy: 0.6783 - val_loss: 1.4005 - val_accuracy: 0.6480\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0412 - accuracy: 0.6798 - val_loss: 1.3772 - val_accuracy: 0.6717\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0390 - accuracy: 0.6801 - val_loss: 1.3280 - val_accuracy: 0.6686\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0177 - accuracy: 0.6819 - val_loss: 1.3512 - val_accuracy: 0.6715\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0094 - accuracy: 0.6835 - val_loss: 1.3566 - val_accuracy: 0.6339\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0176 - accuracy: 0.6846 - val_loss: 1.2901 - val_accuracy: 0.6858\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0068 - accuracy: 0.6875 - val_loss: 1.2752 - val_accuracy: 0.6755\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0065 - accuracy: 0.6883 - val_loss: 1.3594 - val_accuracy: 0.6594\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9943 - accuracy: 0.6928 - val_loss: 1.3649 - val_accuracy: 0.6411\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9894 - accuracy: 0.6903 - val_loss: 1.3206 - val_accuracy: 0.6871\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9842 - accuracy: 0.6935 - val_loss: 1.3049 - val_accuracy: 0.6871\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.5693 - accuracy: 0.1072 - val_loss: 4.0342 - val_accuracy: 0.1672\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.4434 - accuracy: 0.2600 - val_loss: 3.2179 - val_accuracy: 0.3157\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.7165 - accuracy: 0.3755 - val_loss: 2.7103 - val_accuracy: 0.4178\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2402 - accuracy: 0.4472 - val_loss: 2.3854 - val_accuracy: 0.4645\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9212 - accuracy: 0.5053 - val_loss: 2.0879 - val_accuracy: 0.5173\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6672 - accuracy: 0.5497 - val_loss: 1.9247 - val_accuracy: 0.5325\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4789 - accuracy: 0.5877 - val_loss: 1.7549 - val_accuracy: 0.5820\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3504 - accuracy: 0.6178 - val_loss: 1.6724 - val_accuracy: 0.5771\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2635 - accuracy: 0.6329 - val_loss: 1.6129 - val_accuracy: 0.5703\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2029 - accuracy: 0.6448 - val_loss: 1.4941 - val_accuracy: 0.6431\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1458 - accuracy: 0.6614 - val_loss: 1.3513 - val_accuracy: 0.6733\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1092 - accuracy: 0.6644 - val_loss: 1.3167 - val_accuracy: 0.6944\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0796 - accuracy: 0.6782 - val_loss: 1.3538 - val_accuracy: 0.6348\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0494 - accuracy: 0.6786 - val_loss: 1.3156 - val_accuracy: 0.6493\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0269 - accuracy: 0.6886 - val_loss: 1.2124 - val_accuracy: 0.6845\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0074 - accuracy: 0.6934 - val_loss: 1.2109 - val_accuracy: 0.6966\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9966 - accuracy: 0.6944 - val_loss: 1.2032 - val_accuracy: 0.6911\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9790 - accuracy: 0.6982 - val_loss: 1.2294 - val_accuracy: 0.6889\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9617 - accuracy: 0.7034 - val_loss: 1.1814 - val_accuracy: 0.7063\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9651 - accuracy: 0.7010 - val_loss: 1.2467 - val_accuracy: 0.6526\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9453 - accuracy: 0.7054 - val_loss: 1.1928 - val_accuracy: 0.6792\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9393 - accuracy: 0.7069 - val_loss: 1.4910 - val_accuracy: 0.5811\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9157 - accuracy: 0.7129 - val_loss: 1.1500 - val_accuracy: 0.6891\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9218 - accuracy: 0.7113 - val_loss: 1.1053 - val_accuracy: 0.7085\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9000 - accuracy: 0.7161 - val_loss: 1.1928 - val_accuracy: 0.6757\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8965 - accuracy: 0.7192 - val_loss: 1.2165 - val_accuracy: 0.6867\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8913 - accuracy: 0.7184 - val_loss: 1.0599 - val_accuracy: 0.6979\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8876 - accuracy: 0.7214 - val_loss: 1.1926 - val_accuracy: 0.6724\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8679 - accuracy: 0.7257 - val_loss: 1.1127 - val_accuracy: 0.7199\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8679 - accuracy: 0.7230 - val_loss: 1.0415 - val_accuracy: 0.7186\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8616 - accuracy: 0.7295 - val_loss: 1.1419 - val_accuracy: 0.6865\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8635 - accuracy: 0.7291 - val_loss: 1.0291 - val_accuracy: 0.7212\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8560 - accuracy: 0.7305 - val_loss: 1.0177 - val_accuracy: 0.7344\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8311 - accuracy: 0.7307 - val_loss: 1.1010 - val_accuracy: 0.7096\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8543 - accuracy: 0.7325 - val_loss: 1.0761 - val_accuracy: 0.7219\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8345 - accuracy: 0.7308 - val_loss: 1.0239 - val_accuracy: 0.7164\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8295 - accuracy: 0.7323 - val_loss: 1.0373 - val_accuracy: 0.7113\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8251 - accuracy: 0.7377 - val_loss: 1.0454 - val_accuracy: 0.7263\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8230 - accuracy: 0.7336 - val_loss: 1.0265 - val_accuracy: 0.7162\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8316 - accuracy: 0.7326 - val_loss: 1.0425 - val_accuracy: 0.7252\n","Average Validation Accuracy: 0.7147378027439117\n","Average Validation Loss: 0.9928358197212219\n","Average Test Accuracy: 0.7087417840957642\n","------------------------------------------------------------------------\n","\n","Number of input features: 6\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.2332 - accuracy: 0.1862 - val_loss: 3.4703 - val_accuracy: 0.3307\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.7192 - accuracy: 0.4280 - val_loss: 2.4259 - val_accuracy: 0.5628\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8601 - accuracy: 0.5883 - val_loss: 1.8703 - val_accuracy: 0.6308\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3736 - accuracy: 0.6691 - val_loss: 1.5280 - val_accuracy: 0.7069\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1025 - accuracy: 0.7196 - val_loss: 1.3576 - val_accuracy: 0.7349\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9435 - accuracy: 0.7495 - val_loss: 1.2653 - val_accuracy: 0.7371\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8361 - accuracy: 0.7722 - val_loss: 1.1496 - val_accuracy: 0.7672\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7554 - accuracy: 0.7922 - val_loss: 1.1879 - val_accuracy: 0.7157\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6953 - accuracy: 0.8037 - val_loss: 1.0193 - val_accuracy: 0.7817\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6518 - accuracy: 0.8138 - val_loss: 0.9282 - val_accuracy: 0.8092\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6305 - accuracy: 0.8119 - val_loss: 1.0779 - val_accuracy: 0.7630\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5956 - accuracy: 0.8277 - val_loss: 0.8679 - val_accuracy: 0.8257\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5670 - accuracy: 0.8338 - val_loss: 0.8267 - val_accuracy: 0.8442\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5322 - accuracy: 0.8402 - val_loss: 0.8456 - val_accuracy: 0.8114\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5220 - accuracy: 0.8433 - val_loss: 0.7909 - val_accuracy: 0.8442\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4965 - accuracy: 0.8509 - val_loss: 0.8021 - val_accuracy: 0.8299\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4904 - accuracy: 0.8545 - val_loss: 0.8382 - val_accuracy: 0.8139\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4932 - accuracy: 0.8505 - val_loss: 0.7518 - val_accuracy: 0.8227\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4571 - accuracy: 0.8565 - val_loss: 1.0260 - val_accuracy: 0.7584\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4586 - accuracy: 0.8594 - val_loss: 0.7404 - val_accuracy: 0.8209\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4509 - accuracy: 0.8630 - val_loss: 0.7322 - val_accuracy: 0.8400\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4370 - accuracy: 0.8660 - val_loss: 0.7652 - val_accuracy: 0.8348\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4348 - accuracy: 0.8638 - val_loss: 0.7110 - val_accuracy: 0.8438\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4235 - accuracy: 0.8690 - val_loss: 0.7336 - val_accuracy: 0.8341\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4120 - accuracy: 0.8722 - val_loss: 0.7131 - val_accuracy: 0.8585\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4206 - accuracy: 0.8693 - val_loss: 0.7220 - val_accuracy: 0.8205\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3935 - accuracy: 0.8794 - val_loss: 0.7573 - val_accuracy: 0.8345\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3929 - accuracy: 0.8795 - val_loss: 0.7455 - val_accuracy: 0.8317\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4151 - accuracy: 0.8718 - val_loss: 0.5953 - val_accuracy: 0.8935\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3917 - accuracy: 0.8758 - val_loss: 0.6322 - val_accuracy: 0.8766\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3765 - accuracy: 0.8830 - val_loss: 0.6361 - val_accuracy: 0.8614\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3708 - accuracy: 0.8850 - val_loss: 0.6454 - val_accuracy: 0.8620\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3744 - accuracy: 0.8834 - val_loss: 0.6082 - val_accuracy: 0.8719\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3788 - accuracy: 0.8838 - val_loss: 0.6220 - val_accuracy: 0.8535\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3601 - accuracy: 0.8888 - val_loss: 0.6733 - val_accuracy: 0.8583\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3583 - accuracy: 0.8876 - val_loss: 0.6663 - val_accuracy: 0.8469\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3567 - accuracy: 0.8866 - val_loss: 0.5609 - val_accuracy: 0.9025\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3485 - accuracy: 0.8933 - val_loss: 0.5635 - val_accuracy: 0.8904\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3524 - accuracy: 0.8902 - val_loss: 0.5848 - val_accuracy: 0.8724\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3482 - accuracy: 0.8933 - val_loss: 0.5591 - val_accuracy: 0.8964\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.2268 - accuracy: 0.1878 - val_loss: 3.4230 - val_accuracy: 0.3122\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5718 - accuracy: 0.4614 - val_loss: 2.3269 - val_accuracy: 0.5626\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7344 - accuracy: 0.6106 - val_loss: 1.8851 - val_accuracy: 0.6163\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2831 - accuracy: 0.6932 - val_loss: 1.5437 - val_accuracy: 0.7245\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0307 - accuracy: 0.7337 - val_loss: 1.3454 - val_accuracy: 0.7560\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8848 - accuracy: 0.7632 - val_loss: 1.2267 - val_accuracy: 0.7712\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7882 - accuracy: 0.7834 - val_loss: 1.1983 - val_accuracy: 0.7463\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7143 - accuracy: 0.7963 - val_loss: 1.0520 - val_accuracy: 0.7967\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6583 - accuracy: 0.8126 - val_loss: 1.1815 - val_accuracy: 0.7347\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6138 - accuracy: 0.8215 - val_loss: 0.9793 - val_accuracy: 0.7908\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5909 - accuracy: 0.8267 - val_loss: 0.8966 - val_accuracy: 0.8359\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5632 - accuracy: 0.8316 - val_loss: 1.0002 - val_accuracy: 0.7826\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5359 - accuracy: 0.8403 - val_loss: 0.9853 - val_accuracy: 0.7780\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5379 - accuracy: 0.8359 - val_loss: 0.9125 - val_accuracy: 0.8051\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4955 - accuracy: 0.8504 - val_loss: 0.7757 - val_accuracy: 0.8550\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4931 - accuracy: 0.8530 - val_loss: 0.8152 - val_accuracy: 0.8189\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4750 - accuracy: 0.8520 - val_loss: 0.7408 - val_accuracy: 0.8381\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4577 - accuracy: 0.8584 - val_loss: 0.7880 - val_accuracy: 0.8244\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4615 - accuracy: 0.8573 - val_loss: 0.7888 - val_accuracy: 0.8275\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4485 - accuracy: 0.8649 - val_loss: 0.7547 - val_accuracy: 0.8381\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4380 - accuracy: 0.8640 - val_loss: 0.7394 - val_accuracy: 0.8631\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4354 - accuracy: 0.8652 - val_loss: 0.7640 - val_accuracy: 0.8497\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4181 - accuracy: 0.8705 - val_loss: 0.7669 - val_accuracy: 0.8438\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4041 - accuracy: 0.8748 - val_loss: 0.7508 - val_accuracy: 0.8451\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4066 - accuracy: 0.8723 - val_loss: 0.7669 - val_accuracy: 0.8348\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4244 - accuracy: 0.8676 - val_loss: 0.6374 - val_accuracy: 0.8920\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3849 - accuracy: 0.8819 - val_loss: 0.7154 - val_accuracy: 0.8554\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3832 - accuracy: 0.8809 - val_loss: 0.7075 - val_accuracy: 0.8618\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3814 - accuracy: 0.8812 - val_loss: 0.5971 - val_accuracy: 0.9102\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3845 - accuracy: 0.8789 - val_loss: 0.6536 - val_accuracy: 0.8816\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3739 - accuracy: 0.8851 - val_loss: 0.6236 - val_accuracy: 0.8823\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3700 - accuracy: 0.8826 - val_loss: 0.6856 - val_accuracy: 0.8673\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3639 - accuracy: 0.8892 - val_loss: 0.6424 - val_accuracy: 0.8680\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3566 - accuracy: 0.8857 - val_loss: 0.6403 - val_accuracy: 0.8603\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3468 - accuracy: 0.8912 - val_loss: 0.5805 - val_accuracy: 0.8818\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3597 - accuracy: 0.8864 - val_loss: 0.5885 - val_accuracy: 0.9021\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3432 - accuracy: 0.8953 - val_loss: 0.6111 - val_accuracy: 0.8931\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3362 - accuracy: 0.8938 - val_loss: 0.6320 - val_accuracy: 0.8587\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3281 - accuracy: 0.9008 - val_loss: 0.6301 - val_accuracy: 0.8724\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3321 - accuracy: 0.8963 - val_loss: 0.5978 - val_accuracy: 0.8878\n","Average Validation Accuracy: 0.9028427004814148\n","Average Validation Loss: 0.3972732722759247\n","Average Test Accuracy: 0.8961450457572937\n","------------------------------------------------------------------------\n","\n","Number of input features: 7\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.4052 - accuracy: 0.1547 - val_loss: 3.6569 - val_accuracy: 0.2884\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.9245 - accuracy: 0.3808 - val_loss: 2.6808 - val_accuracy: 0.4418\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1692 - accuracy: 0.5261 - val_loss: 2.1426 - val_accuracy: 0.5934\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6560 - accuracy: 0.6203 - val_loss: 1.8305 - val_accuracy: 0.6150\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3178 - accuracy: 0.6827 - val_loss: 1.5207 - val_accuracy: 0.6988\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1023 - accuracy: 0.7210 - val_loss: 1.3671 - val_accuracy: 0.7342\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9581 - accuracy: 0.7476 - val_loss: 1.2523 - val_accuracy: 0.7685\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8533 - accuracy: 0.7714 - val_loss: 1.1773 - val_accuracy: 0.7714\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7749 - accuracy: 0.7877 - val_loss: 1.0794 - val_accuracy: 0.7817\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7149 - accuracy: 0.8003 - val_loss: 1.1155 - val_accuracy: 0.7505\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6738 - accuracy: 0.8053 - val_loss: 0.9899 - val_accuracy: 0.8042\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6296 - accuracy: 0.8149 - val_loss: 0.9273 - val_accuracy: 0.8070\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5907 - accuracy: 0.8283 - val_loss: 0.9263 - val_accuracy: 0.8059\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5680 - accuracy: 0.8311 - val_loss: 0.8537 - val_accuracy: 0.8310\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5505 - accuracy: 0.8380 - val_loss: 0.8311 - val_accuracy: 0.8466\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5141 - accuracy: 0.8453 - val_loss: 0.8117 - val_accuracy: 0.8416\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5110 - accuracy: 0.8473 - val_loss: 0.7819 - val_accuracy: 0.8438\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4923 - accuracy: 0.8500 - val_loss: 0.7627 - val_accuracy: 0.8607\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4614 - accuracy: 0.8602 - val_loss: 0.8173 - val_accuracy: 0.8389\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4634 - accuracy: 0.8594 - val_loss: 0.8207 - val_accuracy: 0.8389\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4575 - accuracy: 0.8615 - val_loss: 0.8699 - val_accuracy: 0.8198\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4415 - accuracy: 0.8674 - val_loss: 0.7771 - val_accuracy: 0.8405\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4259 - accuracy: 0.8692 - val_loss: 0.6919 - val_accuracy: 0.8722\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4216 - accuracy: 0.8700 - val_loss: 0.8082 - val_accuracy: 0.8134\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4043 - accuracy: 0.8765 - val_loss: 0.7064 - val_accuracy: 0.8667\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3885 - accuracy: 0.8840 - val_loss: 0.6630 - val_accuracy: 0.8783\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4077 - accuracy: 0.8736 - val_loss: 0.6889 - val_accuracy: 0.8755\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3922 - accuracy: 0.8808 - val_loss: 0.6465 - val_accuracy: 0.8733\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3679 - accuracy: 0.8881 - val_loss: 0.6501 - val_accuracy: 0.8759\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3801 - accuracy: 0.8839 - val_loss: 0.7467 - val_accuracy: 0.8530\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3668 - accuracy: 0.8938 - val_loss: 0.6486 - val_accuracy: 0.8871\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3544 - accuracy: 0.8916 - val_loss: 0.6127 - val_accuracy: 0.8959\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3511 - accuracy: 0.8928 - val_loss: 0.6315 - val_accuracy: 0.8799\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3504 - accuracy: 0.8928 - val_loss: 0.6080 - val_accuracy: 0.8961\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3385 - accuracy: 0.8980 - val_loss: 0.5976 - val_accuracy: 0.8847\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3263 - accuracy: 0.9038 - val_loss: 0.6434 - val_accuracy: 0.8862\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3311 - accuracy: 0.9006 - val_loss: 0.6458 - val_accuracy: 0.8757\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3298 - accuracy: 0.8990 - val_loss: 0.6726 - val_accuracy: 0.8642\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3137 - accuracy: 0.9059 - val_loss: 0.5924 - val_accuracy: 0.9019\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3301 - accuracy: 0.9035 - val_loss: 0.5598 - val_accuracy: 0.9072\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.4686 - accuracy: 0.1337 - val_loss: 3.7855 - val_accuracy: 0.2389\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.0359 - accuracy: 0.3568 - val_loss: 2.7900 - val_accuracy: 0.4409\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1331 - accuracy: 0.5390 - val_loss: 2.2329 - val_accuracy: 0.5518\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5951 - accuracy: 0.6376 - val_loss: 1.7849 - val_accuracy: 0.6750\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2469 - accuracy: 0.6969 - val_loss: 1.5545 - val_accuracy: 0.7234\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0261 - accuracy: 0.7333 - val_loss: 1.4256 - val_accuracy: 0.7333\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8749 - accuracy: 0.7658 - val_loss: 1.3014 - val_accuracy: 0.7558\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7614 - accuracy: 0.7918 - val_loss: 1.2339 - val_accuracy: 0.7646\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6909 - accuracy: 0.8061 - val_loss: 1.1223 - val_accuracy: 0.7872\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6137 - accuracy: 0.8270 - val_loss: 1.0952 - val_accuracy: 0.7897\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5775 - accuracy: 0.8334 - val_loss: 0.9546 - val_accuracy: 0.8365\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5395 - accuracy: 0.8427 - val_loss: 0.9754 - val_accuracy: 0.8262\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4967 - accuracy: 0.8517 - val_loss: 0.9262 - val_accuracy: 0.8365\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4719 - accuracy: 0.8592 - val_loss: 0.8352 - val_accuracy: 0.8693\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4497 - accuracy: 0.8688 - val_loss: 0.8258 - val_accuracy: 0.8583\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4283 - accuracy: 0.8725 - val_loss: 0.8482 - val_accuracy: 0.8334\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4076 - accuracy: 0.8781 - val_loss: 0.8023 - val_accuracy: 0.8506\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3956 - accuracy: 0.8789 - val_loss: 0.7950 - val_accuracy: 0.8695\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3878 - accuracy: 0.8815 - val_loss: 0.7589 - val_accuracy: 0.8763\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3611 - accuracy: 0.8889 - val_loss: 0.7070 - val_accuracy: 0.8946\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3528 - accuracy: 0.8983 - val_loss: 0.7307 - val_accuracy: 0.8827\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3555 - accuracy: 0.8929 - val_loss: 0.7078 - val_accuracy: 0.8917\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3335 - accuracy: 0.9022 - val_loss: 0.7312 - val_accuracy: 0.8757\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3450 - accuracy: 0.8954 - val_loss: 0.6708 - val_accuracy: 0.8970\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3233 - accuracy: 0.9025 - val_loss: 0.6720 - val_accuracy: 0.9034\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3117 - accuracy: 0.9094 - val_loss: 0.6414 - val_accuracy: 0.9135\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3122 - accuracy: 0.9058 - val_loss: 0.6387 - val_accuracy: 0.9091\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3016 - accuracy: 0.9089 - val_loss: 0.6699 - val_accuracy: 0.8977\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3032 - accuracy: 0.9067 - val_loss: 0.6483 - val_accuracy: 0.9074\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2917 - accuracy: 0.9167 - val_loss: 0.6571 - val_accuracy: 0.9010\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2908 - accuracy: 0.9129 - val_loss: 0.6228 - val_accuracy: 0.9056\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2820 - accuracy: 0.9124 - val_loss: 0.6469 - val_accuracy: 0.9100\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2774 - accuracy: 0.9175 - val_loss: 0.6571 - val_accuracy: 0.8994\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2902 - accuracy: 0.9156 - val_loss: 0.6283 - val_accuracy: 0.9021\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2565 - accuracy: 0.9244 - val_loss: 0.5994 - val_accuracy: 0.9122\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2664 - accuracy: 0.9197 - val_loss: 0.6992 - val_accuracy: 0.8832\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2709 - accuracy: 0.9240 - val_loss: 0.5792 - val_accuracy: 0.9190\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2643 - accuracy: 0.9229 - val_loss: 0.6863 - val_accuracy: 0.8906\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2624 - accuracy: 0.9203 - val_loss: 0.5820 - val_accuracy: 0.9250\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2560 - accuracy: 0.9264 - val_loss: 0.5764 - val_accuracy: 0.9177\n","Average Validation Accuracy: 0.9218313992023468\n","Average Validation Loss: 0.3642950654029846\n","Average Test Accuracy: 0.9195843040943146\n","------------------------------------------------------------------------\n","\n","Number of input features: 8\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.0074 - accuracy: 0.1761 - val_loss: 3.0024 - val_accuracy: 0.3628\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.3166 - accuracy: 0.4767 - val_loss: 2.0625 - val_accuracy: 0.5958\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5665 - accuracy: 0.6242 - val_loss: 1.6041 - val_accuracy: 0.6603\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1961 - accuracy: 0.6909 - val_loss: 1.3581 - val_accuracy: 0.6856\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9856 - accuracy: 0.7314 - val_loss: 1.1895 - val_accuracy: 0.7320\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8633 - accuracy: 0.7573 - val_loss: 1.0742 - val_accuracy: 0.7507\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7839 - accuracy: 0.7714 - val_loss: 1.0035 - val_accuracy: 0.7558\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7210 - accuracy: 0.7854 - val_loss: 0.9886 - val_accuracy: 0.7556\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6759 - accuracy: 0.7977 - val_loss: 0.9055 - val_accuracy: 0.8002\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6435 - accuracy: 0.7936 - val_loss: 0.8250 - val_accuracy: 0.8152\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6039 - accuracy: 0.8086 - val_loss: 0.7649 - val_accuracy: 0.8317\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5821 - accuracy: 0.8158 - val_loss: 0.8112 - val_accuracy: 0.7993\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5628 - accuracy: 0.8264 - val_loss: 0.7347 - val_accuracy: 0.8466\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5282 - accuracy: 0.8344 - val_loss: 0.7257 - val_accuracy: 0.8343\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5123 - accuracy: 0.8392 - val_loss: 0.6958 - val_accuracy: 0.8475\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4944 - accuracy: 0.8486 - val_loss: 0.6786 - val_accuracy: 0.8411\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4866 - accuracy: 0.8481 - val_loss: 0.7038 - val_accuracy: 0.8433\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4742 - accuracy: 0.8487 - val_loss: 0.6962 - val_accuracy: 0.8486\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4618 - accuracy: 0.8568 - val_loss: 0.6377 - val_accuracy: 0.8693\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4480 - accuracy: 0.8601 - val_loss: 0.6469 - val_accuracy: 0.8532\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4378 - accuracy: 0.8620 - val_loss: 0.6583 - val_accuracy: 0.8537\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4410 - accuracy: 0.8643 - val_loss: 0.6307 - val_accuracy: 0.8506\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4244 - accuracy: 0.8652 - val_loss: 0.5797 - val_accuracy: 0.8816\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4195 - accuracy: 0.8629 - val_loss: 0.6488 - val_accuracy: 0.8554\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3926 - accuracy: 0.8756 - val_loss: 0.6341 - val_accuracy: 0.8431\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4093 - accuracy: 0.8725 - val_loss: 0.5502 - val_accuracy: 0.8873\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3950 - accuracy: 0.8771 - val_loss: 0.5792 - val_accuracy: 0.8838\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3842 - accuracy: 0.8786 - val_loss: 0.6317 - val_accuracy: 0.8651\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3754 - accuracy: 0.8815 - val_loss: 0.5678 - val_accuracy: 0.8772\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3843 - accuracy: 0.8773 - val_loss: 0.6001 - val_accuracy: 0.8697\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3751 - accuracy: 0.8794 - val_loss: 0.5790 - val_accuracy: 0.8653\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3759 - accuracy: 0.8821 - val_loss: 0.6832 - val_accuracy: 0.8546\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3588 - accuracy: 0.8865 - val_loss: 0.5920 - val_accuracy: 0.8728\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3533 - accuracy: 0.8859 - val_loss: 0.5730 - val_accuracy: 0.8682\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3682 - accuracy: 0.8834 - val_loss: 0.5656 - val_accuracy: 0.8768\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3550 - accuracy: 0.8850 - val_loss: 0.5563 - val_accuracy: 0.8761\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3493 - accuracy: 0.8864 - val_loss: 0.6001 - val_accuracy: 0.8550\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3355 - accuracy: 0.8932 - val_loss: 0.5356 - val_accuracy: 0.8895\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3358 - accuracy: 0.8954 - val_loss: 0.4900 - val_accuracy: 0.9058\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3438 - accuracy: 0.8918 - val_loss: 0.8361 - val_accuracy: 0.8103\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.0996 - accuracy: 0.1787 - val_loss: 3.2121 - val_accuracy: 0.3677\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4534 - accuracy: 0.4750 - val_loss: 2.3640 - val_accuracy: 0.5487\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7406 - accuracy: 0.6180 - val_loss: 1.9062 - val_accuracy: 0.6475\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3548 - accuracy: 0.6874 - val_loss: 1.6916 - val_accuracy: 0.7003\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0917 - accuracy: 0.7343 - val_loss: 1.5050 - val_accuracy: 0.7347\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9400 - accuracy: 0.7580 - val_loss: 1.3112 - val_accuracy: 0.7663\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8243 - accuracy: 0.7851 - val_loss: 1.2396 - val_accuracy: 0.7826\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7471 - accuracy: 0.7989 - val_loss: 1.1519 - val_accuracy: 0.7912\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6894 - accuracy: 0.8085 - val_loss: 1.1164 - val_accuracy: 0.7861\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6390 - accuracy: 0.8196 - val_loss: 1.0184 - val_accuracy: 0.8354\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5929 - accuracy: 0.8323 - val_loss: 0.9651 - val_accuracy: 0.8372\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5639 - accuracy: 0.8358 - val_loss: 0.9956 - val_accuracy: 0.8310\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5315 - accuracy: 0.8413 - val_loss: 0.9302 - val_accuracy: 0.8312\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5104 - accuracy: 0.8484 - val_loss: 0.9052 - val_accuracy: 0.8288\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4817 - accuracy: 0.8552 - val_loss: 0.8554 - val_accuracy: 0.8517\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4715 - accuracy: 0.8592 - val_loss: 0.8244 - val_accuracy: 0.8508\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4378 - accuracy: 0.8685 - val_loss: 0.8503 - val_accuracy: 0.8370\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4344 - accuracy: 0.8677 - val_loss: 0.7799 - val_accuracy: 0.8790\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4156 - accuracy: 0.8716 - val_loss: 0.8535 - val_accuracy: 0.8530\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4147 - accuracy: 0.8747 - val_loss: 0.8387 - val_accuracy: 0.8521\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4024 - accuracy: 0.8785 - val_loss: 0.7803 - val_accuracy: 0.8680\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3734 - accuracy: 0.8864 - val_loss: 0.7956 - val_accuracy: 0.8620\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3810 - accuracy: 0.8843 - val_loss: 0.7608 - val_accuracy: 0.8711\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3857 - accuracy: 0.8794 - val_loss: 0.7754 - val_accuracy: 0.8645\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3553 - accuracy: 0.8911 - val_loss: 0.7485 - val_accuracy: 0.8794\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3539 - accuracy: 0.8908 - val_loss: 0.7525 - val_accuracy: 0.8695\n","Epoch 27/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3550 - accuracy: 0.8901 - val_loss: 0.7638 - val_accuracy: 0.8596\n","Epoch 28/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3486 - accuracy: 0.8912 - val_loss: 0.7346 - val_accuracy: 0.8726\n","Epoch 29/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3329 - accuracy: 0.8989 - val_loss: 0.7049 - val_accuracy: 0.8869\n","Epoch 30/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3498 - accuracy: 0.8917 - val_loss: 0.6852 - val_accuracy: 0.8990\n","Epoch 31/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3165 - accuracy: 0.9072 - val_loss: 0.7332 - val_accuracy: 0.8814\n","Epoch 32/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3239 - accuracy: 0.9015 - val_loss: 0.6977 - val_accuracy: 0.8909\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3172 - accuracy: 0.9042 - val_loss: 0.8387 - val_accuracy: 0.8715\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3198 - accuracy: 0.9008 - val_loss: 0.7347 - val_accuracy: 0.8904\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3006 - accuracy: 0.9081 - val_loss: 0.7268 - val_accuracy: 0.8867\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3311 - accuracy: 0.8956 - val_loss: 0.7440 - val_accuracy: 0.8862\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2928 - accuracy: 0.9107 - val_loss: 0.6494 - val_accuracy: 0.9102\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3079 - accuracy: 0.9058 - val_loss: 0.6349 - val_accuracy: 0.9105\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2873 - accuracy: 0.9121 - val_loss: 0.6691 - val_accuracy: 0.8928\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2894 - accuracy: 0.9105 - val_loss: 0.7412 - val_accuracy: 0.8761\n","Average Validation Accuracy: 0.8524865210056305\n","Average Validation Loss: 0.581959992647171\n","Average Test Accuracy: 0.8494140207767487\n","------------------------------------------------------------------------\n","\n","Number of input features: 9\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7358 - accuracy: 0.2619 - val_loss: 2.4614 - val_accuracy: 0.5175\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6978 - accuracy: 0.6652 - val_loss: 1.4829 - val_accuracy: 0.7270\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0522 - accuracy: 0.7638 - val_loss: 1.1474 - val_accuracy: 0.7602\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7708 - accuracy: 0.8139 - val_loss: 0.8889 - val_accuracy: 0.8372\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6354 - accuracy: 0.8381 - val_loss: 0.7680 - val_accuracy: 0.8537\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5424 - accuracy: 0.8561 - val_loss: 0.7042 - val_accuracy: 0.8543\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4781 - accuracy: 0.8706 - val_loss: 0.6782 - val_accuracy: 0.8640\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4413 - accuracy: 0.8776 - val_loss: 0.6387 - val_accuracy: 0.8722\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4026 - accuracy: 0.8880 - val_loss: 0.6240 - val_accuracy: 0.8816\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3781 - accuracy: 0.8945 - val_loss: 0.5632 - val_accuracy: 0.8759\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3529 - accuracy: 0.9006 - val_loss: 0.7158 - val_accuracy: 0.8290\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3381 - accuracy: 0.9055 - val_loss: 0.4977 - val_accuracy: 0.9074\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3178 - accuracy: 0.9117 - val_loss: 0.4855 - val_accuracy: 0.9041\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2963 - accuracy: 0.9158 - val_loss: 0.5754 - val_accuracy: 0.8937\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2905 - accuracy: 0.9182 - val_loss: 0.4466 - val_accuracy: 0.9296\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2811 - accuracy: 0.9233 - val_loss: 0.5290 - val_accuracy: 0.8959\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2757 - accuracy: 0.9214 - val_loss: 0.4300 - val_accuracy: 0.9270\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2642 - accuracy: 0.9253 - val_loss: 0.4570 - val_accuracy: 0.9155\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2562 - accuracy: 0.9278 - val_loss: 0.4255 - val_accuracy: 0.9270\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2501 - accuracy: 0.9314 - val_loss: 0.4189 - val_accuracy: 0.9318\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2346 - accuracy: 0.9376 - val_loss: 0.3880 - val_accuracy: 0.9384\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2477 - accuracy: 0.9327 - val_loss: 0.4046 - val_accuracy: 0.9254\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2289 - accuracy: 0.9389 - val_loss: 0.3868 - val_accuracy: 0.9311\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2216 - accuracy: 0.9381 - val_loss: 0.4459 - val_accuracy: 0.9210\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2180 - accuracy: 0.9429 - val_loss: 0.4252 - val_accuracy: 0.9219\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2192 - accuracy: 0.9405 - val_loss: 0.3716 - val_accuracy: 0.9377\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2090 - accuracy: 0.9419 - val_loss: 0.3953 - val_accuracy: 0.9428\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2011 - accuracy: 0.9449 - val_loss: 0.4051 - val_accuracy: 0.9298\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2069 - accuracy: 0.9447 - val_loss: 0.3621 - val_accuracy: 0.9452\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1942 - accuracy: 0.9472 - val_loss: 0.3899 - val_accuracy: 0.9417\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1995 - accuracy: 0.9461 - val_loss: 0.3517 - val_accuracy: 0.9520\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1922 - accuracy: 0.9481 - val_loss: 0.3866 - val_accuracy: 0.9404\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1907 - accuracy: 0.9496 - val_loss: 0.4266 - val_accuracy: 0.9254\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1948 - accuracy: 0.9463 - val_loss: 0.3675 - val_accuracy: 0.9382\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1823 - accuracy: 0.9526 - val_loss: 0.3709 - val_accuracy: 0.9481\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1904 - accuracy: 0.9482 - val_loss: 0.4089 - val_accuracy: 0.9307\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1827 - accuracy: 0.9522 - val_loss: 0.3547 - val_accuracy: 0.9426\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1750 - accuracy: 0.9544 - val_loss: 0.3622 - val_accuracy: 0.9347\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1622 - accuracy: 0.9582 - val_loss: 0.3223 - val_accuracy: 0.9564\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1794 - accuracy: 0.9514 - val_loss: 0.3477 - val_accuracy: 0.9470\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 4.1567 - accuracy: 0.1719 - val_loss: 3.1725 - val_accuracy: 0.4130\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2545 - accuracy: 0.5412 - val_loss: 2.0117 - val_accuracy: 0.6486\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3685 - accuracy: 0.7006 - val_loss: 1.4967 - val_accuracy: 0.7094\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9783 - accuracy: 0.7656 - val_loss: 1.1962 - val_accuracy: 0.7820\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7894 - accuracy: 0.8016 - val_loss: 1.0654 - val_accuracy: 0.7833\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6681 - accuracy: 0.8245 - val_loss: 0.8903 - val_accuracy: 0.8361\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5774 - accuracy: 0.8482 - val_loss: 0.8022 - val_accuracy: 0.8524\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5222 - accuracy: 0.8549 - val_loss: 0.7833 - val_accuracy: 0.8488\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4715 - accuracy: 0.8692 - val_loss: 0.6842 - val_accuracy: 0.8574\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4396 - accuracy: 0.8735 - val_loss: 0.6480 - val_accuracy: 0.8653\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4043 - accuracy: 0.8832 - val_loss: 0.5882 - val_accuracy: 0.8794\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3792 - accuracy: 0.8917 - val_loss: 0.5564 - val_accuracy: 0.8847\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3567 - accuracy: 0.8990 - val_loss: 0.5889 - val_accuracy: 0.8675\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3290 - accuracy: 0.9078 - val_loss: 0.5151 - val_accuracy: 0.8950\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3316 - accuracy: 0.9013 - val_loss: 0.5229 - val_accuracy: 0.9065\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3158 - accuracy: 0.9073 - val_loss: 0.4992 - val_accuracy: 0.8981\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2994 - accuracy: 0.9146 - val_loss: 0.4820 - val_accuracy: 0.9146\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2966 - accuracy: 0.9119 - val_loss: 0.5181 - val_accuracy: 0.8922\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2828 - accuracy: 0.9177 - val_loss: 0.4473 - val_accuracy: 0.9285\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2768 - accuracy: 0.9202 - val_loss: 0.4439 - val_accuracy: 0.9157\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2642 - accuracy: 0.9238 - val_loss: 0.4667 - val_accuracy: 0.9133\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2549 - accuracy: 0.9278 - val_loss: 0.4977 - val_accuracy: 0.9124\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2573 - accuracy: 0.9263 - val_loss: 0.4229 - val_accuracy: 0.9300\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2446 - accuracy: 0.9316 - val_loss: 0.4398 - val_accuracy: 0.9226\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2436 - accuracy: 0.9320 - val_loss: 0.4536 - val_accuracy: 0.9096\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2412 - accuracy: 0.9313 - val_loss: 0.3877 - val_accuracy: 0.9364\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2248 - accuracy: 0.9351 - val_loss: 0.4851 - val_accuracy: 0.8950\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2347 - accuracy: 0.9330 - val_loss: 0.4401 - val_accuracy: 0.9259\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2138 - accuracy: 0.9388 - val_loss: 0.3770 - val_accuracy: 0.9490\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2264 - accuracy: 0.9369 - val_loss: 0.4213 - val_accuracy: 0.9278\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2074 - accuracy: 0.9433 - val_loss: 0.3788 - val_accuracy: 0.9399\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2230 - accuracy: 0.9367 - val_loss: 0.4056 - val_accuracy: 0.9243\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2138 - accuracy: 0.9395 - val_loss: 0.3854 - val_accuracy: 0.9344\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1918 - accuracy: 0.9459 - val_loss: 0.4251 - val_accuracy: 0.9228\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2038 - accuracy: 0.9416 - val_loss: 0.4109 - val_accuracy: 0.9298\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1975 - accuracy: 0.9429 - val_loss: 0.3952 - val_accuracy: 0.9344\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1978 - accuracy: 0.9442 - val_loss: 0.4378 - val_accuracy: 0.9237\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1917 - accuracy: 0.9474 - val_loss: 0.3873 - val_accuracy: 0.9362\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2020 - accuracy: 0.9436 - val_loss: 0.4252 - val_accuracy: 0.9371\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1846 - accuracy: 0.9469 - val_loss: 0.4337 - val_accuracy: 0.9182\n","Average Validation Accuracy: 0.9388950765132904\n","Average Validation Loss: 0.26393067836761475\n","Average Test Accuracy: 0.9384536147117615\n","------------------------------------------------------------------------\n","\n","Number of input features: 10\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.9498 - accuracy: 0.2297 - val_loss: 2.7632 - val_accuracy: 0.5122\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7637 - accuracy: 0.6603 - val_loss: 1.4664 - val_accuracy: 0.7406\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9598 - accuracy: 0.7967 - val_loss: 1.0233 - val_accuracy: 0.8057\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6310 - accuracy: 0.8526 - val_loss: 0.7966 - val_accuracy: 0.8722\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4685 - accuracy: 0.8765 - val_loss: 0.6936 - val_accuracy: 0.8882\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3780 - accuracy: 0.8980 - val_loss: 0.6441 - val_accuracy: 0.8986\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3375 - accuracy: 0.9072 - val_loss: 0.5804 - val_accuracy: 0.8972\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2912 - accuracy: 0.9136 - val_loss: 0.5309 - val_accuracy: 0.9188\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2674 - accuracy: 0.9259 - val_loss: 0.4889 - val_accuracy: 0.9208\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2443 - accuracy: 0.9323 - val_loss: 0.4851 - val_accuracy: 0.9241\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2227 - accuracy: 0.9379 - val_loss: 0.4614 - val_accuracy: 0.9371\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2218 - accuracy: 0.9380 - val_loss: 0.4612 - val_accuracy: 0.9347\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1998 - accuracy: 0.9445 - val_loss: 0.4803 - val_accuracy: 0.9195\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1949 - accuracy: 0.9462 - val_loss: 0.4175 - val_accuracy: 0.9468\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1894 - accuracy: 0.9454 - val_loss: 0.4247 - val_accuracy: 0.9428\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1823 - accuracy: 0.9499 - val_loss: 0.5188 - val_accuracy: 0.9173\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1750 - accuracy: 0.9514 - val_loss: 0.4324 - val_accuracy: 0.9309\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1670 - accuracy: 0.9530 - val_loss: 0.4200 - val_accuracy: 0.9353\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1678 - accuracy: 0.9526 - val_loss: 0.4097 - val_accuracy: 0.9439\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1734 - accuracy: 0.9530 - val_loss: 0.3882 - val_accuracy: 0.9490\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1523 - accuracy: 0.9572 - val_loss: 0.3813 - val_accuracy: 0.9593\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1658 - accuracy: 0.9545 - val_loss: 0.3694 - val_accuracy: 0.9509\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1433 - accuracy: 0.9615 - val_loss: 0.4006 - val_accuracy: 0.9382\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1518 - accuracy: 0.9573 - val_loss: 0.3582 - val_accuracy: 0.9655\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1479 - accuracy: 0.9604 - val_loss: 0.3478 - val_accuracy: 0.9593\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1389 - accuracy: 0.9626 - val_loss: 0.3854 - val_accuracy: 0.9481\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1420 - accuracy: 0.9613 - val_loss: 0.3563 - val_accuracy: 0.9595\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1351 - accuracy: 0.9648 - val_loss: 0.4095 - val_accuracy: 0.9421\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1409 - accuracy: 0.9634 - val_loss: 0.3480 - val_accuracy: 0.9602\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1375 - accuracy: 0.9640 - val_loss: 0.3310 - val_accuracy: 0.9635\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1316 - accuracy: 0.9646 - val_loss: 0.3522 - val_accuracy: 0.9507\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1310 - accuracy: 0.9642 - val_loss: 0.4011 - val_accuracy: 0.9454\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1312 - accuracy: 0.9644 - val_loss: 0.3843 - val_accuracy: 0.9413\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1286 - accuracy: 0.9652 - val_loss: 0.3471 - val_accuracy: 0.9604\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1225 - accuracy: 0.9692 - val_loss: 0.3344 - val_accuracy: 0.9593\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1250 - accuracy: 0.9678 - val_loss: 0.3580 - val_accuracy: 0.9553\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1222 - accuracy: 0.9686 - val_loss: 0.3344 - val_accuracy: 0.9593\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1143 - accuracy: 0.9688 - val_loss: 0.3278 - val_accuracy: 0.9619\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1218 - accuracy: 0.9657 - val_loss: 0.3590 - val_accuracy: 0.9487\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1117 - accuracy: 0.9700 - val_loss: 0.3373 - val_accuracy: 0.9606\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.8072 - accuracy: 0.2597 - val_loss: 2.7870 - val_accuracy: 0.4568\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9597 - accuracy: 0.6050 - val_loss: 1.8460 - val_accuracy: 0.6726\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1993 - accuracy: 0.7586 - val_loss: 1.3909 - val_accuracy: 0.8015\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8476 - accuracy: 0.8207 - val_loss: 1.1758 - val_accuracy: 0.7910\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6531 - accuracy: 0.8501 - val_loss: 0.9658 - val_accuracy: 0.8629\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5271 - accuracy: 0.8740 - val_loss: 0.8385 - val_accuracy: 0.8814\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4485 - accuracy: 0.8925 - val_loss: 0.7934 - val_accuracy: 0.8836\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3967 - accuracy: 0.9000 - val_loss: 0.6746 - val_accuracy: 0.9113\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3506 - accuracy: 0.9096 - val_loss: 0.6578 - val_accuracy: 0.8961\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3167 - accuracy: 0.9170 - val_loss: 0.5757 - val_accuracy: 0.9234\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2973 - accuracy: 0.9200 - val_loss: 0.5622 - val_accuracy: 0.9028\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2691 - accuracy: 0.9277 - val_loss: 0.5482 - val_accuracy: 0.9113\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2543 - accuracy: 0.9328 - val_loss: 0.5310 - val_accuracy: 0.9025\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2448 - accuracy: 0.9335 - val_loss: 0.4851 - val_accuracy: 0.9267\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2347 - accuracy: 0.9356 - val_loss: 0.5040 - val_accuracy: 0.9142\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2252 - accuracy: 0.9400 - val_loss: 0.4470 - val_accuracy: 0.9373\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2216 - accuracy: 0.9420 - val_loss: 0.5213 - val_accuracy: 0.9245\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2065 - accuracy: 0.9451 - val_loss: 0.4617 - val_accuracy: 0.9331\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2026 - accuracy: 0.9466 - val_loss: 0.4840 - val_accuracy: 0.9316\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1987 - accuracy: 0.9473 - val_loss: 0.4767 - val_accuracy: 0.9267\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1874 - accuracy: 0.9482 - val_loss: 0.4596 - val_accuracy: 0.9340\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1858 - accuracy: 0.9513 - val_loss: 0.3935 - val_accuracy: 0.9498\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1801 - accuracy: 0.9531 - val_loss: 0.4141 - val_accuracy: 0.9463\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1764 - accuracy: 0.9531 - val_loss: 0.4627 - val_accuracy: 0.9325\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1713 - accuracy: 0.9551 - val_loss: 0.4280 - val_accuracy: 0.9331\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1715 - accuracy: 0.9555 - val_loss: 0.4617 - val_accuracy: 0.9360\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1567 - accuracy: 0.9593 - val_loss: 0.5268 - val_accuracy: 0.9182\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1644 - accuracy: 0.9561 - val_loss: 0.3987 - val_accuracy: 0.9578\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1643 - accuracy: 0.9569 - val_loss: 0.4207 - val_accuracy: 0.9441\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1551 - accuracy: 0.9603 - val_loss: 0.3776 - val_accuracy: 0.9547\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1452 - accuracy: 0.9627 - val_loss: 0.4386 - val_accuracy: 0.9415\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1615 - accuracy: 0.9583 - val_loss: 0.3925 - val_accuracy: 0.9549\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1489 - accuracy: 0.9614 - val_loss: 0.4296 - val_accuracy: 0.9369\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1429 - accuracy: 0.9640 - val_loss: 0.4335 - val_accuracy: 0.9340\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1653 - accuracy: 0.9573 - val_loss: 0.4167 - val_accuracy: 0.9428\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1373 - accuracy: 0.9654 - val_loss: 0.4380 - val_accuracy: 0.9353\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1426 - accuracy: 0.9615 - val_loss: 0.3452 - val_accuracy: 0.9641\n","Epoch 38/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1359 - accuracy: 0.9645 - val_loss: 0.3768 - val_accuracy: 0.9525\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1316 - accuracy: 0.9671 - val_loss: 0.3651 - val_accuracy: 0.9529\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1364 - accuracy: 0.9633 - val_loss: 0.3896 - val_accuracy: 0.9474\n","Average Validation Accuracy: 0.9657987952232361\n","Average Validation Loss: 0.202916219830513\n","Average Test Accuracy: 0.9664627611637115\n","------------------------------------------------------------------------\n","\n","Number of input features: 11\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.0252 - accuracy: 0.2180 - val_loss: 2.7691 - val_accuracy: 0.4975\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7703 - accuracy: 0.6793 - val_loss: 1.4009 - val_accuracy: 0.7674\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9301 - accuracy: 0.8157 - val_loss: 0.9701 - val_accuracy: 0.8205\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5933 - accuracy: 0.8732 - val_loss: 0.7333 - val_accuracy: 0.8629\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4353 - accuracy: 0.8958 - val_loss: 0.6083 - val_accuracy: 0.8902\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3580 - accuracy: 0.9079 - val_loss: 0.5477 - val_accuracy: 0.9058\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3069 - accuracy: 0.9191 - val_loss: 0.5389 - val_accuracy: 0.9034\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2801 - accuracy: 0.9248 - val_loss: 0.5762 - val_accuracy: 0.8992\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2545 - accuracy: 0.9329 - val_loss: 0.4294 - val_accuracy: 0.9375\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2282 - accuracy: 0.9394 - val_loss: 0.4118 - val_accuracy: 0.9441\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2251 - accuracy: 0.9421 - val_loss: 0.4129 - val_accuracy: 0.9386\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2085 - accuracy: 0.9459 - val_loss: 0.3988 - val_accuracy: 0.9406\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1907 - accuracy: 0.9510 - val_loss: 0.4056 - val_accuracy: 0.9424\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1849 - accuracy: 0.9522 - val_loss: 0.3849 - val_accuracy: 0.9485\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1777 - accuracy: 0.9562 - val_loss: 0.3808 - val_accuracy: 0.9507\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1756 - accuracy: 0.9522 - val_loss: 0.4131 - val_accuracy: 0.9424\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1581 - accuracy: 0.9612 - val_loss: 0.5295 - val_accuracy: 0.9186\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1633 - accuracy: 0.9579 - val_loss: 0.3771 - val_accuracy: 0.9520\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1448 - accuracy: 0.9644 - val_loss: 0.3663 - val_accuracy: 0.9525\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1542 - accuracy: 0.9609 - val_loss: 0.3860 - val_accuracy: 0.9452\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1429 - accuracy: 0.9651 - val_loss: 0.3501 - val_accuracy: 0.9628\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1421 - accuracy: 0.9652 - val_loss: 0.3555 - val_accuracy: 0.9569\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1438 - accuracy: 0.9633 - val_loss: 0.3216 - val_accuracy: 0.9674\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1384 - accuracy: 0.9657 - val_loss: 0.4317 - val_accuracy: 0.9384\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1287 - accuracy: 0.9701 - val_loss: 0.3697 - val_accuracy: 0.9547\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1373 - accuracy: 0.9646 - val_loss: 0.3552 - val_accuracy: 0.9589\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1295 - accuracy: 0.9701 - val_loss: 0.3805 - val_accuracy: 0.9518\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1161 - accuracy: 0.9723 - val_loss: 0.3530 - val_accuracy: 0.9560\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1323 - accuracy: 0.9676 - val_loss: 0.4042 - val_accuracy: 0.9472\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1199 - accuracy: 0.9713 - val_loss: 0.3493 - val_accuracy: 0.9611\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1262 - accuracy: 0.9690 - val_loss: 0.3548 - val_accuracy: 0.9630\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9738 - val_loss: 0.3613 - val_accuracy: 0.9611\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1193 - accuracy: 0.9720 - val_loss: 0.3510 - val_accuracy: 0.9586\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1200 - accuracy: 0.9703 - val_loss: 0.3310 - val_accuracy: 0.9661\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1046 - accuracy: 0.9738 - val_loss: 0.4039 - val_accuracy: 0.9509\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1205 - accuracy: 0.9712 - val_loss: 0.4066 - val_accuracy: 0.9463\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9744 - val_loss: 0.3164 - val_accuracy: 0.9681\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1086 - accuracy: 0.9734 - val_loss: 0.3738 - val_accuracy: 0.9492\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1025 - accuracy: 0.9764 - val_loss: 0.2852 - val_accuracy: 0.9760\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1209 - accuracy: 0.9702 - val_loss: 0.2937 - val_accuracy: 0.9703\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.9759 - accuracy: 0.2227 - val_loss: 2.8176 - val_accuracy: 0.5316\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8879 - accuracy: 0.6386 - val_loss: 1.8386 - val_accuracy: 0.6667\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1148 - accuracy: 0.7707 - val_loss: 1.3045 - val_accuracy: 0.7668\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7851 - accuracy: 0.8257 - val_loss: 1.0636 - val_accuracy: 0.8297\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6208 - accuracy: 0.8564 - val_loss: 0.9160 - val_accuracy: 0.8631\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5243 - accuracy: 0.8731 - val_loss: 0.7953 - val_accuracy: 0.8818\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4547 - accuracy: 0.8860 - val_loss: 0.7124 - val_accuracy: 0.8873\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4015 - accuracy: 0.8979 - val_loss: 0.7071 - val_accuracy: 0.8935\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3769 - accuracy: 0.9021 - val_loss: 0.6144 - val_accuracy: 0.9014\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3337 - accuracy: 0.9135 - val_loss: 0.6065 - val_accuracy: 0.9065\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3132 - accuracy: 0.9167 - val_loss: 0.6465 - val_accuracy: 0.8730\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2893 - accuracy: 0.9231 - val_loss: 0.5353 - val_accuracy: 0.9175\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2821 - accuracy: 0.9224 - val_loss: 0.5609 - val_accuracy: 0.9065\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2613 - accuracy: 0.9292 - val_loss: 0.5445 - val_accuracy: 0.9080\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2589 - accuracy: 0.9297 - val_loss: 0.4832 - val_accuracy: 0.9250\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2396 - accuracy: 0.9374 - val_loss: 0.4773 - val_accuracy: 0.9188\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2358 - accuracy: 0.9376 - val_loss: 0.4940 - val_accuracy: 0.9131\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2222 - accuracy: 0.9387 - val_loss: 0.4551 - val_accuracy: 0.9377\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2177 - accuracy: 0.9397 - val_loss: 0.4328 - val_accuracy: 0.9397\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2102 - accuracy: 0.9458 - val_loss: 0.4873 - val_accuracy: 0.9322\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1967 - accuracy: 0.9455 - val_loss: 0.4291 - val_accuracy: 0.9360\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2086 - accuracy: 0.9451 - val_loss: 0.4833 - val_accuracy: 0.9338\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1948 - accuracy: 0.9480 - val_loss: 0.4433 - val_accuracy: 0.9375\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1800 - accuracy: 0.9527 - val_loss: 0.4303 - val_accuracy: 0.9375\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1918 - accuracy: 0.9479 - val_loss: 0.4126 - val_accuracy: 0.9505\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1792 - accuracy: 0.9510 - val_loss: 0.5789 - val_accuracy: 0.8884\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1762 - accuracy: 0.9532 - val_loss: 0.3992 - val_accuracy: 0.9421\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1826 - accuracy: 0.9491 - val_loss: 0.4459 - val_accuracy: 0.9318\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1716 - accuracy: 0.9569 - val_loss: 0.3687 - val_accuracy: 0.9494\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1701 - accuracy: 0.9543 - val_loss: 0.3949 - val_accuracy: 0.9527\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1735 - accuracy: 0.9547 - val_loss: 0.4249 - val_accuracy: 0.9375\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1514 - accuracy: 0.9614 - val_loss: 0.3396 - val_accuracy: 0.9619\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1649 - accuracy: 0.9566 - val_loss: 0.3597 - val_accuracy: 0.9560\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1605 - accuracy: 0.9553 - val_loss: 0.3787 - val_accuracy: 0.9496\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1544 - accuracy: 0.9586 - val_loss: 0.3430 - val_accuracy: 0.9556\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1426 - accuracy: 0.9627 - val_loss: 0.3716 - val_accuracy: 0.9516\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1538 - accuracy: 0.9575 - val_loss: 0.3771 - val_accuracy: 0.9498\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1421 - accuracy: 0.9640 - val_loss: 0.3575 - val_accuracy: 0.9498\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1425 - accuracy: 0.9633 - val_loss: 0.4119 - val_accuracy: 0.9450\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1417 - accuracy: 0.9614 - val_loss: 0.3333 - val_accuracy: 0.9659\n","Average Validation Accuracy: 0.9767272174358368\n","Average Validation Loss: 0.16594956815242767\n","Average Test Accuracy: 0.9743126630783081\n","------------------------------------------------------------------------\n","\n","Number of input features: 12\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7611 - accuracy: 0.2501 - val_loss: 2.4803 - val_accuracy: 0.5294\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5806 - accuracy: 0.6852 - val_loss: 1.2598 - val_accuracy: 0.7813\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8158 - accuracy: 0.8186 - val_loss: 0.9162 - val_accuracy: 0.8178\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5481 - accuracy: 0.8656 - val_loss: 0.6746 - val_accuracy: 0.8601\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4261 - accuracy: 0.8938 - val_loss: 0.6118 - val_accuracy: 0.8858\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3486 - accuracy: 0.9099 - val_loss: 0.5838 - val_accuracy: 0.8733\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3030 - accuracy: 0.9204 - val_loss: 0.4475 - val_accuracy: 0.9173\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2677 - accuracy: 0.9324 - val_loss: 0.4325 - val_accuracy: 0.9190\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2369 - accuracy: 0.9384 - val_loss: 0.3850 - val_accuracy: 0.9402\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2255 - accuracy: 0.9409 - val_loss: 0.3760 - val_accuracy: 0.9404\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2034 - accuracy: 0.9484 - val_loss: 0.3879 - val_accuracy: 0.9234\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1950 - accuracy: 0.9492 - val_loss: 0.3090 - val_accuracy: 0.9582\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1929 - accuracy: 0.9498 - val_loss: 0.3048 - val_accuracy: 0.9545\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1747 - accuracy: 0.9546 - val_loss: 0.3239 - val_accuracy: 0.9507\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1668 - accuracy: 0.9562 - val_loss: 0.3035 - val_accuracy: 0.9549\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1647 - accuracy: 0.9581 - val_loss: 0.2935 - val_accuracy: 0.9589\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1575 - accuracy: 0.9592 - val_loss: 0.2792 - val_accuracy: 0.9595\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1450 - accuracy: 0.9629 - val_loss: 0.2834 - val_accuracy: 0.9575\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1468 - accuracy: 0.9625 - val_loss: 0.2687 - val_accuracy: 0.9652\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1450 - accuracy: 0.9648 - val_loss: 0.2716 - val_accuracy: 0.9635\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1353 - accuracy: 0.9666 - val_loss: 0.2702 - val_accuracy: 0.9591\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1315 - accuracy: 0.9660 - val_loss: 0.2803 - val_accuracy: 0.9615\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1376 - accuracy: 0.9655 - val_loss: 0.2569 - val_accuracy: 0.9674\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1229 - accuracy: 0.9706 - val_loss: 0.2951 - val_accuracy: 0.9505\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1256 - accuracy: 0.9684 - val_loss: 0.2821 - val_accuracy: 0.9586\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1258 - accuracy: 0.9680 - val_loss: 0.2717 - val_accuracy: 0.9630\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1154 - accuracy: 0.9724 - val_loss: 0.3526 - val_accuracy: 0.9487\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1196 - accuracy: 0.9695 - val_loss: 0.2535 - val_accuracy: 0.9681\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1183 - accuracy: 0.9708 - val_loss: 0.3246 - val_accuracy: 0.9479\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1178 - accuracy: 0.9701 - val_loss: 0.2794 - val_accuracy: 0.9569\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1052 - accuracy: 0.9744 - val_loss: 0.2411 - val_accuracy: 0.9668\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1118 - accuracy: 0.9721 - val_loss: 0.2459 - val_accuracy: 0.9703\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1049 - accuracy: 0.9752 - val_loss: 0.2766 - val_accuracy: 0.9622\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1103 - accuracy: 0.9718 - val_loss: 0.3070 - val_accuracy: 0.9562\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1005 - accuracy: 0.9760 - val_loss: 0.2817 - val_accuracy: 0.9604\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1042 - accuracy: 0.9751 - val_loss: 0.2556 - val_accuracy: 0.9696\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1021 - accuracy: 0.9742 - val_loss: 0.2321 - val_accuracy: 0.9767\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1003 - accuracy: 0.9764 - val_loss: 0.2474 - val_accuracy: 0.9701\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1001 - accuracy: 0.9758 - val_loss: 0.2561 - val_accuracy: 0.9663\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0933 - accuracy: 0.9783 - val_loss: 0.2962 - val_accuracy: 0.9571\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.6876 - accuracy: 0.2913 - val_loss: 2.4529 - val_accuracy: 0.5694\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6061 - accuracy: 0.7071 - val_loss: 1.4883 - val_accuracy: 0.7848\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9608 - accuracy: 0.8230 - val_loss: 1.2070 - val_accuracy: 0.8145\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6749 - accuracy: 0.8664 - val_loss: 0.9076 - val_accuracy: 0.8728\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5110 - accuracy: 0.8934 - val_loss: 0.7622 - val_accuracy: 0.8928\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4060 - accuracy: 0.9099 - val_loss: 0.6535 - val_accuracy: 0.9054\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3378 - accuracy: 0.9262 - val_loss: 0.5820 - val_accuracy: 0.9094\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2859 - accuracy: 0.9349 - val_loss: 0.5357 - val_accuracy: 0.9318\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2535 - accuracy: 0.9389 - val_loss: 0.5357 - val_accuracy: 0.9131\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2393 - accuracy: 0.9421 - val_loss: 0.4654 - val_accuracy: 0.9432\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2109 - accuracy: 0.9471 - val_loss: 0.4856 - val_accuracy: 0.9413\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1954 - accuracy: 0.9534 - val_loss: 0.4084 - val_accuracy: 0.9459\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1951 - accuracy: 0.9508 - val_loss: 0.4609 - val_accuracy: 0.9309\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1704 - accuracy: 0.9591 - val_loss: 0.3952 - val_accuracy: 0.9514\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1765 - accuracy: 0.9571 - val_loss: 0.4342 - val_accuracy: 0.9441\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1653 - accuracy: 0.9582 - val_loss: 0.5336 - val_accuracy: 0.9160\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1596 - accuracy: 0.9593 - val_loss: 0.3839 - val_accuracy: 0.9505\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1503 - accuracy: 0.9621 - val_loss: 0.3685 - val_accuracy: 0.9578\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1551 - accuracy: 0.9625 - val_loss: 0.3722 - val_accuracy: 0.9549\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1501 - accuracy: 0.9627 - val_loss: 0.3946 - val_accuracy: 0.9578\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1415 - accuracy: 0.9659 - val_loss: 0.4407 - val_accuracy: 0.9228\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1439 - accuracy: 0.9648 - val_loss: 0.3598 - val_accuracy: 0.9622\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1381 - accuracy: 0.9660 - val_loss: 0.3696 - val_accuracy: 0.9465\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1378 - accuracy: 0.9662 - val_loss: 0.3279 - val_accuracy: 0.9655\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1257 - accuracy: 0.9684 - val_loss: 0.3405 - val_accuracy: 0.9666\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1329 - accuracy: 0.9673 - val_loss: 0.3210 - val_accuracy: 0.9681\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1266 - accuracy: 0.9690 - val_loss: 0.3643 - val_accuracy: 0.9573\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1248 - accuracy: 0.9698 - val_loss: 0.3480 - val_accuracy: 0.9655\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1152 - accuracy: 0.9730 - val_loss: 0.3238 - val_accuracy: 0.9637\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1170 - accuracy: 0.9716 - val_loss: 0.3442 - val_accuracy: 0.9672\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1249 - accuracy: 0.9727 - val_loss: 0.3172 - val_accuracy: 0.9661\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1121 - accuracy: 0.9732 - val_loss: 0.3046 - val_accuracy: 0.9661\n","Epoch 33/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1141 - accuracy: 0.9718 - val_loss: 0.3069 - val_accuracy: 0.9644\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1140 - accuracy: 0.9740 - val_loss: 0.2882 - val_accuracy: 0.9683\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0983 - accuracy: 0.9777 - val_loss: 0.4048 - val_accuracy: 0.9415\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1158 - accuracy: 0.9732 - val_loss: 0.2852 - val_accuracy: 0.9721\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1075 - accuracy: 0.9773 - val_loss: 0.3569 - val_accuracy: 0.9525\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1061 - accuracy: 0.9757 - val_loss: 0.3222 - val_accuracy: 0.9602\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1038 - accuracy: 0.9770 - val_loss: 0.2754 - val_accuracy: 0.9732\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1015 - accuracy: 0.9765 - val_loss: 0.2520 - val_accuracy: 0.9813\n","Average Validation Accuracy: 0.9765461087226868\n","Average Validation Loss: 0.15838845074176788\n","Average Test Accuracy: 0.9760448336601257\n","------------------------------------------------------------------------\n","\n","Number of input features: 13\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.2764 - accuracy: 0.3734 - val_loss: 2.1099 - val_accuracy: 0.5982\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3530 - accuracy: 0.7495 - val_loss: 1.2164 - val_accuracy: 0.7857\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8144 - accuracy: 0.8309 - val_loss: 0.8816 - val_accuracy: 0.8275\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5594 - accuracy: 0.8677 - val_loss: 0.6935 - val_accuracy: 0.8680\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.4191 - accuracy: 0.8955 - val_loss: 0.6249 - val_accuracy: 0.8755\n","Epoch 6/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.3389 - accuracy: 0.9143 - val_loss: 0.5560 - val_accuracy: 0.8884\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2926 - accuracy: 0.9254 - val_loss: 0.4406 - val_accuracy: 0.9272\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2548 - accuracy: 0.9313 - val_loss: 0.4367 - val_accuracy: 0.9208\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2319 - accuracy: 0.9365 - val_loss: 0.3749 - val_accuracy: 0.9360\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2094 - accuracy: 0.9427 - val_loss: 0.3830 - val_accuracy: 0.9371\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1933 - accuracy: 0.9481 - val_loss: 0.3497 - val_accuracy: 0.9492\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1763 - accuracy: 0.9546 - val_loss: 0.3400 - val_accuracy: 0.9355\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1697 - accuracy: 0.9545 - val_loss: 0.3626 - val_accuracy: 0.9355\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1597 - accuracy: 0.9610 - val_loss: 0.3318 - val_accuracy: 0.9474\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1545 - accuracy: 0.9609 - val_loss: 0.2990 - val_accuracy: 0.9514\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1369 - accuracy: 0.9649 - val_loss: 0.2828 - val_accuracy: 0.9569\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1523 - accuracy: 0.9622 - val_loss: 0.2867 - val_accuracy: 0.9569\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1344 - accuracy: 0.9657 - val_loss: 0.3294 - val_accuracy: 0.9395\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1271 - accuracy: 0.9677 - val_loss: 0.2952 - val_accuracy: 0.9536\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1275 - accuracy: 0.9668 - val_loss: 0.2445 - val_accuracy: 0.9699\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1257 - accuracy: 0.9693 - val_loss: 0.2810 - val_accuracy: 0.9578\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1221 - accuracy: 0.9694 - val_loss: 0.2524 - val_accuracy: 0.9646\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1215 - accuracy: 0.9712 - val_loss: 0.2332 - val_accuracy: 0.9701\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1121 - accuracy: 0.9736 - val_loss: 0.3192 - val_accuracy: 0.9490\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1207 - accuracy: 0.9706 - val_loss: 0.2315 - val_accuracy: 0.9727\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1086 - accuracy: 0.9738 - val_loss: 0.2885 - val_accuracy: 0.9536\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1086 - accuracy: 0.9738 - val_loss: 0.2467 - val_accuracy: 0.9696\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1093 - accuracy: 0.9712 - val_loss: 0.2354 - val_accuracy: 0.9710\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1089 - accuracy: 0.9719 - val_loss: 0.2702 - val_accuracy: 0.9648\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1000 - accuracy: 0.9758 - val_loss: 0.2454 - val_accuracy: 0.9690\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0957 - accuracy: 0.9784 - val_loss: 0.2327 - val_accuracy: 0.9762\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1065 - accuracy: 0.9738 - val_loss: 0.2438 - val_accuracy: 0.9696\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0962 - accuracy: 0.9772 - val_loss: 0.2473 - val_accuracy: 0.9661\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1000 - accuracy: 0.9753 - val_loss: 0.2454 - val_accuracy: 0.9751\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0958 - accuracy: 0.9764 - val_loss: 0.2411 - val_accuracy: 0.9692\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0957 - accuracy: 0.9753 - val_loss: 0.2268 - val_accuracy: 0.9795\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0870 - accuracy: 0.9782 - val_loss: 0.2342 - val_accuracy: 0.9749\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0976 - accuracy: 0.9764 - val_loss: 0.2930 - val_accuracy: 0.9608\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0886 - accuracy: 0.9781 - val_loss: 0.2455 - val_accuracy: 0.9685\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0984 - accuracy: 0.9749 - val_loss: 0.2477 - val_accuracy: 0.9685\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.8199 - accuracy: 0.2561 - val_loss: 2.5724 - val_accuracy: 0.5589\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 1.7059 - accuracy: 0.6910 - val_loss: 1.6316 - val_accuracy: 0.7465\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0318 - accuracy: 0.8076 - val_loss: 1.2845 - val_accuracy: 0.8090\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7211 - accuracy: 0.8542 - val_loss: 1.0309 - val_accuracy: 0.8559\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5441 - accuracy: 0.8837 - val_loss: 0.8869 - val_accuracy: 0.8935\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4422 - accuracy: 0.9032 - val_loss: 0.8455 - val_accuracy: 0.8878\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3798 - accuracy: 0.9112 - val_loss: 0.7655 - val_accuracy: 0.8904\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3287 - accuracy: 0.9265 - val_loss: 0.6951 - val_accuracy: 0.9210\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2919 - accuracy: 0.9292 - val_loss: 0.6383 - val_accuracy: 0.9217\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2684 - accuracy: 0.9350 - val_loss: 0.5850 - val_accuracy: 0.9391\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2366 - accuracy: 0.9400 - val_loss: 0.6327 - val_accuracy: 0.9217\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2198 - accuracy: 0.9453 - val_loss: 0.5607 - val_accuracy: 0.9364\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2089 - accuracy: 0.9488 - val_loss: 0.5380 - val_accuracy: 0.9364\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1954 - accuracy: 0.9522 - val_loss: 0.5158 - val_accuracy: 0.9459\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1834 - accuracy: 0.9543 - val_loss: 0.4922 - val_accuracy: 0.9481\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1752 - accuracy: 0.9578 - val_loss: 0.5639 - val_accuracy: 0.9311\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1711 - accuracy: 0.9565 - val_loss: 0.4636 - val_accuracy: 0.9540\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1620 - accuracy: 0.9598 - val_loss: 0.4678 - val_accuracy: 0.9534\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1585 - accuracy: 0.9609 - val_loss: 0.4670 - val_accuracy: 0.9496\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1555 - accuracy: 0.9612 - val_loss: 0.4369 - val_accuracy: 0.9556\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1403 - accuracy: 0.9665 - val_loss: 0.4504 - val_accuracy: 0.9569\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1446 - accuracy: 0.9640 - val_loss: 0.4554 - val_accuracy: 0.9549\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1359 - accuracy: 0.9681 - val_loss: 0.4920 - val_accuracy: 0.9446\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1400 - accuracy: 0.9668 - val_loss: 0.4640 - val_accuracy: 0.9476\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1275 - accuracy: 0.9710 - val_loss: 0.4223 - val_accuracy: 0.9670\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1299 - accuracy: 0.9691 - val_loss: 0.4262 - val_accuracy: 0.9520\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1189 - accuracy: 0.9734 - val_loss: 0.4009 - val_accuracy: 0.9644\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1277 - accuracy: 0.9715 - val_loss: 0.4141 - val_accuracy: 0.9630\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1195 - accuracy: 0.9717 - val_loss: 0.4012 - val_accuracy: 0.9630\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1156 - accuracy: 0.9733 - val_loss: 0.3931 - val_accuracy: 0.9663\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1145 - accuracy: 0.9731 - val_loss: 0.4061 - val_accuracy: 0.9677\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1084 - accuracy: 0.9741 - val_loss: 0.4086 - val_accuracy: 0.9622\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1138 - accuracy: 0.9739 - val_loss: 0.4010 - val_accuracy: 0.9668\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1037 - accuracy: 0.9766 - val_loss: 0.4126 - val_accuracy: 0.9573\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1049 - accuracy: 0.9759 - val_loss: 0.3622 - val_accuracy: 0.9683\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1056 - accuracy: 0.9772 - val_loss: 0.3978 - val_accuracy: 0.9600\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1097 - accuracy: 0.9745 - val_loss: 0.3579 - val_accuracy: 0.9705\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0996 - accuracy: 0.9789 - val_loss: 0.3568 - val_accuracy: 0.9699\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0960 - accuracy: 0.9786 - val_loss: 0.3511 - val_accuracy: 0.9710\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1017 - accuracy: 0.9753 - val_loss: 0.3712 - val_accuracy: 0.9628\n","Average Validation Accuracy: 0.9724793434143066\n","Average Validation Loss: 0.1690700575709343\n","Average Test Accuracy: 0.9728753864765167\n","------------------------------------------------------------------------\n","\n","Number of input features: 14\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.6887 - accuracy: 0.2995 - val_loss: 2.1123 - val_accuracy: 0.6286\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3144 - accuracy: 0.7504 - val_loss: 1.0929 - val_accuracy: 0.7883\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7624 - accuracy: 0.8279 - val_loss: 0.8467 - val_accuracy: 0.8235\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5471 - accuracy: 0.8630 - val_loss: 0.6650 - val_accuracy: 0.8715\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4224 - accuracy: 0.8887 - val_loss: 0.5476 - val_accuracy: 0.8887\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3465 - accuracy: 0.9082 - val_loss: 0.4661 - val_accuracy: 0.9091\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2919 - accuracy: 0.9198 - val_loss: 0.4713 - val_accuracy: 0.9025\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2509 - accuracy: 0.9329 - val_loss: 0.4168 - val_accuracy: 0.9173\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2323 - accuracy: 0.9358 - val_loss: 0.3590 - val_accuracy: 0.9382\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2115 - accuracy: 0.9413 - val_loss: 0.3943 - val_accuracy: 0.9201\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1971 - accuracy: 0.9455 - val_loss: 0.3483 - val_accuracy: 0.9342\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1817 - accuracy: 0.9526 - val_loss: 0.3200 - val_accuracy: 0.9463\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1811 - accuracy: 0.9507 - val_loss: 0.3648 - val_accuracy: 0.9292\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1623 - accuracy: 0.9569 - val_loss: 0.3018 - val_accuracy: 0.9481\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1531 - accuracy: 0.9582 - val_loss: 0.2762 - val_accuracy: 0.9569\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1520 - accuracy: 0.9603 - val_loss: 0.2915 - val_accuracy: 0.9474\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1408 - accuracy: 0.9639 - val_loss: 0.2635 - val_accuracy: 0.9617\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1369 - accuracy: 0.9644 - val_loss: 0.3256 - val_accuracy: 0.9443\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1385 - accuracy: 0.9657 - val_loss: 0.2694 - val_accuracy: 0.9626\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1260 - accuracy: 0.9670 - val_loss: 0.2782 - val_accuracy: 0.9525\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1267 - accuracy: 0.9680 - val_loss: 0.2863 - val_accuracy: 0.9538\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1242 - accuracy: 0.9668 - val_loss: 0.2425 - val_accuracy: 0.9672\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1157 - accuracy: 0.9724 - val_loss: 0.2655 - val_accuracy: 0.9571\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1111 - accuracy: 0.9726 - val_loss: 0.2264 - val_accuracy: 0.9758\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1180 - accuracy: 0.9691 - val_loss: 0.2596 - val_accuracy: 0.9606\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1093 - accuracy: 0.9737 - val_loss: 0.2400 - val_accuracy: 0.9707\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1041 - accuracy: 0.9746 - val_loss: 0.2403 - val_accuracy: 0.9718\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1089 - accuracy: 0.9740 - val_loss: 0.2403 - val_accuracy: 0.9694\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1135 - accuracy: 0.9733 - val_loss: 0.2460 - val_accuracy: 0.9692\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1009 - accuracy: 0.9772 - val_loss: 0.2368 - val_accuracy: 0.9663\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1054 - accuracy: 0.9738 - val_loss: 0.2217 - val_accuracy: 0.9749\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0991 - accuracy: 0.9749 - val_loss: 0.2106 - val_accuracy: 0.9769\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1004 - accuracy: 0.9765 - val_loss: 0.2341 - val_accuracy: 0.9692\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0960 - accuracy: 0.9768 - val_loss: 0.2228 - val_accuracy: 0.9721\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0980 - accuracy: 0.9745 - val_loss: 0.2311 - val_accuracy: 0.9760\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0856 - accuracy: 0.9801 - val_loss: 0.2312 - val_accuracy: 0.9754\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0916 - accuracy: 0.9786 - val_loss: 0.2271 - val_accuracy: 0.9758\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0936 - accuracy: 0.9773 - val_loss: 0.2342 - val_accuracy: 0.9705\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0860 - accuracy: 0.9781 - val_loss: 0.2239 - val_accuracy: 0.9747\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0889 - accuracy: 0.9781 - val_loss: 0.2576 - val_accuracy: 0.9663\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.9506 - accuracy: 0.2129 - val_loss: 2.9382 - val_accuracy: 0.4425\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 1.9712 - accuracy: 0.6207 - val_loss: 1.7570 - val_accuracy: 0.7078\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1741 - accuracy: 0.7598 - val_loss: 1.3926 - val_accuracy: 0.7877\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8395 - accuracy: 0.8168 - val_loss: 1.1301 - val_accuracy: 0.8328\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6667 - accuracy: 0.8461 - val_loss: 1.0252 - val_accuracy: 0.8290\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5550 - accuracy: 0.8647 - val_loss: 0.8741 - val_accuracy: 0.8629\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4791 - accuracy: 0.8794 - val_loss: 0.7889 - val_accuracy: 0.8845\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4235 - accuracy: 0.8912 - val_loss: 0.7635 - val_accuracy: 0.8638\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3808 - accuracy: 0.9007 - val_loss: 0.6552 - val_accuracy: 0.8931\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3478 - accuracy: 0.9079 - val_loss: 0.6173 - val_accuracy: 0.9050\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3144 - accuracy: 0.9167 - val_loss: 0.6959 - val_accuracy: 0.8781\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2850 - accuracy: 0.9257 - val_loss: 0.5829 - val_accuracy: 0.9129\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2822 - accuracy: 0.9227 - val_loss: 0.5514 - val_accuracy: 0.9173\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.2629 - accuracy: 0.9261 - val_loss: 0.5585 - val_accuracy: 0.9124\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2396 - accuracy: 0.9327 - val_loss: 0.5203 - val_accuracy: 0.9228\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 3ms/step - loss: 0.2289 - accuracy: 0.9370 - val_loss: 0.5533 - val_accuracy: 0.9096\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2212 - accuracy: 0.9384 - val_loss: 0.5142 - val_accuracy: 0.9272\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.2065 - accuracy: 0.9434 - val_loss: 0.5075 - val_accuracy: 0.9261\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2071 - accuracy: 0.9429 - val_loss: 0.4904 - val_accuracy: 0.9307\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1963 - accuracy: 0.9459 - val_loss: 0.5242 - val_accuracy: 0.9190\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1981 - accuracy: 0.9449 - val_loss: 0.5482 - val_accuracy: 0.9160\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1789 - accuracy: 0.9510 - val_loss: 0.4403 - val_accuracy: 0.9424\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1737 - accuracy: 0.9532 - val_loss: 0.4606 - val_accuracy: 0.9375\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1704 - accuracy: 0.9522 - val_loss: 0.5056 - val_accuracy: 0.9254\n","Epoch 25/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1630 - accuracy: 0.9566 - val_loss: 0.4700 - val_accuracy: 0.9327\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1743 - accuracy: 0.9527 - val_loss: 0.4355 - val_accuracy: 0.9468\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1537 - accuracy: 0.9583 - val_loss: 0.4544 - val_accuracy: 0.9413\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1621 - accuracy: 0.9564 - val_loss: 0.4263 - val_accuracy: 0.9415\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1480 - accuracy: 0.9602 - val_loss: 0.4000 - val_accuracy: 0.9538\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1467 - accuracy: 0.9602 - val_loss: 0.4528 - val_accuracy: 0.9344\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1320 - accuracy: 0.9647 - val_loss: 0.4024 - val_accuracy: 0.9483\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1471 - accuracy: 0.9598 - val_loss: 0.3651 - val_accuracy: 0.9628\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1353 - accuracy: 0.9635 - val_loss: 0.3892 - val_accuracy: 0.9476\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1315 - accuracy: 0.9653 - val_loss: 0.3587 - val_accuracy: 0.9652\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1345 - accuracy: 0.9649 - val_loss: 0.3470 - val_accuracy: 0.9646\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1237 - accuracy: 0.9693 - val_loss: 0.4112 - val_accuracy: 0.9446\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1285 - accuracy: 0.9660 - val_loss: 0.3520 - val_accuracy: 0.9663\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1234 - accuracy: 0.9672 - val_loss: 0.3525 - val_accuracy: 0.9630\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1172 - accuracy: 0.9680 - val_loss: 0.3673 - val_accuracy: 0.9586\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1187 - accuracy: 0.9698 - val_loss: 0.3512 - val_accuracy: 0.9600\n","Average Validation Accuracy: 0.9735684990882874\n","Average Validation Loss: 0.16022928804159164\n","Average Test Accuracy: 0.9734650254249573\n","------------------------------------------------------------------------\n","\n","Number of input features: 15\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.3366 - accuracy: 0.3592 - val_loss: 2.0265 - val_accuracy: 0.6381\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2591 - accuracy: 0.7635 - val_loss: 1.0922 - val_accuracy: 0.8123\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6840 - accuracy: 0.8552 - val_loss: 0.7463 - val_accuracy: 0.8689\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4649 - accuracy: 0.8909 - val_loss: 0.5778 - val_accuracy: 0.8882\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3589 - accuracy: 0.9132 - val_loss: 0.4872 - val_accuracy: 0.9109\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2894 - accuracy: 0.9274 - val_loss: 0.4275 - val_accuracy: 0.9287\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2522 - accuracy: 0.9366 - val_loss: 0.3832 - val_accuracy: 0.9377\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2299 - accuracy: 0.9401 - val_loss: 0.3858 - val_accuracy: 0.9285\n","Epoch 9/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2093 - accuracy: 0.9463 - val_loss: 0.3323 - val_accuracy: 0.9452\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1969 - accuracy: 0.9530 - val_loss: 0.3852 - val_accuracy: 0.9410\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1786 - accuracy: 0.9552 - val_loss: 0.3072 - val_accuracy: 0.9448\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1681 - accuracy: 0.9568 - val_loss: 0.3110 - val_accuracy: 0.9536\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1583 - accuracy: 0.9609 - val_loss: 0.3047 - val_accuracy: 0.9529\n","Epoch 14/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1623 - accuracy: 0.9595 - val_loss: 0.3017 - val_accuracy: 0.9505\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1378 - accuracy: 0.9679 - val_loss: 0.2871 - val_accuracy: 0.9553\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1336 - accuracy: 0.9682 - val_loss: 0.2819 - val_accuracy: 0.9600\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1341 - accuracy: 0.9704 - val_loss: 0.2996 - val_accuracy: 0.9536\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1320 - accuracy: 0.9684 - val_loss: 0.2516 - val_accuracy: 0.9701\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1185 - accuracy: 0.9726 - val_loss: 0.2495 - val_accuracy: 0.9674\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1291 - accuracy: 0.9680 - val_loss: 0.2485 - val_accuracy: 0.9622\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1192 - accuracy: 0.9724 - val_loss: 0.2698 - val_accuracy: 0.9589\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1089 - accuracy: 0.9741 - val_loss: 0.2782 - val_accuracy: 0.9520\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1174 - accuracy: 0.9717 - val_loss: 0.2536 - val_accuracy: 0.9626\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1084 - accuracy: 0.9749 - val_loss: 0.2572 - val_accuracy: 0.9600\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1003 - accuracy: 0.9771 - val_loss: 0.2403 - val_accuracy: 0.9602\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1134 - accuracy: 0.9731 - val_loss: 0.2520 - val_accuracy: 0.9633\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1053 - accuracy: 0.9756 - val_loss: 0.2895 - val_accuracy: 0.9575\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0894 - accuracy: 0.9807 - val_loss: 0.2271 - val_accuracy: 0.9718\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1043 - accuracy: 0.9762 - val_loss: 0.2346 - val_accuracy: 0.9657\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0921 - accuracy: 0.9782 - val_loss: 0.3229 - val_accuracy: 0.9492\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0925 - accuracy: 0.9795 - val_loss: 0.2634 - val_accuracy: 0.9545\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0873 - accuracy: 0.9790 - val_loss: 0.2465 - val_accuracy: 0.9668\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0971 - accuracy: 0.9773 - val_loss: 0.2192 - val_accuracy: 0.9674\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0878 - accuracy: 0.9798 - val_loss: 0.2082 - val_accuracy: 0.9769\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0839 - accuracy: 0.9816 - val_loss: 0.2216 - val_accuracy: 0.9723\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0863 - accuracy: 0.9794 - val_loss: 0.2302 - val_accuracy: 0.9679\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0812 - accuracy: 0.9815 - val_loss: 0.2301 - val_accuracy: 0.9736\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0851 - accuracy: 0.9809 - val_loss: 0.2088 - val_accuracy: 0.9732\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0820 - accuracy: 0.9802 - val_loss: 0.2051 - val_accuracy: 0.9685\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0769 - accuracy: 0.9825 - val_loss: 0.2211 - val_accuracy: 0.9692\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.5283 - accuracy: 0.3284 - val_loss: 2.2703 - val_accuracy: 0.6106\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4917 - accuracy: 0.7194 - val_loss: 1.3596 - val_accuracy: 0.7864\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8477 - accuracy: 0.8291 - val_loss: 0.8892 - val_accuracy: 0.8570\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5101 - accuracy: 0.8895 - val_loss: 0.6809 - val_accuracy: 0.9087\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3648 - accuracy: 0.9180 - val_loss: 0.5890 - val_accuracy: 0.9149\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2906 - accuracy: 0.9307 - val_loss: 0.5396 - val_accuracy: 0.9054\n","Epoch 7/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2380 - accuracy: 0.9434 - val_loss: 0.4317 - val_accuracy: 0.9303\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2205 - accuracy: 0.9443 - val_loss: 0.4240 - val_accuracy: 0.9270\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1988 - accuracy: 0.9503 - val_loss: 0.3629 - val_accuracy: 0.9415\n","Epoch 10/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1805 - accuracy: 0.9569 - val_loss: 0.3799 - val_accuracy: 0.9375\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1714 - accuracy: 0.9583 - val_loss: 0.3653 - val_accuracy: 0.9351\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1679 - accuracy: 0.9555 - val_loss: 0.3095 - val_accuracy: 0.9567\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1532 - accuracy: 0.9627 - val_loss: 0.3166 - val_accuracy: 0.9551\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1394 - accuracy: 0.9682 - val_loss: 0.3130 - val_accuracy: 0.9584\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1469 - accuracy: 0.9641 - val_loss: 0.2931 - val_accuracy: 0.9509\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1376 - accuracy: 0.9649 - val_loss: 0.3031 - val_accuracy: 0.9613\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1243 - accuracy: 0.9712 - val_loss: 0.3074 - val_accuracy: 0.9549\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1370 - accuracy: 0.9652 - val_loss: 0.2653 - val_accuracy: 0.9674\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1185 - accuracy: 0.9710 - val_loss: 0.2825 - val_accuracy: 0.9595\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1204 - accuracy: 0.9706 - val_loss: 0.2588 - val_accuracy: 0.9694\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1207 - accuracy: 0.9705 - val_loss: 0.2790 - val_accuracy: 0.9646\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1079 - accuracy: 0.9755 - val_loss: 0.2759 - val_accuracy: 0.9663\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1130 - accuracy: 0.9739 - val_loss: 0.3033 - val_accuracy: 0.9593\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1053 - accuracy: 0.9751 - val_loss: 0.2730 - val_accuracy: 0.9663\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1077 - accuracy: 0.9754 - val_loss: 0.2597 - val_accuracy: 0.9696\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1085 - accuracy: 0.9725 - val_loss: 0.3625 - val_accuracy: 0.9465\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1010 - accuracy: 0.9776 - val_loss: 0.2579 - val_accuracy: 0.9703\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1015 - accuracy: 0.9764 - val_loss: 0.3235 - val_accuracy: 0.9536\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1046 - accuracy: 0.9757 - val_loss: 0.2753 - val_accuracy: 0.9626\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1005 - accuracy: 0.9776 - val_loss: 0.2401 - val_accuracy: 0.9773\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0921 - accuracy: 0.9804 - val_loss: 0.2653 - val_accuracy: 0.9655\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0949 - accuracy: 0.9792 - val_loss: 0.2388 - val_accuracy: 0.9718\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0894 - accuracy: 0.9811 - val_loss: 0.2605 - val_accuracy: 0.9681\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0947 - accuracy: 0.9766 - val_loss: 0.2850 - val_accuracy: 0.9615\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0897 - accuracy: 0.9792 - val_loss: 0.2454 - val_accuracy: 0.9699\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0939 - accuracy: 0.9797 - val_loss: 0.2267 - val_accuracy: 0.9793\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0891 - accuracy: 0.9782 - val_loss: 0.2419 - val_accuracy: 0.9721\n","Epoch 38/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0876 - accuracy: 0.9811 - val_loss: 0.2774 - val_accuracy: 0.9604\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0829 - accuracy: 0.9804 - val_loss: 0.3210 - val_accuracy: 0.9626\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0872 - accuracy: 0.9792 - val_loss: 0.2941 - val_accuracy: 0.9562\n","Average Validation Accuracy: 0.9695383012294769\n","Average Validation Loss: 0.1600327342748642\n","Average Test Accuracy: 0.968673974275589\n","------------------------------------------------------------------------\n","\n","Number of input features: 16\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.6789 - accuracy: 0.3002 - val_loss: 2.4775 - val_accuracy: 0.5993\n","Epoch 2/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.6696 - accuracy: 0.7005 - val_loss: 1.4365 - val_accuracy: 0.7787\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9928 - accuracy: 0.8164 - val_loss: 1.0136 - val_accuracy: 0.8396\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6797 - accuracy: 0.8627 - val_loss: 0.7974 - val_accuracy: 0.8768\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5175 - accuracy: 0.8923 - val_loss: 0.7356 - val_accuracy: 0.8972\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4092 - accuracy: 0.9134 - val_loss: 0.6648 - val_accuracy: 0.8966\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3383 - accuracy: 0.9210 - val_loss: 0.6137 - val_accuracy: 0.9069\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2888 - accuracy: 0.9337 - val_loss: 0.4998 - val_accuracy: 0.9395\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2463 - accuracy: 0.9422 - val_loss: 0.5142 - val_accuracy: 0.9259\n","Epoch 10/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2254 - accuracy: 0.9453 - val_loss: 0.4582 - val_accuracy: 0.9507\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2004 - accuracy: 0.9526 - val_loss: 0.4665 - val_accuracy: 0.9439\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1840 - accuracy: 0.9569 - val_loss: 0.4896 - val_accuracy: 0.9430\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1732 - accuracy: 0.9582 - val_loss: 0.4904 - val_accuracy: 0.9349\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1750 - accuracy: 0.9592 - val_loss: 0.4400 - val_accuracy: 0.9498\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1613 - accuracy: 0.9608 - val_loss: 0.4049 - val_accuracy: 0.9582\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1518 - accuracy: 0.9639 - val_loss: 0.3794 - val_accuracy: 0.9679\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1387 - accuracy: 0.9681 - val_loss: 0.3738 - val_accuracy: 0.9657\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1540 - accuracy: 0.9636 - val_loss: 0.4063 - val_accuracy: 0.9501\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1319 - accuracy: 0.9687 - val_loss: 0.4132 - val_accuracy: 0.9575\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1356 - accuracy: 0.9679 - val_loss: 0.3778 - val_accuracy: 0.9593\n","Epoch 21/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1224 - accuracy: 0.9731 - val_loss: 0.3550 - val_accuracy: 0.9674\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1292 - accuracy: 0.9693 - val_loss: 0.3562 - val_accuracy: 0.9681\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1239 - accuracy: 0.9703 - val_loss: 0.4267 - val_accuracy: 0.9481\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1284 - accuracy: 0.9694 - val_loss: 0.3571 - val_accuracy: 0.9663\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1249 - accuracy: 0.9716 - val_loss: 0.3413 - val_accuracy: 0.9683\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1231 - accuracy: 0.9694 - val_loss: 0.3315 - val_accuracy: 0.9655\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1106 - accuracy: 0.9743 - val_loss: 0.3358 - val_accuracy: 0.9703\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1057 - accuracy: 0.9754 - val_loss: 0.3387 - val_accuracy: 0.9648\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1106 - accuracy: 0.9751 - val_loss: 0.4010 - val_accuracy: 0.9514\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1160 - accuracy: 0.9734 - val_loss: 0.3333 - val_accuracy: 0.9685\n","Epoch 31/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1050 - accuracy: 0.9762 - val_loss: 0.3301 - val_accuracy: 0.9707\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1024 - accuracy: 0.9779 - val_loss: 0.3184 - val_accuracy: 0.9749\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1032 - accuracy: 0.9775 - val_loss: 0.3175 - val_accuracy: 0.9765\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0997 - accuracy: 0.9768 - val_loss: 0.3117 - val_accuracy: 0.9714\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1030 - accuracy: 0.9746 - val_loss: 0.3336 - val_accuracy: 0.9699\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0969 - accuracy: 0.9776 - val_loss: 0.4010 - val_accuracy: 0.9547\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0932 - accuracy: 0.9794 - val_loss: 0.3107 - val_accuracy: 0.9727\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0965 - accuracy: 0.9784 - val_loss: 0.3279 - val_accuracy: 0.9652\n","Epoch 39/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1027 - accuracy: 0.9763 - val_loss: 0.3145 - val_accuracy: 0.9716\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0919 - accuracy: 0.9782 - val_loss: 0.3309 - val_accuracy: 0.9707\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.6456 - accuracy: 0.3050 - val_loss: 2.3925 - val_accuracy: 0.6167\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5356 - accuracy: 0.7250 - val_loss: 1.4560 - val_accuracy: 0.7857\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8983 - accuracy: 0.8199 - val_loss: 1.0438 - val_accuracy: 0.8337\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5985 - accuracy: 0.8682 - val_loss: 0.8143 - val_accuracy: 0.8838\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4318 - accuracy: 0.9013 - val_loss: 0.6872 - val_accuracy: 0.8878\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3466 - accuracy: 0.9164 - val_loss: 0.5971 - val_accuracy: 0.9102\n","Epoch 7/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2957 - accuracy: 0.9275 - val_loss: 0.5207 - val_accuracy: 0.9140\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2595 - accuracy: 0.9335 - val_loss: 0.4979 - val_accuracy: 0.9155\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2379 - accuracy: 0.9381 - val_loss: 0.4217 - val_accuracy: 0.9384\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2175 - accuracy: 0.9462 - val_loss: 0.4102 - val_accuracy: 0.9424\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2032 - accuracy: 0.9481 - val_loss: 0.4066 - val_accuracy: 0.9386\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1920 - accuracy: 0.9520 - val_loss: 0.3848 - val_accuracy: 0.9494\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1748 - accuracy: 0.9571 - val_loss: 0.3799 - val_accuracy: 0.9402\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1634 - accuracy: 0.9588 - val_loss: 0.3727 - val_accuracy: 0.9410\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1682 - accuracy: 0.9558 - val_loss: 0.3525 - val_accuracy: 0.9487\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1588 - accuracy: 0.9614 - val_loss: 0.3225 - val_accuracy: 0.9562\n","Epoch 17/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1476 - accuracy: 0.9638 - val_loss: 0.3363 - val_accuracy: 0.9507\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1448 - accuracy: 0.9645 - val_loss: 0.2885 - val_accuracy: 0.9655\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1357 - accuracy: 0.9667 - val_loss: 0.3159 - val_accuracy: 0.9540\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1374 - accuracy: 0.9682 - val_loss: 0.3466 - val_accuracy: 0.9525\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1307 - accuracy: 0.9713 - val_loss: 0.2746 - val_accuracy: 0.9674\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1284 - accuracy: 0.9686 - val_loss: 0.2894 - val_accuracy: 0.9567\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1163 - accuracy: 0.9718 - val_loss: 0.3052 - val_accuracy: 0.9600\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1151 - accuracy: 0.9739 - val_loss: 0.3282 - val_accuracy: 0.9531\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1218 - accuracy: 0.9715 - val_loss: 0.2698 - val_accuracy: 0.9694\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1175 - accuracy: 0.9734 - val_loss: 0.2651 - val_accuracy: 0.9681\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1170 - accuracy: 0.9725 - val_loss: 0.2848 - val_accuracy: 0.9633\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1142 - accuracy: 0.9743 - val_loss: 0.2603 - val_accuracy: 0.9661\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1145 - accuracy: 0.9744 - val_loss: 0.3043 - val_accuracy: 0.9549\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1036 - accuracy: 0.9772 - val_loss: 0.3842 - val_accuracy: 0.9336\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1126 - accuracy: 0.9731 - val_loss: 0.2563 - val_accuracy: 0.9727\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0914 - accuracy: 0.9810 - val_loss: 0.2659 - val_accuracy: 0.9637\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0966 - accuracy: 0.9776 - val_loss: 0.2192 - val_accuracy: 0.9793\n","Epoch 34/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1051 - accuracy: 0.9752 - val_loss: 0.2603 - val_accuracy: 0.9666\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1011 - accuracy: 0.9782 - val_loss: 0.2282 - val_accuracy: 0.9782\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0950 - accuracy: 0.9784 - val_loss: 0.2441 - val_accuracy: 0.9659\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0899 - accuracy: 0.9807 - val_loss: 0.2280 - val_accuracy: 0.9696\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0961 - accuracy: 0.9784 - val_loss: 0.2325 - val_accuracy: 0.9694\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0866 - accuracy: 0.9810 - val_loss: 0.2251 - val_accuracy: 0.9679\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0931 - accuracy: 0.9798 - val_loss: 0.3325 - val_accuracy: 0.9520\n","Average Validation Accuracy: 0.9664158523082733\n","Average Validation Loss: 0.20121708512306213\n","Average Test Accuracy: 0.9674578011035919\n","------------------------------------------------------------------------\n","\n","Number of input features: 17\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 5ms/step - loss: 3.6660 - accuracy: 0.2914 - val_loss: 2.2965 - val_accuracy: 0.5776\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5393 - accuracy: 0.7186 - val_loss: 1.2993 - val_accuracy: 0.7734\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9243 - accuracy: 0.8219 - val_loss: 0.9411 - val_accuracy: 0.8334\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6570 - accuracy: 0.8675 - val_loss: 0.7251 - val_accuracy: 0.8697\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4902 - accuracy: 0.8998 - val_loss: 0.6487 - val_accuracy: 0.8878\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3903 - accuracy: 0.9173 - val_loss: 0.5238 - val_accuracy: 0.9296\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3183 - accuracy: 0.9325 - val_loss: 0.4653 - val_accuracy: 0.9371\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2683 - accuracy: 0.9401 - val_loss: 0.4565 - val_accuracy: 0.9285\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2393 - accuracy: 0.9471 - val_loss: 0.4290 - val_accuracy: 0.9344\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2142 - accuracy: 0.9505 - val_loss: 0.4839 - val_accuracy: 0.9241\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1906 - accuracy: 0.9564 - val_loss: 0.3974 - val_accuracy: 0.9461\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1801 - accuracy: 0.9574 - val_loss: 0.4582 - val_accuracy: 0.9278\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1729 - accuracy: 0.9585 - val_loss: 0.4045 - val_accuracy: 0.9384\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1557 - accuracy: 0.9653 - val_loss: 0.3448 - val_accuracy: 0.9562\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1539 - accuracy: 0.9649 - val_loss: 0.3494 - val_accuracy: 0.9556\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1489 - accuracy: 0.9652 - val_loss: 0.3358 - val_accuracy: 0.9562\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1335 - accuracy: 0.9694 - val_loss: 0.3231 - val_accuracy: 0.9551\n","Epoch 18/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1314 - accuracy: 0.9710 - val_loss: 0.2972 - val_accuracy: 0.9683\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1307 - accuracy: 0.9691 - val_loss: 0.3054 - val_accuracy: 0.9650\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1266 - accuracy: 0.9705 - val_loss: 0.3043 - val_accuracy: 0.9635\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1170 - accuracy: 0.9736 - val_loss: 0.2932 - val_accuracy: 0.9677\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1197 - accuracy: 0.9726 - val_loss: 0.2824 - val_accuracy: 0.9703\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1198 - accuracy: 0.9728 - val_loss: 0.3621 - val_accuracy: 0.9545\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1215 - accuracy: 0.9713 - val_loss: 0.2622 - val_accuracy: 0.9727\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1003 - accuracy: 0.9776 - val_loss: 0.3037 - val_accuracy: 0.9463\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1054 - accuracy: 0.9751 - val_loss: 0.2781 - val_accuracy: 0.9694\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1087 - accuracy: 0.9771 - val_loss: 0.2809 - val_accuracy: 0.9694\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1042 - accuracy: 0.9770 - val_loss: 0.2505 - val_accuracy: 0.9787\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0983 - accuracy: 0.9764 - val_loss: 0.2880 - val_accuracy: 0.9608\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1015 - accuracy: 0.9764 - val_loss: 0.2457 - val_accuracy: 0.9712\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0963 - accuracy: 0.9792 - val_loss: 0.2469 - val_accuracy: 0.9725\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0960 - accuracy: 0.9776 - val_loss: 0.2458 - val_accuracy: 0.9747\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0927 - accuracy: 0.9794 - val_loss: 0.2648 - val_accuracy: 0.9652\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0918 - accuracy: 0.9791 - val_loss: 0.2630 - val_accuracy: 0.9688\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0921 - accuracy: 0.9799 - val_loss: 0.2540 - val_accuracy: 0.9718\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0921 - accuracy: 0.9793 - val_loss: 0.2318 - val_accuracy: 0.9734\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0866 - accuracy: 0.9819 - val_loss: 0.2345 - val_accuracy: 0.9769\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0935 - accuracy: 0.9801 - val_loss: 0.2531 - val_accuracy: 0.9685\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0877 - accuracy: 0.9823 - val_loss: 0.2376 - val_accuracy: 0.9798\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0802 - accuracy: 0.9823 - val_loss: 0.2200 - val_accuracy: 0.9824\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 4.1874 - accuracy: 0.1680 - val_loss: 3.2029 - val_accuracy: 0.3837\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.2066 - accuracy: 0.5684 - val_loss: 1.9404 - val_accuracy: 0.6860\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3237 - accuracy: 0.7352 - val_loss: 1.4819 - val_accuracy: 0.7476\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9417 - accuracy: 0.8018 - val_loss: 1.1710 - val_accuracy: 0.8143\n","Epoch 5/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.7396 - accuracy: 0.8330 - val_loss: 1.0685 - val_accuracy: 0.8436\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6207 - accuracy: 0.8544 - val_loss: 0.9424 - val_accuracy: 0.8528\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5328 - accuracy: 0.8732 - val_loss: 0.8433 - val_accuracy: 0.8693\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4859 - accuracy: 0.8793 - val_loss: 0.7701 - val_accuracy: 0.8779\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4262 - accuracy: 0.8940 - val_loss: 0.7450 - val_accuracy: 0.8838\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.3862 - accuracy: 0.8988 - val_loss: 0.7119 - val_accuracy: 0.8832\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3580 - accuracy: 0.9047 - val_loss: 0.6423 - val_accuracy: 0.9043\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3267 - accuracy: 0.9148 - val_loss: 0.6150 - val_accuracy: 0.9085\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3203 - accuracy: 0.9154 - val_loss: 0.6545 - val_accuracy: 0.9010\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2885 - accuracy: 0.9235 - val_loss: 0.6024 - val_accuracy: 0.9120\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2836 - accuracy: 0.9258 - val_loss: 0.5796 - val_accuracy: 0.9204\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2685 - accuracy: 0.9284 - val_loss: 0.5417 - val_accuracy: 0.9360\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.2569 - accuracy: 0.9342 - val_loss: 0.5346 - val_accuracy: 0.9252\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2473 - accuracy: 0.9368 - val_loss: 0.5483 - val_accuracy: 0.9342\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2375 - accuracy: 0.9367 - val_loss: 0.5855 - val_accuracy: 0.9300\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2372 - accuracy: 0.9409 - val_loss: 0.5580 - val_accuracy: 0.9283\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2197 - accuracy: 0.9445 - val_loss: 0.5916 - val_accuracy: 0.9193\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2197 - accuracy: 0.9439 - val_loss: 0.5085 - val_accuracy: 0.9450\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2149 - accuracy: 0.9473 - val_loss: 0.5526 - val_accuracy: 0.9285\n","Epoch 24/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2111 - accuracy: 0.9487 - val_loss: 0.5292 - val_accuracy: 0.9364\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2042 - accuracy: 0.9504 - val_loss: 0.5752 - val_accuracy: 0.9322\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2003 - accuracy: 0.9521 - val_loss: 0.4741 - val_accuracy: 0.9490\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1841 - accuracy: 0.9569 - val_loss: 0.5375 - val_accuracy: 0.9217\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1910 - accuracy: 0.9530 - val_loss: 0.4658 - val_accuracy: 0.9512\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1885 - accuracy: 0.9557 - val_loss: 0.6357 - val_accuracy: 0.9133\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1766 - accuracy: 0.9570 - val_loss: 0.6879 - val_accuracy: 0.8955\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1909 - accuracy: 0.9526 - val_loss: 0.4724 - val_accuracy: 0.9514\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1757 - accuracy: 0.9566 - val_loss: 0.5697 - val_accuracy: 0.9113\n","Epoch 33/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1798 - accuracy: 0.9562 - val_loss: 0.5099 - val_accuracy: 0.9384\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1746 - accuracy: 0.9603 - val_loss: 0.4492 - val_accuracy: 0.9593\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1648 - accuracy: 0.9599 - val_loss: 0.5586 - val_accuracy: 0.9349\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1720 - accuracy: 0.9589 - val_loss: 0.4566 - val_accuracy: 0.9507\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1655 - accuracy: 0.9623 - val_loss: 0.6637 - val_accuracy: 0.8770\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1712 - accuracy: 0.9603 - val_loss: 0.5291 - val_accuracy: 0.9223\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1664 - accuracy: 0.9625 - val_loss: 0.4966 - val_accuracy: 0.9417\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1628 - accuracy: 0.9616 - val_loss: 0.5212 - val_accuracy: 0.9371\n","Average Validation Accuracy: 0.9663065373897552\n","Average Validation Loss: 0.2102753035724163\n","Average Test Accuracy: 0.9656887948513031\n","------------------------------------------------------------------------\n","\n","Number of input features: 18\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 12s 4ms/step - loss: 3.5265 - accuracy: 0.3282 - val_loss: 2.0296 - val_accuracy: 0.6295\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3398 - accuracy: 0.7434 - val_loss: 1.1258 - val_accuracy: 0.7960\n","Epoch 3/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.7528 - accuracy: 0.8363 - val_loss: 0.7756 - val_accuracy: 0.8585\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5023 - accuracy: 0.8797 - val_loss: 0.5999 - val_accuracy: 0.8950\n","Epoch 5/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.3736 - accuracy: 0.9070 - val_loss: 0.4648 - val_accuracy: 0.9120\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3011 - accuracy: 0.9216 - val_loss: 0.4340 - val_accuracy: 0.9193\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2659 - accuracy: 0.9267 - val_loss: 0.3785 - val_accuracy: 0.9232\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2312 - accuracy: 0.9377 - val_loss: 0.4535 - val_accuracy: 0.9067\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2275 - accuracy: 0.9370 - val_loss: 0.3701 - val_accuracy: 0.9386\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1972 - accuracy: 0.9476 - val_loss: 0.4057 - val_accuracy: 0.9135\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1871 - accuracy: 0.9515 - val_loss: 0.3382 - val_accuracy: 0.9340\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1753 - accuracy: 0.9551 - val_loss: 0.3062 - val_accuracy: 0.9503\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1614 - accuracy: 0.9584 - val_loss: 0.3575 - val_accuracy: 0.9399\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1612 - accuracy: 0.9591 - val_loss: 0.3005 - val_accuracy: 0.9531\n","Epoch 15/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1587 - accuracy: 0.9584 - val_loss: 0.3750 - val_accuracy: 0.9281\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1504 - accuracy: 0.9602 - val_loss: 0.2942 - val_accuracy: 0.9553\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1357 - accuracy: 0.9667 - val_loss: 0.2668 - val_accuracy: 0.9635\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1481 - accuracy: 0.9600 - val_loss: 0.2688 - val_accuracy: 0.9584\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1354 - accuracy: 0.9650 - val_loss: 0.3074 - val_accuracy: 0.9516\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1305 - accuracy: 0.9684 - val_loss: 0.3327 - val_accuracy: 0.9452\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1284 - accuracy: 0.9687 - val_loss: 0.2163 - val_accuracy: 0.9784\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1299 - accuracy: 0.9669 - val_loss: 0.2461 - val_accuracy: 0.9626\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1279 - accuracy: 0.9687 - val_loss: 0.2366 - val_accuracy: 0.9670\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1224 - accuracy: 0.9699 - val_loss: 0.2342 - val_accuracy: 0.9668\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1173 - accuracy: 0.9719 - val_loss: 0.2603 - val_accuracy: 0.9553\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1151 - accuracy: 0.9725 - val_loss: 0.2254 - val_accuracy: 0.9690\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1214 - accuracy: 0.9712 - val_loss: 0.2580 - val_accuracy: 0.9617\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1160 - accuracy: 0.9715 - val_loss: 0.3583 - val_accuracy: 0.9232\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1108 - accuracy: 0.9726 - val_loss: 0.2171 - val_accuracy: 0.9725\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1130 - accuracy: 0.9729 - val_loss: 0.2127 - val_accuracy: 0.9747\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1161 - accuracy: 0.9708 - val_loss: 0.2380 - val_accuracy: 0.9707\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1077 - accuracy: 0.9746 - val_loss: 0.2451 - val_accuracy: 0.9701\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1029 - accuracy: 0.9755 - val_loss: 0.2429 - val_accuracy: 0.9694\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0962 - accuracy: 0.9775 - val_loss: 0.2486 - val_accuracy: 0.9635\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1107 - accuracy: 0.9725 - val_loss: 0.2553 - val_accuracy: 0.9674\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0951 - accuracy: 0.9791 - val_loss: 0.2473 - val_accuracy: 0.9685\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1070 - accuracy: 0.9742 - val_loss: 0.2291 - val_accuracy: 0.9716\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0967 - accuracy: 0.9773 - val_loss: 0.2557 - val_accuracy: 0.9652\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0989 - accuracy: 0.9760 - val_loss: 0.2154 - val_accuracy: 0.9725\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0902 - accuracy: 0.9794 - val_loss: 0.3156 - val_accuracy: 0.9483\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.4520 - accuracy: 0.3507 - val_loss: 2.1768 - val_accuracy: 0.6440\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4735 - accuracy: 0.7275 - val_loss: 1.4152 - val_accuracy: 0.7817\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9238 - accuracy: 0.8214 - val_loss: 1.0720 - val_accuracy: 0.8451\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6203 - accuracy: 0.8717 - val_loss: 0.9046 - val_accuracy: 0.8590\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4410 - accuracy: 0.9033 - val_loss: 0.7600 - val_accuracy: 0.8865\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3378 - accuracy: 0.9245 - val_loss: 0.6040 - val_accuracy: 0.9239\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2815 - accuracy: 0.9341 - val_loss: 0.5859 - val_accuracy: 0.9252\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2389 - accuracy: 0.9452 - val_loss: 0.4874 - val_accuracy: 0.9347\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2160 - accuracy: 0.9481 - val_loss: 0.4657 - val_accuracy: 0.9316\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1982 - accuracy: 0.9520 - val_loss: 0.4091 - val_accuracy: 0.9479\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1821 - accuracy: 0.9549 - val_loss: 0.4155 - val_accuracy: 0.9446\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1728 - accuracy: 0.9568 - val_loss: 0.3837 - val_accuracy: 0.9454\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1573 - accuracy: 0.9613 - val_loss: 0.3870 - val_accuracy: 0.9501\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1549 - accuracy: 0.9606 - val_loss: 0.3830 - val_accuracy: 0.9520\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1421 - accuracy: 0.9650 - val_loss: 0.3548 - val_accuracy: 0.9582\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1396 - accuracy: 0.9663 - val_loss: 0.4029 - val_accuracy: 0.9349\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1342 - accuracy: 0.9692 - val_loss: 0.3121 - val_accuracy: 0.9666\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1287 - accuracy: 0.9703 - val_loss: 0.3498 - val_accuracy: 0.9514\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1242 - accuracy: 0.9700 - val_loss: 0.3270 - val_accuracy: 0.9575\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1141 - accuracy: 0.9732 - val_loss: 0.2998 - val_accuracy: 0.9648\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1160 - accuracy: 0.9728 - val_loss: 0.3249 - val_accuracy: 0.9611\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1199 - accuracy: 0.9706 - val_loss: 0.3092 - val_accuracy: 0.9659\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1082 - accuracy: 0.9753 - val_loss: 0.2973 - val_accuracy: 0.9677\n","Epoch 24/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1104 - accuracy: 0.9749 - val_loss: 0.2739 - val_accuracy: 0.9701\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0998 - accuracy: 0.9784 - val_loss: 0.2742 - val_accuracy: 0.9639\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1105 - accuracy: 0.9765 - val_loss: 0.2660 - val_accuracy: 0.9745\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1010 - accuracy: 0.9779 - val_loss: 0.3020 - val_accuracy: 0.9582\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0941 - accuracy: 0.9781 - val_loss: 0.2638 - val_accuracy: 0.9701\n","Epoch 29/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1031 - accuracy: 0.9758 - val_loss: 0.2789 - val_accuracy: 0.9721\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0940 - accuracy: 0.9789 - val_loss: 0.2661 - val_accuracy: 0.9670\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1062 - accuracy: 0.9740 - val_loss: 0.2738 - val_accuracy: 0.9716\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0833 - accuracy: 0.9822 - val_loss: 0.3158 - val_accuracy: 0.9560\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0973 - accuracy: 0.9769 - val_loss: 0.2857 - val_accuracy: 0.9701\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0839 - accuracy: 0.9811 - val_loss: 0.2765 - val_accuracy: 0.9674\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0954 - accuracy: 0.9786 - val_loss: 0.2519 - val_accuracy: 0.9725\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0800 - accuracy: 0.9831 - val_loss: 0.2816 - val_accuracy: 0.9694\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0904 - accuracy: 0.9800 - val_loss: 0.2888 - val_accuracy: 0.9624\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0777 - accuracy: 0.9833 - val_loss: 0.2510 - val_accuracy: 0.9701\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0845 - accuracy: 0.9800 - val_loss: 0.2464 - val_accuracy: 0.9765\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0803 - accuracy: 0.9821 - val_loss: 0.2746 - val_accuracy: 0.9694\n","Average Validation Accuracy: 0.9671063125133514\n","Average Validation Loss: 0.1760641485452652\n","Average Test Accuracy: 0.970369279384613\n","------------------------------------------------------------------------\n","\n","Number of input features: 19\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.6564 - accuracy: 0.3005 - val_loss: 2.0162 - val_accuracy: 0.6462\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2085 - accuracy: 0.7706 - val_loss: 0.9915 - val_accuracy: 0.8339\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5902 - accuracy: 0.8742 - val_loss: 0.6734 - val_accuracy: 0.8805\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3878 - accuracy: 0.9090 - val_loss: 0.5239 - val_accuracy: 0.9109\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3101 - accuracy: 0.9242 - val_loss: 0.4557 - val_accuracy: 0.9157\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2558 - accuracy: 0.9340 - val_loss: 0.4349 - val_accuracy: 0.9261\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2307 - accuracy: 0.9407 - val_loss: 0.3364 - val_accuracy: 0.9380\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2017 - accuracy: 0.9470 - val_loss: 0.3412 - val_accuracy: 0.9380\n","Epoch 9/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1851 - accuracy: 0.9522 - val_loss: 0.3197 - val_accuracy: 0.9377\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1679 - accuracy: 0.9584 - val_loss: 0.3198 - val_accuracy: 0.9435\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1579 - accuracy: 0.9612 - val_loss: 0.2855 - val_accuracy: 0.9470\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1524 - accuracy: 0.9630 - val_loss: 0.4859 - val_accuracy: 0.8997\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1452 - accuracy: 0.9637 - val_loss: 0.2869 - val_accuracy: 0.9516\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1376 - accuracy: 0.9640 - val_loss: 0.2887 - val_accuracy: 0.9560\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1334 - accuracy: 0.9672 - val_loss: 0.2596 - val_accuracy: 0.9584\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1222 - accuracy: 0.9719 - val_loss: 0.2644 - val_accuracy: 0.9617\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1289 - accuracy: 0.9684 - val_loss: 0.3599 - val_accuracy: 0.9217\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1143 - accuracy: 0.9729 - val_loss: 0.2402 - val_accuracy: 0.9683\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1212 - accuracy: 0.9707 - val_loss: 0.2372 - val_accuracy: 0.9666\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1131 - accuracy: 0.9721 - val_loss: 0.2664 - val_accuracy: 0.9617\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1065 - accuracy: 0.9757 - val_loss: 0.2259 - val_accuracy: 0.9743\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1082 - accuracy: 0.9732 - val_loss: 0.2166 - val_accuracy: 0.9784\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0956 - accuracy: 0.9784 - val_loss: 0.2987 - val_accuracy: 0.9525\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0974 - accuracy: 0.9773 - val_loss: 0.2344 - val_accuracy: 0.9718\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1027 - accuracy: 0.9749 - val_loss: 0.2395 - val_accuracy: 0.9624\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0888 - accuracy: 0.9794 - val_loss: 0.2593 - val_accuracy: 0.9608\n","Epoch 27/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.0967 - accuracy: 0.9766 - val_loss: 0.2309 - val_accuracy: 0.9734\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0933 - accuracy: 0.9780 - val_loss: 0.2462 - val_accuracy: 0.9626\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0890 - accuracy: 0.9802 - val_loss: 0.2315 - val_accuracy: 0.9714\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0870 - accuracy: 0.9804 - val_loss: 0.2481 - val_accuracy: 0.9714\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0890 - accuracy: 0.9790 - val_loss: 0.2328 - val_accuracy: 0.9674\n","Epoch 32/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0845 - accuracy: 0.9810 - val_loss: 0.2238 - val_accuracy: 0.9734\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0810 - accuracy: 0.9801 - val_loss: 0.2517 - val_accuracy: 0.9641\n","Epoch 34/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.0815 - accuracy: 0.9809 - val_loss: 0.2193 - val_accuracy: 0.9712\n","Epoch 35/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0758 - accuracy: 0.9831 - val_loss: 0.2012 - val_accuracy: 0.9802\n","Epoch 36/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.0757 - accuracy: 0.9815 - val_loss: 0.2110 - val_accuracy: 0.9793\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0751 - accuracy: 0.9823 - val_loss: 0.2954 - val_accuracy: 0.9545\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0714 - accuracy: 0.9843 - val_loss: 0.2134 - val_accuracy: 0.9773\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0814 - accuracy: 0.9806 - val_loss: 0.2838 - val_accuracy: 0.9589\n","Epoch 40/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0744 - accuracy: 0.9822 - val_loss: 0.1941 - val_accuracy: 0.9806\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.4237 - accuracy: 0.3495 - val_loss: 1.9213 - val_accuracy: 0.6682\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2186 - accuracy: 0.7670 - val_loss: 1.1235 - val_accuracy: 0.8286\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6875 - accuracy: 0.8551 - val_loss: 0.8036 - val_accuracy: 0.8825\n","Epoch 4/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.4665 - accuracy: 0.8949 - val_loss: 0.6615 - val_accuracy: 0.8917\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3527 - accuracy: 0.9169 - val_loss: 0.5328 - val_accuracy: 0.9166\n","Epoch 6/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.2907 - accuracy: 0.9285 - val_loss: 0.4783 - val_accuracy: 0.9188\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2498 - accuracy: 0.9376 - val_loss: 0.3796 - val_accuracy: 0.9382\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2184 - accuracy: 0.9454 - val_loss: 0.4091 - val_accuracy: 0.9171\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1964 - accuracy: 0.9501 - val_loss: 0.4708 - val_accuracy: 0.9135\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1895 - accuracy: 0.9524 - val_loss: 0.3402 - val_accuracy: 0.9479\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1778 - accuracy: 0.9548 - val_loss: 0.3220 - val_accuracy: 0.9534\n","Epoch 12/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1665 - accuracy: 0.9613 - val_loss: 0.3346 - val_accuracy: 0.9492\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1628 - accuracy: 0.9602 - val_loss: 0.2926 - val_accuracy: 0.9562\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1537 - accuracy: 0.9615 - val_loss: 0.3060 - val_accuracy: 0.9494\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1455 - accuracy: 0.9666 - val_loss: 0.3020 - val_accuracy: 0.9487\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1407 - accuracy: 0.9680 - val_loss: 0.2865 - val_accuracy: 0.9600\n","Epoch 17/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1388 - accuracy: 0.9681 - val_loss: 0.3098 - val_accuracy: 0.9424\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1315 - accuracy: 0.9684 - val_loss: 0.2882 - val_accuracy: 0.9551\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1343 - accuracy: 0.9695 - val_loss: 0.3141 - val_accuracy: 0.9567\n","Epoch 20/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1197 - accuracy: 0.9726 - val_loss: 0.2553 - val_accuracy: 0.9648\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1211 - accuracy: 0.9712 - val_loss: 0.2458 - val_accuracy: 0.9712\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1188 - accuracy: 0.9723 - val_loss: 0.2795 - val_accuracy: 0.9487\n","Epoch 23/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1164 - accuracy: 0.9742 - val_loss: 0.2265 - val_accuracy: 0.9674\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1084 - accuracy: 0.9740 - val_loss: 0.3157 - val_accuracy: 0.9512\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1115 - accuracy: 0.9734 - val_loss: 0.2484 - val_accuracy: 0.9705\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1072 - accuracy: 0.9760 - val_loss: 0.2223 - val_accuracy: 0.9707\n","Epoch 27/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1026 - accuracy: 0.9782 - val_loss: 0.2328 - val_accuracy: 0.9694\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1028 - accuracy: 0.9766 - val_loss: 0.2536 - val_accuracy: 0.9608\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0987 - accuracy: 0.9785 - val_loss: 0.2002 - val_accuracy: 0.9734\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0985 - accuracy: 0.9796 - val_loss: 0.2175 - val_accuracy: 0.9749\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1008 - accuracy: 0.9785 - val_loss: 0.2420 - val_accuracy: 0.9716\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0958 - accuracy: 0.9792 - val_loss: 0.2636 - val_accuracy: 0.9619\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0952 - accuracy: 0.9783 - val_loss: 0.2149 - val_accuracy: 0.9701\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0848 - accuracy: 0.9800 - val_loss: 0.2845 - val_accuracy: 0.9428\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0912 - accuracy: 0.9802 - val_loss: 0.2043 - val_accuracy: 0.9694\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0884 - accuracy: 0.9809 - val_loss: 0.2733 - val_accuracy: 0.9446\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0875 - accuracy: 0.9816 - val_loss: 0.2358 - val_accuracy: 0.9597\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0920 - accuracy: 0.9790 - val_loss: 0.2113 - val_accuracy: 0.9688\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0875 - accuracy: 0.9814 - val_loss: 0.2058 - val_accuracy: 0.9769\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0756 - accuracy: 0.9855 - val_loss: 0.1929 - val_accuracy: 0.9745\n","Average Validation Accuracy: 0.984170138835907\n","Average Validation Loss: 0.10781360790133476\n","Average Test Accuracy: 0.9847424030303955\n","------------------------------------------------------------------------\n","\n","Number of input features: 20\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.8120 - accuracy: 0.2564 - val_loss: 2.4902 - val_accuracy: 0.5969\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.6243 - accuracy: 0.6833 - val_loss: 1.3948 - val_accuracy: 0.7479\n","Epoch 3/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.9265 - accuracy: 0.8024 - val_loss: 0.9992 - val_accuracy: 0.8284\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6373 - accuracy: 0.8494 - val_loss: 0.7537 - val_accuracy: 0.8697\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4920 - accuracy: 0.8783 - val_loss: 0.6717 - val_accuracy: 0.8695\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4062 - accuracy: 0.8896 - val_loss: 0.7321 - val_accuracy: 0.8471\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3452 - accuracy: 0.9067 - val_loss: 0.5795 - val_accuracy: 0.8986\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3148 - accuracy: 0.9145 - val_loss: 0.4864 - val_accuracy: 0.9182\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2750 - accuracy: 0.9242 - val_loss: 0.5199 - val_accuracy: 0.9050\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2529 - accuracy: 0.9292 - val_loss: 0.4772 - val_accuracy: 0.9160\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2269 - accuracy: 0.9382 - val_loss: 0.4396 - val_accuracy: 0.9179\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2195 - accuracy: 0.9375 - val_loss: 0.4647 - val_accuracy: 0.9206\n","Epoch 13/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.2091 - accuracy: 0.9427 - val_loss: 0.3757 - val_accuracy: 0.9450\n","Epoch 14/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1949 - accuracy: 0.9504 - val_loss: 0.4469 - val_accuracy: 0.9325\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1961 - accuracy: 0.9488 - val_loss: 0.3633 - val_accuracy: 0.9476\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1724 - accuracy: 0.9553 - val_loss: 0.4135 - val_accuracy: 0.9347\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1788 - accuracy: 0.9524 - val_loss: 0.5058 - val_accuracy: 0.9182\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1726 - accuracy: 0.9564 - val_loss: 0.3722 - val_accuracy: 0.9443\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1668 - accuracy: 0.9553 - val_loss: 0.3904 - val_accuracy: 0.9397\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1501 - accuracy: 0.9628 - val_loss: 0.3315 - val_accuracy: 0.9562\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1604 - accuracy: 0.9613 - val_loss: 0.3661 - val_accuracy: 0.9450\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1511 - accuracy: 0.9594 - val_loss: 0.4147 - val_accuracy: 0.9338\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1462 - accuracy: 0.9638 - val_loss: 0.3543 - val_accuracy: 0.9540\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1509 - accuracy: 0.9617 - val_loss: 0.3238 - val_accuracy: 0.9593\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1337 - accuracy: 0.9647 - val_loss: 0.3114 - val_accuracy: 0.9685\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1422 - accuracy: 0.9640 - val_loss: 0.3368 - val_accuracy: 0.9512\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1284 - accuracy: 0.9672 - val_loss: 0.4150 - val_accuracy: 0.9347\n","Epoch 28/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1388 - accuracy: 0.9650 - val_loss: 0.3593 - val_accuracy: 0.9472\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1275 - accuracy: 0.9677 - val_loss: 0.2986 - val_accuracy: 0.9679\n","Epoch 30/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1316 - accuracy: 0.9686 - val_loss: 0.3293 - val_accuracy: 0.9542\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1130 - accuracy: 0.9731 - val_loss: 0.3051 - val_accuracy: 0.9617\n","Epoch 32/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1322 - accuracy: 0.9677 - val_loss: 0.3116 - val_accuracy: 0.9663\n","Epoch 33/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1207 - accuracy: 0.9708 - val_loss: 0.4010 - val_accuracy: 0.9448\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1137 - accuracy: 0.9723 - val_loss: 0.3061 - val_accuracy: 0.9690\n","Epoch 35/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1138 - accuracy: 0.9726 - val_loss: 0.2902 - val_accuracy: 0.9685\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1199 - accuracy: 0.9707 - val_loss: 0.3220 - val_accuracy: 0.9650\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1206 - accuracy: 0.9706 - val_loss: 0.2833 - val_accuracy: 0.9668\n","Epoch 38/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1091 - accuracy: 0.9747 - val_loss: 0.2791 - val_accuracy: 0.9749\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1117 - accuracy: 0.9736 - val_loss: 0.3152 - val_accuracy: 0.9584\n","Epoch 40/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0974 - accuracy: 0.9788 - val_loss: 0.2930 - val_accuracy: 0.9683\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 12s 4ms/step - loss: 3.2401 - accuracy: 0.3974 - val_loss: 1.9894 - val_accuracy: 0.6603\n","Epoch 2/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 1.2596 - accuracy: 0.7555 - val_loss: 1.2732 - val_accuracy: 0.7714\n","Epoch 3/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.7312 - accuracy: 0.8452 - val_loss: 0.9605 - val_accuracy: 0.8323\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5003 - accuracy: 0.8865 - val_loss: 0.7053 - val_accuracy: 0.8933\n","Epoch 5/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.3822 - accuracy: 0.9131 - val_loss: 0.5953 - val_accuracy: 0.8975\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3115 - accuracy: 0.9232 - val_loss: 0.5473 - val_accuracy: 0.9074\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2790 - accuracy: 0.9316 - val_loss: 0.4479 - val_accuracy: 0.9309\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2409 - accuracy: 0.9420 - val_loss: 0.4687 - val_accuracy: 0.9146\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2199 - accuracy: 0.9484 - val_loss: 0.4430 - val_accuracy: 0.9263\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2110 - accuracy: 0.9485 - val_loss: 0.4667 - val_accuracy: 0.9204\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2004 - accuracy: 0.9521 - val_loss: 0.3352 - val_accuracy: 0.9523\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1855 - accuracy: 0.9551 - val_loss: 0.4218 - val_accuracy: 0.9298\n","Epoch 13/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1759 - accuracy: 0.9581 - val_loss: 0.3433 - val_accuracy: 0.9472\n","Epoch 14/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1713 - accuracy: 0.9579 - val_loss: 0.3957 - val_accuracy: 0.9349\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1604 - accuracy: 0.9609 - val_loss: 0.2933 - val_accuracy: 0.9608\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1632 - accuracy: 0.9619 - val_loss: 0.2933 - val_accuracy: 0.9547\n","Epoch 17/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1490 - accuracy: 0.9666 - val_loss: 0.2822 - val_accuracy: 0.9575\n","Epoch 18/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1426 - accuracy: 0.9668 - val_loss: 0.3396 - val_accuracy: 0.9426\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1346 - accuracy: 0.9681 - val_loss: 0.2879 - val_accuracy: 0.9527\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1419 - accuracy: 0.9672 - val_loss: 0.2651 - val_accuracy: 0.9595\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1268 - accuracy: 0.9710 - val_loss: 0.3332 - val_accuracy: 0.9459\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1302 - accuracy: 0.9704 - val_loss: 0.3040 - val_accuracy: 0.9593\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1211 - accuracy: 0.9717 - val_loss: 0.2652 - val_accuracy: 0.9536\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1214 - accuracy: 0.9737 - val_loss: 0.2509 - val_accuracy: 0.9672\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1175 - accuracy: 0.9727 - val_loss: 0.2406 - val_accuracy: 0.9633\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1117 - accuracy: 0.9758 - val_loss: 0.2274 - val_accuracy: 0.9672\n","Epoch 27/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1101 - accuracy: 0.9754 - val_loss: 0.2933 - val_accuracy: 0.9529\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1112 - accuracy: 0.9742 - val_loss: 0.2165 - val_accuracy: 0.9716\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0983 - accuracy: 0.9772 - val_loss: 0.3266 - val_accuracy: 0.9474\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1115 - accuracy: 0.9753 - val_loss: 0.2309 - val_accuracy: 0.9663\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1024 - accuracy: 0.9747 - val_loss: 0.2341 - val_accuracy: 0.9611\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0993 - accuracy: 0.9751 - val_loss: 0.2122 - val_accuracy: 0.9718\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1013 - accuracy: 0.9772 - val_loss: 0.2162 - val_accuracy: 0.9663\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0980 - accuracy: 0.9778 - val_loss: 0.2214 - val_accuracy: 0.9688\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0937 - accuracy: 0.9801 - val_loss: 0.2050 - val_accuracy: 0.9679\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0905 - accuracy: 0.9795 - val_loss: 0.2306 - val_accuracy: 0.9663\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0931 - accuracy: 0.9782 - val_loss: 0.2261 - val_accuracy: 0.9628\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0892 - accuracy: 0.9793 - val_loss: 0.2001 - val_accuracy: 0.9712\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0904 - accuracy: 0.9798 - val_loss: 0.1865 - val_accuracy: 0.9756\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0896 - accuracy: 0.9797 - val_loss: 0.2251 - val_accuracy: 0.9644\n","Average Validation Accuracy: 0.9732418358325958\n","Average Validation Loss: 0.15084272623062134\n","Average Test Accuracy: 0.9733176231384277\n","------------------------------------------------------------------------\n"]}],"source":["# Define the number of folds for k-fold cross-validation\n","k = 2\n","\n","# Define the cross-validation method\n","cv_method = StratifiedKFold(n_splits=k)\n","\n","# Initialize the list to store the history, train & validation(accuracy & loss) for each model\n","models = []\n","model_history = []\n","model_accuracy = []\n","model_train_acc = []\n","model_train_loss = []\n","model_val_acc = []\n","model_val_loss = []\n","\n","for i in range(1, 21):\n","\n","  models_fold = []\n","  hist = []\n","  train_accuracy = []\n","  train_loss = []\n","  val_accuracy = []\n","  val_loss = []\n","  test_accuracy = []\n","\n","  print(\"\\nNumber of input features:\", i)\n","\n","  # Select the input features from the input data\n","  X_train_selected = X_train[:, :i]\n","  X_test_selected = X_test[:, :i]\n","\n","  X_train_selected = X_train_selected.reshape(27543, i, 1, 1)\n","  X_test_selected = X_test_selected.reshape(13567, i, 1, 1)\n","\n","  # Loop over the folds\n","  for fold, (train_index, val_index) in enumerate(cv_method.split(X_train_selected, y_train)):\n","\n","    print(\"Fold:\", fold+1)\n","\n","    # Build the model\n","    model = Sequential()\n","    model.add(Conv2D(60, kernel_size=(5,5), activation='relu',bias_initializer='normal', input_shape=X_train_selected.shape[1:], padding= \"same\")) #keeps the output size same as input size (prevent down or upsampling)\n","    model.add(MaxPooling2D(pool_size=(1,1))) #pool size 2 error, because 1 (1 feature) minus 2 (pool size) is negative)\n","    model.add(Flatten())\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(373, kernel_initializer='normal', activation='softmax'))\n","\n","    # compile model\n","    model.compile(loss = \"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy']) \n","\n","    # # Fit the model to the training data for the current fold\n","    history = model.fit(X_train_selected[train_index], to_categorical(y_train_enc[train_index], num_classes=373), batch_size = 5, epochs = 40, verbose = 1, validation_split = 0.33)\n","\n","    # Evaluate the model on the validation data for the current fold\n","    val_scores = model.evaluate(X_train_selected[val_index], to_categorical(y_train_enc[val_index],num_classes=373), verbose=0)\n","    val_accuracy.append(val_scores[1])\n","    val_loss.append(val_scores[0])\n","\n","    # Evaluate the model on the test data for the current fold\n","    test_scores = model.evaluate(X_test_selected, to_categorical(y_test_enc, num_classes=373), verbose=0)\n","    test_accuracy.append(test_scores[1])\n","\n","    # add the model to the list of models\n","    models_fold.append(model)\n","    hist.append(history)\n","\n","    # store the training accuracy and loss for each fold\n","    train_accuracy.append(history.history['accuracy'])\n","    train_loss.append(history.history['loss'])\n","  \n","  # Calculate the average test and validation accuracy and loss across all folds\n","  avg_test_acc = sum(test_accuracy) / len(test_accuracy)\n","  avg_val_acc = sum(val_accuracy) / len(val_accuracy)\n","  avg_val_loss = sum(val_loss) / len(val_loss)\n","\n","  # Print the average validation and test accuracy and loss\n","  print(\"Average Validation Accuracy:\", avg_val_acc)\n","  print(\"Average Validation Loss:\",avg_val_loss)\n","  print(\"Average Test Accuracy:\", avg_test_acc)\n","\n","  best_fold_index = test_accuracy.index(max(test_accuracy))\n","  model_accuracy.append(test_accuracy[best_fold_index])\n","  models.append(models_fold[best_fold_index])\n","  model_history.append(hist[best_fold_index])\n","  model_train_acc.append(train_accuracy[best_fold_index])\n","  model_train_loss.append(train_loss[best_fold_index])\n","  model_val_acc.append(val_accuracy[best_fold_index])\n","  model_val_loss.append(val_loss[best_fold_index])\n","  print('------------------------------------------------------------------------')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ZG29fO-C4TJH"},"outputs":[],"source":["#to show the no of input features and its corresponding model accuracy\n","model_list = []\n","\n","#Iterate through each model's accuracy \n","for i in range (len(model_accuracy)):\n","    #get the number of input features for the current model\n","    no_features = i + 1\n","\n","    #round the model accuries to 3 d.p.\n","    rounded_model_acc = round(model_accuracy[i], 3)\n","    \n","    model_list.append([no_features, rounded_model_acc])\n","\n","models_df = pd.DataFrame(model_list, columns=[\"No of input features\", \"Model accuracy\"])"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"M1aBlP3GmZ9o"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Final Test Accuracy: 0.9870273470878601\n"]}],"source":["# Select the final model based on the max test accuracy across all models\n","\n","best_model_index = model_accuracy.index(max(model_accuracy))\n","\n","best_model = models[best_model_index]\n","best_model_history = model_history[best_model_index]\n","best_model_train_acc = model_train_acc[best_model_index]\n","best_model_train_loss = model_train_loss[best_model_index]\n","best_model_val_acc = model_val_acc[best_model_index]\n","best_model_val_loss = model_val_loss[best_model_index]\n","\n","# summarize history for accuracy  \n","plt.subplot(211)  \n","plt.plot(best_model_history.history['accuracy'])  \n","plt.plot(best_model_history.history['val_accuracy'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='lower right')  \n","\n","# summarize history for loss\n","plt.subplot(212)  \n","plt.plot(best_model_history.history['loss'])  \n","plt.plot(best_model_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='upper right')  \n","plt.subplots_adjust(hspace=0.7)\n","\n","plt.show() \n","\n","print(\"Final Test Accuracy:\", model_accuracy[best_model_index])"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"RMkWBkrYmZ9s"},"outputs":[{"name":"stdout","output_type":"stream","text":["424/424 [==============================] - 1s 2ms/step\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       591\n","           1       1.00      1.00      1.00       430\n","           2       1.00      1.00      1.00       419\n","           3       1.00      1.00      1.00       384\n","           4       1.00      1.00      1.00       339\n","           5       1.00      1.00      1.00       342\n","           6       1.00      1.00      1.00       310\n","           7       1.00      1.00      1.00       325\n","           8       1.00      1.00      1.00       294\n","           9       1.00      1.00      1.00       269\n","          10       1.00      1.00      1.00       296\n","          11       1.00      1.00      1.00       258\n","          12       1.00      1.00      1.00       247\n","          13       1.00      1.00      1.00       237\n","          14       1.00      1.00      1.00       239\n","          15       1.00      1.00      1.00       235\n","          16       1.00      1.00      1.00       213\n","          17       1.00      1.00      1.00       202\n","          18       0.96      1.00      0.98       196\n","          19       1.00      1.00      1.00       181\n","          20       1.00      1.00      1.00       177\n","          21       1.00      1.00      1.00       177\n","          22       1.00      1.00      1.00       155\n","          23       1.00      1.00      1.00       155\n","          24       1.00      1.00      1.00       144\n","          25       1.00      1.00      1.00       126\n","          26       1.00      1.00      1.00       108\n","          27       1.00      1.00      1.00       121\n","          28       1.00      1.00      1.00        95\n","          29       1.00      1.00      1.00       102\n","          30       1.00      1.00      1.00       106\n","          31       1.00      1.00      1.00        86\n","          32       1.00      1.00      1.00       108\n","          33       1.00      1.00      1.00        88\n","          34       1.00      1.00      1.00       102\n","          35       1.00      1.00      1.00        88\n","          36       1.00      1.00      1.00        83\n","          37       1.00      1.00      1.00        93\n","          38       1.00      1.00      1.00        76\n","          39       1.00      1.00      1.00        85\n","          40       1.00      1.00      1.00        86\n","          41       1.00      1.00      1.00        85\n","          42       1.00      1.00      1.00        68\n","          43       1.00      1.00      1.00        75\n","          44       0.99      1.00      0.99        71\n","          45       0.74      0.84      0.79        58\n","          46       1.00      1.00      1.00        71\n","          47       0.65      0.89      0.75        57\n","          48       1.00      1.00      1.00        67\n","          49       0.83      0.96      0.89        47\n","          50       1.00      1.00      1.00        47\n","          51       1.00      1.00      1.00        48\n","          52       1.00      1.00      1.00        43\n","          53       1.00      1.00      1.00        51\n","          54       1.00      1.00      1.00        44\n","          55       1.00      1.00      1.00        51\n","          56       1.00      1.00      1.00        45\n","          57       1.00      1.00      1.00        44\n","          58       1.00      1.00      1.00        41\n","          59       1.00      1.00      1.00        41\n","          60       1.00      1.00      1.00        52\n","          61       1.00      1.00      1.00        43\n","          62       1.00      1.00      1.00        37\n","          63       1.00      1.00      1.00        43\n","          64       1.00      1.00      1.00        42\n","          65       1.00      1.00      1.00        46\n","          66       1.00      1.00      1.00        43\n","          67       1.00      1.00      1.00        44\n","          68       1.00      1.00      1.00        40\n","          69       1.00      1.00      1.00        43\n","          70       1.00      1.00      1.00        33\n","          71       0.93      1.00      0.96        38\n","          72       1.00      1.00      1.00        45\n","          73       1.00      1.00      1.00        38\n","          74       1.00      1.00      1.00        42\n","          75       1.00      1.00      1.00        39\n","          76       1.00      0.20      0.33        30\n","          77       1.00      1.00      1.00        28\n","          78       1.00      1.00      1.00        28\n","          79       1.00      1.00      1.00        33\n","          80       1.00      1.00      1.00        32\n","          81       1.00      1.00      1.00        35\n","          82       1.00      1.00      1.00        31\n","          83       1.00      1.00      1.00        27\n","          84       1.00      1.00      1.00        36\n","          85       1.00      1.00      1.00        39\n","          86       1.00      1.00      1.00        31\n","          87       1.00      1.00      1.00        28\n","          88       0.95      1.00      0.98        20\n","          89       1.00      1.00      1.00        33\n","          90       1.00      1.00      1.00        24\n","          91       1.00      1.00      1.00        22\n","          92       1.00      1.00      1.00        35\n","          93       1.00      1.00      1.00        26\n","          94       1.00      1.00      1.00        23\n","          95       1.00      1.00      1.00        27\n","          96       0.82      1.00      0.90        27\n","          97       0.69      0.69      0.69        16\n","          98       1.00      1.00      1.00        28\n","          99       1.00      1.00      1.00        35\n","         100       1.00      1.00      1.00        25\n","         101       1.00      1.00      1.00        28\n","         102       1.00      1.00      1.00        26\n","         103       1.00      1.00      1.00        33\n","         104       1.00      1.00      1.00        26\n","         105       0.89      1.00      0.94        24\n","         106       1.00      0.32      0.48        22\n","         107       0.90      1.00      0.95        26\n","         108       1.00      1.00      1.00        25\n","         109       1.00      1.00      1.00        20\n","         110       1.00      1.00      1.00        26\n","         111       0.95      0.91      0.93        23\n","         112       1.00      1.00      1.00        16\n","         113       1.00      1.00      1.00        18\n","         114       1.00      1.00      1.00        25\n","         115       1.00      1.00      1.00        18\n","         116       1.00      1.00      1.00        19\n","         117       1.00      1.00      1.00        16\n","         118       1.00      1.00      1.00        26\n","         119       0.88      1.00      0.94        22\n","         120       1.00      1.00      1.00        18\n","         121       1.00      1.00      1.00        14\n","         122       1.00      1.00      1.00        15\n","         123       1.00      1.00      1.00        20\n","         124       1.00      1.00      1.00        26\n","         125       1.00      0.43      0.60        21\n","         126       1.00      1.00      1.00        22\n","         127       1.00      1.00      1.00        27\n","         128       1.00      1.00      1.00        17\n","         129       1.00      1.00      1.00        19\n","         130       1.00      1.00      1.00        18\n","         131       1.00      1.00      1.00        18\n","         132       1.00      1.00      1.00        20\n","         133       1.00      0.91      0.95        23\n","         134       1.00      1.00      1.00        23\n","         135       1.00      1.00      1.00        11\n","         136       1.00      1.00      1.00        16\n","         137       0.48      1.00      0.65        14\n","         138       1.00      1.00      1.00        19\n","         139       1.00      1.00      1.00        14\n","         140       1.00      1.00      1.00        20\n","         141       1.00      1.00      1.00        14\n","         142       1.00      1.00      1.00        23\n","         143       1.00      0.85      0.92        13\n","         144       1.00      1.00      1.00        24\n","         145       1.00      1.00      1.00        16\n","         146       1.00      1.00      1.00        19\n","         147       1.00      1.00      1.00        22\n","         148       1.00      0.94      0.97        17\n","         149       1.00      1.00      1.00        15\n","         150       1.00      1.00      1.00        20\n","         151       1.00      1.00      1.00        19\n","         152       1.00      1.00      1.00        24\n","         153       1.00      1.00      1.00        11\n","         154       1.00      1.00      1.00        11\n","         155       1.00      1.00      1.00        17\n","         156       1.00      1.00      1.00        12\n","         157       1.00      1.00      1.00        18\n","         158       1.00      1.00      1.00        20\n","         159       1.00      1.00      1.00        18\n","         160       1.00      1.00      1.00        20\n","         161       1.00      1.00      1.00        16\n","         162       1.00      1.00      1.00        15\n","         163       1.00      1.00      1.00        13\n","         164       1.00      1.00      1.00        19\n","         165       1.00      1.00      1.00        15\n","         166       1.00      1.00      1.00        15\n","         167       1.00      1.00      1.00        11\n","         168       1.00      1.00      1.00         9\n","         169       1.00      1.00      1.00        18\n","         170       1.00      0.91      0.95        11\n","         171       1.00      1.00      1.00        11\n","         172       1.00      1.00      1.00        21\n","         173       1.00      1.00      1.00        16\n","         174       1.00      1.00      1.00        10\n","         175       1.00      1.00      1.00        11\n","         176       1.00      1.00      1.00        10\n","         177       1.00      0.80      0.89        15\n","         178       1.00      1.00      1.00        11\n","         179       1.00      1.00      1.00        15\n","         180       1.00      1.00      1.00        13\n","         181       1.00      1.00      1.00        15\n","         182       1.00      1.00      1.00         9\n","         183       0.86      0.50      0.63        12\n","         184       1.00      1.00      1.00         8\n","         185       1.00      1.00      1.00        16\n","         186       1.00      1.00      1.00        14\n","         187       1.00      1.00      1.00        15\n","         188       0.80      0.62      0.70        13\n","         189       1.00      1.00      1.00        15\n","         190       1.00      1.00      1.00         4\n","         191       1.00      1.00      1.00        10\n","         192       1.00      1.00      1.00        17\n","         193       1.00      1.00      1.00         9\n","         194       1.00      1.00      1.00         9\n","         195       1.00      1.00      1.00        11\n","         196       1.00      1.00      1.00        14\n","         197       1.00      1.00      1.00        12\n","         198       1.00      1.00      1.00         7\n","         199       1.00      1.00      1.00         7\n","         200       1.00      1.00      1.00        14\n","         201       1.00      1.00      1.00        12\n","         202       1.00      1.00      1.00         9\n","         203       1.00      1.00      1.00        14\n","         204       1.00      1.00      1.00         7\n","         205       1.00      1.00      1.00         6\n","         206       0.00      0.00      0.00         6\n","         207       1.00      1.00      1.00        11\n","         208       1.00      1.00      1.00        12\n","         209       1.00      1.00      1.00        19\n","         210       0.78      1.00      0.88         7\n","         211       1.00      1.00      1.00         7\n","         212       1.00      1.00      1.00        11\n","         213       1.00      1.00      1.00         9\n","         214       1.00      1.00      1.00         6\n","         215       1.00      1.00      1.00         7\n","         216       1.00      1.00      1.00        12\n","         217       0.00      0.00      0.00         9\n","         218       1.00      1.00      1.00         6\n","         219       0.31      1.00      0.47         4\n","         220       1.00      1.00      1.00         8\n","         221       1.00      1.00      1.00         5\n","         222       1.00      1.00      1.00        12\n","         223       1.00      1.00      1.00        10\n","         224       1.00      1.00      1.00        13\n","         225       1.00      1.00      1.00         4\n","         226       1.00      1.00      1.00        14\n","         227       1.00      1.00      1.00        12\n","         228       1.00      1.00      1.00         5\n","         229       1.00      1.00      1.00        11\n","         230       1.00      1.00      1.00         6\n","         231       1.00      1.00      1.00        13\n","         232       1.00      1.00      1.00         9\n","         233       1.00      1.00      1.00         8\n","         234       1.00      1.00      1.00         7\n","         235       1.00      1.00      1.00         6\n","         236       0.54      0.88      0.67         8\n","         237       1.00      1.00      1.00         4\n","         238       1.00      1.00      1.00        10\n","         239       1.00      1.00      1.00         8\n","         240       0.00      0.00      0.00         9\n","         241       1.00      1.00      1.00         8\n","         242       1.00      1.00      1.00        10\n","         243       1.00      1.00      1.00         7\n","         244       1.00      1.00      1.00         9\n","         245       1.00      1.00      1.00         7\n","         246       1.00      1.00      1.00        12\n","         247       1.00      1.00      1.00         7\n","         248       1.00      1.00      1.00         7\n","         249       1.00      1.00      1.00         6\n","         250       1.00      1.00      1.00         2\n","         251       1.00      1.00      1.00         5\n","         252       1.00      1.00      1.00         9\n","         253       1.00      0.67      0.80         9\n","         254       1.00      0.33      0.50         3\n","         255       1.00      1.00      1.00         5\n","         256       1.00      1.00      1.00        11\n","         257       1.00      1.00      1.00        10\n","         258       1.00      1.00      1.00         7\n","         259       1.00      1.00      1.00         7\n","         260       0.67      1.00      0.80         4\n","         261       1.00      1.00      1.00        10\n","         262       1.00      1.00      1.00         6\n","         263       1.00      1.00      1.00         8\n","         264       1.00      1.00      1.00        10\n","         265       1.00      1.00      1.00         7\n","         266       0.90      1.00      0.95         9\n","         267       1.00      1.00      1.00         8\n","         268       1.00      1.00      1.00         5\n","         269       1.00      1.00      1.00        10\n","         270       1.00      1.00      1.00         6\n","         271       1.00      1.00      1.00         3\n","         272       0.00      0.00      0.00         4\n","         273       1.00      1.00      1.00         9\n","         274       1.00      1.00      1.00         5\n","         275       1.00      1.00      1.00         7\n","         276       0.43      1.00      0.60         3\n","         277       1.00      1.00      1.00         6\n","         278       1.00      1.00      1.00         4\n","         279       1.00      1.00      1.00         4\n","         280       1.00      1.00      1.00         6\n","         281       1.00      1.00      1.00        11\n","         282       0.19      1.00      0.32         5\n","         283       1.00      1.00      1.00         6\n","         284       1.00      1.00      1.00         2\n","         285       1.00      1.00      1.00         7\n","         286       1.00      1.00      1.00         9\n","         287       1.00      1.00      1.00         7\n","         288       1.00      1.00      1.00         5\n","         289       1.00      1.00      1.00         7\n","         290       1.00      1.00      1.00         6\n","         291       1.00      1.00      1.00         4\n","         292       1.00      1.00      1.00         7\n","         293       0.75      1.00      0.86         3\n","         294       1.00      1.00      1.00         6\n","         295       0.00      0.00      0.00         6\n","         296       1.00      1.00      1.00         8\n","         297       1.00      1.00      1.00         8\n","         298       1.00      1.00      1.00         4\n","         299       1.00      1.00      1.00         5\n","         300       1.00      1.00      1.00         2\n","         301       0.00      0.00      0.00         5\n","         302       1.00      1.00      1.00         8\n","         303       1.00      1.00      1.00         3\n","         304       1.00      1.00      1.00         5\n","         305       1.00      1.00      1.00         6\n","         306       1.00      1.00      1.00         4\n","         307       1.00      1.00      1.00         7\n","         308       0.00      0.00      0.00         9\n","         309       1.00      1.00      1.00         4\n","         310       1.00      1.00      1.00         6\n","         311       1.00      1.00      1.00         6\n","         312       1.00      1.00      1.00         3\n","         313       1.00      1.00      1.00         8\n","         314       1.00      1.00      1.00        10\n","         315       1.00      1.00      1.00         6\n","         316       1.00      1.00      1.00         4\n","         317       1.00      1.00      1.00         4\n","         318       1.00      1.00      1.00         2\n","         319       1.00      1.00      1.00         7\n","         320       0.89      1.00      0.94         8\n","         321       1.00      1.00      1.00         7\n","         322       1.00      1.00      1.00         6\n","         323       1.00      1.00      1.00         7\n","         324       1.00      1.00      1.00         4\n","         325       1.00      0.50      0.67         4\n","         326       1.00      1.00      1.00         8\n","         327       1.00      1.00      1.00         6\n","         328       1.00      1.00      1.00         4\n","         329       0.57      1.00      0.73         8\n","         330       1.00      1.00      1.00         1\n","         331       1.00      1.00      1.00         3\n","         332       1.00      1.00      1.00         3\n","         333       1.00      1.00      1.00         4\n","         334       0.00      0.00      0.00         6\n","         335       0.60      1.00      0.75         3\n","         336       1.00      1.00      1.00         6\n","         337       0.25      1.00      0.40         4\n","         338       1.00      1.00      1.00         2\n","         339       1.00      1.00      1.00         6\n","         340       1.00      1.00      1.00         4\n","         341       1.00      1.00      1.00         4\n","         342       1.00      1.00      1.00         7\n","         343       1.00      1.00      1.00         6\n","         344       1.00      1.00      1.00         4\n","         345       1.00      1.00      1.00         4\n","         346       1.00      1.00      1.00         5\n","         347       1.00      1.00      1.00         5\n","         348       1.00      1.00      1.00         4\n","         349       1.00      1.00      1.00         2\n","         350       1.00      1.00      1.00         3\n","         351       0.00      0.00      0.00         1\n","         352       1.00      1.00      1.00         2\n","         353       1.00      1.00      1.00         7\n","         354       1.00      1.00      1.00         7\n","         355       1.00      1.00      1.00         1\n","         356       1.00      1.00      1.00         3\n","         357       1.00      1.00      1.00         4\n","         358       0.00      0.00      0.00         3\n","         359       1.00      1.00      1.00         4\n","         360       1.00      1.00      1.00         1\n","         361       1.00      1.00      1.00         3\n","         363       1.00      1.00      1.00         1\n","         364       1.00      1.00      1.00         3\n","         365       0.00      0.00      0.00         2\n","         366       1.00      1.00      1.00         2\n","         367       1.00      1.00      1.00         2\n","         368       0.00      0.00      0.00         4\n","         369       0.00      0.00      0.00         3\n","         370       0.00      0.00      0.00         3\n","         371       1.00      0.33      0.50         3\n","         372       1.00      0.50      0.67         2\n","\n","    accuracy                           0.99     13567\n","   macro avg       0.94      0.94      0.94     13567\n","weighted avg       0.99      0.99      0.98     13567\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["#Select only the optimal number of input features for X_test\n","X_test = X_test[:,:(best_model_index+1)]\n","\n","X_test = X_test.reshape(13567, best_model_index+1, 1, 1)\n","\n","# Evaluate the best model on the test data\n","y_pred = best_model.predict(X_test)\n","\n","# np.argmax() is used to convert the one-hot encoded predictions and test labels to class labels.\n","y_pred_label = np.argmax(y_pred, axis = 1)\n","\n","# Print the classification report\n","print(\"Classification report:\\n\", classification_report(y_test_enc, y_pred_label))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"FeifaQpJmZ9u"},"outputs":[{"name":"stdout","output_type":"stream","text":["           OsID  True Class  Predicted Class  True/False\n","0  Os03g0179400         336              336        True\n","1  Os04g0659100         161              161        True\n","2  Os01g0686800          17               17        True\n","3  Os04g0107900          34               34        True\n","4  Os04g0517100           7                7        True\n"]}],"source":["# extract class labels from test data\n","class_test = y_test_enc\n","\n","# Invert OsID_labels dictionary\n","inv_OsID_labels = {v: k for k, v in OsID_labels.items()}\n","\n","# map OsID values to the class labels\n","OsID_test = [inv_OsID_labels.get(value, 'Unknown') for value in class_test]\n","\n","# create dataframe with OsID, true class, predicted class, and true/false columns\n","results = pd.DataFrame({\n","    'OsID': OsID_test,\n","    'True Class': y_test_enc,\n","    'Predicted Class': y_pred_label,\n","    'True/False': class_test == y_pred_label\n","})\n","\n","# display dataframe\n","print(results.head())\n","\n","# save results_df to a CSV file\n","results.to_csv('MLP_gene classification.csv', index=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"HcBceHUp0-TI"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>No of input features</th>\n","      <th>Model accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.045</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.068</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.099</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.454</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.732</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.900</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.926</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.883</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>0.952</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>0.971</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0.977</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>0.984</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0.974</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.977</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>0.976</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>0.975</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>0.987</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>0.978</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>0.987</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>0.974</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    No of input features  Model accuracy\n","0                      1           0.045\n","1                      2           0.068\n","2                      3           0.099\n","3                      4           0.454\n","4                      5           0.732\n","5                      6           0.900\n","6                      7           0.926\n","7                      8           0.883\n","8                      9           0.952\n","9                     10           0.971\n","10                    11           0.977\n","11                    12           0.984\n","12                    13           0.974\n","13                    14           0.977\n","14                    15           0.976\n","15                    16           0.975\n","16                    17           0.987\n","17                    18           0.978\n","18                    19           0.987\n","19                    20           0.974"]},"metadata":{},"output_type":"display_data"}],"source":["display(models_df)"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
