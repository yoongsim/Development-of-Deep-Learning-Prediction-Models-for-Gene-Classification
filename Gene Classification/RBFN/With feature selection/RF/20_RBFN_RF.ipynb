{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"G3AagWU9QsYg","executionInfo":{"status":"ok","timestamp":1682308907959,"user_tz":-480,"elapsed":6360,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd \n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","\n","from keras.models import Sequential\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","#for RBN\n","from keras.layers import Layer, Flatten, Dense\n","from keras import backend as K\n","from sklearn.metrics import classification_report\n","\n","\n","from sklearn.model_selection import StratifiedKFold\n","from keras import regularizers\n","from tensorflow.keras.utils import to_categorical\n"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"TAShwIegQsYj","executionInfo":{"status":"ok","timestamp":1682308907960,"user_tz":-480,"elapsed":30,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}}},"outputs":[],"source":["#fixed random seed for reproducibility \n","np.random.seed(0)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"GgUSY9c4QsYl","executionInfo":{"status":"ok","timestamp":1682309103689,"user_tz":-480,"elapsed":195754,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"a6c1eb66-8395-4df3-cebb-e2522379bae8"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["\n","     <input type=\"file\" id=\"files-7d9c2798-991a-43e6-b650-b670fcb6c6be\" name=\"files[]\" multiple disabled\n","        style=\"border:none\" />\n","     <output id=\"result-7d9c2798-991a-43e6-b650-b670fcb6c6be\">\n","      Upload widget is only available when the cell has been executed in the\n","      current browser session. Please rerun this cell to enable.\n","      </output>\n","      <script>// Copyright 2017 Google LLC\n","//\n","// Licensed under the Apache License, Version 2.0 (the \"License\");\n","// you may not use this file except in compliance with the License.\n","// You may obtain a copy of the License at\n","//\n","//      http://www.apache.org/licenses/LICENSE-2.0\n","//\n","// Unless required by applicable law or agreed to in writing, software\n","// distributed under the License is distributed on an \"AS IS\" BASIS,\n","// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n","// See the License for the specific language governing permissions and\n","// limitations under the License.\n","\n","/**\n"," * @fileoverview Helpers for google.colab Python module.\n"," */\n","(function(scope) {\n","function span(text, styleAttributes = {}) {\n","  const element = document.createElement('span');\n","  element.textContent = text;\n","  for (const key of Object.keys(styleAttributes)) {\n","    element.style[key] = styleAttributes[key];\n","  }\n","  return element;\n","}\n","\n","// Max number of bytes which will be uploaded at a time.\n","const MAX_PAYLOAD_SIZE = 100 * 1024;\n","\n","function _uploadFiles(inputId, outputId) {\n","  const steps = uploadFilesStep(inputId, outputId);\n","  const outputElement = document.getElementById(outputId);\n","  // Cache steps on the outputElement to make it available for the next call\n","  // to uploadFilesContinue from Python.\n","  outputElement.steps = steps;\n","\n","  return _uploadFilesContinue(outputId);\n","}\n","\n","// This is roughly an async generator (not supported in the browser yet),\n","// where there are multiple asynchronous steps and the Python side is going\n","// to poll for completion of each step.\n","// This uses a Promise to block the python side on completion of each step,\n","// then passes the result of the previous step as the input to the next step.\n","function _uploadFilesContinue(outputId) {\n","  const outputElement = document.getElementById(outputId);\n","  const steps = outputElement.steps;\n","\n","  const next = steps.next(outputElement.lastPromiseValue);\n","  return Promise.resolve(next.value.promise).then((value) => {\n","    // Cache the last promise value to make it available to the next\n","    // step of the generator.\n","    outputElement.lastPromiseValue = value;\n","    return next.value.response;\n","  });\n","}\n","\n","/**\n"," * Generator function which is called between each async step of the upload\n"," * process.\n"," * @param {string} inputId Element ID of the input file picker element.\n"," * @param {string} outputId Element ID of the output display.\n"," * @return {!Iterable<!Object>} Iterable of next steps.\n"," */\n","function* uploadFilesStep(inputId, outputId) {\n","  const inputElement = document.getElementById(inputId);\n","  inputElement.disabled = false;\n","\n","  const outputElement = document.getElementById(outputId);\n","  outputElement.innerHTML = '';\n","\n","  const pickedPromise = new Promise((resolve) => {\n","    inputElement.addEventListener('change', (e) => {\n","      resolve(e.target.files);\n","    });\n","  });\n","\n","  const cancel = document.createElement('button');\n","  inputElement.parentElement.appendChild(cancel);\n","  cancel.textContent = 'Cancel upload';\n","  const cancelPromise = new Promise((resolve) => {\n","    cancel.onclick = () => {\n","      resolve(null);\n","    };\n","  });\n","\n","  // Wait for the user to pick the files.\n","  const files = yield {\n","    promise: Promise.race([pickedPromise, cancelPromise]),\n","    response: {\n","      action: 'starting',\n","    }\n","  };\n","\n","  cancel.remove();\n","\n","  // Disable the input element since further picks are not allowed.\n","  inputElement.disabled = true;\n","\n","  if (!files) {\n","    return {\n","      response: {\n","        action: 'complete',\n","      }\n","    };\n","  }\n","\n","  for (const file of files) {\n","    const li = document.createElement('li');\n","    li.append(span(file.name, {fontWeight: 'bold'}));\n","    li.append(span(\n","        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n","        `last modified: ${\n","            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n","                                    'n/a'} - `));\n","    const percent = span('0% done');\n","    li.appendChild(percent);\n","\n","    outputElement.appendChild(li);\n","\n","    const fileDataPromise = new Promise((resolve) => {\n","      const reader = new FileReader();\n","      reader.onload = (e) => {\n","        resolve(e.target.result);\n","      };\n","      reader.readAsArrayBuffer(file);\n","    });\n","    // Wait for the data to be ready.\n","    let fileData = yield {\n","      promise: fileDataPromise,\n","      response: {\n","        action: 'continue',\n","      }\n","    };\n","\n","    // Use a chunked sending to avoid message size limits. See b/62115660.\n","    let position = 0;\n","    do {\n","      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n","      const chunk = new Uint8Array(fileData, position, length);\n","      position += length;\n","\n","      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n","      yield {\n","        response: {\n","          action: 'append',\n","          file: file.name,\n","          data: base64,\n","        },\n","      };\n","\n","      let percentDone = fileData.byteLength === 0 ?\n","          100 :\n","          Math.round((position / fileData.byteLength) * 100);\n","      percent.textContent = `${percentDone}% done`;\n","\n","    } while (position < fileData.byteLength);\n","  }\n","\n","  // All done.\n","  yield {\n","    response: {\n","      action: 'complete',\n","    }\n","  };\n","}\n","\n","scope.google = scope.google || {};\n","scope.google.colab = scope.google.colab || {};\n","scope.google.colab._files = {\n","  _uploadFiles,\n","  _uploadFilesContinue,\n","};\n","})(self);\n","</script> "]},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Saving TrainingData.csv to TrainingData.csv\n","Summary of dataGene:\n","        log_2FoldChange            ET  CoExpression           PCC  \\\n","count     41110.000000  41110.000000  41110.000000  41110.000000   \n","mean         -0.037332      1.407395      0.991997     -0.361737   \n","std           0.391444      0.784327      0.089101      0.463979   \n","min          -1.000000      0.000000      0.000000     -1.000000   \n","25%          -0.251534      1.000000      1.000000     -0.747963   \n","50%           0.030675      2.000000      1.000000     -0.449089   \n","75%           0.251534      2.000000      1.000000     -0.051646   \n","max           1.000000      2.000000      1.000000      1.000000   \n","\n","                PPI  Root10DaysSeedling  Root14DaysSeedling  \\\n","count  41110.000000        41110.000000        41110.000000   \n","mean       0.914668           -0.522040           -0.646982   \n","std        0.279379            0.498568            0.393549   \n","min        0.000000           -1.000000           -1.000000   \n","25%        1.000000           -0.901371           -0.965084   \n","50%        1.000000           -0.663664           -0.680003   \n","75%        1.000000           -0.378497           -0.559627   \n","max        1.000000            1.000000            1.000000   \n","\n","       Root17DaysSeedling  Root21DaysSeedling  Root24DaysSeedling  ...  \\\n","count        41110.000000        41110.000000        41110.000000  ...   \n","mean            -0.700869           -0.669349           -0.670048  ...   \n","std              0.378219            0.405860            0.390751  ...   \n","min             -1.000000           -1.000000           -1.000000  ...   \n","25%             -0.980226           -1.000000           -0.982003  ...   \n","50%             -0.795609           -0.726665           -0.708584  ...   \n","75%             -0.601266           -0.543621           -0.482133  ...   \n","max              1.000000            1.000000            1.000000  ...   \n","\n","       Root52DaysSeedling  Shoot3DaysSeedling  Shoot10DaysSeedling  \\\n","count        41110.000000        41110.000000         41110.000000   \n","mean            -0.670345           -0.590806            -0.545055   \n","std              0.478222            0.443552             0.477438   \n","min             -1.000000           -1.000000            -1.000000   \n","25%             -1.000000           -1.000000            -0.906055   \n","50%             -0.853382           -0.676286            -0.698864   \n","75%             -0.542371           -0.409775            -0.250588   \n","max              1.000000            0.955179             1.000000   \n","\n","       Shoot14DaysSeedling  Shoot17DaysSeedling  Shoot21DaysSeedling  \\\n","count         41110.000000         41110.000000         41110.000000   \n","mean             -0.734141            -0.680810            -0.659443   \n","std               0.413716             0.478189             0.463838   \n","min              -1.000000            -1.000000            -1.000000   \n","25%              -1.000000            -1.000000            -1.000000   \n","50%              -0.924976            -0.954040            -0.874080   \n","75%              -0.513759            -0.420386            -0.440577   \n","max               0.997390             1.000000             1.000000   \n","\n","       Shoot35DaysSeedling  Leaf21DaysSeedling  Leaf45DaysOldPlant  \\\n","count         41110.000000        41110.000000        41110.000000   \n","mean             -0.558906           -0.828778           -0.585144   \n","std               0.506423            0.327542            0.399046   \n","min              -1.000000           -1.000000           -1.000000   \n","25%              -0.962199           -1.000000           -0.901444   \n","50%              -0.699035           -0.951894           -0.643376   \n","75%              -0.352995           -0.883755           -0.451900   \n","max               0.993958            1.000000            1.000000   \n","\n","              class  \n","count  41110.000000  \n","mean      60.092703  \n","std       77.624892  \n","min        1.000000  \n","25%        9.000000  \n","50%       26.000000  \n","75%       78.000000  \n","max      373.000000  \n","\n","[8 rows x 21 columns]\n"]}],"source":["from google.colab import files\n","uploaded = files.upload()\n","\n","# load dataset (input variables = X, output variables = Y)\n","df = pd.read_csv(\"TrainingData.csv\")\n","\n","#count the number of occurances for each osID\n","OsID_counts = df['OsID'].value_counts()\n","\n","#filter for osIDs that have 10 or more occurances\n","OsID_counts_filtered = OsID_counts[OsID_counts >= 10]\n","\n","#assign a label for each osID \n","OsID_labels = {}\n","class_no = 1\n","for osID in OsID_counts_filtered.index:\n","    OsID_labels[osID] = class_no\n","    class_no +=1\n","\n","#filter the dataset with osID that contain 10 or more occurances\n","dataGene = df[df['OsID'].isin(OsID_counts_filtered.index)]\n","\n","dataGene = dataGene.drop(['Class', 'Trait'],axis=1)\n","\n","# Add a new column 'class' to the filtered dataset\n","dataGene['class'] = dataGene['OsID'].map(OsID_labels)\n","\n","print(\"Summary of dataGene:\\n\",dataGene.describe())\n"]},{"cell_type":"code","source":["X = dataGene.drop(['class','OsID'], axis=1) # exclude class & OsID column\n","Y = dataGene['class']\n","\n","#input feature names in order of descending importance scores in RF feature selection method\n","feature_names = ['Root10DaysSeedling', 'Leaf45DaysOldPlant', 'Shoot10DaysSeedling', 'Shoot35DaysSeedling', 'Root35DaysSeedling', \n","                 'Leaf21DaysSeedling', 'Root14DaysSeedling', 'Shoot3DaysSeedling', 'Root24DaysSeedling', 'Root52DaysSeedling', \n","                 'Root17DaysSeedling', 'Root21DaysSeedling', 'Shoot14DaysSeedling', 'Shoot21DaysSeedling', 'Shoot17DaysSeedling',\n","                  'ET', 'PCC', 'log_2FoldChange', 'PPI', 'CoExpression' ]\n","\n","X_fs = X.reindex(columns=feature_names)\n","\n","print(\"Shape of X:\\n\",X_fs.shape)\n","print(\"Shape of Y:\\n\",Y.shape)\n","\n","# Statistical summary of the variables\n","print(\"Summary of X:\\n\",X_fs.describe())\n","print(\"Summary of Y:\\n\",Y.describe())\n","\n","# Check for class imbalance\n","print(df.groupby(Y).size())\n","\n","# change both input and target variables datatype to ndarray\n","X_fs = X_fs.values # 2-D array\n","\n","# select target variable \n","\n","Y = Y.values #1-D array\n","Y = Y.reshape(-1, 1)"],"metadata":{"id":"ZQjM56LwvG4i","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682309103691,"user_tz":-480,"elapsed":94,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"437ce9a2-dba9-4f13-8185-e2fe1a87d3d4"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Shape of X:\n"," (41110, 20)\n","Shape of Y:\n"," (41110,)\n","Summary of X:\n","        Root10DaysSeedling  Leaf45DaysOldPlant  Shoot10DaysSeedling  \\\n","count        41110.000000        41110.000000         41110.000000   \n","mean            -0.522040           -0.585144            -0.545055   \n","std              0.498568            0.399046             0.477438   \n","min             -1.000000           -1.000000            -1.000000   \n","25%             -0.901371           -0.901444            -0.906055   \n","50%             -0.663664           -0.643376            -0.698864   \n","75%             -0.378497           -0.451900            -0.250588   \n","max              1.000000            1.000000             1.000000   \n","\n","       Shoot35DaysSeedling  Root35DaysSeedling  Leaf21DaysSeedling  \\\n","count         41110.000000        41110.000000        41110.000000   \n","mean             -0.558906           -0.596196           -0.828778   \n","std               0.506423            0.461679            0.327542   \n","min              -1.000000           -1.000000           -1.000000   \n","25%              -0.962199           -0.937286           -1.000000   \n","50%              -0.699035           -0.769184           -0.951894   \n","75%              -0.352995           -0.323664           -0.883755   \n","max               0.993958            1.000000            1.000000   \n","\n","       Root14DaysSeedling  Shoot3DaysSeedling  Root24DaysSeedling  \\\n","count        41110.000000        41110.000000        41110.000000   \n","mean            -0.646982           -0.590806           -0.670048   \n","std              0.393549            0.443552            0.390751   \n","min             -1.000000           -1.000000           -1.000000   \n","25%             -0.965084           -1.000000           -0.982003   \n","50%             -0.680003           -0.676286           -0.708584   \n","75%             -0.559627           -0.409775           -0.482133   \n","max              1.000000            0.955179            1.000000   \n","\n","       Root52DaysSeedling  Root17DaysSeedling  Root21DaysSeedling  \\\n","count        41110.000000        41110.000000        41110.000000   \n","mean            -0.670345           -0.700869           -0.669349   \n","std              0.478222            0.378219            0.405860   \n","min             -1.000000           -1.000000           -1.000000   \n","25%             -1.000000           -0.980226           -1.000000   \n","50%             -0.853382           -0.795609           -0.726665   \n","75%             -0.542371           -0.601266           -0.543621   \n","max              1.000000            1.000000            1.000000   \n","\n","       Shoot14DaysSeedling  Shoot21DaysSeedling  Shoot17DaysSeedling  \\\n","count         41110.000000         41110.000000         41110.000000   \n","mean             -0.734141            -0.659443            -0.680810   \n","std               0.413716             0.463838             0.478189   \n","min              -1.000000            -1.000000            -1.000000   \n","25%              -1.000000            -1.000000            -1.000000   \n","50%              -0.924976            -0.874080            -0.954040   \n","75%              -0.513759            -0.440577            -0.420386   \n","max               0.997390             1.000000             1.000000   \n","\n","                 ET           PCC  log_2FoldChange           PPI  CoExpression  \n","count  41110.000000  41110.000000     41110.000000  41110.000000  41110.000000  \n","mean       1.407395     -0.361737        -0.037332      0.914668      0.991997  \n","std        0.784327      0.463979         0.391444      0.279379      0.089101  \n","min        0.000000     -1.000000        -1.000000      0.000000      0.000000  \n","25%        1.000000     -0.747963        -0.251534      1.000000      1.000000  \n","50%        2.000000     -0.449089         0.030675      1.000000      1.000000  \n","75%        2.000000     -0.051646         0.251534      1.000000      1.000000  \n","max        2.000000      1.000000         1.000000      1.000000      1.000000  \n","Summary of Y:\n"," count    41110.000000\n","mean        60.092703\n","std         77.624892\n","min          1.000000\n","25%          9.000000\n","50%         26.000000\n","75%         78.000000\n","max        373.000000\n","Name: class, dtype: float64\n","class\n","1.0      1800\n","2.0      1296\n","3.0      1260\n","4.0      1218\n","5.0      1026\n","         ... \n","369.0      10\n","370.0      10\n","371.0      10\n","372.0      10\n","373.0      10\n","Length: 373, dtype: int64\n"]}]},{"cell_type":"code","source":["y_labelenc = LabelEncoder().fit_transform(Y)\n","\n","from collections import Counter\n","# summarize distribution\n","counter = Counter(y_labelenc)\n","\n","# sort counter by keys\n","counter = dict(sorted(counter.items()))\n","\n","\n","for k,v in counter.items():\n"," per = v / len(y_labelenc) * 100\n"," print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n","# plot the distribution\n","plt.bar( counter.keys(), counter.values())\n","\n","plt.ylabel('No of gene samples')\n","plt.xlabel('Class Index of OsID')\n","plt.title('Distribution of Target Classes (OsID)')\n","plt.show()"],"metadata":{"id":"F2UQyOKPvMXF","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1682309104708,"user_tz":-480,"elapsed":1075,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"f4765066-8975-4a2b-81c5-cd3de05e102b"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Class=0, n=1800 (4.378%)\n","Class=1, n=1296 (3.153%)\n","Class=2, n=1260 (3.065%)\n","Class=3, n=1218 (2.963%)\n","Class=4, n=1026 (2.496%)\n","Class=5, n=1008 (2.452%)\n","Class=6, n=930 (2.262%)\n","Class=7, n=912 (2.218%)\n","Class=8, n=880 (2.141%)\n","Class=9, n=798 (1.941%)\n","Class=10, n=792 (1.927%)\n","Class=11, n=759 (1.846%)\n","Class=12, n=729 (1.773%)\n","Class=13, n=720 (1.751%)\n","Class=14, n=702 (1.708%)\n","Class=15, n=693 (1.686%)\n","Class=16, n=672 (1.635%)\n","Class=17, n=640 (1.557%)\n","Class=18, n=625 (1.520%)\n","Class=19, n=570 (1.387%)\n","Class=20, n=546 (1.328%)\n","Class=21, n=506 (1.231%)\n","Class=22, n=483 (1.175%)\n","Class=23, n=448 (1.090%)\n","Class=24, n=432 (1.051%)\n","Class=25, n=384 (0.934%)\n","Class=26, n=360 (0.876%)\n","Class=27, n=360 (0.876%)\n","Class=28, n=320 (0.778%)\n","Class=29, n=312 (0.759%)\n","Class=30, n=312 (0.759%)\n","Class=31, n=306 (0.744%)\n","Class=32, n=304 (0.739%)\n","Class=33, n=299 (0.727%)\n","Class=34, n=297 (0.722%)\n","Class=35, n=296 (0.720%)\n","Class=36, n=280 (0.681%)\n","Class=37, n=264 (0.642%)\n","Class=38, n=260 (0.632%)\n","Class=39, n=253 (0.615%)\n","Class=40, n=252 (0.613%)\n","Class=41, n=248 (0.603%)\n","Class=42, n=242 (0.589%)\n","Class=43, n=228 (0.555%)\n","Class=44, n=216 (0.525%)\n","Class=45, n=210 (0.511%)\n","Class=46, n=200 (0.486%)\n","Class=47, n=192 (0.467%)\n","Class=48, n=180 (0.438%)\n","Class=49, n=171 (0.416%)\n","Class=50, n=168 (0.409%)\n","Class=51, n=168 (0.409%)\n","Class=52, n=162 (0.394%)\n","Class=53, n=150 (0.365%)\n","Class=54, n=148 (0.360%)\n","Class=55, n=138 (0.336%)\n","Class=56, n=135 (0.328%)\n","Class=57, n=135 (0.328%)\n","Class=58, n=133 (0.324%)\n","Class=59, n=132 (0.321%)\n","Class=60, n=132 (0.321%)\n","Class=61, n=130 (0.316%)\n","Class=62, n=130 (0.316%)\n","Class=63, n=130 (0.316%)\n","Class=64, n=128 (0.311%)\n","Class=65, n=128 (0.311%)\n","Class=66, n=126 (0.306%)\n","Class=67, n=124 (0.302%)\n","Class=68, n=124 (0.302%)\n","Class=69, n=124 (0.302%)\n","Class=70, n=120 (0.292%)\n","Class=71, n=120 (0.292%)\n","Class=72, n=118 (0.287%)\n","Class=73, n=116 (0.282%)\n","Class=74, n=114 (0.277%)\n","Class=75, n=105 (0.255%)\n","Class=76, n=104 (0.253%)\n","Class=77, n=102 (0.248%)\n","Class=78, n=99 (0.241%)\n","Class=79, n=98 (0.238%)\n","Class=80, n=98 (0.238%)\n","Class=81, n=98 (0.238%)\n","Class=82, n=98 (0.238%)\n","Class=83, n=96 (0.234%)\n","Class=84, n=96 (0.234%)\n","Class=85, n=96 (0.234%)\n","Class=86, n=93 (0.226%)\n","Class=87, n=92 (0.224%)\n","Class=88, n=92 (0.224%)\n","Class=89, n=91 (0.221%)\n","Class=90, n=88 (0.214%)\n","Class=91, n=88 (0.214%)\n","Class=92, n=86 (0.209%)\n","Class=93, n=86 (0.209%)\n","Class=94, n=84 (0.204%)\n","Class=95, n=84 (0.204%)\n","Class=96, n=84 (0.204%)\n","Class=97, n=78 (0.190%)\n","Class=98, n=78 (0.190%)\n","Class=99, n=76 (0.185%)\n","Class=100, n=75 (0.182%)\n","Class=101, n=75 (0.182%)\n","Class=102, n=73 (0.178%)\n","Class=103, n=72 (0.175%)\n","Class=104, n=72 (0.175%)\n","Class=105, n=70 (0.170%)\n","Class=106, n=69 (0.168%)\n","Class=107, n=68 (0.165%)\n","Class=108, n=67 (0.163%)\n","Class=109, n=66 (0.161%)\n","Class=110, n=66 (0.161%)\n","Class=111, n=66 (0.161%)\n","Class=112, n=66 (0.161%)\n","Class=113, n=66 (0.161%)\n","Class=114, n=65 (0.158%)\n","Class=115, n=64 (0.156%)\n","Class=116, n=63 (0.153%)\n","Class=117, n=63 (0.153%)\n","Class=118, n=62 (0.151%)\n","Class=119, n=61 (0.148%)\n","Class=120, n=60 (0.146%)\n","Class=121, n=60 (0.146%)\n","Class=122, n=60 (0.146%)\n","Class=123, n=60 (0.146%)\n","Class=124, n=60 (0.146%)\n","Class=125, n=60 (0.146%)\n","Class=126, n=60 (0.146%)\n","Class=127, n=60 (0.146%)\n","Class=128, n=60 (0.146%)\n","Class=129, n=60 (0.146%)\n","Class=130, n=59 (0.144%)\n","Class=131, n=59 (0.144%)\n","Class=132, n=58 (0.141%)\n","Class=133, n=56 (0.136%)\n","Class=134, n=56 (0.136%)\n","Class=135, n=56 (0.136%)\n","Class=136, n=56 (0.136%)\n","Class=137, n=56 (0.136%)\n","Class=138, n=56 (0.136%)\n","Class=139, n=56 (0.136%)\n","Class=140, n=56 (0.136%)\n","Class=141, n=56 (0.136%)\n","Class=142, n=55 (0.134%)\n","Class=143, n=55 (0.134%)\n","Class=144, n=54 (0.131%)\n","Class=145, n=54 (0.131%)\n","Class=146, n=54 (0.131%)\n","Class=147, n=54 (0.131%)\n","Class=148, n=54 (0.131%)\n","Class=149, n=53 (0.129%)\n","Class=150, n=52 (0.126%)\n","Class=151, n=52 (0.126%)\n","Class=152, n=52 (0.126%)\n","Class=153, n=52 (0.126%)\n","Class=154, n=50 (0.122%)\n","Class=155, n=50 (0.122%)\n","Class=156, n=49 (0.119%)\n","Class=157, n=49 (0.119%)\n","Class=158, n=48 (0.117%)\n","Class=159, n=48 (0.117%)\n","Class=160, n=48 (0.117%)\n","Class=161, n=46 (0.112%)\n","Class=162, n=45 (0.109%)\n","Class=163, n=44 (0.107%)\n","Class=164, n=44 (0.107%)\n","Class=165, n=44 (0.107%)\n","Class=166, n=42 (0.102%)\n","Class=167, n=42 (0.102%)\n","Class=168, n=42 (0.102%)\n","Class=169, n=42 (0.102%)\n","Class=170, n=42 (0.102%)\n","Class=171, n=42 (0.102%)\n","Class=172, n=42 (0.102%)\n","Class=173, n=41 (0.100%)\n","Class=174, n=41 (0.100%)\n","Class=175, n=40 (0.097%)\n","Class=176, n=40 (0.097%)\n","Class=177, n=39 (0.095%)\n","Class=178, n=39 (0.095%)\n","Class=179, n=38 (0.092%)\n","Class=180, n=37 (0.090%)\n","Class=181, n=36 (0.088%)\n","Class=182, n=35 (0.085%)\n","Class=183, n=35 (0.085%)\n","Class=184, n=35 (0.085%)\n","Class=185, n=35 (0.085%)\n","Class=186, n=34 (0.083%)\n","Class=187, n=34 (0.083%)\n","Class=188, n=34 (0.083%)\n","Class=189, n=34 (0.083%)\n","Class=190, n=32 (0.078%)\n","Class=191, n=32 (0.078%)\n","Class=192, n=32 (0.078%)\n","Class=193, n=32 (0.078%)\n","Class=194, n=32 (0.078%)\n","Class=195, n=32 (0.078%)\n","Class=196, n=31 (0.075%)\n","Class=197, n=31 (0.075%)\n","Class=198, n=31 (0.075%)\n","Class=199, n=31 (0.075%)\n","Class=200, n=30 (0.073%)\n","Class=201, n=30 (0.073%)\n","Class=202, n=30 (0.073%)\n","Class=203, n=30 (0.073%)\n","Class=204, n=30 (0.073%)\n","Class=205, n=30 (0.073%)\n","Class=206, n=30 (0.073%)\n","Class=207, n=30 (0.073%)\n","Class=208, n=30 (0.073%)\n","Class=209, n=29 (0.071%)\n","Class=210, n=29 (0.071%)\n","Class=211, n=28 (0.068%)\n","Class=212, n=28 (0.068%)\n","Class=213, n=28 (0.068%)\n","Class=214, n=28 (0.068%)\n","Class=215, n=28 (0.068%)\n","Class=216, n=28 (0.068%)\n","Class=217, n=27 (0.066%)\n","Class=218, n=27 (0.066%)\n","Class=219, n=27 (0.066%)\n","Class=220, n=27 (0.066%)\n","Class=221, n=27 (0.066%)\n","Class=222, n=27 (0.066%)\n","Class=223, n=26 (0.063%)\n","Class=224, n=26 (0.063%)\n","Class=225, n=26 (0.063%)\n","Class=226, n=26 (0.063%)\n","Class=227, n=26 (0.063%)\n","Class=228, n=25 (0.061%)\n","Class=229, n=25 (0.061%)\n","Class=230, n=25 (0.061%)\n","Class=231, n=25 (0.061%)\n","Class=232, n=24 (0.058%)\n","Class=233, n=24 (0.058%)\n","Class=234, n=24 (0.058%)\n","Class=235, n=24 (0.058%)\n","Class=236, n=24 (0.058%)\n","Class=237, n=24 (0.058%)\n","Class=238, n=24 (0.058%)\n","Class=239, n=24 (0.058%)\n","Class=240, n=24 (0.058%)\n","Class=241, n=24 (0.058%)\n","Class=242, n=24 (0.058%)\n","Class=243, n=24 (0.058%)\n","Class=244, n=23 (0.056%)\n","Class=245, n=23 (0.056%)\n","Class=246, n=22 (0.054%)\n","Class=247, n=22 (0.054%)\n","Class=248, n=22 (0.054%)\n","Class=249, n=22 (0.054%)\n","Class=250, n=22 (0.054%)\n","Class=251, n=22 (0.054%)\n","Class=252, n=22 (0.054%)\n","Class=253, n=22 (0.054%)\n","Class=254, n=22 (0.054%)\n","Class=255, n=22 (0.054%)\n","Class=256, n=22 (0.054%)\n","Class=257, n=22 (0.054%)\n","Class=258, n=22 (0.054%)\n","Class=259, n=22 (0.054%)\n","Class=260, n=22 (0.054%)\n","Class=261, n=22 (0.054%)\n","Class=262, n=22 (0.054%)\n","Class=263, n=22 (0.054%)\n","Class=264, n=21 (0.051%)\n","Class=265, n=21 (0.051%)\n","Class=266, n=21 (0.051%)\n","Class=267, n=21 (0.051%)\n","Class=268, n=21 (0.051%)\n","Class=269, n=20 (0.049%)\n","Class=270, n=20 (0.049%)\n","Class=271, n=20 (0.049%)\n","Class=272, n=20 (0.049%)\n","Class=273, n=20 (0.049%)\n","Class=274, n=20 (0.049%)\n","Class=275, n=20 (0.049%)\n","Class=276, n=20 (0.049%)\n","Class=277, n=20 (0.049%)\n","Class=278, n=20 (0.049%)\n","Class=279, n=20 (0.049%)\n","Class=280, n=19 (0.046%)\n","Class=281, n=19 (0.046%)\n","Class=282, n=19 (0.046%)\n","Class=283, n=18 (0.044%)\n","Class=284, n=18 (0.044%)\n","Class=285, n=18 (0.044%)\n","Class=286, n=18 (0.044%)\n","Class=287, n=18 (0.044%)\n","Class=288, n=18 (0.044%)\n","Class=289, n=18 (0.044%)\n","Class=290, n=18 (0.044%)\n","Class=291, n=18 (0.044%)\n","Class=292, n=17 (0.041%)\n","Class=293, n=17 (0.041%)\n","Class=294, n=17 (0.041%)\n","Class=295, n=17 (0.041%)\n","Class=296, n=17 (0.041%)\n","Class=297, n=17 (0.041%)\n","Class=298, n=16 (0.039%)\n","Class=299, n=16 (0.039%)\n","Class=300, n=16 (0.039%)\n","Class=301, n=16 (0.039%)\n","Class=302, n=16 (0.039%)\n","Class=303, n=16 (0.039%)\n","Class=304, n=16 (0.039%)\n","Class=305, n=16 (0.039%)\n","Class=306, n=15 (0.036%)\n","Class=307, n=15 (0.036%)\n","Class=308, n=15 (0.036%)\n","Class=309, n=15 (0.036%)\n","Class=310, n=15 (0.036%)\n","Class=311, n=14 (0.034%)\n","Class=312, n=14 (0.034%)\n","Class=313, n=14 (0.034%)\n","Class=314, n=14 (0.034%)\n","Class=315, n=14 (0.034%)\n","Class=316, n=14 (0.034%)\n","Class=317, n=14 (0.034%)\n","Class=318, n=14 (0.034%)\n","Class=319, n=14 (0.034%)\n","Class=320, n=14 (0.034%)\n","Class=321, n=14 (0.034%)\n","Class=322, n=14 (0.034%)\n","Class=323, n=14 (0.034%)\n","Class=324, n=14 (0.034%)\n","Class=325, n=14 (0.034%)\n","Class=326, n=14 (0.034%)\n","Class=327, n=14 (0.034%)\n","Class=328, n=13 (0.032%)\n","Class=329, n=13 (0.032%)\n","Class=330, n=13 (0.032%)\n","Class=331, n=13 (0.032%)\n","Class=332, n=13 (0.032%)\n","Class=333, n=13 (0.032%)\n","Class=334, n=13 (0.032%)\n","Class=335, n=13 (0.032%)\n","Class=336, n=13 (0.032%)\n","Class=337, n=12 (0.029%)\n","Class=338, n=12 (0.029%)\n","Class=339, n=12 (0.029%)\n","Class=340, n=12 (0.029%)\n","Class=341, n=12 (0.029%)\n","Class=342, n=12 (0.029%)\n","Class=343, n=12 (0.029%)\n","Class=344, n=12 (0.029%)\n","Class=345, n=12 (0.029%)\n","Class=346, n=12 (0.029%)\n","Class=347, n=12 (0.029%)\n","Class=348, n=12 (0.029%)\n","Class=349, n=12 (0.029%)\n","Class=350, n=12 (0.029%)\n","Class=351, n=12 (0.029%)\n","Class=352, n=12 (0.029%)\n","Class=353, n=12 (0.029%)\n","Class=354, n=12 (0.029%)\n","Class=355, n=11 (0.027%)\n","Class=356, n=11 (0.027%)\n","Class=357, n=11 (0.027%)\n","Class=358, n=11 (0.027%)\n","Class=359, n=11 (0.027%)\n","Class=360, n=11 (0.027%)\n","Class=361, n=10 (0.024%)\n","Class=362, n=10 (0.024%)\n","Class=363, n=10 (0.024%)\n","Class=364, n=10 (0.024%)\n","Class=365, n=10 (0.024%)\n","Class=366, n=10 (0.024%)\n","Class=367, n=10 (0.024%)\n","Class=368, n=10 (0.024%)\n","Class=369, n=10 (0.024%)\n","Class=370, n=10 (0.024%)\n","Class=371, n=10 (0.024%)\n","Class=372, n=10 (0.024%)\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 1 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"code","source":["# prepare target data\n","def prepare_targets(y_train, y_test):\n","\tle = LabelEncoder()\n","\t\n","\t#fit the encoders only to the training data and then transform both train and test data\n","\ty_train_enc = le.fit_transform(y_train)\n","\ty_test_enc = le.transform(y_test)\n","\n","\treturn y_train_enc, y_test_enc"],"metadata":{"id":"SyCZMH9wvSyC","executionInfo":{"status":"ok","timestamp":1682309104712,"user_tz":-480,"elapsed":50,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","execution_count":7,"metadata":{"id":"wZNqq1dZQsYs","executionInfo":{"status":"ok","timestamp":1682309104715,"user_tz":-480,"elapsed":50,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}}},"outputs":[],"source":["# define the RBFLayer layer as a custom layer\n","class RBFLayer(Layer):\n","    def __init__(self, units, gamma, **kwargs):\n","        super(RBFLayer, self).__init__(**kwargs)\n","        self.units = units\n","        self.gamma = K.cast_to_floatx(gamma)\n","\n","    def build(self, input_shape):\n","        self.mu = self.add_weight(name='mu',\n","                                  shape=(int(input_shape[1]), self.units),\n","                                  initializer='uniform',\n","                                  trainable=True)\n","        super(RBFLayer, self).build(input_shape)\n","\n","    def call(self, inputs):\n","        diff = K.expand_dims(inputs) - self.mu\n","        l2 = K.sum(K.pow(diff, 2), axis=1)\n","        res = K.exp(-1 * self.gamma * l2)\n","        return res\n","\n","    def compute_output_shape(self, input_shape):\n","        return (input_shape[0], self.units)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"0AqXG7_jQsYu","executionInfo":{"status":"ok","timestamp":1682309104716,"user_tz":-480,"elapsed":48,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}}},"outputs":[],"source":["# prepare target data\n","def prepare_targets(y_train, y_test):\n","\tle = LabelEncoder()\n","\t\n","\t#fit the encoders only to the training data and then transform both train and test data\n","\ty_train_enc = le.fit_transform(y_train)\n","\ty_test_enc = le.transform(y_test)\n","\n","\treturn y_train_enc, y_test_enc"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"Nh4EHT34QsYv","executionInfo":{"status":"ok","timestamp":1682309104718,"user_tz":-480,"elapsed":50,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}}},"outputs":[],"source":["# define baseline model (RBFN)\n","def RBFN_model(input_dim):\n","\n","    model = Sequential()\n","    model.add(Flatten(input_shape=(input_dim,)))\n","    #add the RBF layer\n","    model.add(RBFLayer(10, 0.5))\n","    \n","    model.add(Dense(60, input_dim=input_dim, activation='relu',bias_initializer='normal',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(20,bias_initializer='normal',activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(20,bias_initializer='normal',activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(373,kernel_initializer='normal',activation='softmax'))\n","\n","    # Compile model\n","    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","    \n","    return model"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"qGxBoDFmQsYw","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682309104718,"user_tz":-480,"elapsed":48,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"10c20959-b681-4055-e7bb-66bf7ed20941"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]}],"source":["# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_fs, Y, test_size=0.33, random_state=1)\n","\n","# prepare output data\n","y_train_enc, y_test_enc = prepare_targets(y_train, y_test)\n"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"21D3eb-NQsYx","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682314536772,"user_tz":-480,"elapsed":5432093,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"d24cf18e-e6cc-43a6-ec85-33d9abe7ad81"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["Number of input features: 1\n","Fold: 1\n","Epoch 1/20\n","1846/1846 [==============================] - 7s 3ms/step - loss: 5.0095 - accuracy: 0.0384 - val_loss: 4.9188 - val_accuracy: 0.0750\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 4.5064 - accuracy: 0.0936 - val_loss: 4.2589 - val_accuracy: 0.1259\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.9801 - accuracy: 0.1319 - val_loss: 3.9394 - val_accuracy: 0.1538\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.6590 - accuracy: 0.1709 - val_loss: 3.6618 - val_accuracy: 0.1916\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.3850 - accuracy: 0.2296 - val_loss: 3.4353 - val_accuracy: 0.2345\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.1642 - accuracy: 0.2543 - val_loss: 3.2860 - val_accuracy: 0.2284\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.9970 - accuracy: 0.2834 - val_loss: 3.1391 - val_accuracy: 0.2497\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.8576 - accuracy: 0.3137 - val_loss: 3.0287 - val_accuracy: 0.3263\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7413 - accuracy: 0.3459 - val_loss: 3.0062 - val_accuracy: 0.2884\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.6476 - accuracy: 0.3592 - val_loss: 2.8518 - val_accuracy: 0.3303\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.5614 - accuracy: 0.3729 - val_loss: 2.7773 - val_accuracy: 0.3996\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4898 - accuracy: 0.3829 - val_loss: 2.7369 - val_accuracy: 0.3600\n","Epoch 13/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4333 - accuracy: 0.3884 - val_loss: 2.6686 - val_accuracy: 0.3890\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3736 - accuracy: 0.3975 - val_loss: 2.6400 - val_accuracy: 0.3622\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 2.3397 - accuracy: 0.3984 - val_loss: 2.6132 - val_accuracy: 0.4073\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2978 - accuracy: 0.4107 - val_loss: 2.5499 - val_accuracy: 0.3846\n","Epoch 17/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 2.2507 - accuracy: 0.4153 - val_loss: 2.5330 - val_accuracy: 0.4473\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2359 - accuracy: 0.4124 - val_loss: 2.5293 - val_accuracy: 0.3826\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.1903 - accuracy: 0.4195 - val_loss: 2.4692 - val_accuracy: 0.4352\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1670 - accuracy: 0.4219 - val_loss: 2.4803 - val_accuracy: 0.4070\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 5.0156 - accuracy: 0.0414 - val_loss: 4.9387 - val_accuracy: 0.0768\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.5578 - accuracy: 0.0845 - val_loss: 4.3681 - val_accuracy: 0.1050\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 4.0464 - accuracy: 0.1273 - val_loss: 4.0581 - val_accuracy: 0.1611\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.7465 - accuracy: 0.1695 - val_loss: 3.8336 - val_accuracy: 0.1914\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.4959 - accuracy: 0.2054 - val_loss: 3.6382 - val_accuracy: 0.2299\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.2885 - accuracy: 0.2519 - val_loss: 3.4925 - val_accuracy: 0.2768\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.1204 - accuracy: 0.2728 - val_loss: 3.3512 - val_accuracy: 0.2752\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.9741 - accuracy: 0.2952 - val_loss: 3.2937 - val_accuracy: 0.2493\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.8519 - accuracy: 0.3177 - val_loss: 3.2355 - val_accuracy: 0.3395\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7516 - accuracy: 0.3338 - val_loss: 3.1096 - val_accuracy: 0.3690\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.6581 - accuracy: 0.3442 - val_loss: 3.0626 - val_accuracy: 0.3534\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5825 - accuracy: 0.3550 - val_loss: 2.9964 - val_accuracy: 0.3899\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.5211 - accuracy: 0.3657 - val_loss: 2.9325 - val_accuracy: 0.3534\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4677 - accuracy: 0.3723 - val_loss: 2.8892 - val_accuracy: 0.3635\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.4183 - accuracy: 0.3891 - val_loss: 2.8367 - val_accuracy: 0.3881\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3804 - accuracy: 0.3898 - val_loss: 2.8885 - val_accuracy: 0.3129\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.3420 - accuracy: 0.3989 - val_loss: 2.8112 - val_accuracy: 0.3811\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.3136 - accuracy: 0.4090 - val_loss: 2.7230 - val_accuracy: 0.3813\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.2851 - accuracy: 0.4092 - val_loss: 2.6969 - val_accuracy: 0.4051\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2611 - accuracy: 0.4138 - val_loss: 2.7620 - val_accuracy: 0.3595\n","Average Validation Accuracy: 0.3987573832273483\n","Average Validation Loss: 2.3409076929092407\n","Average Test Accuracy: 0.3992776572704315\n","Final Test Accuracy for each fold: 0.4232328534126282\n","Number of input features: 2\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.9557 - accuracy: 0.0477 - val_loss: 4.6096 - val_accuracy: 0.0708\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.2170 - accuracy: 0.1343 - val_loss: 4.0837 - val_accuracy: 0.1622\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.7248 - accuracy: 0.1874 - val_loss: 3.6460 - val_accuracy: 0.2279\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.3202 - accuracy: 0.2432 - val_loss: 3.3146 - val_accuracy: 0.2803\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.0129 - accuracy: 0.2753 - val_loss: 3.0768 - val_accuracy: 0.3230\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7905 - accuracy: 0.3105 - val_loss: 2.9221 - val_accuracy: 0.2933\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.5906 - accuracy: 0.3473 - val_loss: 2.7007 - val_accuracy: 0.3595\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4246 - accuracy: 0.3836 - val_loss: 2.5425 - val_accuracy: 0.4011\n","Epoch 9/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2253 - accuracy: 0.4413 - val_loss: 2.4149 - val_accuracy: 0.4046\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0364 - accuracy: 0.4871 - val_loss: 2.2202 - val_accuracy: 0.4737\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8765 - accuracy: 0.5214 - val_loss: 2.0096 - val_accuracy: 0.5267\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7277 - accuracy: 0.5516 - val_loss: 1.9106 - val_accuracy: 0.5586\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5965 - accuracy: 0.5843 - val_loss: 2.0843 - val_accuracy: 0.5028\n","Epoch 14/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4935 - accuracy: 0.6084 - val_loss: 1.7395 - val_accuracy: 0.5835\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3990 - accuracy: 0.6302 - val_loss: 1.6176 - val_accuracy: 0.6310\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3230 - accuracy: 0.6521 - val_loss: 1.5626 - val_accuracy: 0.6922\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2606 - accuracy: 0.6628 - val_loss: 1.4831 - val_accuracy: 0.7107\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2031 - accuracy: 0.6819 - val_loss: 1.4384 - val_accuracy: 0.6981\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1595 - accuracy: 0.6846 - val_loss: 1.4982 - val_accuracy: 0.6312\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1184 - accuracy: 0.6959 - val_loss: 1.3964 - val_accuracy: 0.6792\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 5.0018 - accuracy: 0.0425 - val_loss: 4.7524 - val_accuracy: 0.0939\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 4.2904 - accuracy: 0.1092 - val_loss: 4.1489 - val_accuracy: 0.1828\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.8274 - accuracy: 0.1833 - val_loss: 3.8366 - val_accuracy: 0.1978\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.4407 - accuracy: 0.2442 - val_loss: 3.5264 - val_accuracy: 0.2552\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0751 - accuracy: 0.3032 - val_loss: 3.1607 - val_accuracy: 0.3661\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.5972 - accuracy: 0.4019 - val_loss: 2.7016 - val_accuracy: 0.4471\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1271 - accuracy: 0.4903 - val_loss: 2.4032 - val_accuracy: 0.5485\n","Epoch 8/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8027 - accuracy: 0.5432 - val_loss: 2.0747 - val_accuracy: 0.5699\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5774 - accuracy: 0.5956 - val_loss: 1.9025 - val_accuracy: 0.6367\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4135 - accuracy: 0.6300 - val_loss: 1.8010 - val_accuracy: 0.6818\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2908 - accuracy: 0.6693 - val_loss: 1.6722 - val_accuracy: 0.6999\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2140 - accuracy: 0.6868 - val_loss: 1.6788 - val_accuracy: 0.7028\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1409 - accuracy: 0.7111 - val_loss: 1.5782 - val_accuracy: 0.7133\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0899 - accuracy: 0.7125 - val_loss: 1.5624 - val_accuracy: 0.7124\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0573 - accuracy: 0.7202 - val_loss: 1.6165 - val_accuracy: 0.6777\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0196 - accuracy: 0.7279 - val_loss: 1.4618 - val_accuracy: 0.7432\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9815 - accuracy: 0.7378 - val_loss: 1.4485 - val_accuracy: 0.7639\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9572 - accuracy: 0.7451 - val_loss: 1.4010 - val_accuracy: 0.7461\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9398 - accuracy: 0.7428 - val_loss: 1.4156 - val_accuracy: 0.7714\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9051 - accuracy: 0.7569 - val_loss: 1.5034 - val_accuracy: 0.7045\n","Average Validation Accuracy: 0.6981449723243713\n","Average Validation Loss: 1.1624149680137634\n","Average Test Accuracy: 0.6991228759288788\n","Final Test Accuracy for each fold: 0.7094420194625854\n","Number of input features: 3\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 6s 3ms/step - loss: 5.0224 - accuracy: 0.0422 - val_loss: 4.8012 - val_accuracy: 0.0964\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 4.3548 - accuracy: 0.1153 - val_loss: 4.1443 - val_accuracy: 0.2185\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.5828 - accuracy: 0.2912 - val_loss: 3.4102 - val_accuracy: 0.3316\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.9582 - accuracy: 0.3869 - val_loss: 2.9190 - val_accuracy: 0.4022\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5269 - accuracy: 0.4429 - val_loss: 2.5967 - val_accuracy: 0.4521\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.2165 - accuracy: 0.4937 - val_loss: 2.3214 - val_accuracy: 0.4966\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9670 - accuracy: 0.5330 - val_loss: 2.1517 - val_accuracy: 0.5483\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7730 - accuracy: 0.5649 - val_loss: 1.9871 - val_accuracy: 0.5987\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6306 - accuracy: 0.5994 - val_loss: 1.9113 - val_accuracy: 0.6022\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5257 - accuracy: 0.6175 - val_loss: 1.8131 - val_accuracy: 0.6229\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4462 - accuracy: 0.6278 - val_loss: 1.7693 - val_accuracy: 0.6277\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3701 - accuracy: 0.6497 - val_loss: 1.7502 - val_accuracy: 0.6257\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3150 - accuracy: 0.6526 - val_loss: 1.6353 - val_accuracy: 0.7107\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2594 - accuracy: 0.6684 - val_loss: 1.6344 - val_accuracy: 0.6561\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2241 - accuracy: 0.6689 - val_loss: 2.1205 - val_accuracy: 0.4858\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1743 - accuracy: 0.6830 - val_loss: 1.5358 - val_accuracy: 0.7019\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1434 - accuracy: 0.6897 - val_loss: 1.5356 - val_accuracy: 0.6823\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1096 - accuracy: 0.7021 - val_loss: 1.5065 - val_accuracy: 0.7168\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0991 - accuracy: 0.6984 - val_loss: 1.4395 - val_accuracy: 0.7076\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0637 - accuracy: 0.7154 - val_loss: 1.4469 - val_accuracy: 0.7406\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.9821 - accuracy: 0.0451 - val_loss: 4.5929 - val_accuracy: 0.0768\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.9488 - accuracy: 0.2062 - val_loss: 3.6086 - val_accuracy: 0.3635\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0550 - accuracy: 0.3623 - val_loss: 3.0057 - val_accuracy: 0.4229\n","Epoch 4/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.5026 - accuracy: 0.4511 - val_loss: 2.6168 - val_accuracy: 0.4988\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1178 - accuracy: 0.5248 - val_loss: 2.4201 - val_accuracy: 0.4893\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.8418 - accuracy: 0.5730 - val_loss: 2.2956 - val_accuracy: 0.5710\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6479 - accuracy: 0.6067 - val_loss: 2.0576 - val_accuracy: 0.6317\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5059 - accuracy: 0.6305 - val_loss: 2.0063 - val_accuracy: 0.6482\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3894 - accuracy: 0.6559 - val_loss: 2.1141 - val_accuracy: 0.5562\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3194 - accuracy: 0.6652 - val_loss: 1.7901 - val_accuracy: 0.6968\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2441 - accuracy: 0.6825 - val_loss: 1.7513 - val_accuracy: 0.7039\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2003 - accuracy: 0.6894 - val_loss: 1.7977 - val_accuracy: 0.6495\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1424 - accuracy: 0.6999 - val_loss: 1.8436 - val_accuracy: 0.5872\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1165 - accuracy: 0.6999 - val_loss: 1.6044 - val_accuracy: 0.7058\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0780 - accuracy: 0.7098 - val_loss: 1.5677 - val_accuracy: 0.7439\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0593 - accuracy: 0.7142 - val_loss: 1.5071 - val_accuracy: 0.7558\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0217 - accuracy: 0.7258 - val_loss: 1.5662 - val_accuracy: 0.7406\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0055 - accuracy: 0.7257 - val_loss: 1.5182 - val_accuracy: 0.7113\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9829 - accuracy: 0.7301 - val_loss: 1.4132 - val_accuracy: 0.7729\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9650 - accuracy: 0.7368 - val_loss: 1.5868 - val_accuracy: 0.6790\n","Average Validation Accuracy: 0.7242122292518616\n","Average Validation Loss: 1.1693590879440308\n","Average Test Accuracy: 0.721861869096756\n","Final Test Accuracy for each fold: 0.7497604489326477\n","Number of input features: 4\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 5.0414 - accuracy: 0.0437 - val_loss: 4.8577 - val_accuracy: 0.0647\n","Epoch 2/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 4.3978 - accuracy: 0.1086 - val_loss: 4.1149 - val_accuracy: 0.2150\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.4519 - accuracy: 0.3041 - val_loss: 3.1640 - val_accuracy: 0.3626\n","Epoch 4/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.6981 - accuracy: 0.4290 - val_loss: 2.6733 - val_accuracy: 0.4629\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2410 - accuracy: 0.5106 - val_loss: 2.3429 - val_accuracy: 0.5012\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9275 - accuracy: 0.5688 - val_loss: 2.1351 - val_accuracy: 0.5619\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6885 - accuracy: 0.6199 - val_loss: 1.9655 - val_accuracy: 0.6499\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5015 - accuracy: 0.6574 - val_loss: 1.8787 - val_accuracy: 0.6095\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3765 - accuracy: 0.6824 - val_loss: 1.7471 - val_accuracy: 0.6961\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 1.2814 - accuracy: 0.7011 - val_loss: 1.6655 - val_accuracy: 0.7142\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2041 - accuracy: 0.7145 - val_loss: 1.5991 - val_accuracy: 0.7028\n","Epoch 12/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.1412 - accuracy: 0.7241 - val_loss: 1.5300 - val_accuracy: 0.7201\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0867 - accuracy: 0.7327 - val_loss: 1.4952 - val_accuracy: 0.7270\n","Epoch 14/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0414 - accuracy: 0.7405 - val_loss: 1.4562 - val_accuracy: 0.7525\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0089 - accuracy: 0.7443 - val_loss: 1.3784 - val_accuracy: 0.7485\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9699 - accuracy: 0.7509 - val_loss: 1.3800 - val_accuracy: 0.7386\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9476 - accuracy: 0.7557 - val_loss: 1.3449 - val_accuracy: 0.7333\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9135 - accuracy: 0.7596 - val_loss: 1.4905 - val_accuracy: 0.6942\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8851 - accuracy: 0.7686 - val_loss: 1.2912 - val_accuracy: 0.7602\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8716 - accuracy: 0.7682 - val_loss: 1.2719 - val_accuracy: 0.7597\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 3ms/step - loss: 4.5934 - accuracy: 0.0882 - val_loss: 4.0875 - val_accuracy: 0.1573\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.4886 - accuracy: 0.2821 - val_loss: 3.2864 - val_accuracy: 0.3626\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6662 - accuracy: 0.4409 - val_loss: 2.6776 - val_accuracy: 0.5540\n","Epoch 4/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.0657 - accuracy: 0.5598 - val_loss: 2.3316 - val_accuracy: 0.5569\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6898 - accuracy: 0.6154 - val_loss: 2.0806 - val_accuracy: 0.6414\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4560 - accuracy: 0.6589 - val_loss: 2.0393 - val_accuracy: 0.5930\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3111 - accuracy: 0.6884 - val_loss: 1.8175 - val_accuracy: 0.7074\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2126 - accuracy: 0.7053 - val_loss: 1.7184 - val_accuracy: 0.6968\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1314 - accuracy: 0.7178 - val_loss: 1.6555 - val_accuracy: 0.7138\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0772 - accuracy: 0.7271 - val_loss: 1.5733 - val_accuracy: 0.7166\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0231 - accuracy: 0.7365 - val_loss: 1.5413 - val_accuracy: 0.7206\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9800 - accuracy: 0.7446 - val_loss: 1.3904 - val_accuracy: 0.7710\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9407 - accuracy: 0.7541 - val_loss: 1.4703 - val_accuracy: 0.6931\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9148 - accuracy: 0.7606 - val_loss: 1.3044 - val_accuracy: 0.7446\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8937 - accuracy: 0.7618 - val_loss: 1.3262 - val_accuracy: 0.7450\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8627 - accuracy: 0.7718 - val_loss: 1.2914 - val_accuracy: 0.7479\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8410 - accuracy: 0.7757 - val_loss: 1.3071 - val_accuracy: 0.7448\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8217 - accuracy: 0.7805 - val_loss: 1.3106 - val_accuracy: 0.7485\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8111 - accuracy: 0.7842 - val_loss: 1.1944 - val_accuracy: 0.7824\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8029 - accuracy: 0.7837 - val_loss: 1.1827 - val_accuracy: 0.7855\n","Average Validation Accuracy: 0.785354346036911\n","Average Validation Loss: 0.9335412681102753\n","Average Test Accuracy: 0.7823763787746429\n","Final Test Accuracy for each fold: 0.7961229681968689\n","Number of input features: 5\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.5714 - accuracy: 0.0913 - val_loss: 3.9889 - val_accuracy: 0.1622\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.3534 - accuracy: 0.3174 - val_loss: 3.0383 - val_accuracy: 0.4561\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4617 - accuracy: 0.4880 - val_loss: 2.3681 - val_accuracy: 0.5776\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8451 - accuracy: 0.5897 - val_loss: 1.9523 - val_accuracy: 0.6284\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4806 - accuracy: 0.6530 - val_loss: 1.7377 - val_accuracy: 0.6561\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2702 - accuracy: 0.6866 - val_loss: 1.6153 - val_accuracy: 0.6763\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1347 - accuracy: 0.7137 - val_loss: 1.4545 - val_accuracy: 0.7190\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0410 - accuracy: 0.7318 - val_loss: 1.3874 - val_accuracy: 0.7250\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9592 - accuracy: 0.7520 - val_loss: 1.2446 - val_accuracy: 0.7485\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9004 - accuracy: 0.7654 - val_loss: 1.2511 - val_accuracy: 0.7406\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8561 - accuracy: 0.7749 - val_loss: 1.2643 - val_accuracy: 0.7542\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8225 - accuracy: 0.7787 - val_loss: 1.0988 - val_accuracy: 0.7806\n","Epoch 13/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7902 - accuracy: 0.7885 - val_loss: 1.1132 - val_accuracy: 0.7782\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7644 - accuracy: 0.7924 - val_loss: 1.0653 - val_accuracy: 0.7813\n","Epoch 15/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.7461 - accuracy: 0.7963 - val_loss: 1.0344 - val_accuracy: 0.7831\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7235 - accuracy: 0.8023 - val_loss: 1.0668 - val_accuracy: 0.7875\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7105 - accuracy: 0.8072 - val_loss: 0.9637 - val_accuracy: 0.8097\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6889 - accuracy: 0.8075 - val_loss: 1.0036 - val_accuracy: 0.7670\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.6773 - accuracy: 0.8135 - val_loss: 0.9254 - val_accuracy: 0.8169\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6599 - accuracy: 0.8145 - val_loss: 0.9098 - val_accuracy: 0.8077\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.5792 - accuracy: 0.0831 - val_loss: 3.9963 - val_accuracy: 0.1265\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.3155 - accuracy: 0.3043 - val_loss: 3.0278 - val_accuracy: 0.4103\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4720 - accuracy: 0.4644 - val_loss: 2.5730 - val_accuracy: 0.5457\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9833 - accuracy: 0.5547 - val_loss: 2.2455 - val_accuracy: 0.5611\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6438 - accuracy: 0.6158 - val_loss: 2.0296 - val_accuracy: 0.6198\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4110 - accuracy: 0.6590 - val_loss: 1.8909 - val_accuracy: 0.6581\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2567 - accuracy: 0.6927 - val_loss: 1.7362 - val_accuracy: 0.6825\n","Epoch 8/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1432 - accuracy: 0.7130 - val_loss: 1.6484 - val_accuracy: 0.6570\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0636 - accuracy: 0.7247 - val_loss: 1.5353 - val_accuracy: 0.7465\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.9909 - accuracy: 0.7382 - val_loss: 1.4960 - val_accuracy: 0.7617\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9379 - accuracy: 0.7489 - val_loss: 1.4022 - val_accuracy: 0.7531\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8989 - accuracy: 0.7541 - val_loss: 1.3617 - val_accuracy: 0.7547\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8546 - accuracy: 0.7651 - val_loss: 1.3255 - val_accuracy: 0.7787\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8342 - accuracy: 0.7699 - val_loss: 1.3532 - val_accuracy: 0.7481\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7959 - accuracy: 0.7775 - val_loss: 1.2416 - val_accuracy: 0.7648\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7636 - accuracy: 0.7858 - val_loss: 1.2122 - val_accuracy: 0.7971\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7363 - accuracy: 0.7996 - val_loss: 1.2616 - val_accuracy: 0.7831\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7158 - accuracy: 0.8011 - val_loss: 1.1858 - val_accuracy: 0.7943\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6990 - accuracy: 0.8028 - val_loss: 1.0930 - val_accuracy: 0.8231\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6771 - accuracy: 0.8049 - val_loss: 1.1495 - val_accuracy: 0.7846\n","Average Validation Accuracy: 0.8121117949485779\n","Average Validation Loss: 0.7608534097671509\n","Average Test Accuracy: 0.8106066286563873\n","Final Test Accuracy for each fold: 0.8143289089202881\n","Number of input features: 6\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.7266 - accuracy: 0.0752 - val_loss: 4.1741 - val_accuracy: 0.1668\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.6731 - accuracy: 0.2617 - val_loss: 3.4550 - val_accuracy: 0.3899\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.9537 - accuracy: 0.4188 - val_loss: 2.8800 - val_accuracy: 0.4515\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4437 - accuracy: 0.4649 - val_loss: 2.5234 - val_accuracy: 0.4849\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0696 - accuracy: 0.5305 - val_loss: 2.2192 - val_accuracy: 0.5327\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7777 - accuracy: 0.5922 - val_loss: 1.9916 - val_accuracy: 0.6275\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5406 - accuracy: 0.6447 - val_loss: 1.8437 - val_accuracy: 0.6640\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3582 - accuracy: 0.6760 - val_loss: 1.7181 - val_accuracy: 0.6917\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2247 - accuracy: 0.7023 - val_loss: 1.6650 - val_accuracy: 0.6950\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1166 - accuracy: 0.7207 - val_loss: 1.5700 - val_accuracy: 0.7116\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0443 - accuracy: 0.7329 - val_loss: 1.5155 - val_accuracy: 0.7245\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9911 - accuracy: 0.7402 - val_loss: 1.4591 - val_accuracy: 0.7342\n","Epoch 13/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9423 - accuracy: 0.7493 - val_loss: 1.4274 - val_accuracy: 0.7144\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9066 - accuracy: 0.7572 - val_loss: 1.4034 - val_accuracy: 0.7399\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8686 - accuracy: 0.7644 - val_loss: 1.3492 - val_accuracy: 0.7441\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8596 - accuracy: 0.7647 - val_loss: 1.2965 - val_accuracy: 0.7745\n","Epoch 17/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8189 - accuracy: 0.7753 - val_loss: 1.2957 - val_accuracy: 0.7503\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8008 - accuracy: 0.7789 - val_loss: 1.2624 - val_accuracy: 0.7804\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7690 - accuracy: 0.7852 - val_loss: 1.3023 - val_accuracy: 0.7569\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7573 - accuracy: 0.7864 - val_loss: 1.2762 - val_accuracy: 0.7234\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.8949 - accuracy: 0.0551 - val_loss: 4.3733 - val_accuracy: 0.0827\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.7898 - accuracy: 0.2231 - val_loss: 3.6081 - val_accuracy: 0.3021\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.0552 - accuracy: 0.3951 - val_loss: 3.1407 - val_accuracy: 0.4304\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4830 - accuracy: 0.4921 - val_loss: 2.7046 - val_accuracy: 0.5175\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.0476 - accuracy: 0.5734 - val_loss: 2.4264 - val_accuracy: 0.5806\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7258 - accuracy: 0.6363 - val_loss: 2.1726 - val_accuracy: 0.6568\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4938 - accuracy: 0.6752 - val_loss: 2.1168 - val_accuracy: 0.6211\n","Epoch 8/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3303 - accuracy: 0.7024 - val_loss: 1.9490 - val_accuracy: 0.6836\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2053 - accuracy: 0.7219 - val_loss: 1.8324 - val_accuracy: 0.7166\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1036 - accuracy: 0.7399 - val_loss: 1.7993 - val_accuracy: 0.7479\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0242 - accuracy: 0.7555 - val_loss: 1.6976 - val_accuracy: 0.7406\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9568 - accuracy: 0.7715 - val_loss: 1.6237 - val_accuracy: 0.7712\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9114 - accuracy: 0.7792 - val_loss: 1.5771 - val_accuracy: 0.7844\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8569 - accuracy: 0.7927 - val_loss: 1.5422 - val_accuracy: 0.7745\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8210 - accuracy: 0.7981 - val_loss: 1.4985 - val_accuracy: 0.7897\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7857 - accuracy: 0.8021 - val_loss: 1.5029 - val_accuracy: 0.7965\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7535 - accuracy: 0.8123 - val_loss: 1.4107 - val_accuracy: 0.8068\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7297 - accuracy: 0.8153 - val_loss: 1.3801 - val_accuracy: 0.8110\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7051 - accuracy: 0.8180 - val_loss: 1.3699 - val_accuracy: 0.8163\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6827 - accuracy: 0.8225 - val_loss: 1.3807 - val_accuracy: 0.8178\n","Average Validation Accuracy: 0.7839394509792328\n","Average Validation Loss: 0.9084514677524567\n","Average Test Accuracy: 0.7804967761039734\n","Final Test Accuracy for each fold: 0.8246480226516724\n","Number of input features: 7\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 6s 3ms/step - loss: 4.4404 - accuracy: 0.0943 - val_loss: 3.9178 - val_accuracy: 0.1798\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.3625 - accuracy: 0.2985 - val_loss: 3.1337 - val_accuracy: 0.3916\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5803 - accuracy: 0.4672 - val_loss: 2.5578 - val_accuracy: 0.5173\n","Epoch 4/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.0219 - accuracy: 0.5683 - val_loss: 2.0842 - val_accuracy: 0.5848\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6197 - accuracy: 0.6432 - val_loss: 1.7876 - val_accuracy: 0.6609\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3541 - accuracy: 0.6886 - val_loss: 1.6161 - val_accuracy: 0.6865\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1862 - accuracy: 0.7181 - val_loss: 1.4977 - val_accuracy: 0.7184\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0710 - accuracy: 0.7327 - val_loss: 1.4056 - val_accuracy: 0.7146\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9827 - accuracy: 0.7503 - val_loss: 1.2873 - val_accuracy: 0.7534\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9028 - accuracy: 0.7702 - val_loss: 1.3049 - val_accuracy: 0.7635\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8551 - accuracy: 0.7774 - val_loss: 1.2503 - val_accuracy: 0.7674\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8112 - accuracy: 0.7830 - val_loss: 1.3467 - val_accuracy: 0.7529\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7764 - accuracy: 0.7923 - val_loss: 1.1603 - val_accuracy: 0.8004\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7427 - accuracy: 0.8057 - val_loss: 1.0929 - val_accuracy: 0.8044\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7249 - accuracy: 0.8082 - val_loss: 1.1511 - val_accuracy: 0.7751\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7063 - accuracy: 0.8096 - val_loss: 1.1106 - val_accuracy: 0.8064\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6786 - accuracy: 0.8158 - val_loss: 1.1966 - val_accuracy: 0.7949\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6614 - accuracy: 0.8157 - val_loss: 1.0533 - val_accuracy: 0.8108\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6480 - accuracy: 0.8229 - val_loss: 1.0899 - val_accuracy: 0.7927\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6233 - accuracy: 0.8289 - val_loss: 1.0490 - val_accuracy: 0.7934\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.7849 - accuracy: 0.0684 - val_loss: 4.1937 - val_accuracy: 0.1450\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.7055 - accuracy: 0.2080 - val_loss: 3.5374 - val_accuracy: 0.2537\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.9822 - accuracy: 0.3996 - val_loss: 2.9814 - val_accuracy: 0.4594\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3403 - accuracy: 0.5127 - val_loss: 2.5558 - val_accuracy: 0.5377\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.8885 - accuracy: 0.5806 - val_loss: 2.2715 - val_accuracy: 0.6020\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5970 - accuracy: 0.6365 - val_loss: 2.1095 - val_accuracy: 0.6497\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3977 - accuracy: 0.6710 - val_loss: 1.9873 - val_accuracy: 0.6867\n","Epoch 8/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2503 - accuracy: 0.6941 - val_loss: 1.9092 - val_accuracy: 0.6953\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1432 - accuracy: 0.7181 - val_loss: 1.8249 - val_accuracy: 0.7168\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0658 - accuracy: 0.7318 - val_loss: 1.8023 - val_accuracy: 0.7058\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9962 - accuracy: 0.7452 - val_loss: 1.6844 - val_accuracy: 0.7461\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9364 - accuracy: 0.7565 - val_loss: 1.6409 - val_accuracy: 0.7382\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9009 - accuracy: 0.7673 - val_loss: 1.6082 - val_accuracy: 0.7560\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8620 - accuracy: 0.7736 - val_loss: 1.5350 - val_accuracy: 0.7765\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8218 - accuracy: 0.7837 - val_loss: 1.6362 - val_accuracy: 0.7274\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7992 - accuracy: 0.7866 - val_loss: 1.4871 - val_accuracy: 0.7872\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7804 - accuracy: 0.7954 - val_loss: 1.4159 - val_accuracy: 0.8075\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7540 - accuracy: 0.8016 - val_loss: 1.4508 - val_accuracy: 0.7872\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7188 - accuracy: 0.8125 - val_loss: 1.4150 - val_accuracy: 0.8057\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7059 - accuracy: 0.8124 - val_loss: 1.3990 - val_accuracy: 0.8114\n","Average Validation Accuracy: 0.8148351311683655\n","Average Validation Loss: 0.8386180400848389\n","Average Test Accuracy: 0.8135918080806732\n","Final Test Accuracy for each fold: 0.8170561194419861\n","Number of input features: 8\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 3ms/step - loss: 4.5591 - accuracy: 0.0791 - val_loss: 4.0902 - val_accuracy: 0.0911\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.6090 - accuracy: 0.2084 - val_loss: 3.4065 - val_accuracy: 0.2821\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.8526 - accuracy: 0.4295 - val_loss: 2.7620 - val_accuracy: 0.4717\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2406 - accuracy: 0.5499 - val_loss: 2.2903 - val_accuracy: 0.5721\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.8055 - accuracy: 0.6191 - val_loss: 1.9752 - val_accuracy: 0.6400\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5241 - accuracy: 0.6624 - val_loss: 1.7738 - val_accuracy: 0.6499\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3389 - accuracy: 0.6878 - val_loss: 1.6041 - val_accuracy: 0.6807\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1912 - accuracy: 0.7142 - val_loss: 1.4666 - val_accuracy: 0.7058\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0811 - accuracy: 0.7370 - val_loss: 1.4392 - val_accuracy: 0.7201\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0027 - accuracy: 0.7503 - val_loss: 1.3309 - val_accuracy: 0.7406\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9497 - accuracy: 0.7556 - val_loss: 1.2611 - val_accuracy: 0.7716\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8945 - accuracy: 0.7688 - val_loss: 1.2441 - val_accuracy: 0.7666\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8538 - accuracy: 0.7775 - val_loss: 1.1870 - val_accuracy: 0.7765\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8160 - accuracy: 0.7867 - val_loss: 1.1793 - val_accuracy: 0.7608\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7894 - accuracy: 0.7909 - val_loss: 1.0993 - val_accuracy: 0.7969\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7488 - accuracy: 0.8014 - val_loss: 1.1763 - val_accuracy: 0.7663\n","Epoch 17/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7414 - accuracy: 0.8027 - val_loss: 1.1504 - val_accuracy: 0.7692\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.7190 - accuracy: 0.8091 - val_loss: 1.0923 - val_accuracy: 0.7927\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6805 - accuracy: 0.8168 - val_loss: 1.0508 - val_accuracy: 0.7985\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6785 - accuracy: 0.8167 - val_loss: 0.9957 - val_accuracy: 0.8121\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.5772 - accuracy: 0.0833 - val_loss: 4.0398 - val_accuracy: 0.1914\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.4515 - accuracy: 0.3149 - val_loss: 3.3168 - val_accuracy: 0.4024\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.7118 - accuracy: 0.4606 - val_loss: 2.8403 - val_accuracy: 0.5056\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1859 - accuracy: 0.5385 - val_loss: 2.4656 - val_accuracy: 0.5980\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8178 - accuracy: 0.6161 - val_loss: 2.2405 - val_accuracy: 0.6326\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5667 - accuracy: 0.6444 - val_loss: 2.1643 - val_accuracy: 0.6143\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3875 - accuracy: 0.6701 - val_loss: 1.9596 - val_accuracy: 0.6451\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2664 - accuracy: 0.6941 - val_loss: 1.8555 - val_accuracy: 0.6860\n","Epoch 9/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1607 - accuracy: 0.7137 - val_loss: 1.8277 - val_accuracy: 0.6909\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0804 - accuracy: 0.7322 - val_loss: 1.6825 - val_accuracy: 0.7439\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0212 - accuracy: 0.7403 - val_loss: 1.6649 - val_accuracy: 0.7221\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9724 - accuracy: 0.7502 - val_loss: 1.6437 - val_accuracy: 0.7223\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9301 - accuracy: 0.7578 - val_loss: 1.5570 - val_accuracy: 0.7586\n","Epoch 14/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8998 - accuracy: 0.7641 - val_loss: 1.4662 - val_accuracy: 0.7765\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8585 - accuracy: 0.7721 - val_loss: 1.6353 - val_accuracy: 0.7008\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8321 - accuracy: 0.7751 - val_loss: 1.4260 - val_accuracy: 0.7683\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8164 - accuracy: 0.7801 - val_loss: 1.3645 - val_accuracy: 0.7800\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7963 - accuracy: 0.7823 - val_loss: 1.3800 - val_accuracy: 0.7569\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7694 - accuracy: 0.7927 - val_loss: 1.3259 - val_accuracy: 0.7923\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7590 - accuracy: 0.7921 - val_loss: 1.3474 - val_accuracy: 0.7606\n","Average Validation Accuracy: 0.8013279139995575\n","Average Validation Loss: 0.8384221792221069\n","Average Test Accuracy: 0.8015404939651489\n","Final Test Accuracy for each fold: 0.8267855644226074\n","Number of input features: 9\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.5340 - accuracy: 0.0823 - val_loss: 4.0374 - val_accuracy: 0.0961\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.4985 - accuracy: 0.2235 - val_loss: 3.2366 - val_accuracy: 0.3558\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.6721 - accuracy: 0.4570 - val_loss: 2.5488 - val_accuracy: 0.5272\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0574 - accuracy: 0.5700 - val_loss: 2.1081 - val_accuracy: 0.5967\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.6312 - accuracy: 0.6396 - val_loss: 1.7831 - val_accuracy: 0.6284\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3548 - accuracy: 0.6878 - val_loss: 1.5780 - val_accuracy: 0.6876\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1670 - accuracy: 0.7181 - val_loss: 1.4440 - val_accuracy: 0.7298\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0307 - accuracy: 0.7432 - val_loss: 1.3237 - val_accuracy: 0.7391\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9217 - accuracy: 0.7686 - val_loss: 1.2313 - val_accuracy: 0.7589\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8578 - accuracy: 0.7805 - val_loss: 1.1701 - val_accuracy: 0.7842\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7877 - accuracy: 0.7948 - val_loss: 1.1086 - val_accuracy: 0.8046\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7496 - accuracy: 0.8023 - val_loss: 1.1508 - val_accuracy: 0.7661\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7028 - accuracy: 0.8144 - val_loss: 1.0288 - val_accuracy: 0.8255\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6670 - accuracy: 0.8216 - val_loss: 1.0160 - val_accuracy: 0.8337\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6472 - accuracy: 0.8246 - val_loss: 0.9903 - val_accuracy: 0.8194\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6341 - accuracy: 0.8290 - val_loss: 0.9780 - val_accuracy: 0.8066\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5990 - accuracy: 0.8392 - val_loss: 0.9662 - val_accuracy: 0.8334\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5896 - accuracy: 0.8388 - val_loss: 0.9539 - val_accuracy: 0.8246\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5754 - accuracy: 0.8459 - val_loss: 0.9669 - val_accuracy: 0.8356\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5543 - accuracy: 0.8518 - val_loss: 0.9329 - val_accuracy: 0.8249\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.5641 - accuracy: 0.0918 - val_loss: 3.9178 - val_accuracy: 0.2425\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.3104 - accuracy: 0.3076 - val_loss: 3.2116 - val_accuracy: 0.3989\n","Epoch 3/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 2.5869 - accuracy: 0.4720 - val_loss: 2.7457 - val_accuracy: 0.4891\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1063 - accuracy: 0.5406 - val_loss: 2.4532 - val_accuracy: 0.5646\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7852 - accuracy: 0.6025 - val_loss: 2.2315 - val_accuracy: 0.5791\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5678 - accuracy: 0.6415 - val_loss: 2.0467 - val_accuracy: 0.6570\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3983 - accuracy: 0.6728 - val_loss: 1.9062 - val_accuracy: 0.6990\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2568 - accuracy: 0.7000 - val_loss: 1.7968 - val_accuracy: 0.6946\n","Epoch 9/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 1.1466 - accuracy: 0.7210 - val_loss: 1.7320 - val_accuracy: 0.7091\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0656 - accuracy: 0.7374 - val_loss: 1.6259 - val_accuracy: 0.7490\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9958 - accuracy: 0.7507 - val_loss: 1.5821 - val_accuracy: 0.7556\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9408 - accuracy: 0.7619 - val_loss: 1.4990 - val_accuracy: 0.7688\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8895 - accuracy: 0.7754 - val_loss: 1.4528 - val_accuracy: 0.7589\n","Epoch 14/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8503 - accuracy: 0.7800 - val_loss: 1.4182 - val_accuracy: 0.7547\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8080 - accuracy: 0.7904 - val_loss: 1.4064 - val_accuracy: 0.7657\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7813 - accuracy: 0.7960 - val_loss: 1.3269 - val_accuracy: 0.7861\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7555 - accuracy: 0.8031 - val_loss: 1.2889 - val_accuracy: 0.7980\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7265 - accuracy: 0.8077 - val_loss: 1.2150 - val_accuracy: 0.8224\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7023 - accuracy: 0.8134 - val_loss: 1.1961 - val_accuracy: 0.8136\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6840 - accuracy: 0.8172 - val_loss: 1.1740 - val_accuracy: 0.8128\n","Average Validation Accuracy: 0.8352029621601105\n","Average Validation Loss: 0.7332477271556854\n","Average Test Accuracy: 0.8310975134372711\n","Final Test Accuracy for each fold: 0.8354831337928772\n","Number of input features: 10\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.4996 - accuracy: 0.0901 - val_loss: 4.0119 - val_accuracy: 0.1666\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.5000 - accuracy: 0.2313 - val_loss: 3.1777 - val_accuracy: 0.3410\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.5476 - accuracy: 0.4661 - val_loss: 2.4100 - val_accuracy: 0.5470\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9491 - accuracy: 0.5761 - val_loss: 1.9603 - val_accuracy: 0.6284\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5604 - accuracy: 0.6440 - val_loss: 1.7157 - val_accuracy: 0.6651\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3124 - accuracy: 0.6890 - val_loss: 1.5056 - val_accuracy: 0.6911\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1378 - accuracy: 0.7241 - val_loss: 1.4391 - val_accuracy: 0.7056\n","Epoch 8/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0062 - accuracy: 0.7582 - val_loss: 1.3078 - val_accuracy: 0.7573\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9289 - accuracy: 0.7693 - val_loss: 1.2424 - val_accuracy: 0.7527\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8572 - accuracy: 0.7821 - val_loss: 1.2552 - val_accuracy: 0.7459\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8057 - accuracy: 0.7941 - val_loss: 1.1916 - val_accuracy: 0.7637\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7728 - accuracy: 0.7958 - val_loss: 1.0969 - val_accuracy: 0.7868\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7286 - accuracy: 0.8101 - val_loss: 1.1042 - val_accuracy: 0.7956\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6999 - accuracy: 0.8187 - val_loss: 1.0609 - val_accuracy: 0.8015\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6754 - accuracy: 0.8242 - val_loss: 1.0291 - val_accuracy: 0.8200\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6575 - accuracy: 0.8263 - val_loss: 1.0554 - val_accuracy: 0.7932\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6329 - accuracy: 0.8334 - val_loss: 0.9898 - val_accuracy: 0.8246\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6138 - accuracy: 0.8410 - val_loss: 0.9623 - val_accuracy: 0.8249\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6000 - accuracy: 0.8369 - val_loss: 0.9632 - val_accuracy: 0.8315\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5872 - accuracy: 0.8459 - val_loss: 1.0781 - val_accuracy: 0.8013\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.5100 - accuracy: 0.0890 - val_loss: 4.0978 - val_accuracy: 0.2216\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.6418 - accuracy: 0.1913 - val_loss: 3.5278 - val_accuracy: 0.2464\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.8986 - accuracy: 0.3762 - val_loss: 2.8036 - val_accuracy: 0.4724\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 2.2103 - accuracy: 0.5034 - val_loss: 2.4042 - val_accuracy: 0.5404\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.7564 - accuracy: 0.5990 - val_loss: 2.0779 - val_accuracy: 0.5837\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4618 - accuracy: 0.6588 - val_loss: 1.8862 - val_accuracy: 0.6473\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2625 - accuracy: 0.6931 - val_loss: 1.7000 - val_accuracy: 0.6966\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1051 - accuracy: 0.7312 - val_loss: 1.5765 - val_accuracy: 0.7613\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9876 - accuracy: 0.7598 - val_loss: 1.5097 - val_accuracy: 0.7536\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9087 - accuracy: 0.7776 - val_loss: 1.4497 - val_accuracy: 0.7655\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8365 - accuracy: 0.7921 - val_loss: 1.4508 - val_accuracy: 0.7644\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7838 - accuracy: 0.8007 - val_loss: 1.3961 - val_accuracy: 0.7976\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7570 - accuracy: 0.7993 - val_loss: 1.3452 - val_accuracy: 0.7822\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7055 - accuracy: 0.8146 - val_loss: 1.2813 - val_accuracy: 0.7952\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6726 - accuracy: 0.8245 - val_loss: 1.1956 - val_accuracy: 0.8152\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6464 - accuracy: 0.8290 - val_loss: 1.1886 - val_accuracy: 0.8365\n","Epoch 17/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6244 - accuracy: 0.8355 - val_loss: 1.1641 - val_accuracy: 0.8438\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6015 - accuracy: 0.8404 - val_loss: 1.1336 - val_accuracy: 0.8352\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5843 - accuracy: 0.8429 - val_loss: 1.1126 - val_accuracy: 0.8473\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5716 - accuracy: 0.8479 - val_loss: 1.0730 - val_accuracy: 0.8605\n","Average Validation Accuracy: 0.842646986246109\n","Average Validation Loss: 0.7454123198986053\n","Average Test Accuracy: 0.8383578062057495\n","Final Test Accuracy for each fold: 0.861797034740448\n","Number of input features: 11\n","Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1846/1846 [==============================] - 7s 3ms/step - loss: 4.5513 - accuracy: 0.0736 - val_loss: 4.1303 - val_accuracy: 0.1118\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.5771 - accuracy: 0.2240 - val_loss: 3.2999 - val_accuracy: 0.3322\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7007 - accuracy: 0.4265 - val_loss: 2.5251 - val_accuracy: 0.4827\n","Epoch 4/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.9814 - accuracy: 0.5534 - val_loss: 1.9930 - val_accuracy: 0.6024\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5255 - accuracy: 0.6423 - val_loss: 1.6759 - val_accuracy: 0.6684\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2338 - accuracy: 0.7016 - val_loss: 1.5216 - val_accuracy: 0.6845\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0536 - accuracy: 0.7348 - val_loss: 1.3495 - val_accuracy: 0.7417\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9474 - accuracy: 0.7583 - val_loss: 1.2450 - val_accuracy: 0.7498\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8637 - accuracy: 0.7770 - val_loss: 1.1463 - val_accuracy: 0.7826\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8123 - accuracy: 0.7834 - val_loss: 1.0949 - val_accuracy: 0.7762\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7512 - accuracy: 0.7982 - val_loss: 1.1087 - val_accuracy: 0.7655\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7223 - accuracy: 0.8020 - val_loss: 1.0314 - val_accuracy: 0.7793\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6856 - accuracy: 0.8085 - val_loss: 0.9784 - val_accuracy: 0.8117\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6586 - accuracy: 0.8154 - val_loss: 0.9622 - val_accuracy: 0.7892\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6324 - accuracy: 0.8232 - val_loss: 0.9500 - val_accuracy: 0.8070\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6135 - accuracy: 0.8294 - val_loss: 0.8676 - val_accuracy: 0.8407\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6012 - accuracy: 0.8319 - val_loss: 0.9097 - val_accuracy: 0.8343\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5779 - accuracy: 0.8367 - val_loss: 0.9257 - val_accuracy: 0.8048\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5698 - accuracy: 0.8388 - val_loss: 0.8553 - val_accuracy: 0.8352\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5586 - accuracy: 0.8408 - val_loss: 0.8632 - val_accuracy: 0.8361\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 3ms/step - loss: 4.5304 - accuracy: 0.0818 - val_loss: 4.1060 - val_accuracy: 0.1452\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.6384 - accuracy: 0.1893 - val_loss: 3.5044 - val_accuracy: 0.2759\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 2.9635 - accuracy: 0.3477 - val_loss: 2.8353 - val_accuracy: 0.4475\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3276 - accuracy: 0.4808 - val_loss: 2.3843 - val_accuracy: 0.5109\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8404 - accuracy: 0.5771 - val_loss: 1.9935 - val_accuracy: 0.5980\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4546 - accuracy: 0.6610 - val_loss: 1.7152 - val_accuracy: 0.6961\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2013 - accuracy: 0.7082 - val_loss: 1.5770 - val_accuracy: 0.7184\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0497 - accuracy: 0.7353 - val_loss: 1.4551 - val_accuracy: 0.7448\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9476 - accuracy: 0.7606 - val_loss: 1.3763 - val_accuracy: 0.7606\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8698 - accuracy: 0.7760 - val_loss: 1.2488 - val_accuracy: 0.7679\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8098 - accuracy: 0.7864 - val_loss: 1.2802 - val_accuracy: 0.7740\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7689 - accuracy: 0.7951 - val_loss: 1.1964 - val_accuracy: 0.7982\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7257 - accuracy: 0.8054 - val_loss: 1.2266 - val_accuracy: 0.7971\n","Epoch 14/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6929 - accuracy: 0.8140 - val_loss: 1.1557 - val_accuracy: 0.7993\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6711 - accuracy: 0.8175 - val_loss: 1.1866 - val_accuracy: 0.8000\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6474 - accuracy: 0.8266 - val_loss: 1.1058 - val_accuracy: 0.8295\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6227 - accuracy: 0.8304 - val_loss: 1.1122 - val_accuracy: 0.8130\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6106 - accuracy: 0.8352 - val_loss: 1.0722 - val_accuracy: 0.8416\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5951 - accuracy: 0.8383 - val_loss: 1.0370 - val_accuracy: 0.8387\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5729 - accuracy: 0.8434 - val_loss: 1.0732 - val_accuracy: 0.8352\n","Average Validation Accuracy: 0.8499436676502228\n","Average Validation Loss: 0.671658843755722\n","Average Test Accuracy: 0.8471290469169617\n","Final Test Accuracy for each fold: 0.8477187156677246\n","Number of input features: 12\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.5405 - accuracy: 0.0768 - val_loss: 4.0733 - val_accuracy: 0.1111\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.5051 - accuracy: 0.2498 - val_loss: 3.1901 - val_accuracy: 0.4134\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5954 - accuracy: 0.4588 - val_loss: 2.5038 - val_accuracy: 0.5107\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9687 - accuracy: 0.5751 - val_loss: 2.0782 - val_accuracy: 0.6304\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5792 - accuracy: 0.6497 - val_loss: 1.7415 - val_accuracy: 0.6585\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3337 - accuracy: 0.6904 - val_loss: 1.5871 - val_accuracy: 0.6937\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1645 - accuracy: 0.7273 - val_loss: 1.4401 - val_accuracy: 0.7305\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0449 - accuracy: 0.7514 - val_loss: 1.3554 - val_accuracy: 0.7446\n","Epoch 9/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9583 - accuracy: 0.7645 - val_loss: 1.2510 - val_accuracy: 0.7820\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8822 - accuracy: 0.7822 - val_loss: 1.2323 - val_accuracy: 0.7883\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8285 - accuracy: 0.7930 - val_loss: 1.1437 - val_accuracy: 0.7987\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7816 - accuracy: 0.8021 - val_loss: 1.0858 - val_accuracy: 0.7987\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7404 - accuracy: 0.8083 - val_loss: 1.0869 - val_accuracy: 0.7952\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6995 - accuracy: 0.8204 - val_loss: 0.9857 - val_accuracy: 0.8255\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6578 - accuracy: 0.8309 - val_loss: 1.0304 - val_accuracy: 0.8081\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6409 - accuracy: 0.8320 - val_loss: 0.9498 - val_accuracy: 0.8334\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6184 - accuracy: 0.8377 - val_loss: 0.9118 - val_accuracy: 0.8495\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5887 - accuracy: 0.8441 - val_loss: 0.9436 - val_accuracy: 0.8385\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5710 - accuracy: 0.8509 - val_loss: 0.9102 - val_accuracy: 0.8482\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5523 - accuracy: 0.8586 - val_loss: 1.0012 - val_accuracy: 0.8174\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.6484 - accuracy: 0.0652 - val_loss: 4.2650 - val_accuracy: 0.1124\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.7228 - accuracy: 0.1828 - val_loss: 3.3661 - val_accuracy: 0.3083\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6894 - accuracy: 0.4127 - val_loss: 2.6617 - val_accuracy: 0.4774\n","Epoch 4/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.0452 - accuracy: 0.5525 - val_loss: 2.2484 - val_accuracy: 0.6057\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6326 - accuracy: 0.6280 - val_loss: 2.0008 - val_accuracy: 0.6499\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4063 - accuracy: 0.6692 - val_loss: 1.7996 - val_accuracy: 0.6744\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2551 - accuracy: 0.6965 - val_loss: 1.7061 - val_accuracy: 0.6986\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1443 - accuracy: 0.7141 - val_loss: 1.6020 - val_accuracy: 0.7041\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0441 - accuracy: 0.7389 - val_loss: 1.4616 - val_accuracy: 0.7415\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9700 - accuracy: 0.7516 - val_loss: 1.3825 - val_accuracy: 0.7386\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8989 - accuracy: 0.7671 - val_loss: 1.3745 - val_accuracy: 0.7395\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8389 - accuracy: 0.7812 - val_loss: 1.2818 - val_accuracy: 0.7595\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7875 - accuracy: 0.7961 - val_loss: 1.1656 - val_accuracy: 0.7809\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7470 - accuracy: 0.8034 - val_loss: 1.1377 - val_accuracy: 0.7721\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7175 - accuracy: 0.8093 - val_loss: 1.0890 - val_accuracy: 0.8015\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.6740 - accuracy: 0.8213 - val_loss: 1.0468 - val_accuracy: 0.8209\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6496 - accuracy: 0.8303 - val_loss: 1.0316 - val_accuracy: 0.8112\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6251 - accuracy: 0.8315 - val_loss: 1.0085 - val_accuracy: 0.8244\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5955 - accuracy: 0.8426 - val_loss: 0.9590 - val_accuracy: 0.8376\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5731 - accuracy: 0.8466 - val_loss: 0.9769 - val_accuracy: 0.8328\n","Average Validation Accuracy: 0.8430092632770538\n","Average Validation Loss: 0.7165088057518005\n","Average Test Accuracy: 0.8428171277046204\n","Final Test Accuracy for each fold: 0.8464657068252563\n","Number of input features: 13\n","Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1846/1846 [==============================] - 7s 3ms/step - loss: 4.5328 - accuracy: 0.0931 - val_loss: 3.9977 - val_accuracy: 0.1503\n","Epoch 2/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 3.5802 - accuracy: 0.2039 - val_loss: 3.3972 - val_accuracy: 0.2473\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0044 - accuracy: 0.3071 - val_loss: 2.9172 - val_accuracy: 0.3633\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 2.4229 - accuracy: 0.4483 - val_loss: 2.3124 - val_accuracy: 0.5377\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8316 - accuracy: 0.5836 - val_loss: 1.8767 - val_accuracy: 0.6251\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4420 - accuracy: 0.6691 - val_loss: 1.5795 - val_accuracy: 0.6860\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2025 - accuracy: 0.7132 - val_loss: 1.4049 - val_accuracy: 0.7327\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0524 - accuracy: 0.7420 - val_loss: 1.3078 - val_accuracy: 0.7457\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9566 - accuracy: 0.7645 - val_loss: 1.1610 - val_accuracy: 0.7800\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8685 - accuracy: 0.7818 - val_loss: 1.1049 - val_accuracy: 0.7771\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8156 - accuracy: 0.7916 - val_loss: 1.0610 - val_accuracy: 0.7956\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7682 - accuracy: 0.8016 - val_loss: 1.0353 - val_accuracy: 0.7883\n","Epoch 13/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.7377 - accuracy: 0.8080 - val_loss: 1.0036 - val_accuracy: 0.8051\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7005 - accuracy: 0.8147 - val_loss: 0.9562 - val_accuracy: 0.8066\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6726 - accuracy: 0.8225 - val_loss: 0.9473 - val_accuracy: 0.8033\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6508 - accuracy: 0.8287 - val_loss: 0.9162 - val_accuracy: 0.8209\n","Epoch 17/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6265 - accuracy: 0.8367 - val_loss: 0.9494 - val_accuracy: 0.8044\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6019 - accuracy: 0.8409 - val_loss: 0.8732 - val_accuracy: 0.8359\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5925 - accuracy: 0.8419 - val_loss: 0.8707 - val_accuracy: 0.8286\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5741 - accuracy: 0.8466 - val_loss: 0.8844 - val_accuracy: 0.8277\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.5293 - accuracy: 0.0819 - val_loss: 4.0478 - val_accuracy: 0.1281\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.5936 - accuracy: 0.1809 - val_loss: 3.4954 - val_accuracy: 0.2873\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.9746 - accuracy: 0.3349 - val_loss: 2.9006 - val_accuracy: 0.3718\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3111 - accuracy: 0.4770 - val_loss: 2.3958 - val_accuracy: 0.5564\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7988 - accuracy: 0.5979 - val_loss: 2.0548 - val_accuracy: 0.6304\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4518 - accuracy: 0.6717 - val_loss: 1.8409 - val_accuracy: 0.6788\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2339 - accuracy: 0.7076 - val_loss: 1.6752 - val_accuracy: 0.7206\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0960 - accuracy: 0.7341 - val_loss: 1.5562 - val_accuracy: 0.7413\n","Epoch 9/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9887 - accuracy: 0.7511 - val_loss: 1.4834 - val_accuracy: 0.7402\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9075 - accuracy: 0.7707 - val_loss: 1.3858 - val_accuracy: 0.7795\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8527 - accuracy: 0.7813 - val_loss: 1.3163 - val_accuracy: 0.7943\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7934 - accuracy: 0.7974 - val_loss: 1.2961 - val_accuracy: 0.7952\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7619 - accuracy: 0.8041 - val_loss: 1.2933 - val_accuracy: 0.7936\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7186 - accuracy: 0.8129 - val_loss: 1.2016 - val_accuracy: 0.8106\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6947 - accuracy: 0.8183 - val_loss: 1.1274 - val_accuracy: 0.8297\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6690 - accuracy: 0.8252 - val_loss: 1.1382 - val_accuracy: 0.8174\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6477 - accuracy: 0.8258 - val_loss: 1.0938 - val_accuracy: 0.8359\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6207 - accuracy: 0.8356 - val_loss: 1.1037 - val_accuracy: 0.8257\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6089 - accuracy: 0.8379 - val_loss: 1.0773 - val_accuracy: 0.8143\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5883 - accuracy: 0.8437 - val_loss: 1.0200 - val_accuracy: 0.8473\n","Average Validation Accuracy: 0.8531753420829773\n","Average Validation Loss: 0.6824342310428619\n","Average Test Accuracy: 0.8512567281723022\n","Final Test Accuracy for each fold: 0.8567848205566406\n","Number of input features: 14\n","Fold: 1\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","1846/1846 [==============================] - 7s 3ms/step - loss: 4.7218 - accuracy: 0.0749 - val_loss: 4.1881 - val_accuracy: 0.1204\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.7511 - accuracy: 0.1710 - val_loss: 3.6288 - val_accuracy: 0.2634\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0428 - accuracy: 0.3645 - val_loss: 2.9311 - val_accuracy: 0.4471\n","Epoch 4/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.4251 - accuracy: 0.4949 - val_loss: 2.5111 - val_accuracy: 0.5265\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0019 - accuracy: 0.5538 - val_loss: 2.1940 - val_accuracy: 0.5877\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.6746 - accuracy: 0.6214 - val_loss: 1.9878 - val_accuracy: 0.6539\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4258 - accuracy: 0.6711 - val_loss: 1.8288 - val_accuracy: 0.6601\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2491 - accuracy: 0.7096 - val_loss: 1.6639 - val_accuracy: 0.7017\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1274 - accuracy: 0.7314 - val_loss: 1.5995 - val_accuracy: 0.7311\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0284 - accuracy: 0.7504 - val_loss: 1.5691 - val_accuracy: 0.7386\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9582 - accuracy: 0.7613 - val_loss: 1.4438 - val_accuracy: 0.7426\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9085 - accuracy: 0.7700 - val_loss: 1.3712 - val_accuracy: 0.7877\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8528 - accuracy: 0.7840 - val_loss: 1.3476 - val_accuracy: 0.7780\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8175 - accuracy: 0.7884 - val_loss: 1.3451 - val_accuracy: 0.7677\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7834 - accuracy: 0.8009 - val_loss: 1.3012 - val_accuracy: 0.7945\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7625 - accuracy: 0.8054 - val_loss: 1.3534 - val_accuracy: 0.7534\n","Epoch 17/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7341 - accuracy: 0.8106 - val_loss: 1.2914 - val_accuracy: 0.8154\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7104 - accuracy: 0.8174 - val_loss: 1.2785 - val_accuracy: 0.8024\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6932 - accuracy: 0.8220 - val_loss: 1.2425 - val_accuracy: 0.8117\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6836 - accuracy: 0.8213 - val_loss: 1.2626 - val_accuracy: 0.8092\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.6276 - accuracy: 0.0733 - val_loss: 4.1142 - val_accuracy: 0.0961\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.6658 - accuracy: 0.1804 - val_loss: 3.5169 - val_accuracy: 0.2772\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 2.9369 - accuracy: 0.3621 - val_loss: 2.8822 - val_accuracy: 0.4152\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2751 - accuracy: 0.5098 - val_loss: 2.4493 - val_accuracy: 0.5274\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.8121 - accuracy: 0.6069 - val_loss: 2.2259 - val_accuracy: 0.6141\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5068 - accuracy: 0.6616 - val_loss: 2.0263 - val_accuracy: 0.6849\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2986 - accuracy: 0.7078 - val_loss: 1.9223 - val_accuracy: 0.6909\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1574 - accuracy: 0.7313 - val_loss: 1.7989 - val_accuracy: 0.7465\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0519 - accuracy: 0.7548 - val_loss: 1.7424 - val_accuracy: 0.7413\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9779 - accuracy: 0.7701 - val_loss: 1.7588 - val_accuracy: 0.7529\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9185 - accuracy: 0.7810 - val_loss: 1.6031 - val_accuracy: 0.7798\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8714 - accuracy: 0.7910 - val_loss: 1.5768 - val_accuracy: 0.7987\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8264 - accuracy: 0.7974 - val_loss: 1.5338 - val_accuracy: 0.8053\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7813 - accuracy: 0.8123 - val_loss: 1.5821 - val_accuracy: 0.7861\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7495 - accuracy: 0.8108 - val_loss: 1.5740 - val_accuracy: 0.7853\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7191 - accuracy: 0.8183 - val_loss: 1.4216 - val_accuracy: 0.8110\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6942 - accuracy: 0.8259 - val_loss: 1.4168 - val_accuracy: 0.8097\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6686 - accuracy: 0.8279 - val_loss: 1.3476 - val_accuracy: 0.8323\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6561 - accuracy: 0.8321 - val_loss: 1.4047 - val_accuracy: 0.8198\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6251 - accuracy: 0.8413 - val_loss: 1.3153 - val_accuracy: 0.8328\n","Average Validation Accuracy: 0.8350584805011749\n","Average Validation Loss: 0.8505503237247467\n","Average Test Accuracy: 0.828075498342514\n","Final Test Accuracy for each fold: 0.8449178338050842\n","Number of input features: 15\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.7983 - accuracy: 0.0598 - val_loss: 4.2999 - val_accuracy: 0.1025\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.8116 - accuracy: 0.1533 - val_loss: 3.6368 - val_accuracy: 0.1503\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.1732 - accuracy: 0.2944 - val_loss: 3.1043 - val_accuracy: 0.3228\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6215 - accuracy: 0.4530 - val_loss: 2.6520 - val_accuracy: 0.4948\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.1803 - accuracy: 0.5427 - val_loss: 2.2986 - val_accuracy: 0.5721\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8297 - accuracy: 0.6095 - val_loss: 2.0629 - val_accuracy: 0.6108\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5710 - accuracy: 0.6503 - val_loss: 1.8713 - val_accuracy: 0.6425\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3939 - accuracy: 0.6803 - val_loss: 1.7052 - val_accuracy: 0.6860\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2481 - accuracy: 0.7039 - val_loss: 1.6298 - val_accuracy: 0.7083\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1436 - accuracy: 0.7244 - val_loss: 1.5617 - val_accuracy: 0.7149\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0554 - accuracy: 0.7401 - val_loss: 1.4703 - val_accuracy: 0.7432\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9868 - accuracy: 0.7561 - val_loss: 1.3957 - val_accuracy: 0.7419\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9278 - accuracy: 0.7727 - val_loss: 1.3493 - val_accuracy: 0.7644\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8667 - accuracy: 0.7877 - val_loss: 1.2953 - val_accuracy: 0.7767\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8232 - accuracy: 0.7972 - val_loss: 1.2486 - val_accuracy: 0.7925\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7845 - accuracy: 0.8088 - val_loss: 1.2223 - val_accuracy: 0.8053\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7421 - accuracy: 0.8161 - val_loss: 1.1984 - val_accuracy: 0.8011\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7046 - accuracy: 0.8285 - val_loss: 1.1795 - val_accuracy: 0.8042\n","Epoch 19/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.6829 - accuracy: 0.8321 - val_loss: 1.1582 - val_accuracy: 0.8128\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6518 - accuracy: 0.8375 - val_loss: 1.1009 - val_accuracy: 0.8370\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.5873 - accuracy: 0.0781 - val_loss: 4.1238 - val_accuracy: 0.1395\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.6500 - accuracy: 0.1821 - val_loss: 3.4721 - val_accuracy: 0.2233\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 2.9194 - accuracy: 0.3605 - val_loss: 2.9429 - val_accuracy: 0.4539\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2830 - accuracy: 0.5241 - val_loss: 2.4156 - val_accuracy: 0.5439\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.8232 - accuracy: 0.5928 - val_loss: 2.1444 - val_accuracy: 0.6057\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5316 - accuracy: 0.6431 - val_loss: 1.9878 - val_accuracy: 0.6418\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3361 - accuracy: 0.6874 - val_loss: 1.8216 - val_accuracy: 0.7089\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1884 - accuracy: 0.7164 - val_loss: 1.7092 - val_accuracy: 0.7217\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0723 - accuracy: 0.7370 - val_loss: 1.6479 - val_accuracy: 0.7219\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9927 - accuracy: 0.7572 - val_loss: 1.5827 - val_accuracy: 0.7738\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9274 - accuracy: 0.7686 - val_loss: 1.5058 - val_accuracy: 0.7650\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8729 - accuracy: 0.7800 - val_loss: 1.5258 - val_accuracy: 0.7679\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8375 - accuracy: 0.7912 - val_loss: 1.4405 - val_accuracy: 0.7648\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7980 - accuracy: 0.7979 - val_loss: 1.3689 - val_accuracy: 0.7842\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7668 - accuracy: 0.8023 - val_loss: 1.3361 - val_accuracy: 0.8013\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7331 - accuracy: 0.8134 - val_loss: 1.3758 - val_accuracy: 0.7987\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7157 - accuracy: 0.8135 - val_loss: 1.3435 - val_accuracy: 0.7967\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7040 - accuracy: 0.8187 - val_loss: 1.3187 - val_accuracy: 0.7945\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6791 - accuracy: 0.8240 - val_loss: 1.2893 - val_accuracy: 0.7870\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6580 - accuracy: 0.8309 - val_loss: 1.2708 - val_accuracy: 0.8136\n","Average Validation Accuracy: 0.8425005078315735\n","Average Validation Loss: 0.7937020361423492\n","Average Test Accuracy: 0.8409375548362732\n","Final Test Accuracy for each fold: 0.8478661179542542\n","Number of input features: 16\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.6965 - accuracy: 0.0764 - val_loss: 4.1954 - val_accuracy: 0.0994\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.7570 - accuracy: 0.1599 - val_loss: 3.5646 - val_accuracy: 0.2092\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.0975 - accuracy: 0.3070 - val_loss: 2.8659 - val_accuracy: 0.4616\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4014 - accuracy: 0.4928 - val_loss: 2.3428 - val_accuracy: 0.5221\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9400 - accuracy: 0.5770 - val_loss: 1.9576 - val_accuracy: 0.6092\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6137 - accuracy: 0.6411 - val_loss: 1.7331 - val_accuracy: 0.6568\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3940 - accuracy: 0.6830 - val_loss: 1.5889 - val_accuracy: 0.6862\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2401 - accuracy: 0.7100 - val_loss: 1.4496 - val_accuracy: 0.7127\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1305 - accuracy: 0.7297 - val_loss: 1.4576 - val_accuracy: 0.6953\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0439 - accuracy: 0.7450 - val_loss: 1.3707 - val_accuracy: 0.7052\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9702 - accuracy: 0.7582 - val_loss: 1.2315 - val_accuracy: 0.7600\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9232 - accuracy: 0.7640 - val_loss: 1.2235 - val_accuracy: 0.7637\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8752 - accuracy: 0.7790 - val_loss: 1.3163 - val_accuracy: 0.7569\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8347 - accuracy: 0.7864 - val_loss: 1.1053 - val_accuracy: 0.7769\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7918 - accuracy: 0.7971 - val_loss: 1.0810 - val_accuracy: 0.7798\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7599 - accuracy: 0.8019 - val_loss: 1.0611 - val_accuracy: 0.7936\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7299 - accuracy: 0.8108 - val_loss: 1.0634 - val_accuracy: 0.7842\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7019 - accuracy: 0.8179 - val_loss: 1.0193 - val_accuracy: 0.7949\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6875 - accuracy: 0.8202 - val_loss: 0.9740 - val_accuracy: 0.8409\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6617 - accuracy: 0.8310 - val_loss: 1.0236 - val_accuracy: 0.8108\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.5960 - accuracy: 0.0884 - val_loss: 4.0951 - val_accuracy: 0.1358\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.6764 - accuracy: 0.1743 - val_loss: 3.4951 - val_accuracy: 0.2183\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.9753 - accuracy: 0.3312 - val_loss: 2.7714 - val_accuracy: 0.4616\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2728 - accuracy: 0.5111 - val_loss: 2.3478 - val_accuracy: 0.5597\n","Epoch 5/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.8378 - accuracy: 0.6047 - val_loss: 2.0475 - val_accuracy: 0.5952\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5547 - accuracy: 0.6529 - val_loss: 1.8701 - val_accuracy: 0.6748\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3669 - accuracy: 0.6877 - val_loss: 1.7016 - val_accuracy: 0.6942\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2289 - accuracy: 0.7103 - val_loss: 1.6088 - val_accuracy: 0.6807\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1157 - accuracy: 0.7350 - val_loss: 1.5019 - val_accuracy: 0.7173\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0233 - accuracy: 0.7571 - val_loss: 1.4540 - val_accuracy: 0.7461\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9445 - accuracy: 0.7722 - val_loss: 1.4134 - val_accuracy: 0.7369\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8931 - accuracy: 0.7826 - val_loss: 1.3233 - val_accuracy: 0.7672\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8420 - accuracy: 0.7933 - val_loss: 1.2846 - val_accuracy: 0.7828\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7998 - accuracy: 0.8044 - val_loss: 1.2335 - val_accuracy: 0.7859\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7569 - accuracy: 0.8083 - val_loss: 1.2252 - val_accuracy: 0.7899\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7433 - accuracy: 0.8117 - val_loss: 1.2625 - val_accuracy: 0.7571\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7064 - accuracy: 0.8191 - val_loss: 1.1932 - val_accuracy: 0.8121\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7014 - accuracy: 0.8191 - val_loss: 1.1617 - val_accuracy: 0.8112\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6724 - accuracy: 0.8279 - val_loss: 1.1538 - val_accuracy: 0.8174\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6513 - accuracy: 0.8301 - val_loss: 1.1024 - val_accuracy: 0.8143\n","Average Validation Accuracy: 0.8281596601009369\n","Average Validation Loss: 0.7753082811832428\n","Average Test Accuracy: 0.8240952491760254\n","Final Test Accuracy for each fold: 0.8242058157920837\n","Number of input features: 17\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.7570 - accuracy: 0.0677 - val_loss: 4.2805 - val_accuracy: 0.1177\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.9355 - accuracy: 0.1523 - val_loss: 3.8317 - val_accuracy: 0.1740\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.5163 - accuracy: 0.1989 - val_loss: 3.4538 - val_accuracy: 0.2216\n","Epoch 4/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 3.0420 - accuracy: 0.2907 - val_loss: 2.9085 - val_accuracy: 0.3556\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5059 - accuracy: 0.4137 - val_loss: 2.4874 - val_accuracy: 0.4667\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1500 - accuracy: 0.4937 - val_loss: 2.2469 - val_accuracy: 0.5052\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9259 - accuracy: 0.5375 - val_loss: 2.0904 - val_accuracy: 0.5463\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7578 - accuracy: 0.5637 - val_loss: 1.9586 - val_accuracy: 0.5758\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6237 - accuracy: 0.5908 - val_loss: 1.8763 - val_accuracy: 0.5877\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5079 - accuracy: 0.6190 - val_loss: 1.7477 - val_accuracy: 0.6374\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4043 - accuracy: 0.6458 - val_loss: 1.6870 - val_accuracy: 0.6462\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3141 - accuracy: 0.6649 - val_loss: 1.6240 - val_accuracy: 0.6543\n","Epoch 13/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2464 - accuracy: 0.6804 - val_loss: 1.6513 - val_accuracy: 0.6352\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1894 - accuracy: 0.6917 - val_loss: 1.5618 - val_accuracy: 0.6750\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1424 - accuracy: 0.6999 - val_loss: 1.4837 - val_accuracy: 0.7067\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1050 - accuracy: 0.7102 - val_loss: 1.4942 - val_accuracy: 0.6851\n","Epoch 17/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 1.0649 - accuracy: 0.7202 - val_loss: 1.4121 - val_accuracy: 0.7272\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0328 - accuracy: 0.7271 - val_loss: 1.4221 - val_accuracy: 0.7254\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9974 - accuracy: 0.7347 - val_loss: 1.3855 - val_accuracy: 0.7186\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9762 - accuracy: 0.7419 - val_loss: 1.4219 - val_accuracy: 0.7149\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 3ms/step - loss: 4.7998 - accuracy: 0.0593 - val_loss: 4.3562 - val_accuracy: 0.0645\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.9343 - accuracy: 0.1414 - val_loss: 3.8117 - val_accuracy: 0.1760\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.4469 - accuracy: 0.1990 - val_loss: 3.4209 - val_accuracy: 0.2220\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.9792 - accuracy: 0.3004 - val_loss: 2.9633 - val_accuracy: 0.3292\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.5171 - accuracy: 0.4100 - val_loss: 2.5646 - val_accuracy: 0.4823\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1551 - accuracy: 0.4930 - val_loss: 2.3000 - val_accuracy: 0.4946\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.8859 - accuracy: 0.5469 - val_loss: 2.0911 - val_accuracy: 0.5230\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6825 - accuracy: 0.5918 - val_loss: 1.9209 - val_accuracy: 0.6002\n","Epoch 9/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5230 - accuracy: 0.6272 - val_loss: 1.8368 - val_accuracy: 0.6218\n","Epoch 10/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3987 - accuracy: 0.6550 - val_loss: 1.7302 - val_accuracy: 0.6691\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3124 - accuracy: 0.6733 - val_loss: 1.7229 - val_accuracy: 0.6315\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2426 - accuracy: 0.6857 - val_loss: 1.5663 - val_accuracy: 0.6862\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1847 - accuracy: 0.6989 - val_loss: 1.7027 - val_accuracy: 0.6253\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1340 - accuracy: 0.7079 - val_loss: 1.4612 - val_accuracy: 0.7153\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0982 - accuracy: 0.7146 - val_loss: 1.4600 - val_accuracy: 0.7030\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0480 - accuracy: 0.7262 - val_loss: 1.3919 - val_accuracy: 0.7230\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0218 - accuracy: 0.7307 - val_loss: 1.3590 - val_accuracy: 0.7278\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9809 - accuracy: 0.7400 - val_loss: 1.3683 - val_accuracy: 0.7327\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9698 - accuracy: 0.7416 - val_loss: 1.3572 - val_accuracy: 0.7366\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9391 - accuracy: 0.7478 - val_loss: 1.3182 - val_accuracy: 0.7318\n","Average Validation Accuracy: 0.7359768748283386\n","Average Validation Loss: 1.0901885032653809\n","Average Test Accuracy: 0.7355716228485107\n","Final Test Accuracy for each fold: 0.7442323565483093\n","Number of input features: 18\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 10s 4ms/step - loss: 4.8260 - accuracy: 0.0632 - val_loss: 4.4654 - val_accuracy: 0.1054\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.0475 - accuracy: 0.1379 - val_loss: 3.8865 - val_accuracy: 0.1573\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.6338 - accuracy: 0.1849 - val_loss: 3.6310 - val_accuracy: 0.1914\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.4026 - accuracy: 0.2110 - val_loss: 3.4443 - val_accuracy: 0.2075\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.2090 - accuracy: 0.2406 - val_loss: 3.2841 - val_accuracy: 0.2477\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.0064 - accuracy: 0.2816 - val_loss: 3.1072 - val_accuracy: 0.2781\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.7933 - accuracy: 0.3380 - val_loss: 2.8989 - val_accuracy: 0.3476\n","Epoch 8/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.5959 - accuracy: 0.3673 - val_loss: 2.7482 - val_accuracy: 0.3793\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.4294 - accuracy: 0.3939 - val_loss: 2.6109 - val_accuracy: 0.3987\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2892 - accuracy: 0.4226 - val_loss: 2.5119 - val_accuracy: 0.4273\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.1561 - accuracy: 0.4531 - val_loss: 2.3848 - val_accuracy: 0.4594\n","Epoch 12/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0322 - accuracy: 0.4807 - val_loss: 2.2480 - val_accuracy: 0.4895\n","Epoch 13/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.9129 - accuracy: 0.5050 - val_loss: 2.1571 - val_accuracy: 0.5199\n","Epoch 14/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8017 - accuracy: 0.5349 - val_loss: 2.1101 - val_accuracy: 0.5646\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7095 - accuracy: 0.5567 - val_loss: 2.0808 - val_accuracy: 0.5397\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6232 - accuracy: 0.5855 - val_loss: 1.9686 - val_accuracy: 0.5901\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5536 - accuracy: 0.5974 - val_loss: 2.0193 - val_accuracy: 0.5723\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4923 - accuracy: 0.6111 - val_loss: 1.8793 - val_accuracy: 0.6293\n","Epoch 19/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.4289 - accuracy: 0.6296 - val_loss: 1.8673 - val_accuracy: 0.6189\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3889 - accuracy: 0.6409 - val_loss: 1.8101 - val_accuracy: 0.6317\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.8163 - accuracy: 0.0619 - val_loss: 4.3928 - val_accuracy: 0.0895\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.9913 - accuracy: 0.1350 - val_loss: 3.8440 - val_accuracy: 0.1740\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.5517 - accuracy: 0.1848 - val_loss: 3.5252 - val_accuracy: 0.2062\n","Epoch 4/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.2165 - accuracy: 0.2268 - val_loss: 3.2498 - val_accuracy: 0.2570\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.8220 - accuracy: 0.3302 - val_loss: 2.8700 - val_accuracy: 0.3738\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.4430 - accuracy: 0.4209 - val_loss: 2.5918 - val_accuracy: 0.4403\n","Epoch 7/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1649 - accuracy: 0.4737 - val_loss: 2.3572 - val_accuracy: 0.4719\n","Epoch 8/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9489 - accuracy: 0.5203 - val_loss: 2.1666 - val_accuracy: 0.5432\n","Epoch 9/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7667 - accuracy: 0.5645 - val_loss: 2.0869 - val_accuracy: 0.5518\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.6169 - accuracy: 0.5998 - val_loss: 1.9057 - val_accuracy: 0.6099\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4970 - accuracy: 0.6223 - val_loss: 1.8431 - val_accuracy: 0.6200\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4012 - accuracy: 0.6456 - val_loss: 1.7515 - val_accuracy: 0.6207\n","Epoch 13/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3278 - accuracy: 0.6593 - val_loss: 1.6763 - val_accuracy: 0.6660\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2649 - accuracy: 0.6764 - val_loss: 1.6419 - val_accuracy: 0.6605\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2127 - accuracy: 0.6860 - val_loss: 1.6042 - val_accuracy: 0.6823\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1719 - accuracy: 0.6930 - val_loss: 1.6103 - val_accuracy: 0.6601\n","Epoch 17/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1435 - accuracy: 0.7006 - val_loss: 1.5165 - val_accuracy: 0.6933\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1030 - accuracy: 0.7063 - val_loss: 1.5301 - val_accuracy: 0.6845\n","Epoch 19/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0802 - accuracy: 0.7130 - val_loss: 1.4900 - val_accuracy: 0.7164\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0610 - accuracy: 0.7143 - val_loss: 1.4154 - val_accuracy: 0.7140\n","Average Validation Accuracy: 0.6869637668132782\n","Average Validation Loss: 1.3031066060066223\n","Average Test Accuracy: 0.6881034970283508\n","Final Test Accuracy for each fold: 0.7334709167480469\n","Number of input features: 19\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 4ms/step - loss: 4.8179 - accuracy: 0.0611 - val_loss: 4.3969 - val_accuracy: 0.1010\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.0097 - accuracy: 0.1507 - val_loss: 3.8537 - val_accuracy: 0.1531\n","Epoch 3/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 3.5157 - accuracy: 0.2014 - val_loss: 3.4336 - val_accuracy: 0.2075\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.0140 - accuracy: 0.3034 - val_loss: 2.9344 - val_accuracy: 0.3388\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.5359 - accuracy: 0.4111 - val_loss: 2.5583 - val_accuracy: 0.4277\n","Epoch 6/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2051 - accuracy: 0.4736 - val_loss: 2.2927 - val_accuracy: 0.4898\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.9710 - accuracy: 0.5132 - val_loss: 2.1365 - val_accuracy: 0.5298\n","Epoch 8/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8015 - accuracy: 0.5499 - val_loss: 1.9926 - val_accuracy: 0.5221\n","Epoch 9/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.6505 - accuracy: 0.5823 - val_loss: 1.8609 - val_accuracy: 0.5894\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5366 - accuracy: 0.6063 - val_loss: 1.7339 - val_accuracy: 0.6405\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4334 - accuracy: 0.6345 - val_loss: 1.6778 - val_accuracy: 0.6328\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3666 - accuracy: 0.6455 - val_loss: 1.6815 - val_accuracy: 0.6136\n","Epoch 13/20\n","1846/1846 [==============================] - 6s 4ms/step - loss: 1.2983 - accuracy: 0.6635 - val_loss: 1.5705 - val_accuracy: 0.6653\n","Epoch 14/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2479 - accuracy: 0.6763 - val_loss: 1.5098 - val_accuracy: 0.6816\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2023 - accuracy: 0.6842 - val_loss: 1.5118 - val_accuracy: 0.6906\n","Epoch 16/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1586 - accuracy: 0.6973 - val_loss: 1.4357 - val_accuracy: 0.7021\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1214 - accuracy: 0.7094 - val_loss: 1.4695 - val_accuracy: 0.7052\n","Epoch 18/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0862 - accuracy: 0.7172 - val_loss: 1.3677 - val_accuracy: 0.7347\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.0588 - accuracy: 0.7197 - val_loss: 1.4300 - val_accuracy: 0.6915\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0295 - accuracy: 0.7278 - val_loss: 1.3591 - val_accuracy: 0.7197\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.8719 - accuracy: 0.0561 - val_loss: 4.5377 - val_accuracy: 0.0700\n","Epoch 2/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 4.0724 - accuracy: 0.1286 - val_loss: 3.9255 - val_accuracy: 0.1723\n","Epoch 3/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.6396 - accuracy: 0.1845 - val_loss: 3.6502 - val_accuracy: 0.1877\n","Epoch 4/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.3797 - accuracy: 0.2098 - val_loss: 3.4678 - val_accuracy: 0.2066\n","Epoch 5/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.1737 - accuracy: 0.2376 - val_loss: 3.3221 - val_accuracy: 0.2339\n","Epoch 6/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.9550 - accuracy: 0.2803 - val_loss: 3.0569 - val_accuracy: 0.3019\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7130 - accuracy: 0.3307 - val_loss: 2.8450 - val_accuracy: 0.3732\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.4706 - accuracy: 0.3937 - val_loss: 2.6623 - val_accuracy: 0.3894\n","Epoch 9/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2359 - accuracy: 0.4465 - val_loss: 2.4418 - val_accuracy: 0.4510\n","Epoch 10/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.0309 - accuracy: 0.4973 - val_loss: 2.2553 - val_accuracy: 0.5223\n","Epoch 11/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8499 - accuracy: 0.5308 - val_loss: 2.1279 - val_accuracy: 0.5373\n","Epoch 12/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7065 - accuracy: 0.5642 - val_loss: 2.0119 - val_accuracy: 0.5809\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5723 - accuracy: 0.5945 - val_loss: 1.9066 - val_accuracy: 0.6086\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4643 - accuracy: 0.6191 - val_loss: 1.8067 - val_accuracy: 0.6381\n","Epoch 15/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3822 - accuracy: 0.6455 - val_loss: 1.7992 - val_accuracy: 0.6246\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3101 - accuracy: 0.6621 - val_loss: 1.7111 - val_accuracy: 0.6332\n","Epoch 17/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.2509 - accuracy: 0.6724 - val_loss: 1.6687 - val_accuracy: 0.6493\n","Epoch 18/20\n","1846/1846 [==============================] - 9s 5ms/step - loss: 1.2030 - accuracy: 0.6828 - val_loss: 1.6972 - val_accuracy: 0.6543\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1638 - accuracy: 0.6913 - val_loss: 1.5984 - val_accuracy: 0.7006\n","Epoch 20/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1261 - accuracy: 0.7030 - val_loss: 1.6056 - val_accuracy: 0.6950\n","Average Validation Accuracy: 0.7147364914417267\n","Average Validation Loss: 1.1962517499923706\n","Average Test Accuracy: 0.7107319235801697\n","Final Test Accuracy for each fold: 0.7213090658187866\n","Number of input features: 20\n","Fold: 1\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 8s 3ms/step - loss: 4.8674 - accuracy: 0.0590 - val_loss: 4.5183 - val_accuracy: 0.0691\n","Epoch 2/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.1304 - accuracy: 0.1277 - val_loss: 3.9994 - val_accuracy: 0.1512\n","Epoch 3/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.7270 - accuracy: 0.1743 - val_loss: 3.7018 - val_accuracy: 0.2022\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.4200 - accuracy: 0.2104 - val_loss: 3.4079 - val_accuracy: 0.2172\n","Epoch 5/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.0944 - accuracy: 0.2677 - val_loss: 3.1081 - val_accuracy: 0.2906\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.7434 - accuracy: 0.3446 - val_loss: 2.7561 - val_accuracy: 0.3751\n","Epoch 7/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.4476 - accuracy: 0.4070 - val_loss: 2.5586 - val_accuracy: 0.4178\n","Epoch 8/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2174 - accuracy: 0.4533 - val_loss: 2.3380 - val_accuracy: 0.4950\n","Epoch 9/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 2.0182 - accuracy: 0.4983 - val_loss: 2.1531 - val_accuracy: 0.5138\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8470 - accuracy: 0.5385 - val_loss: 2.0642 - val_accuracy: 0.5338\n","Epoch 11/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7053 - accuracy: 0.5737 - val_loss: 1.9710 - val_accuracy: 0.5604\n","Epoch 12/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5975 - accuracy: 0.5954 - val_loss: 1.8851 - val_accuracy: 0.5956\n","Epoch 13/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5120 - accuracy: 0.6175 - val_loss: 1.8187 - val_accuracy: 0.5974\n","Epoch 14/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4326 - accuracy: 0.6346 - val_loss: 1.7490 - val_accuracy: 0.6343\n","Epoch 15/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3712 - accuracy: 0.6451 - val_loss: 1.7169 - val_accuracy: 0.6233\n","Epoch 16/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3191 - accuracy: 0.6554 - val_loss: 1.6476 - val_accuracy: 0.6565\n","Epoch 17/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2729 - accuracy: 0.6646 - val_loss: 1.6223 - val_accuracy: 0.6693\n","Epoch 18/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2279 - accuracy: 0.6811 - val_loss: 1.6505 - val_accuracy: 0.6499\n","Epoch 19/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1947 - accuracy: 0.6810 - val_loss: 1.6105 - val_accuracy: 0.6645\n","Epoch 20/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1624 - accuracy: 0.6921 - val_loss: 1.5853 - val_accuracy: 0.6598\n","Fold: 2\n","Epoch 1/20\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:116: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n","/usr/local/lib/python3.9/dist-packages/sklearn/preprocessing/_label.py:134: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, dtype=self.classes_.dtype, warn=True)\n"]},{"output_type":"stream","name":"stdout","text":["1846/1846 [==============================] - 7s 3ms/step - loss: 4.8654 - accuracy: 0.0544 - val_loss: 4.5617 - val_accuracy: 0.0834\n","Epoch 2/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 4.0876 - accuracy: 0.1288 - val_loss: 3.9607 - val_accuracy: 0.1481\n","Epoch 3/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 3.6331 - accuracy: 0.1836 - val_loss: 3.6660 - val_accuracy: 0.1901\n","Epoch 4/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.3167 - accuracy: 0.2290 - val_loss: 3.3643 - val_accuracy: 0.2642\n","Epoch 5/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.9906 - accuracy: 0.2941 - val_loss: 3.0811 - val_accuracy: 0.3384\n","Epoch 6/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.6532 - accuracy: 0.3672 - val_loss: 2.7762 - val_accuracy: 0.4145\n","Epoch 7/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3523 - accuracy: 0.4328 - val_loss: 2.5143 - val_accuracy: 0.4847\n","Epoch 8/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.0957 - accuracy: 0.4839 - val_loss: 2.2759 - val_accuracy: 0.5272\n","Epoch 9/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8706 - accuracy: 0.5315 - val_loss: 2.1535 - val_accuracy: 0.5608\n","Epoch 10/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7000 - accuracy: 0.5728 - val_loss: 1.9906 - val_accuracy: 0.5694\n","Epoch 11/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5682 - accuracy: 0.5956 - val_loss: 1.8835 - val_accuracy: 0.5978\n","Epoch 12/20\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.4708 - accuracy: 0.6217 - val_loss: 1.8312 - val_accuracy: 0.6101\n","Epoch 13/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3960 - accuracy: 0.6391 - val_loss: 1.7458 - val_accuracy: 0.6587\n","Epoch 14/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3295 - accuracy: 0.6524 - val_loss: 1.7311 - val_accuracy: 0.6255\n","Epoch 15/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2757 - accuracy: 0.6662 - val_loss: 1.7261 - val_accuracy: 0.6350\n","Epoch 16/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2346 - accuracy: 0.6704 - val_loss: 1.6117 - val_accuracy: 0.6724\n","Epoch 17/20\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1913 - accuracy: 0.6836 - val_loss: 1.6056 - val_accuracy: 0.6609\n","Epoch 18/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1564 - accuracy: 0.6911 - val_loss: 1.5729 - val_accuracy: 0.6834\n","Epoch 19/20\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1290 - accuracy: 0.7008 - val_loss: 1.5395 - val_accuracy: 0.6836\n","Epoch 20/20\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.1012 - accuracy: 0.7061 - val_loss: 1.5287 - val_accuracy: 0.6898\n","Average Validation Accuracy: 0.6889596581459045\n","Average Validation Loss: 1.2494309544563293\n","Average Test Accuracy: 0.6882140338420868\n","Final Test Accuracy for each fold: 0.7067148089408875\n"]}],"source":["# Define the number of folds for k-fold cross-validation\n","k = 2\n","\n","# Define the cross-validation method\n","cv_method = StratifiedKFold(n_splits=k)\n","\n","# Initialize the list to store the history, train & validation(accuracy & loss) for each model\n","models = []\n","model_history = []\n","model_accuracy = []\n","model_train_acc = []\n","model_train_loss = []\n","model_val_acc = []\n","model_val_loss = []\n","\n","\n","for i in range(1,21):\n","\n","    models_fold = []\n","    hist = []\n","    train_accuracy = []\n","    train_loss = []\n","    val_accuracy = []\n","    val_loss = []\n","    test_accuracy = []\n","\n","    print(\"Number of input features:\",i)\n","\n","    # Select the input features from the input data\n","    X_train_selected = X_train[:, :i]\n","    X_test_selected = X_test[:, :i]\n","\n","    # Loop over the folds\n","    for fold, (train_index, val_index) in enumerate(cv_method.split(X_train_selected, y_train)):\n","\n","        print(\"Fold:\", fold+1)\n","\n","        # Split the data into train and validation sets using the current fold index\n","        X_train_fold  = X_train_selected[train_index]\n","        y_train_fold  = y_train[train_index]\n","        X_val_fold = X_train_selected[val_index]\n","        y_val_fold = y_train[val_index]\n","\n","        # Prepare the target data\n","        y_train_fold_enc, y_val_fold_enc = prepare_targets(y_train_fold, y_val_fold)\n","\n","        # build the model\n","        model = RBFN_model(i)\n","\n","        # Fit the model to the training data for the current fold\n","        history = model.fit(X_train_fold, to_categorical(y_train_fold_enc, num_classes=373), epochs=20, batch_size=5, verbose=1, validation_split = 0.33)\n","    \n","        # Evaluate the model on the validation data for the current fold\n","        val_scores = model.evaluate(X_val_fold, to_categorical(y_val_fold_enc, num_classes=373), verbose=0)\n","        val_accuracy.append(val_scores[1])\n","        val_loss.append(val_scores[0])\n","\n","        # Evaluate the model on the test data for the current fold\n","        test_scores = model.evaluate(X_test_selected, to_categorical(y_test_enc, num_classes=373), verbose=0)\n","        test_accuracy.append(test_scores[1])\n","\n","        # add the model to the list of models\n","        models_fold.append(model)\n","        hist.append(history)\n","\n","        # store the training accuracy and loss for each fold\n","        train_accuracy.append(history.history['accuracy'])\n","        train_loss.append(history.history['loss'])\n","        \n","    # Calculate the average test and validation accuracy and loss across all folds\n","    avg_test_acc = sum(test_accuracy) / len(test_accuracy)\n","    avg_val_acc = sum(val_accuracy) / len(val_accuracy)\n","    avg_val_loss = sum(val_loss) / len(val_loss)\n","\n","    # Print the average validation and test accuracy and loss\n","    print(\"Average Validation Accuracy:\", avg_val_acc)\n","    print(\"Average Validation Loss:\",avg_val_loss)\n","    print(\"Average Test Accuracy:\", avg_test_acc)\n","\n","    best_fold_index = test_accuracy.index(max(test_accuracy))\n","    model_accuracy.append(test_accuracy[best_fold_index])\n","    models.append(models_fold[best_fold_index])\n","    model_history.append(hist[best_fold_index])\n","    model_train_acc.append(train_accuracy[best_fold_index])\n","    model_train_loss.append(train_loss[best_fold_index])\n","    model_val_acc.append(val_accuracy[best_fold_index])\n","    model_val_loss.append(val_loss[best_fold_index])\n","\n","\n","    print(\"Final Test Accuracy for each fold:\", test_accuracy[best_fold_index])"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"xzn9CBYTQsYy","executionInfo":{"status":"ok","timestamp":1682314536779,"user_tz":-480,"elapsed":156,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}}},"outputs":[],"source":["#to show the no of input features and its corresponding model accuracy\n","model_list = []\n","\n","#Iterate through each model's accuracy \n","for i in range (len(model_accuracy)):\n","    #get the number of input features for the current model\n","    no_features = i + 1\n","\n","    #round the model accuries to 3 d.p.\n","    rounded_model_acc = round(model_accuracy[i], 3)\n","    \n","    model_list.append([no_features, rounded_model_acc])\n","\n","models_df = pd.DataFrame(model_list, columns=[\"No of input features\", \"Model accuracy\"])"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"WAjs7sLtQsYz","colab":{"base_uri":"https://localhost:8080/","height":489},"executionInfo":{"status":"ok","timestamp":1682314538210,"user_tz":-480,"elapsed":1570,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"1ed1a0b3-a5e7-4486-ec40-ffdb6b7ffe09"},"outputs":[{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}},{"output_type":"stream","name":"stdout","text":["Final Test Accuracy: 0.861797034740448\n"]}],"source":["# Select the final model based on the max test accuracy across all models\n","\n","best_model_index = model_accuracy.index(max(model_accuracy))\n","\n","best_model = models[best_model_index]\n","best_model_history = model_history[best_model_index]\n","best_model_train_acc = model_train_acc[best_model_index]\n","best_model_train_loss = model_train_loss[best_model_index]\n","best_model_val_acc = model_val_acc[best_model_index]\n","best_model_val_loss = model_val_loss[best_model_index]\n","\n","# summarize history for accuracy  \n","plt.subplot(211)  \n","plt.plot(best_model_history.history['accuracy'])  \n","plt.plot(best_model_history.history['val_accuracy'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='lower right')  \n","\n","# summarize history for loss\n","plt.subplot(212)  \n","plt.plot(best_model_history.history['loss'])  \n","plt.plot(best_model_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='upper right')  \n","plt.subplots_adjust(hspace=0.7)\n","\n","plt.show() \n","\n","print(\"Final Test Accuracy:\", model_accuracy[best_model_index])"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"KfbFjY7JQsY1","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682314539360,"user_tz":-480,"elapsed":1882,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"ffb242c8-27fa-46e0-df6b-4722c4be10af"},"outputs":[{"output_type":"stream","name":"stdout","text":["424/424 [==============================] - 1s 2ms/step\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       0.98      1.00      0.99       591\n","           1       1.00      1.00      1.00       430\n","           2       1.00      1.00      1.00       419\n","           3       1.00      1.00      1.00       384\n","           4       1.00      1.00      1.00       339\n","           5       1.00      1.00      1.00       342\n","           6       1.00      1.00      1.00       310\n","           7       1.00      1.00      1.00       325\n","           8       0.91      1.00      0.95       294\n","           9       0.97      1.00      0.99       269\n","          10       0.97      1.00      0.99       296\n","          11       0.96      1.00      0.98       258\n","          12       1.00      1.00      1.00       247\n","          13       0.96      1.00      0.98       237\n","          14       0.84      1.00      0.91       239\n","          15       1.00      1.00      1.00       235\n","          16       1.00      1.00      1.00       213\n","          17       1.00      1.00      1.00       202\n","          18       1.00      1.00      1.00       196\n","          19       0.94      1.00      0.97       181\n","          20       1.00      1.00      1.00       177\n","          21       1.00      1.00      1.00       177\n","          22       1.00      1.00      1.00       155\n","          23       0.95      1.00      0.97       155\n","          24       1.00      1.00      1.00       144\n","          25       1.00      1.00      1.00       126\n","          26       1.00      1.00      1.00       108\n","          27       0.92      1.00      0.96       121\n","          28       0.81      1.00      0.90        95\n","          29       0.88      1.00      0.94       106\n","          30       1.00      1.00      1.00       102\n","          31       0.85      1.00      0.92        86\n","          32       1.00      1.00      1.00       108\n","          33       0.93      1.00      0.96        88\n","          34       1.00      1.00      1.00       102\n","          35       1.00      1.00      1.00        88\n","          36       1.00      1.00      1.00        83\n","          37       0.94      1.00      0.97        93\n","          38       0.88      1.00      0.94        76\n","          39       0.93      1.00      0.97        85\n","          40       0.92      1.00      0.96        86\n","          41       0.87      1.00      0.93        85\n","          42       1.00      1.00      1.00        68\n","          43       0.85      1.00      0.92        75\n","          44       0.57      1.00      0.73        71\n","          45       0.00      0.00      0.00        58\n","          46       0.83      1.00      0.90        71\n","          47       0.00      0.00      0.00        57\n","          48       0.79      1.00      0.88        67\n","          49       0.94      1.00      0.97        47\n","          50       1.00      1.00      1.00        48\n","          51       0.68      1.00      0.81        47\n","          52       1.00      1.00      1.00        43\n","          53       1.00      1.00      1.00        51\n","          54       1.00      1.00      1.00        44\n","          55       1.00      1.00      1.00        51\n","          56       0.51      1.00      0.68        45\n","          57       1.00      1.00      1.00        44\n","          58       1.00      1.00      1.00        41\n","          59       0.85      1.00      0.92        41\n","          60       1.00      1.00      1.00        52\n","          61       0.41      1.00      0.59        43\n","          62       1.00      1.00      1.00        37\n","          63       0.80      1.00      0.89        43\n","          64       0.00      0.00      0.00        42\n","          65       0.74      1.00      0.85        46\n","          66       1.00      1.00      1.00        43\n","          67       0.56      1.00      0.71        40\n","          68       1.00      1.00      1.00        44\n","          69       0.00      0.00      0.00        43\n","          70       1.00      1.00      1.00        38\n","          71       0.63      1.00      0.78        33\n","          72       1.00      1.00      1.00        45\n","          73       1.00      1.00      1.00        38\n","          74       1.00      1.00      1.00        42\n","          75       0.85      1.00      0.92        39\n","          76       0.00      0.00      0.00        30\n","          77       1.00      1.00      1.00        28\n","          78       0.82      1.00      0.90        28\n","          79       0.00      0.00      0.00        32\n","          80       1.00      1.00      1.00        33\n","          81       1.00      1.00      1.00        31\n","          82       1.00      1.00      1.00        35\n","          83       1.00      1.00      1.00        39\n","          84       1.00      1.00      1.00        27\n","          85       0.53      1.00      0.69        36\n","          86       1.00      1.00      1.00        31\n","          87       0.88      1.00      0.93        28\n","          88       0.30      1.00      0.47        20\n","          89       1.00      1.00      1.00        33\n","          90       0.00      0.00      0.00        24\n","          91       1.00      1.00      1.00        22\n","          92       1.00      1.00      1.00        26\n","          93       1.00      1.00      1.00        35\n","          94       0.75      1.00      0.86        27\n","          95       0.39      1.00      0.56        23\n","          96       0.00      0.00      0.00        27\n","          97       0.00      0.00      0.00        28\n","          98       0.07      1.00      0.13        16\n","          99       1.00      1.00      1.00        35\n","         100       0.68      1.00      0.81        28\n","         101       0.00      0.00      0.00        25\n","         102       0.00      0.00      0.00        26\n","         103       0.51      1.00      0.67        33\n","         104       0.58      1.00      0.73        26\n","         105       0.00      0.00      0.00        24\n","         106       0.47      1.00      0.64        22\n","         107       0.30      1.00      0.46        26\n","         108       0.00      0.00      0.00        25\n","         109       0.73      1.00      0.84        16\n","         110       1.00      1.00      1.00        20\n","         111       1.00      1.00      1.00        26\n","         112       1.00      1.00      1.00        18\n","         113       0.92      1.00      0.96        23\n","         114       0.89      1.00      0.94        25\n","         115       1.00      1.00      1.00        18\n","         116       0.83      1.00      0.90        19\n","         117       0.40      1.00      0.57        16\n","         118       0.00      0.00      0.00        26\n","         119       0.63      1.00      0.77        22\n","         120       0.00      0.00      0.00        17\n","         121       1.00      1.00      1.00        15\n","         122       0.67      1.00      0.80        18\n","         123       0.00      0.00      0.00        20\n","         124       0.36      1.00      0.53        14\n","         125       1.00      1.00      1.00        22\n","         126       0.68      1.00      0.81        19\n","         127       1.00      1.00      1.00        27\n","         128       0.00      0.00      0.00        26\n","         129       0.88      1.00      0.93        21\n","         130       0.29      1.00      0.44        18\n","         131       0.00      0.00      0.00        18\n","         132       0.00      0.00      0.00        20\n","         133       1.00      1.00      1.00        14\n","         134       1.00      1.00      1.00        19\n","         135       0.00      0.00      0.00        16\n","         136       0.32      1.00      0.49        23\n","         137       0.00      0.00      0.00        11\n","         138       0.78      1.00      0.88        14\n","         139       0.65      1.00      0.78        20\n","         140       0.00      0.00      0.00        23\n","         141       0.00      0.00      0.00        14\n","         142       0.39      1.00      0.57        13\n","         143       1.00      1.00      1.00        23\n","         144       0.71      1.00      0.83        17\n","         145       0.00      0.00      0.00        24\n","         146       0.00      0.00      0.00        16\n","         147       1.00      1.00      1.00        19\n","         148       0.00      0.00      0.00        22\n","         149       1.00      1.00      1.00        15\n","         150       0.37      1.00      0.54        11\n","         151       1.00      1.00      1.00        19\n","         152       1.00      1.00      1.00        20\n","         153       1.00      1.00      1.00        24\n","         154       0.55      1.00      0.71        11\n","         155       1.00      1.00      1.00        17\n","         156       0.00      0.00      0.00        18\n","         157       0.32      1.00      0.49        12\n","         158       0.35      1.00      0.52        18\n","         159       0.00      0.00      0.00        20\n","         160       0.00      0.00      0.00        20\n","         161       0.46      1.00      0.63        16\n","         162       0.00      0.00      0.00        15\n","         163       0.00      0.00      0.00        15\n","         164       1.00      1.00      1.00        13\n","         165       0.00      0.00      0.00        19\n","         166       0.00      0.00      0.00        11\n","         167       1.00      1.00      1.00         9\n","         168       0.42      1.00      0.59        11\n","         169       0.00      0.00      0.00        21\n","         170       0.62      1.00      0.77        15\n","         171       0.58      1.00      0.73        18\n","         172       0.00      0.00      0.00        11\n","         173       0.52      1.00      0.68        16\n","         174       0.00      0.00      0.00        10\n","         175       0.00      0.00      0.00        11\n","         176       1.00      1.00      1.00        10\n","         177       0.00      0.00      0.00        15\n","         178       0.20      1.00      0.33        11\n","         179       1.00      1.00      1.00        15\n","         180       0.00      0.00      0.00        13\n","         181       0.00      0.00      0.00        15\n","         182       0.00      0.00      0.00         9\n","         183       0.00      0.00      0.00        16\n","         184       1.00      1.00      1.00         8\n","         185       0.00      0.00      0.00        12\n","         186       0.00      0.00      0.00        15\n","         187       0.71      1.00      0.83        15\n","         188       0.00      0.00      0.00        13\n","         189       0.00      0.00      0.00        14\n","         190       1.00      1.00      1.00        11\n","         191       1.00      1.00      1.00        10\n","         192       0.00      0.00      0.00        17\n","         193       0.00      0.00      0.00         9\n","         194       0.00      0.00      0.00         9\n","         195       0.50      1.00      0.67         4\n","         196       0.44      1.00      0.61         7\n","         197       0.00      0.00      0.00         7\n","         198       0.00      0.00      0.00        12\n","         199       0.00      0.00      0.00        14\n","         200       0.00      0.00      0.00         6\n","         201       0.00      0.00      0.00         9\n","         202       0.00      0.00      0.00         7\n","         203       0.00      0.00      0.00         6\n","         204       0.52      1.00      0.69        11\n","         205       0.00      0.00      0.00        14\n","         206       0.00      0.00      0.00        12\n","         207       0.00      0.00      0.00        14\n","         208       0.00      0.00      0.00        12\n","         209       1.00      1.00      1.00         7\n","         210       0.00      0.00      0.00        19\n","         211       1.00      1.00      1.00         7\n","         212       0.00      0.00      0.00        11\n","         213       1.00      1.00      1.00         9\n","         214       1.00      1.00      1.00         7\n","         215       0.00      0.00      0.00         6\n","         216       0.33      1.00      0.50        12\n","         217       0.00      0.00      0.00        12\n","         218       0.00      0.00      0.00         9\n","         219       0.00      0.00      0.00         6\n","         220       0.00      0.00      0.00         8\n","         221       1.00      1.00      1.00         5\n","         222       0.00      0.00      0.00         4\n","         223       1.00      1.00      1.00        14\n","         224       0.00      0.00      0.00        13\n","         225       1.00      1.00      1.00         4\n","         226       0.29      1.00      0.45        10\n","         227       0.00      0.00      0.00        12\n","         228       0.00      0.00      0.00        13\n","         229       0.00      0.00      0.00        11\n","         230       0.00      0.00      0.00         5\n","         231       1.00      1.00      1.00         6\n","         232       0.00      0.00      0.00         8\n","         233       0.00      0.00      0.00        10\n","         234       0.15      1.00      0.26         4\n","         235       1.00      1.00      1.00         8\n","         236       0.00      0.00      0.00         9\n","         237       0.00      0.00      0.00         8\n","         238       0.00      0.00      0.00        10\n","         239       0.16      1.00      0.27         9\n","         240       1.00      1.00      1.00         7\n","         241       0.22      1.00      0.36         8\n","         242       0.00      0.00      0.00         6\n","         243       0.00      0.00      0.00         7\n","         244       0.00      0.00      0.00         9\n","         245       0.00      0.00      0.00         7\n","         246       0.00      0.00      0.00         9\n","         247       0.00      0.00      0.00         7\n","         248       0.59      1.00      0.74        10\n","         249       0.00      0.00      0.00        10\n","         250       0.00      0.00      0.00         7\n","         251       1.00      1.00      1.00         6\n","         252       0.00      0.00      0.00        11\n","         253       0.00      0.00      0.00         7\n","         254       1.00      1.00      1.00         8\n","         255       0.00      0.00      0.00         5\n","         256       0.00      0.00      0.00         7\n","         257       1.00      1.00      1.00         9\n","         258       0.15      1.00      0.26         6\n","         259       0.00      0.00      0.00         3\n","         260       0.00      0.00      0.00         4\n","         261       0.00      0.00      0.00         2\n","         262       0.00      0.00      0.00         5\n","         263       0.00      0.00      0.00        12\n","         264       1.00      1.00      1.00         5\n","         265       1.00      1.00      1.00         7\n","         266       0.00      0.00      0.00        10\n","         267       0.73      1.00      0.84         8\n","         268       0.00      0.00      0.00         9\n","         269       0.00      0.00      0.00         6\n","         270       0.00      0.00      0.00         4\n","         271       0.00      0.00      0.00         7\n","         272       0.00      0.00      0.00        10\n","         273       0.23      1.00      0.38         3\n","         274       0.00      0.00      0.00         9\n","         275       0.60      1.00      0.75         6\n","         276       0.26      1.00      0.42         5\n","         277       0.00      0.00      0.00         4\n","         278       0.00      0.00      0.00         3\n","         279       0.50      1.00      0.67         4\n","         280       0.00      0.00      0.00         5\n","         281       0.00      0.00      0.00         6\n","         282       0.00      0.00      0.00        11\n","         283       0.50      1.00      0.67         6\n","         284       0.00      0.00      0.00         2\n","         285       0.00      0.00      0.00         4\n","         286       1.00      1.00      1.00         7\n","         287       0.00      0.00      0.00         9\n","         288       0.00      0.00      0.00         7\n","         289       1.00      1.00      1.00         7\n","         290       0.00      0.00      0.00         6\n","         291       0.00      0.00      0.00         5\n","         292       0.00      0.00      0.00         6\n","         293       0.00      0.00      0.00         8\n","         294       0.00      0.00      0.00         7\n","         295       0.00      0.00      0.00         3\n","         296       0.00      0.00      0.00         6\n","         297       1.00      1.00      1.00         8\n","         298       0.00      0.00      0.00         4\n","         299       0.00      0.00      0.00         6\n","         300       0.00      0.00      0.00         5\n","         301       0.00      0.00      0.00         5\n","         302       0.00      0.00      0.00         5\n","         303       1.00      1.00      1.00         2\n","         304       0.00      0.00      0.00         8\n","         305       0.20      1.00      0.33         3\n","         306       0.75      1.00      0.86         6\n","         307       0.00      0.00      0.00         7\n","         308       0.00      0.00      0.00         4\n","         309       1.00      1.00      1.00         4\n","         310       0.00      0.00      0.00         9\n","         311       0.00      0.00      0.00         7\n","         312       0.00      0.00      0.00         6\n","         313       0.00      0.00      0.00         6\n","         314       0.00      0.00      0.00         8\n","         315       0.00      0.00      0.00         7\n","         316       0.00      0.00      0.00         3\n","         317       0.00      0.00      0.00         6\n","         318       0.00      0.00      0.00        10\n","         319       0.19      1.00      0.32         6\n","         320       0.00      0.00      0.00         2\n","         321       0.00      0.00      0.00         8\n","         322       0.00      0.00      0.00         4\n","         323       0.00      0.00      0.00         4\n","         324       0.00      0.00      0.00         8\n","         325       0.00      0.00      0.00         4\n","         326       0.00      0.00      0.00         7\n","         327       0.00      0.00      0.00         4\n","         328       0.00      0.00      0.00         6\n","         329       0.00      0.00      0.00         4\n","         330       0.00      0.00      0.00         3\n","         331       0.00      0.00      0.00         8\n","         332       0.00      0.00      0.00         1\n","         333       0.00      0.00      0.00         3\n","         334       0.00      0.00      0.00         4\n","         335       1.00      1.00      1.00         3\n","         336       0.00      0.00      0.00         6\n","         337       0.00      0.00      0.00         2\n","         338       0.00      0.00      0.00         7\n","         339       0.00      0.00      0.00         4\n","         340       0.00      0.00      0.00         6\n","         341       0.00      0.00      0.00         7\n","         342       0.00      0.00      0.00         2\n","         343       0.00      0.00      0.00         5\n","         344       0.00      0.00      0.00         4\n","         345       0.00      0.00      0.00         1\n","         346       0.00      0.00      0.00         2\n","         347       0.00      0.00      0.00         4\n","         348       0.00      0.00      0.00         7\n","         349       0.00      0.00      0.00         4\n","         350       0.00      0.00      0.00         6\n","         351       0.00      0.00      0.00         4\n","         352       0.00      0.00      0.00         5\n","         353       0.00      0.00      0.00         4\n","         354       0.00      0.00      0.00         3\n","         355       0.00      0.00      0.00         1\n","         356       0.00      0.00      0.00         4\n","         357       0.00      0.00      0.00         1\n","         358       0.00      0.00      0.00         3\n","         359       0.00      0.00      0.00         4\n","         360       0.00      0.00      0.00         3\n","         361       0.00      0.00      0.00         3\n","         362       0.00      0.00      0.00         3\n","         363       0.00      0.00      0.00         2\n","         364       0.00      0.00      0.00         3\n","         365       0.00      0.00      0.00         3\n","         366       0.00      0.00      0.00         2\n","         367       0.00      0.00      0.00         3\n","         368       0.00      0.00      0.00         1\n","         369       1.00      1.00      1.00         2\n","         370       0.00      0.00      0.00         2\n","         371       0.00      0.00      0.00         0\n","         372       0.00      0.00      0.00         4\n","\n","    accuracy                           0.86     13567\n","   macro avg       0.41      0.50      0.44     13567\n","weighted avg       0.80      0.86      0.82     13567\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/usr/local/lib/python3.9/dist-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["#Select only the optimal number of input features for X_test\n","X_test = X_test[:,:(best_model_index+1)]\n","\n","# Evaluate the best model on the test data\n","y_pred = best_model.predict(X_test)\n","\n","# np.argmax() is used to convert the one-hot encoded predictions and test labels to class labels.\n","y_pred_label = np.argmax(y_pred, axis = 1)\n","\n","# Print the classification report\n","print(\"Classification report:\\n\", classification_report(y_test_enc, y_pred_label))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"zbyINa_nQsY4","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682314539362,"user_tz":-480,"elapsed":54,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"ecb1eb00-ef93-4eb3-eb54-a3de24ee93e7"},"outputs":[{"output_type":"stream","name":"stdout","text":["           OsID  True Class  Predicted Class  True/False\n","0  Os04g0475500         328              239       False\n","1  Os04g0659100         161              161        True\n","2  Os01g0686800          17               17        True\n","3  Os04g0107900          34               34        True\n","4  Os04g0517100           7                7        True\n"]}],"source":["# extract class labels from test data\n","class_test = y_test_enc\n","\n","# Invert OsID_labels dictionary\n","inv_OsID_labels = {v: k for k, v in OsID_labels.items()}\n","\n","# map OsID values to the class labels\n","OsID_test = [inv_OsID_labels.get(value, 'Unknown') for value in class_test]\n","\n","# create dataframe with OsID, true class, predicted class, and true/false columns\n","results = pd.DataFrame({\n","    'OsID': OsID_test,\n","    'True Class': y_test_enc,\n","    'Predicted Class': y_pred_label,\n","    'True/False': class_test == y_pred_label\n","})\n","\n","# display dataframe\n","print(results.head())\n","\n","# save results_df to a CSV file\n","results.to_csv('MLP_gene classification.csv', index=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"l2lvuFxIN3QQ","colab":{"base_uri":"https://localhost:8080/","height":676},"executionInfo":{"status":"ok","timestamp":1682314539364,"user_tz":-480,"elapsed":35,"user":{"displayName":"chong yoongsim","userId":"18145963220657887961"}},"outputId":"894a2d34-2b3f-4376-a9b8-f6c9b9f20aa5"},"outputs":[{"output_type":"display_data","data":{"text/plain":["    No of input features  Model accuracy\n","0                      1           0.423\n","1                      2           0.709\n","2                      3           0.750\n","3                      4           0.796\n","4                      5           0.814\n","5                      6           0.825\n","6                      7           0.817\n","7                      8           0.827\n","8                      9           0.835\n","9                     10           0.862\n","10                    11           0.848\n","11                    12           0.846\n","12                    13           0.857\n","13                    14           0.845\n","14                    15           0.848\n","15                    16           0.824\n","16                    17           0.744\n","17                    18           0.733\n","18                    19           0.721\n","19                    20           0.707"],"text/html":["\n","  <div id=\"df-749d9b4b-340b-4546-a400-e14728320be7\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>No of input features</th>\n","      <th>Model accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.423</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.709</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.750</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.796</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.814</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.825</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.817</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.827</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>0.835</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>0.862</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0.848</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>0.846</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0.857</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.845</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>0.848</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>0.824</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>0.744</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>0.733</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>0.721</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>0.707</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-749d9b4b-340b-4546-a400-e14728320be7')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-749d9b4b-340b-4546-a400-e14728320be7 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-749d9b4b-340b-4546-a400-e14728320be7');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{}}],"source":["display(models_df)"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.0"},"vscode":{"interpreter":{"hash":"54645332476aec3a1589d49135d9c8280fdb5d7db877f5b7af7a1b58b8f996bc"}}},"nbformat":4,"nbformat_minor":0}