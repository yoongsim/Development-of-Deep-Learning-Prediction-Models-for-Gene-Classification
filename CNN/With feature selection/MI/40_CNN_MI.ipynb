{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5905,"status":"ok","timestamp":1682739389732,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"UsLpi_0MmZ9Z"},"outputs":[],"source":["from itertools import cycle\n","\n","import numpy as np\n","import pandas as pd \n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Model ,Sequential #for CNN\n","from keras.layers import Dense \n","from sklearn.model_selection import KFold\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from keras.layers import Conv2D, Input, MaxPooling2D, Dropout, Flatten, Dense, Activation\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.model_selection import StratifiedKFold\n","from keras import regularizers"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1682739389734,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"B95hUV4pmZ9g"},"outputs":[],"source":["#fixed random seed for reproducibility \n","np.random.seed(0)"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":238974,"status":"ok","timestamp":1682739628693,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"EECGNCI3mZ9i","outputId":"7a2768e1-3a29-4fbc-bb15-15b09b57c30c"},"outputs":[],"source":["# load dataset (input variables = X, output variables = Y)\n","df = pd.read_csv(\"TrainingData.csv\")\n","\n","#count the number of occurances for each osID\n","OsID_counts = df['OsID'].value_counts()\n","\n","#filter for osIDs that have 10 or more occurances\n","OsID_counts_filtered = OsID_counts[OsID_counts >= 10]\n","\n","#assign a label for each osID \n","OsID_labels = {}\n","class_no = 1\n","for osID in OsID_counts_filtered.index:\n","    OsID_labels[osID] = class_no\n","    class_no +=1\n","\n","#filter the dataset with osID that contain 10 or more occurances\n","dataGene = df[df['OsID'].isin(OsID_counts_filtered.index)]\n","\n","dataGene = dataGene.drop(['Class', 'Trait'],axis=1)\n","\n","# Add a new column 'class' to the filtered dataset\n","dataGene['class'] = dataGene['OsID'].map(OsID_labels)\n","\n","#print(\"Summary of dataGene:\\n\",dataGene.describe())"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1682739628694,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"Vuf_bBJBUC1h","outputId":"6735bffa-c3c0-466f-d672-34d142eaba7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X:\n"," (41110, 20)\n","Shape of Y:\n"," (41110,)\n","class\n","1.0      1800\n","2.0      1296\n","3.0      1260\n","4.0      1218\n","5.0      1026\n","6.0      1008\n","7.0       930\n","8.0       912\n","9.0       880\n","10.0      798\n","11.0      792\n","12.0      759\n","13.0      729\n","14.0      720\n","15.0      702\n","16.0      693\n","17.0      672\n","18.0      640\n","19.0      625\n","20.0      570\n","21.0      546\n","22.0      506\n","23.0      483\n","24.0      448\n","25.0      432\n","26.0      384\n","27.0      360\n","28.0      360\n","29.0      320\n","30.0      312\n","         ... \n","344.0      12\n","345.0      12\n","346.0      12\n","347.0      12\n","348.0      12\n","349.0      12\n","350.0      12\n","351.0      12\n","352.0      12\n","353.0      12\n","354.0      12\n","355.0      12\n","356.0      11\n","357.0      11\n","358.0      11\n","359.0      11\n","360.0      11\n","361.0      11\n","362.0      10\n","363.0      10\n","364.0      10\n","365.0      10\n","366.0      10\n","367.0      10\n","368.0      10\n","369.0      10\n","370.0      10\n","371.0      10\n","372.0      10\n","373.0      10\n","Length: 373, dtype: int64\n"]}],"source":["X = dataGene.drop(['class','OsID'], axis=1) # exclude class & OsID column\n","Y = dataGene['class']\n","\n","#input feature names in order of descending importance scores in MI feature selection method\n","feature_names = ['Root10DaysSeedling', 'Shoot10DaysSeedling', 'Root35DaysSeedling', 'Leaf45DaysOldPlant', 'Shoot35DaysSeedling', \n","                 'Root14DaysSeedling', 'Root24DaysSeedling', 'Root17DaysSeedling', 'Root21DaysSeedling', 'Shoot3DaysSeedling', \n","                 'Shoot21DaysSeedling', 'PCC', 'Shoot14DaysSeedling', 'Root52DaysSeedling', 'Shoot17DaysSeedling', \n","                 'Leaf21DaysSeedling', 'log_2FoldChange', 'ET', 'PPI', 'CoExpression' ]\n","\n","X_fs = X.reindex(columns=feature_names)\n","\n","print(\"Shape of X:\\n\",X_fs.shape)\n","print(\"Shape of Y:\\n\",Y.shape)\n","\n","# Statistical summary of the variables\n","#print(\"Summary of X:\\n\",X_fs.describe())\n","#print(\"Summary of Y:\\n\",Y.describe())\n","\n","# Check for class imbalance\n","print(df.groupby(Y).size())\n","\n","# change both input and target variables datatype to ndarray\n","X_fs = X_fs.values # 2-D array\n","\n","# select target variable \n","\n","Y = Y.values #1-D array\n","Y = Y.reshape(-1, 1)"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1590,"status":"ok","timestamp":1682739630270,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"W5zIyx8RVDJu","outputId":"3b50bdef-9a58-4044-b5db-65745e766b49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Class=0, n=1800 (4.378%)\n","Class=1, n=1296 (3.153%)\n","Class=2, n=1260 (3.065%)\n","Class=3, n=1218 (2.963%)\n","Class=4, n=1026 (2.496%)\n","Class=5, n=1008 (2.452%)\n","Class=6, n=930 (2.262%)\n","Class=7, n=912 (2.218%)\n","Class=8, n=880 (2.141%)\n","Class=9, n=798 (1.941%)\n","Class=10, n=792 (1.927%)\n","Class=11, n=759 (1.846%)\n","Class=12, n=729 (1.773%)\n","Class=13, n=720 (1.751%)\n","Class=14, n=702 (1.708%)\n","Class=15, n=693 (1.686%)\n","Class=16, n=672 (1.635%)\n","Class=17, n=640 (1.557%)\n","Class=18, n=625 (1.520%)\n","Class=19, n=570 (1.387%)\n","Class=20, n=546 (1.328%)\n","Class=21, n=506 (1.231%)\n","Class=22, n=483 (1.175%)\n","Class=23, n=448 (1.090%)\n","Class=24, n=432 (1.051%)\n","Class=25, n=384 (0.934%)\n","Class=26, n=360 (0.876%)\n","Class=27, n=360 (0.876%)\n","Class=28, n=320 (0.778%)\n","Class=29, n=312 (0.759%)\n","Class=30, n=312 (0.759%)\n","Class=31, n=306 (0.744%)\n","Class=32, n=304 (0.739%)\n","Class=33, n=299 (0.727%)\n","Class=34, n=297 (0.722%)\n","Class=35, n=296 (0.720%)\n","Class=36, n=280 (0.681%)\n","Class=37, n=264 (0.642%)\n","Class=38, n=260 (0.632%)\n","Class=39, n=253 (0.615%)\n","Class=40, n=252 (0.613%)\n","Class=41, n=248 (0.603%)\n","Class=42, n=242 (0.589%)\n","Class=43, n=228 (0.555%)\n","Class=44, n=216 (0.525%)\n","Class=45, n=210 (0.511%)\n","Class=46, n=200 (0.486%)\n","Class=47, n=192 (0.467%)\n","Class=48, n=180 (0.438%)\n","Class=49, n=171 (0.416%)\n","Class=50, n=168 (0.409%)\n","Class=51, n=168 (0.409%)\n","Class=52, n=162 (0.394%)\n","Class=53, n=150 (0.365%)\n","Class=54, n=148 (0.360%)\n","Class=55, n=138 (0.336%)\n","Class=56, n=135 (0.328%)\n","Class=57, n=135 (0.328%)\n","Class=58, n=133 (0.324%)\n","Class=59, n=132 (0.321%)\n","Class=60, n=132 (0.321%)\n","Class=61, n=130 (0.316%)\n","Class=62, n=130 (0.316%)\n","Class=63, n=130 (0.316%)\n","Class=64, n=128 (0.311%)\n","Class=65, n=128 (0.311%)\n","Class=66, n=126 (0.306%)\n","Class=67, n=124 (0.302%)\n","Class=68, n=124 (0.302%)\n","Class=69, n=124 (0.302%)\n","Class=70, n=120 (0.292%)\n","Class=71, n=120 (0.292%)\n","Class=72, n=118 (0.287%)\n","Class=73, n=116 (0.282%)\n","Class=74, n=114 (0.277%)\n","Class=75, n=105 (0.255%)\n","Class=76, n=104 (0.253%)\n","Class=77, n=102 (0.248%)\n","Class=78, n=99 (0.241%)\n","Class=79, n=98 (0.238%)\n","Class=80, n=98 (0.238%)\n","Class=81, n=98 (0.238%)\n","Class=82, n=98 (0.238%)\n","Class=83, n=96 (0.234%)\n","Class=84, n=96 (0.234%)\n","Class=85, n=96 (0.234%)\n","Class=86, n=93 (0.226%)\n","Class=87, n=92 (0.224%)\n","Class=88, n=92 (0.224%)\n","Class=89, n=91 (0.221%)\n","Class=90, n=88 (0.214%)\n","Class=91, n=88 (0.214%)\n","Class=92, n=86 (0.209%)\n","Class=93, n=86 (0.209%)\n","Class=94, n=84 (0.204%)\n","Class=95, n=84 (0.204%)\n","Class=96, n=84 (0.204%)\n","Class=97, n=78 (0.190%)\n","Class=98, n=78 (0.190%)\n","Class=99, n=76 (0.185%)\n","Class=100, n=75 (0.182%)\n","Class=101, n=75 (0.182%)\n","Class=102, n=73 (0.178%)\n","Class=103, n=72 (0.175%)\n","Class=104, n=72 (0.175%)\n","Class=105, n=70 (0.170%)\n","Class=106, n=69 (0.168%)\n","Class=107, n=68 (0.165%)\n","Class=108, n=67 (0.163%)\n","Class=109, n=66 (0.161%)\n","Class=110, n=66 (0.161%)\n","Class=111, n=66 (0.161%)\n","Class=112, n=66 (0.161%)\n","Class=113, n=66 (0.161%)\n","Class=114, n=65 (0.158%)\n","Class=115, n=64 (0.156%)\n","Class=116, n=63 (0.153%)\n","Class=117, n=63 (0.153%)\n","Class=118, n=62 (0.151%)\n","Class=119, n=61 (0.148%)\n","Class=120, n=60 (0.146%)\n","Class=121, n=60 (0.146%)\n","Class=122, n=60 (0.146%)\n","Class=123, n=60 (0.146%)\n","Class=124, n=60 (0.146%)\n","Class=125, n=60 (0.146%)\n","Class=126, n=60 (0.146%)\n","Class=127, n=60 (0.146%)\n","Class=128, n=60 (0.146%)\n","Class=129, n=60 (0.146%)\n","Class=130, n=59 (0.144%)\n","Class=131, n=59 (0.144%)\n","Class=132, n=58 (0.141%)\n","Class=133, n=56 (0.136%)\n","Class=134, n=56 (0.136%)\n","Class=135, n=56 (0.136%)\n","Class=136, n=56 (0.136%)\n","Class=137, n=56 (0.136%)\n","Class=138, n=56 (0.136%)\n","Class=139, n=56 (0.136%)\n","Class=140, n=56 (0.136%)\n","Class=141, n=56 (0.136%)\n","Class=142, n=55 (0.134%)\n","Class=143, n=55 (0.134%)\n","Class=144, n=54 (0.131%)\n","Class=145, n=54 (0.131%)\n","Class=146, n=54 (0.131%)\n","Class=147, n=54 (0.131%)\n","Class=148, n=54 (0.131%)\n","Class=149, n=53 (0.129%)\n","Class=150, n=52 (0.126%)\n","Class=151, n=52 (0.126%)\n","Class=152, n=52 (0.126%)\n","Class=153, n=52 (0.126%)\n","Class=154, n=50 (0.122%)\n","Class=155, n=50 (0.122%)\n","Class=156, n=49 (0.119%)\n","Class=157, n=49 (0.119%)\n","Class=158, n=48 (0.117%)\n","Class=159, n=48 (0.117%)\n","Class=160, n=48 (0.117%)\n","Class=161, n=46 (0.112%)\n","Class=162, n=45 (0.109%)\n","Class=163, n=44 (0.107%)\n","Class=164, n=44 (0.107%)\n","Class=165, n=44 (0.107%)\n","Class=166, n=42 (0.102%)\n","Class=167, n=42 (0.102%)\n","Class=168, n=42 (0.102%)\n","Class=169, n=42 (0.102%)\n","Class=170, n=42 (0.102%)\n","Class=171, n=42 (0.102%)\n","Class=172, n=42 (0.102%)\n","Class=173, n=41 (0.100%)\n","Class=174, n=41 (0.100%)\n","Class=175, n=40 (0.097%)\n","Class=176, n=40 (0.097%)\n","Class=177, n=39 (0.095%)\n","Class=178, n=39 (0.095%)\n","Class=179, n=38 (0.092%)\n","Class=180, n=37 (0.090%)\n","Class=181, n=36 (0.088%)\n","Class=182, n=35 (0.085%)\n","Class=183, n=35 (0.085%)\n","Class=184, n=35 (0.085%)\n","Class=185, n=35 (0.085%)\n","Class=186, n=34 (0.083%)\n","Class=187, n=34 (0.083%)\n","Class=188, n=34 (0.083%)\n","Class=189, n=34 (0.083%)\n","Class=190, n=32 (0.078%)\n","Class=191, n=32 (0.078%)\n","Class=192, n=32 (0.078%)\n","Class=193, n=32 (0.078%)\n","Class=194, n=32 (0.078%)\n","Class=195, n=32 (0.078%)\n","Class=196, n=31 (0.075%)\n","Class=197, n=31 (0.075%)\n","Class=198, n=31 (0.075%)\n","Class=199, n=31 (0.075%)\n","Class=200, n=30 (0.073%)\n","Class=201, n=30 (0.073%)\n","Class=202, n=30 (0.073%)\n","Class=203, n=30 (0.073%)\n","Class=204, n=30 (0.073%)\n","Class=205, n=30 (0.073%)\n","Class=206, n=30 (0.073%)\n","Class=207, n=30 (0.073%)\n","Class=208, n=30 (0.073%)\n","Class=209, n=29 (0.071%)\n","Class=210, n=29 (0.071%)\n","Class=211, n=28 (0.068%)\n","Class=212, n=28 (0.068%)\n","Class=213, n=28 (0.068%)\n","Class=214, n=28 (0.068%)\n","Class=215, n=28 (0.068%)\n","Class=216, n=28 (0.068%)\n","Class=217, n=27 (0.066%)\n","Class=218, n=27 (0.066%)\n","Class=219, n=27 (0.066%)\n","Class=220, n=27 (0.066%)\n","Class=221, n=27 (0.066%)\n","Class=222, n=27 (0.066%)\n","Class=223, n=26 (0.063%)\n","Class=224, n=26 (0.063%)\n","Class=225, n=26 (0.063%)\n","Class=226, n=26 (0.063%)\n","Class=227, n=26 (0.063%)\n","Class=228, n=25 (0.061%)\n","Class=229, n=25 (0.061%)\n","Class=230, n=25 (0.061%)\n","Class=231, n=25 (0.061%)\n","Class=232, n=24 (0.058%)\n","Class=233, n=24 (0.058%)\n","Class=234, n=24 (0.058%)\n","Class=235, n=24 (0.058%)\n","Class=236, n=24 (0.058%)\n","Class=237, n=24 (0.058%)\n","Class=238, n=24 (0.058%)\n","Class=239, n=24 (0.058%)\n","Class=240, n=24 (0.058%)\n","Class=241, n=24 (0.058%)\n","Class=242, n=24 (0.058%)\n","Class=243, n=24 (0.058%)\n","Class=244, n=23 (0.056%)\n","Class=245, n=23 (0.056%)\n","Class=246, n=22 (0.054%)\n","Class=247, n=22 (0.054%)\n","Class=248, n=22 (0.054%)\n","Class=249, n=22 (0.054%)\n","Class=250, n=22 (0.054%)\n","Class=251, n=22 (0.054%)\n","Class=252, n=22 (0.054%)\n","Class=253, n=22 (0.054%)\n","Class=254, n=22 (0.054%)\n","Class=255, n=22 (0.054%)\n","Class=256, n=22 (0.054%)\n","Class=257, n=22 (0.054%)\n","Class=258, n=22 (0.054%)\n","Class=259, n=22 (0.054%)\n","Class=260, n=22 (0.054%)\n","Class=261, n=22 (0.054%)\n","Class=262, n=22 (0.054%)\n","Class=263, n=22 (0.054%)\n","Class=264, n=21 (0.051%)\n","Class=265, n=21 (0.051%)\n","Class=266, n=21 (0.051%)\n","Class=267, n=21 (0.051%)\n","Class=268, n=21 (0.051%)\n","Class=269, n=20 (0.049%)\n","Class=270, n=20 (0.049%)\n","Class=271, n=20 (0.049%)\n","Class=272, n=20 (0.049%)\n","Class=273, n=20 (0.049%)\n","Class=274, n=20 (0.049%)\n","Class=275, n=20 (0.049%)\n","Class=276, n=20 (0.049%)\n","Class=277, n=20 (0.049%)\n","Class=278, n=20 (0.049%)\n","Class=279, n=20 (0.049%)\n","Class=280, n=19 (0.046%)\n","Class=281, n=19 (0.046%)\n","Class=282, n=19 (0.046%)\n","Class=283, n=18 (0.044%)\n","Class=284, n=18 (0.044%)\n","Class=285, n=18 (0.044%)\n","Class=286, n=18 (0.044%)\n","Class=287, n=18 (0.044%)\n","Class=288, n=18 (0.044%)\n","Class=289, n=18 (0.044%)\n","Class=290, n=18 (0.044%)\n","Class=291, n=18 (0.044%)\n","Class=292, n=17 (0.041%)\n","Class=293, n=17 (0.041%)\n","Class=294, n=17 (0.041%)\n","Class=295, n=17 (0.041%)\n","Class=296, n=17 (0.041%)\n","Class=297, n=17 (0.041%)\n","Class=298, n=16 (0.039%)\n","Class=299, n=16 (0.039%)\n","Class=300, n=16 (0.039%)\n","Class=301, n=16 (0.039%)\n","Class=302, n=16 (0.039%)\n","Class=303, n=16 (0.039%)\n","Class=304, n=16 (0.039%)\n","Class=305, n=16 (0.039%)\n","Class=306, n=15 (0.036%)\n","Class=307, n=15 (0.036%)\n","Class=308, n=15 (0.036%)\n","Class=309, n=15 (0.036%)\n","Class=310, n=15 (0.036%)\n","Class=311, n=14 (0.034%)\n","Class=312, n=14 (0.034%)\n","Class=313, n=14 (0.034%)\n","Class=314, n=14 (0.034%)\n","Class=315, n=14 (0.034%)\n","Class=316, n=14 (0.034%)\n","Class=317, n=14 (0.034%)\n","Class=318, n=14 (0.034%)\n","Class=319, n=14 (0.034%)\n","Class=320, n=14 (0.034%)\n","Class=321, n=14 (0.034%)\n","Class=322, n=14 (0.034%)\n","Class=323, n=14 (0.034%)\n","Class=324, n=14 (0.034%)\n","Class=325, n=14 (0.034%)\n","Class=326, n=14 (0.034%)\n","Class=327, n=14 (0.034%)\n","Class=328, n=13 (0.032%)\n","Class=329, n=13 (0.032%)\n","Class=330, n=13 (0.032%)\n","Class=331, n=13 (0.032%)\n","Class=332, n=13 (0.032%)\n","Class=333, n=13 (0.032%)\n","Class=334, n=13 (0.032%)\n","Class=335, n=13 (0.032%)\n","Class=336, n=13 (0.032%)\n","Class=337, n=12 (0.029%)\n","Class=338, n=12 (0.029%)\n","Class=339, n=12 (0.029%)\n","Class=340, n=12 (0.029%)\n","Class=341, n=12 (0.029%)\n","Class=342, n=12 (0.029%)\n","Class=343, n=12 (0.029%)\n","Class=344, n=12 (0.029%)\n","Class=345, n=12 (0.029%)\n","Class=346, n=12 (0.029%)\n","Class=347, n=12 (0.029%)\n","Class=348, n=12 (0.029%)\n","Class=349, n=12 (0.029%)\n","Class=350, n=12 (0.029%)\n","Class=351, n=12 (0.029%)\n","Class=352, n=12 (0.029%)\n","Class=353, n=12 (0.029%)\n","Class=354, n=12 (0.029%)\n","Class=355, n=11 (0.027%)\n","Class=356, n=11 (0.027%)\n","Class=357, n=11 (0.027%)\n","Class=358, n=11 (0.027%)\n","Class=359, n=11 (0.027%)\n","Class=360, n=11 (0.027%)\n","Class=361, n=10 (0.024%)\n","Class=362, n=10 (0.024%)\n","Class=363, n=10 (0.024%)\n","Class=364, n=10 (0.024%)\n","Class=365, n=10 (0.024%)\n","Class=366, n=10 (0.024%)\n","Class=367, n=10 (0.024%)\n","Class=368, n=10 (0.024%)\n","Class=369, n=10 (0.024%)\n","Class=370, n=10 (0.024%)\n","Class=371, n=10 (0.024%)\n","Class=372, n=10 (0.024%)\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["y_labelenc = LabelEncoder().fit_transform(Y)\n","\n","from collections import Counter\n","# summarize distribution\n","counter = Counter(y_labelenc)\n","\n","# sort counter by keys\n","counter = dict(sorted(counter.items()))\n","\n","\n","for k,v in counter.items():\n"," per = v / len(y_labelenc) * 100\n"," print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n","# plot the distribution\n","plt.bar( counter.keys(), counter.values())\n","\n","plt.ylabel('No of gene samples')\n","plt.xlabel('Class Index of OsID')\n","plt.title('Distribution of Target Classes (OsID)')\n","plt.show()"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682739630271,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"W1WdWupjmZ9l"},"outputs":[],"source":["# prepare target data\n","def prepare_targets(y_train, y_test):\n","\tle = LabelEncoder()\n","\t\n","\t#fit the encoders only to the training data and then transform both train and test data\n","\ty_train_enc = le.fit_transform(y_train)\n","\ty_test_enc = le.transform(y_test)\n","\n","\treturn y_train_enc, y_test_enc"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682739630271,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"JjjBaPUOtmlx","outputId":"10ebe3b7-e849-4104-fd5e-871649020289"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_fs, Y, test_size=0.33, random_state=1)\n","\n","# prepare output data\n","y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POiHy56emZ9m","outputId":"b45f4937-b684-42aa-ac0f-fbc0d3e6edb4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of input features: 1\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.7043 - accuracy: 0.0813 - val_loss: 4.2710 - val_accuracy: 0.1155\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.9560 - accuracy: 0.1448 - val_loss: 3.8933 - val_accuracy: 0.1325\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.5965 - accuracy: 0.2008 - val_loss: 3.5625 - val_accuracy: 0.2491\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.2725 - accuracy: 0.2628 - val_loss: 3.2919 - val_accuracy: 0.2488\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0062 - accuracy: 0.3018 - val_loss: 3.0654 - val_accuracy: 0.2788\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.8087 - accuracy: 0.3386 - val_loss: 2.9694 - val_accuracy: 0.3105\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6625 - accuracy: 0.3604 - val_loss: 2.7865 - val_accuracy: 0.3476\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5432 - accuracy: 0.3867 - val_loss: 2.6913 - val_accuracy: 0.3703\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4491 - accuracy: 0.3927 - val_loss: 2.6084 - val_accuracy: 0.4106\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3728 - accuracy: 0.4114 - val_loss: 2.5888 - val_accuracy: 0.4172\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3138 - accuracy: 0.4093 - val_loss: 2.5480 - val_accuracy: 0.3597\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2528 - accuracy: 0.4252 - val_loss: 2.5533 - val_accuracy: 0.3809\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2144 - accuracy: 0.4287 - val_loss: 2.4496 - val_accuracy: 0.4246\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1734 - accuracy: 0.4326 - val_loss: 2.4043 - val_accuracy: 0.4271\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1484 - accuracy: 0.4387 - val_loss: 2.3856 - val_accuracy: 0.4279\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1125 - accuracy: 0.4400 - val_loss: 2.3558 - val_accuracy: 0.4387\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0887 - accuracy: 0.4456 - val_loss: 2.3812 - val_accuracy: 0.4596\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0614 - accuracy: 0.4559 - val_loss: 2.3774 - val_accuracy: 0.4202\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0460 - accuracy: 0.4553 - val_loss: 2.3468 - val_accuracy: 0.4163\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0399 - accuracy: 0.4499 - val_loss: 2.3437 - val_accuracy: 0.4255\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0051 - accuracy: 0.4640 - val_loss: 2.2851 - val_accuracy: 0.4473\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0000 - accuracy: 0.4638 - val_loss: 2.2955 - val_accuracy: 0.4700\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9848 - accuracy: 0.4667 - val_loss: 2.2743 - val_accuracy: 0.4684\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9754 - accuracy: 0.4615 - val_loss: 2.3234 - val_accuracy: 0.4174\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9692 - accuracy: 0.4688 - val_loss: 2.2182 - val_accuracy: 0.4416\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9448 - accuracy: 0.4703 - val_loss: 2.2535 - val_accuracy: 0.4616\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9418 - accuracy: 0.4768 - val_loss: 2.2817 - val_accuracy: 0.4449\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9375 - accuracy: 0.4772 - val_loss: 2.2139 - val_accuracy: 0.4185\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9209 - accuracy: 0.4749 - val_loss: 2.2348 - val_accuracy: 0.4700\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9286 - accuracy: 0.4736 - val_loss: 2.1618 - val_accuracy: 0.4882\n","Epoch 31/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.9200 - accuracy: 0.4759 - val_loss: 2.2000 - val_accuracy: 0.4887\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9105 - accuracy: 0.4782 - val_loss: 2.1619 - val_accuracy: 0.4854\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8939 - accuracy: 0.4793 - val_loss: 2.1930 - val_accuracy: 0.4656\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8852 - accuracy: 0.4822 - val_loss: 2.1539 - val_accuracy: 0.4959\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8837 - accuracy: 0.4808 - val_loss: 2.1667 - val_accuracy: 0.4656\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8828 - accuracy: 0.4842 - val_loss: 2.2159 - val_accuracy: 0.4246\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8728 - accuracy: 0.4833 - val_loss: 2.1687 - val_accuracy: 0.4992\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8625 - accuracy: 0.4895 - val_loss: 2.2673 - val_accuracy: 0.4392\n","Epoch 39/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.8715 - accuracy: 0.4832 - val_loss: 2.1328 - val_accuracy: 0.4953\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 1.8514 - accuracy: 0.4902 - val_loss: 2.1793 - val_accuracy: 0.5182\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 7s 3ms/step - loss: 4.9410 - accuracy: 0.0534 - val_loss: 4.6152 - val_accuracy: 0.0768\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.2301 - accuracy: 0.1112 - val_loss: 4.1314 - val_accuracy: 0.1683\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.8045 - accuracy: 0.1607 - val_loss: 3.8466 - val_accuracy: 0.1969\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.5011 - accuracy: 0.2139 - val_loss: 3.6043 - val_accuracy: 0.2233\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.2478 - accuracy: 0.2442 - val_loss: 3.4293 - val_accuracy: 0.3003\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0463 - accuracy: 0.2758 - val_loss: 3.2672 - val_accuracy: 0.2625\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.8828 - accuracy: 0.3103 - val_loss: 3.1621 - val_accuracy: 0.2891\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7428 - accuracy: 0.3343 - val_loss: 3.0665 - val_accuracy: 0.3171\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6304 - accuracy: 0.3614 - val_loss: 2.9904 - val_accuracy: 0.3413\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5351 - accuracy: 0.3759 - val_loss: 2.9002 - val_accuracy: 0.4117\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4552 - accuracy: 0.3922 - val_loss: 2.8619 - val_accuracy: 0.3734\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3923 - accuracy: 0.4081 - val_loss: 2.7614 - val_accuracy: 0.3509\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3362 - accuracy: 0.4130 - val_loss: 2.7376 - val_accuracy: 0.4139\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2812 - accuracy: 0.4254 - val_loss: 2.6924 - val_accuracy: 0.4161\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2427 - accuracy: 0.4281 - val_loss: 2.6689 - val_accuracy: 0.3824\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2137 - accuracy: 0.4280 - val_loss: 2.5759 - val_accuracy: 0.4420\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1775 - accuracy: 0.4352 - val_loss: 2.6961 - val_accuracy: 0.3527\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1519 - accuracy: 0.4401 - val_loss: 2.5615 - val_accuracy: 0.4471\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1250 - accuracy: 0.4439 - val_loss: 2.5069 - val_accuracy: 0.4455\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1091 - accuracy: 0.4440 - val_loss: 2.5011 - val_accuracy: 0.3844\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0908 - accuracy: 0.4472 - val_loss: 2.5066 - val_accuracy: 0.4365\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0666 - accuracy: 0.4576 - val_loss: 2.5107 - val_accuracy: 0.4073\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0505 - accuracy: 0.4543 - val_loss: 2.4496 - val_accuracy: 0.4304\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0364 - accuracy: 0.4581 - val_loss: 2.4945 - val_accuracy: 0.4191\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0236 - accuracy: 0.4597 - val_loss: 2.4268 - val_accuracy: 0.4552\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0053 - accuracy: 0.4652 - val_loss: 2.4046 - val_accuracy: 0.4636\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9941 - accuracy: 0.4617 - val_loss: 2.3607 - val_accuracy: 0.4506\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9861 - accuracy: 0.4633 - val_loss: 2.3627 - val_accuracy: 0.4348\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9745 - accuracy: 0.4644 - val_loss: 2.3376 - val_accuracy: 0.4484\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9648 - accuracy: 0.4637 - val_loss: 2.3528 - val_accuracy: 0.4246\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9573 - accuracy: 0.4658 - val_loss: 2.3591 - val_accuracy: 0.4299\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9519 - accuracy: 0.4698 - val_loss: 2.3181 - val_accuracy: 0.4590\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9399 - accuracy: 0.4686 - val_loss: 2.3395 - val_accuracy: 0.4409\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9295 - accuracy: 0.4711 - val_loss: 2.2828 - val_accuracy: 0.4975\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9254 - accuracy: 0.4700 - val_loss: 2.3468 - val_accuracy: 0.4713\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9273 - accuracy: 0.4671 - val_loss: 2.3179 - val_accuracy: 0.4306\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9079 - accuracy: 0.4755 - val_loss: 2.2517 - val_accuracy: 0.5006\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8958 - accuracy: 0.4804 - val_loss: 2.2461 - val_accuracy: 0.4746\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9052 - accuracy: 0.4766 - val_loss: 2.3539 - val_accuracy: 0.4378\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8846 - accuracy: 0.4783 - val_loss: 2.2973 - val_accuracy: 0.4504\n","Average Validation Accuracy: 0.492392435669899\n","Average Validation Loss: 1.9846771955490112\n","Average Test Accuracy: 0.49100758135318756\n","------------------------------------------------------------------------\n","\n","Number of input features: 2\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.6940 - accuracy: 0.0845 - val_loss: 4.1234 - val_accuracy: 0.2070\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.5464 - accuracy: 0.2866 - val_loss: 3.2958 - val_accuracy: 0.3784\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7863 - accuracy: 0.4203 - val_loss: 2.7009 - val_accuracy: 0.4493\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2637 - accuracy: 0.5039 - val_loss: 2.3372 - val_accuracy: 0.5226\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9200 - accuracy: 0.5628 - val_loss: 2.0861 - val_accuracy: 0.5492\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6986 - accuracy: 0.5921 - val_loss: 1.9434 - val_accuracy: 0.5971\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5315 - accuracy: 0.6172 - val_loss: 1.8158 - val_accuracy: 0.6231\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4124 - accuracy: 0.6345 - val_loss: 1.7719 - val_accuracy: 0.6330\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3195 - accuracy: 0.6496 - val_loss: 1.6397 - val_accuracy: 0.6268\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 1.2524 - accuracy: 0.6669 - val_loss: 1.5864 - val_accuracy: 0.6944\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1913 - accuracy: 0.6772 - val_loss: 1.5981 - val_accuracy: 0.6154\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1496 - accuracy: 0.6886 - val_loss: 1.5115 - val_accuracy: 0.7034\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1031 - accuracy: 0.6964 - val_loss: 1.4390 - val_accuracy: 0.7296\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0852 - accuracy: 0.7030 - val_loss: 1.3964 - val_accuracy: 0.7217\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0455 - accuracy: 0.7090 - val_loss: 1.3821 - val_accuracy: 0.7028\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0155 - accuracy: 0.7218 - val_loss: 1.3385 - val_accuracy: 0.7045\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0061 - accuracy: 0.7210 - val_loss: 1.3095 - val_accuracy: 0.7329\n","Epoch 18/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.9699 - accuracy: 0.7323 - val_loss: 1.2788 - val_accuracy: 0.7644\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9532 - accuracy: 0.7341 - val_loss: 1.2793 - val_accuracy: 0.7305\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9359 - accuracy: 0.7394 - val_loss: 1.1974 - val_accuracy: 0.7648\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9451 - accuracy: 0.7392 - val_loss: 1.2782 - val_accuracy: 0.7155\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9048 - accuracy: 0.7493 - val_loss: 1.2178 - val_accuracy: 0.7417\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9034 - accuracy: 0.7464 - val_loss: 1.2821 - val_accuracy: 0.7474\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8914 - accuracy: 0.7528 - val_loss: 1.2230 - val_accuracy: 0.7520\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8789 - accuracy: 0.7508 - val_loss: 1.2768 - val_accuracy: 0.7457\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8675 - accuracy: 0.7567 - val_loss: 1.1982 - val_accuracy: 0.7560\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8475 - accuracy: 0.7591 - val_loss: 1.1339 - val_accuracy: 0.7694\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8408 - accuracy: 0.7617 - val_loss: 1.1595 - val_accuracy: 0.7300\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8381 - accuracy: 0.7598 - val_loss: 1.1834 - val_accuracy: 0.7375\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8286 - accuracy: 0.7667 - val_loss: 1.1017 - val_accuracy: 0.7826\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8275 - accuracy: 0.7649 - val_loss: 1.1611 - val_accuracy: 0.7397\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8185 - accuracy: 0.7691 - val_loss: 1.3988 - val_accuracy: 0.7578\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7972 - accuracy: 0.7748 - val_loss: 1.1551 - val_accuracy: 0.7461\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7975 - accuracy: 0.7710 - val_loss: 1.0425 - val_accuracy: 0.7826\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8025 - accuracy: 0.7730 - val_loss: 1.0456 - val_accuracy: 0.7760\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7924 - accuracy: 0.7738 - val_loss: 1.0697 - val_accuracy: 0.7919\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7847 - accuracy: 0.7776 - val_loss: 1.0772 - val_accuracy: 0.7758\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7707 - accuracy: 0.7809 - val_loss: 1.1001 - val_accuracy: 0.7657\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7927 - accuracy: 0.7749 - val_loss: 1.0014 - val_accuracy: 0.8095\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7712 - accuracy: 0.7807 - val_loss: 1.0547 - val_accuracy: 0.7751\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.4633 - accuracy: 0.1358 - val_loss: 3.7656 - val_accuracy: 0.2554\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.0740 - accuracy: 0.3839 - val_loss: 2.8995 - val_accuracy: 0.4418\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3319 - accuracy: 0.5047 - val_loss: 2.4774 - val_accuracy: 0.5234\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8918 - accuracy: 0.5700 - val_loss: 2.1537 - val_accuracy: 0.5985\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6037 - accuracy: 0.6132 - val_loss: 1.9969 - val_accuracy: 0.6161\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4147 - accuracy: 0.6417 - val_loss: 1.7937 - val_accuracy: 0.6548\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2827 - accuracy: 0.6686 - val_loss: 1.7351 - val_accuracy: 0.6796\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1895 - accuracy: 0.6887 - val_loss: 1.6068 - val_accuracy: 0.7127\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1223 - accuracy: 0.6995 - val_loss: 1.4966 - val_accuracy: 0.7285\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0585 - accuracy: 0.7152 - val_loss: 1.4597 - val_accuracy: 0.7078\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0141 - accuracy: 0.7241 - val_loss: 1.4284 - val_accuracy: 0.7303\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9846 - accuracy: 0.7326 - val_loss: 1.3563 - val_accuracy: 0.7261\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9413 - accuracy: 0.7453 - val_loss: 1.3750 - val_accuracy: 0.6851\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9293 - accuracy: 0.7409 - val_loss: 1.2678 - val_accuracy: 0.7597\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9052 - accuracy: 0.7465 - val_loss: 1.2591 - val_accuracy: 0.7439\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8660 - accuracy: 0.7535 - val_loss: 1.2176 - val_accuracy: 0.7410\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8541 - accuracy: 0.7602 - val_loss: 1.1662 - val_accuracy: 0.7525\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8246 - accuracy: 0.7681 - val_loss: 1.1846 - val_accuracy: 0.7624\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8150 - accuracy: 0.7698 - val_loss: 1.1540 - val_accuracy: 0.7743\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8058 - accuracy: 0.7740 - val_loss: 1.1213 - val_accuracy: 0.7921\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7836 - accuracy: 0.7787 - val_loss: 1.1786 - val_accuracy: 0.7646\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7824 - accuracy: 0.7756 - val_loss: 1.1275 - val_accuracy: 0.7890\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7624 - accuracy: 0.7812 - val_loss: 1.1451 - val_accuracy: 0.7633\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7503 - accuracy: 0.7866 - val_loss: 1.1045 - val_accuracy: 0.7839\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7399 - accuracy: 0.7861 - val_loss: 1.1291 - val_accuracy: 0.7789\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7352 - accuracy: 0.7887 - val_loss: 1.0405 - val_accuracy: 0.8018\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7317 - accuracy: 0.7895 - val_loss: 1.0754 - val_accuracy: 0.7923\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7082 - accuracy: 0.7959 - val_loss: 1.0600 - val_accuracy: 0.8020\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.7010 - accuracy: 0.7974 - val_loss: 1.0103 - val_accuracy: 0.8095\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6971 - accuracy: 0.8006 - val_loss: 1.0348 - val_accuracy: 0.7912\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6815 - accuracy: 0.8047 - val_loss: 1.0042 - val_accuracy: 0.8040\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6802 - accuracy: 0.8034 - val_loss: 1.0553 - val_accuracy: 0.8040\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6807 - accuracy: 0.8030 - val_loss: 0.9970 - val_accuracy: 0.8031\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6688 - accuracy: 0.8032 - val_loss: 0.9844 - val_accuracy: 0.8064\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6685 - accuracy: 0.8050 - val_loss: 1.0542 - val_accuracy: 0.8018\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6575 - accuracy: 0.8086 - val_loss: 0.9828 - val_accuracy: 0.8123\n","Epoch 37/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.6576 - accuracy: 0.8056 - val_loss: 0.9906 - val_accuracy: 0.7718\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6415 - accuracy: 0.8106 - val_loss: 0.9589 - val_accuracy: 0.7916\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6496 - accuracy: 0.8102 - val_loss: 0.9172 - val_accuracy: 0.8405\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6369 - accuracy: 0.8136 - val_loss: 0.9033 - val_accuracy: 0.8200\n","Average Validation Accuracy: 0.8063037991523743\n","Average Validation Loss: 0.7540844678878784\n","Average Test Accuracy: 0.8018353283405304\n","------------------------------------------------------------------------\n","\n","Number of input features: 3\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.1621 - accuracy: 0.1988 - val_loss: 3.3784 - val_accuracy: 0.3448\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5741 - accuracy: 0.4794 - val_loss: 2.2574 - val_accuracy: 0.5943\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6652 - accuracy: 0.6444 - val_loss: 1.7443 - val_accuracy: 0.6895\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2490 - accuracy: 0.7144 - val_loss: 1.4340 - val_accuracy: 0.7432\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0156 - accuracy: 0.7508 - val_loss: 1.2894 - val_accuracy: 0.7494\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8662 - accuracy: 0.7788 - val_loss: 1.2591 - val_accuracy: 0.7432\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7716 - accuracy: 0.7957 - val_loss: 1.0175 - val_accuracy: 0.8042\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6975 - accuracy: 0.8098 - val_loss: 0.9818 - val_accuracy: 0.7978\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6519 - accuracy: 0.8191 - val_loss: 0.9000 - val_accuracy: 0.8301\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6164 - accuracy: 0.8293 - val_loss: 0.8751 - val_accuracy: 0.8251\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5813 - accuracy: 0.8389 - val_loss: 0.9696 - val_accuracy: 0.7982\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5527 - accuracy: 0.8448 - val_loss: 0.7991 - val_accuracy: 0.8286\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5277 - accuracy: 0.8503 - val_loss: 0.8337 - val_accuracy: 0.8275\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5091 - accuracy: 0.8567 - val_loss: 0.7793 - val_accuracy: 0.8427\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4908 - accuracy: 0.8586 - val_loss: 0.7280 - val_accuracy: 0.8546\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4817 - accuracy: 0.8628 - val_loss: 0.7225 - val_accuracy: 0.8581\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4573 - accuracy: 0.8672 - val_loss: 0.7276 - val_accuracy: 0.8671\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4466 - accuracy: 0.8737 - val_loss: 0.7275 - val_accuracy: 0.8475\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4350 - accuracy: 0.8765 - val_loss: 0.7328 - val_accuracy: 0.8495\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4295 - accuracy: 0.8788 - val_loss: 0.7339 - val_accuracy: 0.8572\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4139 - accuracy: 0.8813 - val_loss: 0.6884 - val_accuracy: 0.8768\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4004 - accuracy: 0.8861 - val_loss: 0.7354 - val_accuracy: 0.8449\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3991 - accuracy: 0.8850 - val_loss: 0.6400 - val_accuracy: 0.8805\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3885 - accuracy: 0.8902 - val_loss: 0.6819 - val_accuracy: 0.8691\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3724 - accuracy: 0.8946 - val_loss: 0.6298 - val_accuracy: 0.8873\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3678 - accuracy: 0.8957 - val_loss: 0.6233 - val_accuracy: 0.8832\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3656 - accuracy: 0.8943 - val_loss: 0.6151 - val_accuracy: 0.8803\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3555 - accuracy: 0.8978 - val_loss: 0.5854 - val_accuracy: 0.8913\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3657 - accuracy: 0.8981 - val_loss: 0.5672 - val_accuracy: 0.9019\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3448 - accuracy: 0.9034 - val_loss: 0.5879 - val_accuracy: 0.9039\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3527 - accuracy: 0.9005 - val_loss: 0.5623 - val_accuracy: 0.9056\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3444 - accuracy: 0.8995 - val_loss: 0.5474 - val_accuracy: 0.9014\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3379 - accuracy: 0.9052 - val_loss: 0.5981 - val_accuracy: 0.8816\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3305 - accuracy: 0.9049 - val_loss: 0.5474 - val_accuracy: 0.9023\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3169 - accuracy: 0.9095 - val_loss: 0.5730 - val_accuracy: 0.8796\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3259 - accuracy: 0.9085 - val_loss: 0.5554 - val_accuracy: 0.8821\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3224 - accuracy: 0.9072 - val_loss: 0.5665 - val_accuracy: 0.8935\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3072 - accuracy: 0.9136 - val_loss: 0.6100 - val_accuracy: 0.8711\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3201 - accuracy: 0.9075 - val_loss: 0.5127 - val_accuracy: 0.9166\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3008 - accuracy: 0.9142 - val_loss: 0.5148 - val_accuracy: 0.9127\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.1870 - accuracy: 0.1847 - val_loss: 3.3873 - val_accuracy: 0.3509\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5765 - accuracy: 0.4945 - val_loss: 2.3924 - val_accuracy: 0.6088\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.7188 - accuracy: 0.6458 - val_loss: 1.8399 - val_accuracy: 0.6968\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2525 - accuracy: 0.7262 - val_loss: 1.5862 - val_accuracy: 0.6900\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0138 - accuracy: 0.7598 - val_loss: 1.3975 - val_accuracy: 0.7571\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8735 - accuracy: 0.7834 - val_loss: 1.2577 - val_accuracy: 0.7820\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7898 - accuracy: 0.8009 - val_loss: 1.2067 - val_accuracy: 0.8064\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.7247 - accuracy: 0.8155 - val_loss: 1.1433 - val_accuracy: 0.7949\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6780 - accuracy: 0.8179 - val_loss: 1.0471 - val_accuracy: 0.8161\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6367 - accuracy: 0.8303 - val_loss: 1.0592 - val_accuracy: 0.8095\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6066 - accuracy: 0.8395 - val_loss: 0.9839 - val_accuracy: 0.8119\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5702 - accuracy: 0.8484 - val_loss: 0.9364 - val_accuracy: 0.8385\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5562 - accuracy: 0.8476 - val_loss: 0.9028 - val_accuracy: 0.8297\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5343 - accuracy: 0.8540 - val_loss: 0.8745 - val_accuracy: 0.8541\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.5128 - accuracy: 0.8574 - val_loss: 0.8901 - val_accuracy: 0.8295\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4992 - accuracy: 0.8592 - val_loss: 0.8403 - val_accuracy: 0.8422\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4852 - accuracy: 0.8657 - val_loss: 0.8000 - val_accuracy: 0.8620\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4710 - accuracy: 0.8696 - val_loss: 0.7891 - val_accuracy: 0.8585\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4658 - accuracy: 0.8716 - val_loss: 0.8107 - val_accuracy: 0.8552\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4488 - accuracy: 0.8759 - val_loss: 0.8104 - val_accuracy: 0.8532\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4412 - accuracy: 0.8805 - val_loss: 0.8059 - val_accuracy: 0.8546\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4344 - accuracy: 0.8773 - val_loss: 0.7627 - val_accuracy: 0.8680\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4300 - accuracy: 0.8791 - val_loss: 0.7207 - val_accuracy: 0.8702\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4162 - accuracy: 0.8871 - val_loss: 0.7531 - val_accuracy: 0.8682\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4087 - accuracy: 0.8867 - val_loss: 0.7564 - val_accuracy: 0.8649\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4040 - accuracy: 0.8883 - val_loss: 0.7150 - val_accuracy: 0.8913\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3934 - accuracy: 0.8891 - val_loss: 0.7672 - val_accuracy: 0.8673\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3930 - accuracy: 0.8913 - val_loss: 0.6738 - val_accuracy: 0.8986\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3793 - accuracy: 0.8954 - val_loss: 0.7333 - val_accuracy: 0.8667\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3796 - accuracy: 0.8949 - val_loss: 0.6955 - val_accuracy: 0.8882\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3687 - accuracy: 0.8983 - val_loss: 0.6823 - val_accuracy: 0.8926\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3673 - accuracy: 0.8985 - val_loss: 0.7201 - val_accuracy: 0.8843\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3751 - accuracy: 0.8975 - val_loss: 0.7239 - val_accuracy: 0.8829\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3591 - accuracy: 0.9020 - val_loss: 0.6553 - val_accuracy: 0.9032\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3503 - accuracy: 0.9035 - val_loss: 0.6675 - val_accuracy: 0.8900\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3458 - accuracy: 0.9055 - val_loss: 0.6528 - val_accuracy: 0.9021\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3449 - accuracy: 0.9059 - val_loss: 0.6401 - val_accuracy: 0.8966\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3374 - accuracy: 0.9078 - val_loss: 0.6753 - val_accuracy: 0.8880\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3407 - accuracy: 0.9050 - val_loss: 0.7138 - val_accuracy: 0.8761\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3243 - accuracy: 0.9104 - val_loss: 0.6676 - val_accuracy: 0.9058\n","Average Validation Accuracy: 0.9168935716152191\n","Average Validation Loss: 0.3927837610244751\n","Average Test Accuracy: 0.9146826863288879\n","------------------------------------------------------------------------\n","\n","Number of input features: 4\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.1354 - accuracy: 0.2057 - val_loss: 3.1987 - val_accuracy: 0.4097\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2641 - accuracy: 0.5661 - val_loss: 1.9776 - val_accuracy: 0.6475\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3608 - accuracy: 0.7288 - val_loss: 1.4304 - val_accuracy: 0.7661\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9445 - accuracy: 0.7917 - val_loss: 1.1243 - val_accuracy: 0.8013\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7326 - accuracy: 0.8300 - val_loss: 1.0037 - val_accuracy: 0.8218\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6121 - accuracy: 0.8457 - val_loss: 0.9167 - val_accuracy: 0.8359\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5347 - accuracy: 0.8606 - val_loss: 0.8573 - val_accuracy: 0.8411\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4849 - accuracy: 0.8687 - val_loss: 0.7167 - val_accuracy: 0.8739\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4433 - accuracy: 0.8811 - val_loss: 0.7184 - val_accuracy: 0.8642\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4145 - accuracy: 0.8902 - val_loss: 0.6967 - val_accuracy: 0.8772\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3911 - accuracy: 0.8928 - val_loss: 0.6260 - val_accuracy: 0.8878\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3642 - accuracy: 0.8998 - val_loss: 0.5824 - val_accuracy: 0.9102\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3516 - accuracy: 0.9032 - val_loss: 0.5900 - val_accuracy: 0.8977\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3436 - accuracy: 0.9080 - val_loss: 0.5603 - val_accuracy: 0.9190\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3235 - accuracy: 0.9122 - val_loss: 0.5794 - val_accuracy: 0.8937\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3154 - accuracy: 0.9124 - val_loss: 0.5422 - val_accuracy: 0.9120\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2943 - accuracy: 0.9210 - val_loss: 0.5355 - val_accuracy: 0.9151\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2979 - accuracy: 0.9163 - val_loss: 0.5417 - val_accuracy: 0.9052\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2826 - accuracy: 0.9246 - val_loss: 0.5161 - val_accuracy: 0.9270\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2724 - accuracy: 0.9259 - val_loss: 0.5356 - val_accuracy: 0.9025\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2712 - accuracy: 0.9266 - val_loss: 0.4661 - val_accuracy: 0.9283\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2520 - accuracy: 0.9333 - val_loss: 0.4944 - val_accuracy: 0.9254\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2647 - accuracy: 0.9306 - val_loss: 0.4420 - val_accuracy: 0.9355\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2489 - accuracy: 0.9356 - val_loss: 0.4489 - val_accuracy: 0.9234\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2395 - accuracy: 0.9349 - val_loss: 0.4457 - val_accuracy: 0.9454\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2383 - accuracy: 0.9377 - val_loss: 0.4253 - val_accuracy: 0.9380\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2291 - accuracy: 0.9410 - val_loss: 0.4269 - val_accuracy: 0.9459\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2276 - accuracy: 0.9394 - val_loss: 0.3946 - val_accuracy: 0.9501\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2166 - accuracy: 0.9415 - val_loss: 0.4471 - val_accuracy: 0.9309\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2214 - accuracy: 0.9428 - val_loss: 0.4047 - val_accuracy: 0.9397\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2207 - accuracy: 0.9410 - val_loss: 0.4087 - val_accuracy: 0.9322\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2078 - accuracy: 0.9452 - val_loss: 0.4122 - val_accuracy: 0.9496\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2193 - accuracy: 0.9418 - val_loss: 0.3712 - val_accuracy: 0.9547\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2054 - accuracy: 0.9448 - val_loss: 0.3962 - val_accuracy: 0.9540\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.2058 - accuracy: 0.9458 - val_loss: 0.4307 - val_accuracy: 0.9254\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2050 - accuracy: 0.9491 - val_loss: 0.3954 - val_accuracy: 0.9382\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1984 - accuracy: 0.9478 - val_loss: 0.3734 - val_accuracy: 0.9468\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2035 - accuracy: 0.9447 - val_loss: 0.3730 - val_accuracy: 0.9481\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1868 - accuracy: 0.9517 - val_loss: 0.3988 - val_accuracy: 0.9349\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1993 - accuracy: 0.9483 - val_loss: 0.4040 - val_accuracy: 0.9380\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.2752 - accuracy: 0.1820 - val_loss: 3.4212 - val_accuracy: 0.3201\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5073 - accuracy: 0.5118 - val_loss: 2.2201 - val_accuracy: 0.6339\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5004 - accuracy: 0.6957 - val_loss: 1.5964 - val_accuracy: 0.7487\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0137 - accuracy: 0.7769 - val_loss: 1.2321 - val_accuracy: 0.7892\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7604 - accuracy: 0.8209 - val_loss: 0.9943 - val_accuracy: 0.8449\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6307 - accuracy: 0.8452 - val_loss: 0.9281 - val_accuracy: 0.8266\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5452 - accuracy: 0.8621 - val_loss: 0.8040 - val_accuracy: 0.8651\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5010 - accuracy: 0.8631 - val_loss: 0.7097 - val_accuracy: 0.8785\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4508 - accuracy: 0.8793 - val_loss: 0.6881 - val_accuracy: 0.8706\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4205 - accuracy: 0.8857 - val_loss: 0.6638 - val_accuracy: 0.8689\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4017 - accuracy: 0.8872 - val_loss: 0.6422 - val_accuracy: 0.8722\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3883 - accuracy: 0.8937 - val_loss: 0.6268 - val_accuracy: 0.8719\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3626 - accuracy: 0.9025 - val_loss: 0.5940 - val_accuracy: 0.8891\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3457 - accuracy: 0.9020 - val_loss: 0.5500 - val_accuracy: 0.8959\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3311 - accuracy: 0.9082 - val_loss: 0.6340 - val_accuracy: 0.8752\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3264 - accuracy: 0.9093 - val_loss: 0.5868 - val_accuracy: 0.8796\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3152 - accuracy: 0.9123 - val_loss: 0.5596 - val_accuracy: 0.8651\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2991 - accuracy: 0.9198 - val_loss: 0.5233 - val_accuracy: 0.9199\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2898 - accuracy: 0.9201 - val_loss: 0.5497 - val_accuracy: 0.8957\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2920 - accuracy: 0.9213 - val_loss: 0.5195 - val_accuracy: 0.9052\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2736 - accuracy: 0.9242 - val_loss: 0.5139 - val_accuracy: 0.9122\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2718 - accuracy: 0.9278 - val_loss: 0.5101 - val_accuracy: 0.9047\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2607 - accuracy: 0.9298 - val_loss: 0.4859 - val_accuracy: 0.9109\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2620 - accuracy: 0.9289 - val_loss: 0.4363 - val_accuracy: 0.9256\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2488 - accuracy: 0.9302 - val_loss: 0.4511 - val_accuracy: 0.9217\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2421 - accuracy: 0.9375 - val_loss: 0.5075 - val_accuracy: 0.9226\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2467 - accuracy: 0.9361 - val_loss: 0.4713 - val_accuracy: 0.9186\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2337 - accuracy: 0.9371 - val_loss: 0.4316 - val_accuracy: 0.9217\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2325 - accuracy: 0.9375 - val_loss: 0.4538 - val_accuracy: 0.9199\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2250 - accuracy: 0.9418 - val_loss: 0.4629 - val_accuracy: 0.9278\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2252 - accuracy: 0.9416 - val_loss: 0.4369 - val_accuracy: 0.9307\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2219 - accuracy: 0.9387 - val_loss: 0.3913 - val_accuracy: 0.9529\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2243 - accuracy: 0.9416 - val_loss: 0.3950 - val_accuracy: 0.9263\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2084 - accuracy: 0.9440 - val_loss: 0.4351 - val_accuracy: 0.9267\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2150 - accuracy: 0.9444 - val_loss: 0.3936 - val_accuracy: 0.9331\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2138 - accuracy: 0.9436 - val_loss: 0.4456 - val_accuracy: 0.9318\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1943 - accuracy: 0.9482 - val_loss: 0.3677 - val_accuracy: 0.9518\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2010 - accuracy: 0.9486 - val_loss: 0.3864 - val_accuracy: 0.9450\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2015 - accuracy: 0.9481 - val_loss: 0.3582 - val_accuracy: 0.9413\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1998 - accuracy: 0.9462 - val_loss: 0.3942 - val_accuracy: 0.9402\n","Average Validation Accuracy: 0.9482991397380829\n","Average Validation Loss: 0.2623419836163521\n","Average Test Accuracy: 0.9484779238700867\n","------------------------------------------------------------------------\n","\n","Number of input features: 5\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.3716 - accuracy: 0.1737 - val_loss: 3.5175 - val_accuracy: 0.3703\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5432 - accuracy: 0.5464 - val_loss: 2.0958 - val_accuracy: 0.6576\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4604 - accuracy: 0.7288 - val_loss: 1.4133 - val_accuracy: 0.7767\n","Epoch 4/40\n","1846/1846 [==============================] - 10s 5ms/step - loss: 0.9228 - accuracy: 0.8139 - val_loss: 1.0626 - val_accuracy: 0.8097\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6698 - accuracy: 0.8478 - val_loss: 0.8820 - val_accuracy: 0.8614\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5354 - accuracy: 0.8709 - val_loss: 0.7654 - val_accuracy: 0.8631\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4519 - accuracy: 0.8864 - val_loss: 0.6946 - val_accuracy: 0.8807\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4072 - accuracy: 0.8943 - val_loss: 0.6651 - val_accuracy: 0.8803\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3632 - accuracy: 0.9071 - val_loss: 0.6046 - val_accuracy: 0.8906\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3434 - accuracy: 0.9068 - val_loss: 0.5529 - val_accuracy: 0.8953\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3176 - accuracy: 0.9132 - val_loss: 0.5039 - val_accuracy: 0.9168\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2948 - accuracy: 0.9206 - val_loss: 0.4965 - val_accuracy: 0.9045\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2850 - accuracy: 0.9209 - val_loss: 0.4873 - val_accuracy: 0.9171\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2664 - accuracy: 0.9301 - val_loss: 0.4784 - val_accuracy: 0.9221\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2652 - accuracy: 0.9273 - val_loss: 0.4605 - val_accuracy: 0.9303\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2457 - accuracy: 0.9344 - val_loss: 0.4503 - val_accuracy: 0.9210\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2483 - accuracy: 0.9344 - val_loss: 0.4256 - val_accuracy: 0.9316\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2348 - accuracy: 0.9391 - val_loss: 0.4083 - val_accuracy: 0.9426\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2226 - accuracy: 0.9417 - val_loss: 0.4238 - val_accuracy: 0.9461\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2177 - accuracy: 0.9421 - val_loss: 0.3994 - val_accuracy: 0.9479\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2169 - accuracy: 0.9433 - val_loss: 0.4063 - val_accuracy: 0.9353\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2091 - accuracy: 0.9457 - val_loss: 0.4037 - val_accuracy: 0.9336\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1979 - accuracy: 0.9483 - val_loss: 0.3757 - val_accuracy: 0.9424\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2011 - accuracy: 0.9471 - val_loss: 0.3886 - val_accuracy: 0.9472\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1939 - accuracy: 0.9492 - val_loss: 0.3978 - val_accuracy: 0.9452\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1894 - accuracy: 0.9520 - val_loss: 0.3506 - val_accuracy: 0.9617\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1876 - accuracy: 0.9506 - val_loss: 0.3861 - val_accuracy: 0.9454\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1842 - accuracy: 0.9517 - val_loss: 0.3469 - val_accuracy: 0.9558\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1778 - accuracy: 0.9547 - val_loss: 0.3564 - val_accuracy: 0.9545\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1709 - accuracy: 0.9566 - val_loss: 0.3514 - val_accuracy: 0.9626\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1720 - accuracy: 0.9574 - val_loss: 0.3583 - val_accuracy: 0.9322\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1634 - accuracy: 0.9595 - val_loss: 0.3514 - val_accuracy: 0.9534\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1777 - accuracy: 0.9540 - val_loss: 0.3289 - val_accuracy: 0.9586\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1631 - accuracy: 0.9591 - val_loss: 0.3364 - val_accuracy: 0.9531\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1630 - accuracy: 0.9595 - val_loss: 0.3187 - val_accuracy: 0.9534\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1637 - accuracy: 0.9565 - val_loss: 0.3558 - val_accuracy: 0.9364\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1543 - accuracy: 0.9608 - val_loss: 0.3070 - val_accuracy: 0.9595\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1537 - accuracy: 0.9633 - val_loss: 0.3207 - val_accuracy: 0.9441\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1485 - accuracy: 0.9630 - val_loss: 0.3010 - val_accuracy: 0.9547\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1523 - accuracy: 0.9615 - val_loss: 0.2953 - val_accuracy: 0.9666\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.1421 - accuracy: 0.2081 - val_loss: 3.0003 - val_accuracy: 0.4799\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0651 - accuracy: 0.6244 - val_loss: 1.8763 - val_accuracy: 0.6735\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2406 - accuracy: 0.7531 - val_loss: 1.4059 - val_accuracy: 0.7813\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8302 - accuracy: 0.8193 - val_loss: 1.1230 - val_accuracy: 0.8405\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6152 - accuracy: 0.8579 - val_loss: 0.9189 - val_accuracy: 0.8671\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4909 - accuracy: 0.8827 - val_loss: 0.8143 - val_accuracy: 0.8810\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4258 - accuracy: 0.8917 - val_loss: 0.6639 - val_accuracy: 0.9120\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3723 - accuracy: 0.9021 - val_loss: 0.6679 - val_accuracy: 0.8915\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3400 - accuracy: 0.9113 - val_loss: 0.6325 - val_accuracy: 0.8961\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3142 - accuracy: 0.9165 - val_loss: 0.6168 - val_accuracy: 0.9087\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2996 - accuracy: 0.9193 - val_loss: 0.5652 - val_accuracy: 0.9124\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2807 - accuracy: 0.9242 - val_loss: 0.5219 - val_accuracy: 0.9212\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2682 - accuracy: 0.9264 - val_loss: 0.5211 - val_accuracy: 0.9133\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2599 - accuracy: 0.9307 - val_loss: 0.5393 - val_accuracy: 0.9221\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2400 - accuracy: 0.9379 - val_loss: 0.5051 - val_accuracy: 0.9195\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2328 - accuracy: 0.9368 - val_loss: 0.4646 - val_accuracy: 0.9377\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2233 - accuracy: 0.9408 - val_loss: 0.4566 - val_accuracy: 0.9364\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2193 - accuracy: 0.9413 - val_loss: 0.5332 - val_accuracy: 0.9157\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2137 - accuracy: 0.9430 - val_loss: 0.4603 - val_accuracy: 0.9377\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2030 - accuracy: 0.9483 - val_loss: 0.4143 - val_accuracy: 0.9377\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1959 - accuracy: 0.9481 - val_loss: 0.4201 - val_accuracy: 0.9406\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1950 - accuracy: 0.9505 - val_loss: 0.3914 - val_accuracy: 0.9474\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1838 - accuracy: 0.9538 - val_loss: 0.3615 - val_accuracy: 0.9503\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1818 - accuracy: 0.9540 - val_loss: 0.3959 - val_accuracy: 0.9283\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1824 - accuracy: 0.9547 - val_loss: 0.3688 - val_accuracy: 0.9518\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1767 - accuracy: 0.9539 - val_loss: 0.3880 - val_accuracy: 0.9380\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1752 - accuracy: 0.9548 - val_loss: 0.3270 - val_accuracy: 0.9582\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1692 - accuracy: 0.9577 - val_loss: 0.4681 - val_accuracy: 0.9171\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1603 - accuracy: 0.9603 - val_loss: 0.3778 - val_accuracy: 0.9476\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1636 - accuracy: 0.9588 - val_loss: 0.3430 - val_accuracy: 0.9498\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1608 - accuracy: 0.9588 - val_loss: 0.3495 - val_accuracy: 0.9406\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1613 - accuracy: 0.9612 - val_loss: 0.3376 - val_accuracy: 0.9492\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1497 - accuracy: 0.9640 - val_loss: 0.3126 - val_accuracy: 0.9635\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1539 - accuracy: 0.9612 - val_loss: 0.3308 - val_accuracy: 0.9560\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1518 - accuracy: 0.9620 - val_loss: 0.3186 - val_accuracy: 0.9589\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1385 - accuracy: 0.9671 - val_loss: 0.2972 - val_accuracy: 0.9639\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1478 - accuracy: 0.9637 - val_loss: 0.3122 - val_accuracy: 0.9628\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1349 - accuracy: 0.9674 - val_loss: 0.3107 - val_accuracy: 0.9602\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1430 - accuracy: 0.9645 - val_loss: 0.2822 - val_accuracy: 0.9685\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1335 - accuracy: 0.9677 - val_loss: 0.3052 - val_accuracy: 0.9595\n","Average Validation Accuracy: 0.9681588709354401\n","Average Validation Loss: 0.18436366319656372\n","Average Test Accuracy: 0.9677157998085022\n","------------------------------------------------------------------------\n","\n","Number of input features: 6\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.9626 - accuracy: 0.2599 - val_loss: 2.7545 - val_accuracy: 0.4999\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8052 - accuracy: 0.6770 - val_loss: 1.5184 - val_accuracy: 0.7307\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0129 - accuracy: 0.7949 - val_loss: 1.0636 - val_accuracy: 0.8125\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6803 - accuracy: 0.8517 - val_loss: 0.8057 - val_accuracy: 0.8515\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4983 - accuracy: 0.8832 - val_loss: 0.7119 - val_accuracy: 0.8744\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4159 - accuracy: 0.8962 - val_loss: 0.6495 - val_accuracy: 0.8801\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3588 - accuracy: 0.9099 - val_loss: 0.5078 - val_accuracy: 0.9085\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3231 - accuracy: 0.9153 - val_loss: 0.5262 - val_accuracy: 0.9010\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3028 - accuracy: 0.9210 - val_loss: 0.4457 - val_accuracy: 0.9300\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2712 - accuracy: 0.9301 - val_loss: 0.4187 - val_accuracy: 0.9182\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2636 - accuracy: 0.9304 - val_loss: 0.3762 - val_accuracy: 0.9369\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2398 - accuracy: 0.9396 - val_loss: 0.4032 - val_accuracy: 0.9283\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2363 - accuracy: 0.9370 - val_loss: 0.3946 - val_accuracy: 0.9270\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2242 - accuracy: 0.9414 - val_loss: 0.3733 - val_accuracy: 0.9292\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2152 - accuracy: 0.9424 - val_loss: 0.3448 - val_accuracy: 0.9353\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1971 - accuracy: 0.9481 - val_loss: 0.3289 - val_accuracy: 0.9481\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2057 - accuracy: 0.9498 - val_loss: 0.3052 - val_accuracy: 0.9498\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1954 - accuracy: 0.9501 - val_loss: 0.3313 - val_accuracy: 0.9446\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1840 - accuracy: 0.9523 - val_loss: 0.3467 - val_accuracy: 0.9384\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1838 - accuracy: 0.9529 - val_loss: 0.3002 - val_accuracy: 0.9494\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1805 - accuracy: 0.9544 - val_loss: 0.3004 - val_accuracy: 0.9549\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1699 - accuracy: 0.9572 - val_loss: 0.2878 - val_accuracy: 0.9622\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1684 - accuracy: 0.9571 - val_loss: 0.2879 - val_accuracy: 0.9509\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1653 - accuracy: 0.9585 - val_loss: 0.2816 - val_accuracy: 0.9567\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1623 - accuracy: 0.9570 - val_loss: 0.2985 - val_accuracy: 0.9525\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1625 - accuracy: 0.9585 - val_loss: 0.2806 - val_accuracy: 0.9529\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1586 - accuracy: 0.9605 - val_loss: 0.2972 - val_accuracy: 0.9399\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1482 - accuracy: 0.9620 - val_loss: 0.3019 - val_accuracy: 0.9419\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1539 - accuracy: 0.9602 - val_loss: 0.2721 - val_accuracy: 0.9558\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1462 - accuracy: 0.9637 - val_loss: 0.2893 - val_accuracy: 0.9536\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1428 - accuracy: 0.9627 - val_loss: 0.2666 - val_accuracy: 0.9569\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1403 - accuracy: 0.9643 - val_loss: 0.2615 - val_accuracy: 0.9593\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1393 - accuracy: 0.9652 - val_loss: 0.2584 - val_accuracy: 0.9622\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1407 - accuracy: 0.9635 - val_loss: 0.3387 - val_accuracy: 0.9459\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1342 - accuracy: 0.9666 - val_loss: 0.2646 - val_accuracy: 0.9635\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1345 - accuracy: 0.9652 - val_loss: 0.2673 - val_accuracy: 0.9551\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1365 - accuracy: 0.9651 - val_loss: 0.2933 - val_accuracy: 0.9474\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1369 - accuracy: 0.9657 - val_loss: 0.2437 - val_accuracy: 0.9659\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1261 - accuracy: 0.9702 - val_loss: 0.3344 - val_accuracy: 0.9454\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1258 - accuracy: 0.9698 - val_loss: 0.2412 - val_accuracy: 0.9670\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.8753 - accuracy: 0.2643 - val_loss: 2.6350 - val_accuracy: 0.5129\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7422 - accuracy: 0.6808 - val_loss: 1.6485 - val_accuracy: 0.7184\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9953 - accuracy: 0.7935 - val_loss: 1.1661 - val_accuracy: 0.8187\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6541 - accuracy: 0.8586 - val_loss: 0.8897 - val_accuracy: 0.8532\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4833 - accuracy: 0.8903 - val_loss: 0.6989 - val_accuracy: 0.8724\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3884 - accuracy: 0.9047 - val_loss: 0.5829 - val_accuracy: 0.8955\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3321 - accuracy: 0.9178 - val_loss: 0.5316 - val_accuracy: 0.9041\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3004 - accuracy: 0.9239 - val_loss: 0.4975 - val_accuracy: 0.9124\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2776 - accuracy: 0.9255 - val_loss: 0.5271 - val_accuracy: 0.8933\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2492 - accuracy: 0.9346 - val_loss: 0.4143 - val_accuracy: 0.9333\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2243 - accuracy: 0.9438 - val_loss: 0.4299 - val_accuracy: 0.9173\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2197 - accuracy: 0.9420 - val_loss: 0.3607 - val_accuracy: 0.9362\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2091 - accuracy: 0.9456 - val_loss: 0.3871 - val_accuracy: 0.9421\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1987 - accuracy: 0.9477 - val_loss: 0.3897 - val_accuracy: 0.9338\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1945 - accuracy: 0.9486 - val_loss: 0.3106 - val_accuracy: 0.9578\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1860 - accuracy: 0.9509 - val_loss: 0.3313 - val_accuracy: 0.9490\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1788 - accuracy: 0.9531 - val_loss: 0.3083 - val_accuracy: 0.9527\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1740 - accuracy: 0.9574 - val_loss: 0.3047 - val_accuracy: 0.9569\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1654 - accuracy: 0.9595 - val_loss: 0.3095 - val_accuracy: 0.9527\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1602 - accuracy: 0.9600 - val_loss: 0.3062 - val_accuracy: 0.9503\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1577 - accuracy: 0.9612 - val_loss: 0.3147 - val_accuracy: 0.9483\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1583 - accuracy: 0.9595 - val_loss: 0.3219 - val_accuracy: 0.9375\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1490 - accuracy: 0.9630 - val_loss: 0.3007 - val_accuracy: 0.9567\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1572 - accuracy: 0.9591 - val_loss: 0.2952 - val_accuracy: 0.9575\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1412 - accuracy: 0.9656 - val_loss: 0.3055 - val_accuracy: 0.9584\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1423 - accuracy: 0.9646 - val_loss: 0.3090 - val_accuracy: 0.9472\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1330 - accuracy: 0.9666 - val_loss: 0.2687 - val_accuracy: 0.9679\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1376 - accuracy: 0.9664 - val_loss: 0.2947 - val_accuracy: 0.9538\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1444 - accuracy: 0.9640 - val_loss: 0.2915 - val_accuracy: 0.9569\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1230 - accuracy: 0.9690 - val_loss: 0.2729 - val_accuracy: 0.9690\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1412 - accuracy: 0.9649 - val_loss: 0.3052 - val_accuracy: 0.9560\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1257 - accuracy: 0.9688 - val_loss: 0.2737 - val_accuracy: 0.9624\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1253 - accuracy: 0.9694 - val_loss: 0.3132 - val_accuracy: 0.9485\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1281 - accuracy: 0.9679 - val_loss: 0.2947 - val_accuracy: 0.9536\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1188 - accuracy: 0.9719 - val_loss: 0.2664 - val_accuracy: 0.9663\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1206 - accuracy: 0.9716 - val_loss: 0.2733 - val_accuracy: 0.9696\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1221 - accuracy: 0.9703 - val_loss: 0.2767 - val_accuracy: 0.9648\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1241 - accuracy: 0.9704 - val_loss: 0.2837 - val_accuracy: 0.9641\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1118 - accuracy: 0.9734 - val_loss: 0.2844 - val_accuracy: 0.9597\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1156 - accuracy: 0.9724 - val_loss: 0.2641 - val_accuracy: 0.9622\n","Average Validation Accuracy: 0.97146275639534\n","Average Validation Loss: 0.1546185165643692\n","Average Test Accuracy: 0.9705903828144073\n","------------------------------------------------------------------------\n","\n","Number of input features: 7\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.8445 - accuracy: 0.2900 - val_loss: 2.5911 - val_accuracy: 0.6117\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6872 - accuracy: 0.6955 - val_loss: 1.4213 - val_accuracy: 0.7630\n","Epoch 3/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.8873 - accuracy: 0.8132 - val_loss: 0.9453 - val_accuracy: 0.8271\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5699 - accuracy: 0.8671 - val_loss: 0.7282 - val_accuracy: 0.8662\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4293 - accuracy: 0.8963 - val_loss: 0.5834 - val_accuracy: 0.8961\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3551 - accuracy: 0.9122 - val_loss: 0.4868 - val_accuracy: 0.9151\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3054 - accuracy: 0.9210 - val_loss: 0.4589 - val_accuracy: 0.9190\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2768 - accuracy: 0.9302 - val_loss: 0.4426 - val_accuracy: 0.9177\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2580 - accuracy: 0.9330 - val_loss: 0.3952 - val_accuracy: 0.9369\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2394 - accuracy: 0.9371 - val_loss: 0.3833 - val_accuracy: 0.9413\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2264 - accuracy: 0.9417 - val_loss: 0.3738 - val_accuracy: 0.9256\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2190 - accuracy: 0.9423 - val_loss: 0.3652 - val_accuracy: 0.9276\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2049 - accuracy: 0.9482 - val_loss: 0.3486 - val_accuracy: 0.9428\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2032 - accuracy: 0.9461 - val_loss: 0.3297 - val_accuracy: 0.9509\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1856 - accuracy: 0.9527 - val_loss: 0.3203 - val_accuracy: 0.9344\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1808 - accuracy: 0.9526 - val_loss: 0.3043 - val_accuracy: 0.9551\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1778 - accuracy: 0.9544 - val_loss: 0.3418 - val_accuracy: 0.9399\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1717 - accuracy: 0.9566 - val_loss: 0.2936 - val_accuracy: 0.9531\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1647 - accuracy: 0.9589 - val_loss: 0.2872 - val_accuracy: 0.9573\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1639 - accuracy: 0.9594 - val_loss: 0.3254 - val_accuracy: 0.9602\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1566 - accuracy: 0.9614 - val_loss: 0.3163 - val_accuracy: 0.9426\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1530 - accuracy: 0.9614 - val_loss: 0.3298 - val_accuracy: 0.9364\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1537 - accuracy: 0.9614 - val_loss: 0.2788 - val_accuracy: 0.9586\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1457 - accuracy: 0.9652 - val_loss: 0.3097 - val_accuracy: 0.9428\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1489 - accuracy: 0.9643 - val_loss: 0.2714 - val_accuracy: 0.9503\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1423 - accuracy: 0.9655 - val_loss: 0.2676 - val_accuracy: 0.9582\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1369 - accuracy: 0.9685 - val_loss: 0.2750 - val_accuracy: 0.9560\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1338 - accuracy: 0.9674 - val_loss: 0.2456 - val_accuracy: 0.9641\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1338 - accuracy: 0.9682 - val_loss: 0.2385 - val_accuracy: 0.9729\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1297 - accuracy: 0.9692 - val_loss: 0.2497 - val_accuracy: 0.9723\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1246 - accuracy: 0.9695 - val_loss: 0.2390 - val_accuracy: 0.9718\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1299 - accuracy: 0.9688 - val_loss: 0.2332 - val_accuracy: 0.9677\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1209 - accuracy: 0.9719 - val_loss: 0.2542 - val_accuracy: 0.9593\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1239 - accuracy: 0.9707 - val_loss: 0.2221 - val_accuracy: 0.9696\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1199 - accuracy: 0.9699 - val_loss: 0.2265 - val_accuracy: 0.9714\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1182 - accuracy: 0.9700 - val_loss: 0.2317 - val_accuracy: 0.9637\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1134 - accuracy: 0.9740 - val_loss: 0.2425 - val_accuracy: 0.9670\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1211 - accuracy: 0.9714 - val_loss: 0.2294 - val_accuracy: 0.9802\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1107 - accuracy: 0.9742 - val_loss: 0.2162 - val_accuracy: 0.9666\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1107 - accuracy: 0.9739 - val_loss: 0.2145 - val_accuracy: 0.9806\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.6923 - accuracy: 0.3280 - val_loss: 2.4714 - val_accuracy: 0.5584\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6330 - accuracy: 0.6923 - val_loss: 1.4691 - val_accuracy: 0.7347\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9441 - accuracy: 0.7991 - val_loss: 1.0490 - val_accuracy: 0.8123\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6592 - accuracy: 0.8451 - val_loss: 0.8888 - val_accuracy: 0.8356\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5078 - accuracy: 0.8734 - val_loss: 0.7065 - val_accuracy: 0.8805\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4271 - accuracy: 0.8896 - val_loss: 0.6747 - val_accuracy: 0.8695\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3670 - accuracy: 0.9039 - val_loss: 0.5688 - val_accuracy: 0.9003\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3358 - accuracy: 0.9097 - val_loss: 0.5049 - val_accuracy: 0.9124\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3063 - accuracy: 0.9137 - val_loss: 0.5063 - val_accuracy: 0.9111\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2837 - accuracy: 0.9225 - val_loss: 0.4793 - val_accuracy: 0.9096\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2706 - accuracy: 0.9271 - val_loss: 0.4685 - val_accuracy: 0.9149\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2519 - accuracy: 0.9316 - val_loss: 0.4233 - val_accuracy: 0.9199\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2482 - accuracy: 0.9333 - val_loss: 0.3865 - val_accuracy: 0.9426\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2316 - accuracy: 0.9401 - val_loss: 0.4136 - val_accuracy: 0.9096\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2243 - accuracy: 0.9403 - val_loss: 0.3835 - val_accuracy: 0.9377\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2151 - accuracy: 0.9426 - val_loss: 0.3744 - val_accuracy: 0.9322\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2024 - accuracy: 0.9493 - val_loss: 0.3804 - val_accuracy: 0.9314\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1856 - accuracy: 0.9530 - val_loss: 0.3345 - val_accuracy: 0.9472\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1969 - accuracy: 0.9521 - val_loss: 0.3540 - val_accuracy: 0.9441\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1781 - accuracy: 0.9535 - val_loss: 0.3148 - val_accuracy: 0.9562\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1767 - accuracy: 0.9555 - val_loss: 0.3359 - val_accuracy: 0.9375\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1720 - accuracy: 0.9570 - val_loss: 0.3411 - val_accuracy: 0.9417\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1698 - accuracy: 0.9573 - val_loss: 0.3420 - val_accuracy: 0.9386\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1660 - accuracy: 0.9583 - val_loss: 0.3030 - val_accuracy: 0.9547\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1604 - accuracy: 0.9606 - val_loss: 0.2998 - val_accuracy: 0.9575\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1482 - accuracy: 0.9642 - val_loss: 0.3275 - val_accuracy: 0.9360\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1492 - accuracy: 0.9634 - val_loss: 0.3014 - val_accuracy: 0.9560\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1468 - accuracy: 0.9643 - val_loss: 0.3134 - val_accuracy: 0.9450\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1435 - accuracy: 0.9633 - val_loss: 0.2577 - val_accuracy: 0.9690\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1340 - accuracy: 0.9676 - val_loss: 0.3525 - val_accuracy: 0.9371\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1453 - accuracy: 0.9629 - val_loss: 0.2795 - val_accuracy: 0.9529\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1302 - accuracy: 0.9684 - val_loss: 0.3034 - val_accuracy: 0.9441\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1352 - accuracy: 0.9660 - val_loss: 0.2703 - val_accuracy: 0.9534\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1325 - accuracy: 0.9654 - val_loss: 0.3259 - val_accuracy: 0.9426\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1258 - accuracy: 0.9690 - val_loss: 0.2816 - val_accuracy: 0.9529\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1222 - accuracy: 0.9694 - val_loss: 0.2623 - val_accuracy: 0.9578\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1236 - accuracy: 0.9697 - val_loss: 0.2607 - val_accuracy: 0.9644\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1219 - accuracy: 0.9704 - val_loss: 0.2465 - val_accuracy: 0.9721\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1194 - accuracy: 0.9706 - val_loss: 0.2610 - val_accuracy: 0.9619\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1073 - accuracy: 0.9734 - val_loss: 0.2549 - val_accuracy: 0.9705\n","Average Validation Accuracy: 0.9819917380809784\n","Average Validation Loss: 0.1413477584719658\n","Average Test Accuracy: 0.979582816362381\n","------------------------------------------------------------------------\n","\n","Number of input features: 8\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7652 - accuracy: 0.3219 - val_loss: 2.4692 - val_accuracy: 0.5912\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6478 - accuracy: 0.6960 - val_loss: 1.4262 - val_accuracy: 0.7624\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9012 - accuracy: 0.8160 - val_loss: 1.0248 - val_accuracy: 0.8266\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5903 - accuracy: 0.8664 - val_loss: 0.7359 - val_accuracy: 0.8697\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4447 - accuracy: 0.8920 - val_loss: 0.6426 - val_accuracy: 0.8757\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3691 - accuracy: 0.9051 - val_loss: 0.5678 - val_accuracy: 0.8891\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3198 - accuracy: 0.9175 - val_loss: 0.4888 - val_accuracy: 0.9098\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2920 - accuracy: 0.9234 - val_loss: 0.5107 - val_accuracy: 0.9023\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2590 - accuracy: 0.9327 - val_loss: 0.5419 - val_accuracy: 0.8799\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2477 - accuracy: 0.9346 - val_loss: 0.4014 - val_accuracy: 0.9276\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2236 - accuracy: 0.9411 - val_loss: 0.3845 - val_accuracy: 0.9219\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2134 - accuracy: 0.9450 - val_loss: 0.3817 - val_accuracy: 0.9285\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2021 - accuracy: 0.9458 - val_loss: 0.3472 - val_accuracy: 0.9463\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1940 - accuracy: 0.9507 - val_loss: 0.3040 - val_accuracy: 0.9450\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1881 - accuracy: 0.9515 - val_loss: 0.3380 - val_accuracy: 0.9432\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1781 - accuracy: 0.9549 - val_loss: 0.3003 - val_accuracy: 0.9578\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1710 - accuracy: 0.9571 - val_loss: 0.2959 - val_accuracy: 0.9597\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1625 - accuracy: 0.9594 - val_loss: 0.3232 - val_accuracy: 0.9428\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1615 - accuracy: 0.9581 - val_loss: 0.2860 - val_accuracy: 0.9646\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1481 - accuracy: 0.9642 - val_loss: 0.2722 - val_accuracy: 0.9624\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1554 - accuracy: 0.9610 - val_loss: 0.3001 - val_accuracy: 0.9441\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1470 - accuracy: 0.9636 - val_loss: 0.3065 - val_accuracy: 0.9474\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1393 - accuracy: 0.9670 - val_loss: 0.3762 - val_accuracy: 0.9386\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1416 - accuracy: 0.9622 - val_loss: 0.2763 - val_accuracy: 0.9589\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1368 - accuracy: 0.9665 - val_loss: 0.2853 - val_accuracy: 0.9617\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1310 - accuracy: 0.9675 - val_loss: 0.2690 - val_accuracy: 0.9641\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1318 - accuracy: 0.9659 - val_loss: 0.2731 - val_accuracy: 0.9729\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1267 - accuracy: 0.9694 - val_loss: 0.2567 - val_accuracy: 0.9641\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1239 - accuracy: 0.9702 - val_loss: 0.2937 - val_accuracy: 0.9538\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1263 - accuracy: 0.9681 - val_loss: 0.2901 - val_accuracy: 0.9569\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1239 - accuracy: 0.9701 - val_loss: 0.3094 - val_accuracy: 0.9421\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1177 - accuracy: 0.9724 - val_loss: 0.3079 - val_accuracy: 0.9571\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1255 - accuracy: 0.9690 - val_loss: 0.2598 - val_accuracy: 0.9756\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1158 - accuracy: 0.9718 - val_loss: 0.2769 - val_accuracy: 0.9683\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1208 - accuracy: 0.9716 - val_loss: 0.2531 - val_accuracy: 0.9765\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1100 - accuracy: 0.9729 - val_loss: 0.2657 - val_accuracy: 0.9769\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1089 - accuracy: 0.9733 - val_loss: 0.2982 - val_accuracy: 0.9551\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1194 - accuracy: 0.9704 - val_loss: 0.2638 - val_accuracy: 0.9705\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1057 - accuracy: 0.9757 - val_loss: 0.2675 - val_accuracy: 0.9727\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1097 - accuracy: 0.9751 - val_loss: 0.2644 - val_accuracy: 0.9795\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.8287 - accuracy: 0.2884 - val_loss: 2.5265 - val_accuracy: 0.6169\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6078 - accuracy: 0.7024 - val_loss: 1.4441 - val_accuracy: 0.7685\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8973 - accuracy: 0.8080 - val_loss: 1.0356 - val_accuracy: 0.8398\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6161 - accuracy: 0.8517 - val_loss: 0.8122 - val_accuracy: 0.8510\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4670 - accuracy: 0.8822 - val_loss: 0.7179 - val_accuracy: 0.8557\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3823 - accuracy: 0.9038 - val_loss: 0.5783 - val_accuracy: 0.8913\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3329 - accuracy: 0.9148 - val_loss: 0.4924 - val_accuracy: 0.9052\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2944 - accuracy: 0.9209 - val_loss: 0.4887 - val_accuracy: 0.9069\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2735 - accuracy: 0.9288 - val_loss: 0.4629 - val_accuracy: 0.9228\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2442 - accuracy: 0.9345 - val_loss: 0.4772 - val_accuracy: 0.9144\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2437 - accuracy: 0.9367 - val_loss: 0.4525 - val_accuracy: 0.9239\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2204 - accuracy: 0.9414 - val_loss: 0.4226 - val_accuracy: 0.9287\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2115 - accuracy: 0.9456 - val_loss: 0.4283 - val_accuracy: 0.9226\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1910 - accuracy: 0.9516 - val_loss: 0.4456 - val_accuracy: 0.9164\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1970 - accuracy: 0.9498 - val_loss: 0.3340 - val_accuracy: 0.9437\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1844 - accuracy: 0.9508 - val_loss: 0.3596 - val_accuracy: 0.9395\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1811 - accuracy: 0.9536 - val_loss: 0.3599 - val_accuracy: 0.9380\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1700 - accuracy: 0.9563 - val_loss: 0.3625 - val_accuracy: 0.9432\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1628 - accuracy: 0.9579 - val_loss: 0.3643 - val_accuracy: 0.9384\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1614 - accuracy: 0.9596 - val_loss: 0.3328 - val_accuracy: 0.9446\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1602 - accuracy: 0.9585 - val_loss: 0.3196 - val_accuracy: 0.9545\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1494 - accuracy: 0.9613 - val_loss: 0.3700 - val_accuracy: 0.9340\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1472 - accuracy: 0.9635 - val_loss: 0.3057 - val_accuracy: 0.9459\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1471 - accuracy: 0.9626 - val_loss: 0.3236 - val_accuracy: 0.9432\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1431 - accuracy: 0.9627 - val_loss: 0.2895 - val_accuracy: 0.9564\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1475 - accuracy: 0.9608 - val_loss: 0.3060 - val_accuracy: 0.9567\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1348 - accuracy: 0.9650 - val_loss: 0.2731 - val_accuracy: 0.9622\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1378 - accuracy: 0.9655 - val_loss: 0.2972 - val_accuracy: 0.9492\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1256 - accuracy: 0.9689 - val_loss: 0.2923 - val_accuracy: 0.9582\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1264 - accuracy: 0.9703 - val_loss: 0.2727 - val_accuracy: 0.9617\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1321 - accuracy: 0.9668 - val_loss: 0.2618 - val_accuracy: 0.9635\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1164 - accuracy: 0.9712 - val_loss: 0.2624 - val_accuracy: 0.9694\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1239 - accuracy: 0.9690 - val_loss: 0.2726 - val_accuracy: 0.9644\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1167 - accuracy: 0.9731 - val_loss: 0.2655 - val_accuracy: 0.9633\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1144 - accuracy: 0.9716 - val_loss: 0.2705 - val_accuracy: 0.9575\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1164 - accuracy: 0.9715 - val_loss: 0.2538 - val_accuracy: 0.9628\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1153 - accuracy: 0.9712 - val_loss: 0.2592 - val_accuracy: 0.9644\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1096 - accuracy: 0.9740 - val_loss: 0.2687 - val_accuracy: 0.9633\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1074 - accuracy: 0.9738 - val_loss: 0.2583 - val_accuracy: 0.9602\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1159 - accuracy: 0.9698 - val_loss: 0.2554 - val_accuracy: 0.9628\n","Average Validation Accuracy: 0.9763640761375427\n","Average Validation Loss: 0.15233086049556732\n","Average Test Accuracy: 0.9738704264163971\n","------------------------------------------------------------------------\n","\n","Number of input features: 9\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.8168 - accuracy: 0.2806 - val_loss: 2.5362 - val_accuracy: 0.5751\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6322 - accuracy: 0.7040 - val_loss: 1.4158 - val_accuracy: 0.7439\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8465 - accuracy: 0.8200 - val_loss: 0.9091 - val_accuracy: 0.8306\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5712 - accuracy: 0.8641 - val_loss: 0.7244 - val_accuracy: 0.8453\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4451 - accuracy: 0.8871 - val_loss: 0.6575 - val_accuracy: 0.8576\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3766 - accuracy: 0.9051 - val_loss: 0.5304 - val_accuracy: 0.8823\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3343 - accuracy: 0.9119 - val_loss: 0.4706 - val_accuracy: 0.9032\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2976 - accuracy: 0.9228 - val_loss: 0.4095 - val_accuracy: 0.9333\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2719 - accuracy: 0.9292 - val_loss: 0.4555 - val_accuracy: 0.9122\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2591 - accuracy: 0.9340 - val_loss: 0.3729 - val_accuracy: 0.9325\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2371 - accuracy: 0.9403 - val_loss: 0.3707 - val_accuracy: 0.9408\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2311 - accuracy: 0.9423 - val_loss: 0.3722 - val_accuracy: 0.9270\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2133 - accuracy: 0.9454 - val_loss: 0.3017 - val_accuracy: 0.9452\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2033 - accuracy: 0.9499 - val_loss: 0.3212 - val_accuracy: 0.9419\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1890 - accuracy: 0.9542 - val_loss: 0.2864 - val_accuracy: 0.9542\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1991 - accuracy: 0.9497 - val_loss: 0.2807 - val_accuracy: 0.9619\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1790 - accuracy: 0.9573 - val_loss: 0.3265 - val_accuracy: 0.9628\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1740 - accuracy: 0.9595 - val_loss: 0.2795 - val_accuracy: 0.9558\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1719 - accuracy: 0.9575 - val_loss: 0.3153 - val_accuracy: 0.9404\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1671 - accuracy: 0.9610 - val_loss: 0.2620 - val_accuracy: 0.9637\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1605 - accuracy: 0.9625 - val_loss: 0.3012 - val_accuracy: 0.9534\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1554 - accuracy: 0.9642 - val_loss: 0.2949 - val_accuracy: 0.9564\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1414 - accuracy: 0.9675 - val_loss: 0.2877 - val_accuracy: 0.9668\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1536 - accuracy: 0.9629 - val_loss: 0.2938 - val_accuracy: 0.9589\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1427 - accuracy: 0.9656 - val_loss: 0.2809 - val_accuracy: 0.9547\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1412 - accuracy: 0.9674 - val_loss: 0.2926 - val_accuracy: 0.9630\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1424 - accuracy: 0.9667 - val_loss: 0.2744 - val_accuracy: 0.9626\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1357 - accuracy: 0.9682 - val_loss: 0.2505 - val_accuracy: 0.9699\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1235 - accuracy: 0.9711 - val_loss: 0.2445 - val_accuracy: 0.9736\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1356 - accuracy: 0.9681 - val_loss: 0.2500 - val_accuracy: 0.9701\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1243 - accuracy: 0.9698 - val_loss: 0.2571 - val_accuracy: 0.9723\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1298 - accuracy: 0.9688 - val_loss: 0.2973 - val_accuracy: 0.9395\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1191 - accuracy: 0.9732 - val_loss: 0.2389 - val_accuracy: 0.9723\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1298 - accuracy: 0.9702 - val_loss: 0.2431 - val_accuracy: 0.9725\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1156 - accuracy: 0.9730 - val_loss: 0.2829 - val_accuracy: 0.9558\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1176 - accuracy: 0.9732 - val_loss: 0.2715 - val_accuracy: 0.9547\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1148 - accuracy: 0.9721 - val_loss: 0.2523 - val_accuracy: 0.9723\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1140 - accuracy: 0.9731 - val_loss: 0.2341 - val_accuracy: 0.9765\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1161 - accuracy: 0.9749 - val_loss: 0.3015 - val_accuracy: 0.9611\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1100 - accuracy: 0.9744 - val_loss: 0.2388 - val_accuracy: 0.9723\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7406 - accuracy: 0.3036 - val_loss: 2.6795 - val_accuracy: 0.5085\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8127 - accuracy: 0.6649 - val_loss: 1.6631 - val_accuracy: 0.7248\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0218 - accuracy: 0.7943 - val_loss: 1.1499 - val_accuracy: 0.8231\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6434 - accuracy: 0.8546 - val_loss: 0.8759 - val_accuracy: 0.8629\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4945 - accuracy: 0.8836 - val_loss: 0.7523 - val_accuracy: 0.8794\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4022 - accuracy: 0.9024 - val_loss: 0.6715 - val_accuracy: 0.8816\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3512 - accuracy: 0.9145 - val_loss: 0.5735 - val_accuracy: 0.9094\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3177 - accuracy: 0.9220 - val_loss: 0.5323 - val_accuracy: 0.9149\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2899 - accuracy: 0.9248 - val_loss: 0.6051 - val_accuracy: 0.9058\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2730 - accuracy: 0.9298 - val_loss: 0.4574 - val_accuracy: 0.9118\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2494 - accuracy: 0.9372 - val_loss: 0.4754 - val_accuracy: 0.9201\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2401 - accuracy: 0.9405 - val_loss: 0.4444 - val_accuracy: 0.9428\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2330 - accuracy: 0.9408 - val_loss: 0.4169 - val_accuracy: 0.9261\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2155 - accuracy: 0.9470 - val_loss: 0.4200 - val_accuracy: 0.9358\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2065 - accuracy: 0.9477 - val_loss: 0.4206 - val_accuracy: 0.9391\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2002 - accuracy: 0.9484 - val_loss: 0.3742 - val_accuracy: 0.9457\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1990 - accuracy: 0.9497 - val_loss: 0.3953 - val_accuracy: 0.9404\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1851 - accuracy: 0.9542 - val_loss: 0.3581 - val_accuracy: 0.9476\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1838 - accuracy: 0.9550 - val_loss: 0.3384 - val_accuracy: 0.9538\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1719 - accuracy: 0.9593 - val_loss: 0.3364 - val_accuracy: 0.9483\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1633 - accuracy: 0.9596 - val_loss: 0.3398 - val_accuracy: 0.9501\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1619 - accuracy: 0.9599 - val_loss: 0.3157 - val_accuracy: 0.9575\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1590 - accuracy: 0.9619 - val_loss: 0.3424 - val_accuracy: 0.9472\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1520 - accuracy: 0.9634 - val_loss: 0.3250 - val_accuracy: 0.9518\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1509 - accuracy: 0.9634 - val_loss: 0.3571 - val_accuracy: 0.9373\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1490 - accuracy: 0.9655 - val_loss: 0.3062 - val_accuracy: 0.9564\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1361 - accuracy: 0.9682 - val_loss: 0.3728 - val_accuracy: 0.9399\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1404 - accuracy: 0.9679 - val_loss: 0.2990 - val_accuracy: 0.9641\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1356 - accuracy: 0.9687 - val_loss: 0.3138 - val_accuracy: 0.9505\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1342 - accuracy: 0.9681 - val_loss: 0.2962 - val_accuracy: 0.9639\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1313 - accuracy: 0.9690 - val_loss: 0.3541 - val_accuracy: 0.9316\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1255 - accuracy: 0.9700 - val_loss: 0.2858 - val_accuracy: 0.9617\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1251 - accuracy: 0.9713 - val_loss: 0.2862 - val_accuracy: 0.9573\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1171 - accuracy: 0.9734 - val_loss: 0.2893 - val_accuracy: 0.9622\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1208 - accuracy: 0.9724 - val_loss: 0.2856 - val_accuracy: 0.9628\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1145 - accuracy: 0.9756 - val_loss: 0.2685 - val_accuracy: 0.9560\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1185 - accuracy: 0.9733 - val_loss: 0.3119 - val_accuracy: 0.9520\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9738 - val_loss: 0.2715 - val_accuracy: 0.9608\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1114 - accuracy: 0.9757 - val_loss: 0.2640 - val_accuracy: 0.9571\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1052 - accuracy: 0.9746 - val_loss: 0.2758 - val_accuracy: 0.9655\n","Average Validation Accuracy: 0.9742583930492401\n","Average Validation Loss: 0.15181659162044525\n","Average Test Accuracy: 0.9732070565223694\n","------------------------------------------------------------------------\n","\n","Number of input features: 10\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.5870 - accuracy: 0.3454 - val_loss: 2.2910 - val_accuracy: 0.6024\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4682 - accuracy: 0.7305 - val_loss: 1.2166 - val_accuracy: 0.7582\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7988 - accuracy: 0.8252 - val_loss: 0.8355 - val_accuracy: 0.8273\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5535 - accuracy: 0.8667 - val_loss: 0.7352 - val_accuracy: 0.8548\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4418 - accuracy: 0.8864 - val_loss: 0.6321 - val_accuracy: 0.8662\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3685 - accuracy: 0.9053 - val_loss: 0.5184 - val_accuracy: 0.9063\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3281 - accuracy: 0.9151 - val_loss: 0.5020 - val_accuracy: 0.9023\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2909 - accuracy: 0.9246 - val_loss: 0.4667 - val_accuracy: 0.9188\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2631 - accuracy: 0.9313 - val_loss: 0.4520 - val_accuracy: 0.9144\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2491 - accuracy: 0.9368 - val_loss: 0.3726 - val_accuracy: 0.9331\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2267 - accuracy: 0.9431 - val_loss: 0.4089 - val_accuracy: 0.9366\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2199 - accuracy: 0.9442 - val_loss: 0.3901 - val_accuracy: 0.9256\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2013 - accuracy: 0.9494 - val_loss: 0.3532 - val_accuracy: 0.9507\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1967 - accuracy: 0.9500 - val_loss: 0.3396 - val_accuracy: 0.9388\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1837 - accuracy: 0.9531 - val_loss: 0.3269 - val_accuracy: 0.9459\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1802 - accuracy: 0.9559 - val_loss: 0.3509 - val_accuracy: 0.9417\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1700 - accuracy: 0.9576 - val_loss: 0.3196 - val_accuracy: 0.9531\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1721 - accuracy: 0.9566 - val_loss: 0.3347 - val_accuracy: 0.9479\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1567 - accuracy: 0.9605 - val_loss: 0.2987 - val_accuracy: 0.9562\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1574 - accuracy: 0.9600 - val_loss: 0.3163 - val_accuracy: 0.9547\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1509 - accuracy: 0.9613 - val_loss: 0.2903 - val_accuracy: 0.9613\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1491 - accuracy: 0.9624 - val_loss: 0.3002 - val_accuracy: 0.9505\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1402 - accuracy: 0.9661 - val_loss: 0.2840 - val_accuracy: 0.9562\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1334 - accuracy: 0.9686 - val_loss: 0.2841 - val_accuracy: 0.9703\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1387 - accuracy: 0.9660 - val_loss: 0.2592 - val_accuracy: 0.9721\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1326 - accuracy: 0.9676 - val_loss: 0.2622 - val_accuracy: 0.9666\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1288 - accuracy: 0.9688 - val_loss: 0.2632 - val_accuracy: 0.9677\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1269 - accuracy: 0.9682 - val_loss: 0.2742 - val_accuracy: 0.9560\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1198 - accuracy: 0.9717 - val_loss: 0.2515 - val_accuracy: 0.9628\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1193 - accuracy: 0.9707 - val_loss: 0.2568 - val_accuracy: 0.9784\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1234 - accuracy: 0.9699 - val_loss: 0.2454 - val_accuracy: 0.9714\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1105 - accuracy: 0.9733 - val_loss: 0.2864 - val_accuracy: 0.9628\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1137 - accuracy: 0.9721 - val_loss: 0.2515 - val_accuracy: 0.9729\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1109 - accuracy: 0.9739 - val_loss: 0.2518 - val_accuracy: 0.9747\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1038 - accuracy: 0.9744 - val_loss: 0.4006 - val_accuracy: 0.9419\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1152 - accuracy: 0.9716 - val_loss: 0.2375 - val_accuracy: 0.9765\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0996 - accuracy: 0.9753 - val_loss: 0.2366 - val_accuracy: 0.9683\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1038 - accuracy: 0.9756 - val_loss: 0.2335 - val_accuracy: 0.9769\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1002 - accuracy: 0.9759 - val_loss: 0.2336 - val_accuracy: 0.9754\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0999 - accuracy: 0.9763 - val_loss: 0.2562 - val_accuracy: 0.9677\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 4.1192 - accuracy: 0.2214 - val_loss: 3.0367 - val_accuracy: 0.4513\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0643 - accuracy: 0.6231 - val_loss: 1.8182 - val_accuracy: 0.6838\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1557 - accuracy: 0.7620 - val_loss: 1.2676 - val_accuracy: 0.8066\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7434 - accuracy: 0.8397 - val_loss: 0.9989 - val_accuracy: 0.8451\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5651 - accuracy: 0.8703 - val_loss: 0.8297 - val_accuracy: 0.8878\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4494 - accuracy: 0.8893 - val_loss: 0.7576 - val_accuracy: 0.8880\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3911 - accuracy: 0.9011 - val_loss: 0.6563 - val_accuracy: 0.8832\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3423 - accuracy: 0.9120 - val_loss: 0.5581 - val_accuracy: 0.9109\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3083 - accuracy: 0.9196 - val_loss: 0.5684 - val_accuracy: 0.9091\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2849 - accuracy: 0.9270 - val_loss: 0.5320 - val_accuracy: 0.9098\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2619 - accuracy: 0.9331 - val_loss: 0.5114 - val_accuracy: 0.9067\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2446 - accuracy: 0.9375 - val_loss: 0.4435 - val_accuracy: 0.9311\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2303 - accuracy: 0.9412 - val_loss: 0.4249 - val_accuracy: 0.9355\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2230 - accuracy: 0.9425 - val_loss: 0.4191 - val_accuracy: 0.9386\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2100 - accuracy: 0.9465 - val_loss: 0.4167 - val_accuracy: 0.9362\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2001 - accuracy: 0.9517 - val_loss: 0.4169 - val_accuracy: 0.9322\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2019 - accuracy: 0.9475 - val_loss: 0.4073 - val_accuracy: 0.9336\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1879 - accuracy: 0.9520 - val_loss: 0.3452 - val_accuracy: 0.9527\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1768 - accuracy: 0.9565 - val_loss: 0.3457 - val_accuracy: 0.9487\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1829 - accuracy: 0.9536 - val_loss: 0.3469 - val_accuracy: 0.9494\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1742 - accuracy: 0.9560 - val_loss: 0.3511 - val_accuracy: 0.9525\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1649 - accuracy: 0.9576 - val_loss: 0.3390 - val_accuracy: 0.9529\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1592 - accuracy: 0.9593 - val_loss: 0.3785 - val_accuracy: 0.9358\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1613 - accuracy: 0.9597 - val_loss: 0.3951 - val_accuracy: 0.9498\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1486 - accuracy: 0.9643 - val_loss: 0.3221 - val_accuracy: 0.9646\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1530 - accuracy: 0.9627 - val_loss: 0.3261 - val_accuracy: 0.9459\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1435 - accuracy: 0.9640 - val_loss: 0.3102 - val_accuracy: 0.9608\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1397 - accuracy: 0.9654 - val_loss: 0.3037 - val_accuracy: 0.9672\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1349 - accuracy: 0.9690 - val_loss: 0.3002 - val_accuracy: 0.9617\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1364 - accuracy: 0.9666 - val_loss: 0.2983 - val_accuracy: 0.9633\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1295 - accuracy: 0.9688 - val_loss: 0.3247 - val_accuracy: 0.9496\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1278 - accuracy: 0.9695 - val_loss: 0.3193 - val_accuracy: 0.9410\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1262 - accuracy: 0.9705 - val_loss: 0.3029 - val_accuracy: 0.9619\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1304 - accuracy: 0.9687 - val_loss: 0.2932 - val_accuracy: 0.9701\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1218 - accuracy: 0.9714 - val_loss: 0.2886 - val_accuracy: 0.9721\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1242 - accuracy: 0.9704 - val_loss: 0.2999 - val_accuracy: 0.9639\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1130 - accuracy: 0.9730 - val_loss: 0.2925 - val_accuracy: 0.9602\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1176 - accuracy: 0.9730 - val_loss: 0.2975 - val_accuracy: 0.9641\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1115 - accuracy: 0.9731 - val_loss: 0.3203 - val_accuracy: 0.9564\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1164 - accuracy: 0.9724 - val_loss: 0.2982 - val_accuracy: 0.9604\n","Average Validation Accuracy: 0.9704098999500275\n","Average Validation Loss: 0.16504652798175812\n","Average Test Accuracy: 0.9700744450092316\n","------------------------------------------------------------------------\n","\n","Number of input features: 11\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.8642 - accuracy: 0.2928 - val_loss: 2.6745 - val_accuracy: 0.5490\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7619 - accuracy: 0.6872 - val_loss: 1.4253 - val_accuracy: 0.7540\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9758 - accuracy: 0.7985 - val_loss: 0.9726 - val_accuracy: 0.8163\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6293 - accuracy: 0.8616 - val_loss: 0.7321 - val_accuracy: 0.8587\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4562 - accuracy: 0.8907 - val_loss: 0.6284 - val_accuracy: 0.8902\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3707 - accuracy: 0.9083 - val_loss: 0.5555 - val_accuracy: 0.8913\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3203 - accuracy: 0.9163 - val_loss: 0.5093 - val_accuracy: 0.8986\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2874 - accuracy: 0.9247 - val_loss: 0.4451 - val_accuracy: 0.9226\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2678 - accuracy: 0.9295 - val_loss: 0.4091 - val_accuracy: 0.9278\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2419 - accuracy: 0.9382 - val_loss: 0.3993 - val_accuracy: 0.9340\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2272 - accuracy: 0.9394 - val_loss: 0.4092 - val_accuracy: 0.9241\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2173 - accuracy: 0.9455 - val_loss: 0.3678 - val_accuracy: 0.9468\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2052 - accuracy: 0.9460 - val_loss: 0.3643 - val_accuracy: 0.9415\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2010 - accuracy: 0.9476 - val_loss: 0.3280 - val_accuracy: 0.9518\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1963 - accuracy: 0.9499 - val_loss: 0.3276 - val_accuracy: 0.9479\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1842 - accuracy: 0.9531 - val_loss: 0.3217 - val_accuracy: 0.9547\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1751 - accuracy: 0.9565 - val_loss: 0.3154 - val_accuracy: 0.9470\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1759 - accuracy: 0.9553 - val_loss: 0.3099 - val_accuracy: 0.9531\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1612 - accuracy: 0.9604 - val_loss: 0.2987 - val_accuracy: 0.9567\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1569 - accuracy: 0.9620 - val_loss: 0.3646 - val_accuracy: 0.9314\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1575 - accuracy: 0.9598 - val_loss: 0.2833 - val_accuracy: 0.9558\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1568 - accuracy: 0.9594 - val_loss: 0.2762 - val_accuracy: 0.9564\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1405 - accuracy: 0.9647 - val_loss: 0.2742 - val_accuracy: 0.9668\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1443 - accuracy: 0.9614 - val_loss: 0.2781 - val_accuracy: 0.9567\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1396 - accuracy: 0.9652 - val_loss: 0.3015 - val_accuracy: 0.9514\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1313 - accuracy: 0.9676 - val_loss: 0.3482 - val_accuracy: 0.9342\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1361 - accuracy: 0.9662 - val_loss: 0.2872 - val_accuracy: 0.9613\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1302 - accuracy: 0.9675 - val_loss: 0.2749 - val_accuracy: 0.9571\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1269 - accuracy: 0.9682 - val_loss: 0.3194 - val_accuracy: 0.9419\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1265 - accuracy: 0.9685 - val_loss: 0.2588 - val_accuracy: 0.9657\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1192 - accuracy: 0.9713 - val_loss: 0.2678 - val_accuracy: 0.9688\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1197 - accuracy: 0.9700 - val_loss: 0.2743 - val_accuracy: 0.9619\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1151 - accuracy: 0.9717 - val_loss: 0.2475 - val_accuracy: 0.9705\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1130 - accuracy: 0.9718 - val_loss: 0.2477 - val_accuracy: 0.9710\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1138 - accuracy: 0.9714 - val_loss: 0.2635 - val_accuracy: 0.9705\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1047 - accuracy: 0.9754 - val_loss: 0.2442 - val_accuracy: 0.9727\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1045 - accuracy: 0.9756 - val_loss: 0.3049 - val_accuracy: 0.9703\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1115 - accuracy: 0.9737 - val_loss: 0.2482 - val_accuracy: 0.9683\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1034 - accuracy: 0.9747 - val_loss: 0.2301 - val_accuracy: 0.9767\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0960 - accuracy: 0.9762 - val_loss: 0.2366 - val_accuracy: 0.9762\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 4.0743 - accuracy: 0.2264 - val_loss: 2.9440 - val_accuracy: 0.4735\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9533 - accuracy: 0.6447 - val_loss: 1.6511 - val_accuracy: 0.7529\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0616 - accuracy: 0.7853 - val_loss: 1.1525 - val_accuracy: 0.8044\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6955 - accuracy: 0.8436 - val_loss: 0.9369 - val_accuracy: 0.8524\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5328 - accuracy: 0.8702 - val_loss: 0.8152 - val_accuracy: 0.8640\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4408 - accuracy: 0.8911 - val_loss: 0.6640 - val_accuracy: 0.8693\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3807 - accuracy: 0.9035 - val_loss: 0.5980 - val_accuracy: 0.9080\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3431 - accuracy: 0.9124 - val_loss: 0.5401 - val_accuracy: 0.9063\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3114 - accuracy: 0.9195 - val_loss: 0.4898 - val_accuracy: 0.9120\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2888 - accuracy: 0.9264 - val_loss: 0.4898 - val_accuracy: 0.9193\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2659 - accuracy: 0.9327 - val_loss: 0.4392 - val_accuracy: 0.9151\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2428 - accuracy: 0.9375 - val_loss: 0.4282 - val_accuracy: 0.9186\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2283 - accuracy: 0.9407 - val_loss: 0.4221 - val_accuracy: 0.9265\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2228 - accuracy: 0.9432 - val_loss: 0.3841 - val_accuracy: 0.9413\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2026 - accuracy: 0.9485 - val_loss: 0.4137 - val_accuracy: 0.9263\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1936 - accuracy: 0.9519 - val_loss: 0.3857 - val_accuracy: 0.9382\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1933 - accuracy: 0.9527 - val_loss: 0.3423 - val_accuracy: 0.9364\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1735 - accuracy: 0.9585 - val_loss: 0.3372 - val_accuracy: 0.9490\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1742 - accuracy: 0.9564 - val_loss: 0.3461 - val_accuracy: 0.9459\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1645 - accuracy: 0.9599 - val_loss: 0.3330 - val_accuracy: 0.9494\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1654 - accuracy: 0.9603 - val_loss: 0.3307 - val_accuracy: 0.9481\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1568 - accuracy: 0.9597 - val_loss: 0.3416 - val_accuracy: 0.9492\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1474 - accuracy: 0.9634 - val_loss: 0.3278 - val_accuracy: 0.9437\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1461 - accuracy: 0.9640 - val_loss: 0.3114 - val_accuracy: 0.9589\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1431 - accuracy: 0.9639 - val_loss: 0.3150 - val_accuracy: 0.9472\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1391 - accuracy: 0.9645 - val_loss: 0.2964 - val_accuracy: 0.9615\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1349 - accuracy: 0.9664 - val_loss: 0.3058 - val_accuracy: 0.9512\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1352 - accuracy: 0.9674 - val_loss: 0.3049 - val_accuracy: 0.9589\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1276 - accuracy: 0.9698 - val_loss: 0.2993 - val_accuracy: 0.9463\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1291 - accuracy: 0.9678 - val_loss: 0.2914 - val_accuracy: 0.9474\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1227 - accuracy: 0.9697 - val_loss: 0.2725 - val_accuracy: 0.9690\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1197 - accuracy: 0.9698 - val_loss: 0.3166 - val_accuracy: 0.9505\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1231 - accuracy: 0.9694 - val_loss: 0.2988 - val_accuracy: 0.9514\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1188 - accuracy: 0.9719 - val_loss: 0.2671 - val_accuracy: 0.9619\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1228 - accuracy: 0.9692 - val_loss: 0.2653 - val_accuracy: 0.9668\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1090 - accuracy: 0.9738 - val_loss: 0.2710 - val_accuracy: 0.9611\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1084 - accuracy: 0.9732 - val_loss: 0.2971 - val_accuracy: 0.9578\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1150 - accuracy: 0.9701 - val_loss: 0.2725 - val_accuracy: 0.9690\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9712 - val_loss: 0.2860 - val_accuracy: 0.9600\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9731 - val_loss: 0.2742 - val_accuracy: 0.9685\n","Average Validation Accuracy: 0.9775623381137848\n","Average Validation Loss: 0.14920447766780853\n","Average Test Accuracy: 0.9770399034023285\n","------------------------------------------------------------------------\n","\n","Number of input features: 12\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 4.0633 - accuracy: 0.2331 - val_loss: 3.0340 - val_accuracy: 0.4537\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.0831 - accuracy: 0.6203 - val_loss: 1.7106 - val_accuracy: 0.7164\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1277 - accuracy: 0.7755 - val_loss: 1.1996 - val_accuracy: 0.8101\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7365 - accuracy: 0.8358 - val_loss: 0.9341 - val_accuracy: 0.8482\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5404 - accuracy: 0.8754 - val_loss: 0.7818 - val_accuracy: 0.8928\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4417 - accuracy: 0.8936 - val_loss: 0.6962 - val_accuracy: 0.9012\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3624 - accuracy: 0.9099 - val_loss: 0.6402 - val_accuracy: 0.9100\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3302 - accuracy: 0.9170 - val_loss: 0.6018 - val_accuracy: 0.9171\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2910 - accuracy: 0.9261 - val_loss: 0.5072 - val_accuracy: 0.9248\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2672 - accuracy: 0.9324 - val_loss: 0.5044 - val_accuracy: 0.9276\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2393 - accuracy: 0.9401 - val_loss: 0.5157 - val_accuracy: 0.9338\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2226 - accuracy: 0.9445 - val_loss: 0.4690 - val_accuracy: 0.9265\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2205 - accuracy: 0.9459 - val_loss: 0.4459 - val_accuracy: 0.9377\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2035 - accuracy: 0.9500 - val_loss: 0.4313 - val_accuracy: 0.9404\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1891 - accuracy: 0.9543 - val_loss: 0.4443 - val_accuracy: 0.9377\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1916 - accuracy: 0.9524 - val_loss: 0.3779 - val_accuracy: 0.9507\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1693 - accuracy: 0.9596 - val_loss: 0.3799 - val_accuracy: 0.9503\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1791 - accuracy: 0.9556 - val_loss: 0.3855 - val_accuracy: 0.9545\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1646 - accuracy: 0.9583 - val_loss: 0.4022 - val_accuracy: 0.9415\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1584 - accuracy: 0.9608 - val_loss: 0.3939 - val_accuracy: 0.9481\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1510 - accuracy: 0.9633 - val_loss: 0.3670 - val_accuracy: 0.9549\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1518 - accuracy: 0.9625 - val_loss: 0.3511 - val_accuracy: 0.9657\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1410 - accuracy: 0.9661 - val_loss: 0.3375 - val_accuracy: 0.9701\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1501 - accuracy: 0.9635 - val_loss: 0.3523 - val_accuracy: 0.9584\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1344 - accuracy: 0.9659 - val_loss: 0.3564 - val_accuracy: 0.9549\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1363 - accuracy: 0.9678 - val_loss: 0.3556 - val_accuracy: 0.9516\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1312 - accuracy: 0.9691 - val_loss: 0.4027 - val_accuracy: 0.9446\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1330 - accuracy: 0.9677 - val_loss: 0.3299 - val_accuracy: 0.9624\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1215 - accuracy: 0.9718 - val_loss: 0.3506 - val_accuracy: 0.9586\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1242 - accuracy: 0.9701 - val_loss: 0.3407 - val_accuracy: 0.9622\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1189 - accuracy: 0.9710 - val_loss: 0.3397 - val_accuracy: 0.9701\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1218 - accuracy: 0.9714 - val_loss: 0.3293 - val_accuracy: 0.9743\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1116 - accuracy: 0.9728 - val_loss: 0.3254 - val_accuracy: 0.9681\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1114 - accuracy: 0.9740 - val_loss: 0.3277 - val_accuracy: 0.9703\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1135 - accuracy: 0.9734 - val_loss: 0.3669 - val_accuracy: 0.9624\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1070 - accuracy: 0.9757 - val_loss: 0.3128 - val_accuracy: 0.9743\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1101 - accuracy: 0.9753 - val_loss: 0.3841 - val_accuracy: 0.9628\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1056 - accuracy: 0.9741 - val_loss: 0.3310 - val_accuracy: 0.9701\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1039 - accuracy: 0.9753 - val_loss: 0.3670 - val_accuracy: 0.9655\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0980 - accuracy: 0.9777 - val_loss: 0.3137 - val_accuracy: 0.9754\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.5291 - accuracy: 0.3474 - val_loss: 2.1851 - val_accuracy: 0.6409\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3712 - accuracy: 0.7392 - val_loss: 1.2492 - val_accuracy: 0.8002\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7411 - accuracy: 0.8381 - val_loss: 0.8728 - val_accuracy: 0.8667\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5063 - accuracy: 0.8818 - val_loss: 0.7426 - val_accuracy: 0.8609\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3971 - accuracy: 0.9042 - val_loss: 0.6306 - val_accuracy: 0.8807\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3407 - accuracy: 0.9125 - val_loss: 0.5269 - val_accuracy: 0.9206\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2947 - accuracy: 0.9268 - val_loss: 0.5001 - val_accuracy: 0.9166\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2688 - accuracy: 0.9316 - val_loss: 0.4993 - val_accuracy: 0.9219\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2514 - accuracy: 0.9355 - val_loss: 0.4466 - val_accuracy: 0.9234\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2274 - accuracy: 0.9427 - val_loss: 0.4538 - val_accuracy: 0.9289\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2182 - accuracy: 0.9438 - val_loss: 0.4199 - val_accuracy: 0.9382\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2025 - accuracy: 0.9482 - val_loss: 0.3694 - val_accuracy: 0.9498\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1947 - accuracy: 0.9498 - val_loss: 0.3923 - val_accuracy: 0.9399\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1895 - accuracy: 0.9516 - val_loss: 0.3740 - val_accuracy: 0.9399\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1744 - accuracy: 0.9560 - val_loss: 0.3457 - val_accuracy: 0.9571\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1695 - accuracy: 0.9581 - val_loss: 0.3598 - val_accuracy: 0.9443\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1680 - accuracy: 0.9594 - val_loss: 0.3594 - val_accuracy: 0.9512\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1501 - accuracy: 0.9637 - val_loss: 0.3474 - val_accuracy: 0.9487\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1577 - accuracy: 0.9589 - val_loss: 0.3456 - val_accuracy: 0.9547\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1537 - accuracy: 0.9609 - val_loss: 0.3457 - val_accuracy: 0.9481\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1488 - accuracy: 0.9621 - val_loss: 0.3350 - val_accuracy: 0.9560\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1423 - accuracy: 0.9650 - val_loss: 0.4260 - val_accuracy: 0.9349\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1457 - accuracy: 0.9620 - val_loss: 0.3284 - val_accuracy: 0.9578\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1390 - accuracy: 0.9659 - val_loss: 0.3462 - val_accuracy: 0.9428\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1288 - accuracy: 0.9688 - val_loss: 0.2928 - val_accuracy: 0.9639\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1375 - accuracy: 0.9649 - val_loss: 0.2895 - val_accuracy: 0.9639\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1336 - accuracy: 0.9671 - val_loss: 0.3590 - val_accuracy: 0.9364\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1286 - accuracy: 0.9691 - val_loss: 0.2970 - val_accuracy: 0.9608\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1241 - accuracy: 0.9687 - val_loss: 0.2807 - val_accuracy: 0.9659\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1195 - accuracy: 0.9706 - val_loss: 0.3300 - val_accuracy: 0.9443\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1157 - accuracy: 0.9729 - val_loss: 0.3019 - val_accuracy: 0.9531\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1172 - accuracy: 0.9728 - val_loss: 0.2831 - val_accuracy: 0.9624\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1227 - accuracy: 0.9698 - val_loss: 0.2994 - val_accuracy: 0.9613\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1171 - accuracy: 0.9741 - val_loss: 0.2986 - val_accuracy: 0.9622\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1076 - accuracy: 0.9751 - val_loss: 0.2863 - val_accuracy: 0.9622\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1175 - accuracy: 0.9723 - val_loss: 0.2919 - val_accuracy: 0.9551\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9747 - val_loss: 0.2810 - val_accuracy: 0.9661\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1001 - accuracy: 0.9777 - val_loss: 0.2729 - val_accuracy: 0.9584\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1096 - accuracy: 0.9733 - val_loss: 0.2989 - val_accuracy: 0.9586\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1028 - accuracy: 0.9778 - val_loss: 0.2552 - val_accuracy: 0.9699\n","Average Validation Accuracy: 0.9774534106254578\n","Average Validation Loss: 0.15225279331207275\n","Average Test Accuracy: 0.9774821102619171\n","------------------------------------------------------------------------\n","\n","Number of input features: 13\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.6220 - accuracy: 0.3244 - val_loss: 2.3374 - val_accuracy: 0.6092\n","Epoch 2/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.5052 - accuracy: 0.7238 - val_loss: 1.3477 - val_accuracy: 0.7699\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8888 - accuracy: 0.8139 - val_loss: 0.9649 - val_accuracy: 0.8328\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6340 - accuracy: 0.8487 - val_loss: 0.8382 - val_accuracy: 0.8543\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4967 - accuracy: 0.8798 - val_loss: 0.7394 - val_accuracy: 0.8737\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4121 - accuracy: 0.8964 - val_loss: 0.6221 - val_accuracy: 0.9032\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3485 - accuracy: 0.9118 - val_loss: 0.6323 - val_accuracy: 0.8882\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3127 - accuracy: 0.9200 - val_loss: 0.5214 - val_accuracy: 0.9278\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2745 - accuracy: 0.9321 - val_loss: 0.5424 - val_accuracy: 0.9144\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2520 - accuracy: 0.9389 - val_loss: 0.5549 - val_accuracy: 0.9109\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2426 - accuracy: 0.9416 - val_loss: 0.4268 - val_accuracy: 0.9415\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2274 - accuracy: 0.9459 - val_loss: 0.4009 - val_accuracy: 0.9428\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2076 - accuracy: 0.9493 - val_loss: 0.3999 - val_accuracy: 0.9410\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1999 - accuracy: 0.9510 - val_loss: 0.3839 - val_accuracy: 0.9501\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1948 - accuracy: 0.9535 - val_loss: 0.4235 - val_accuracy: 0.9393\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1913 - accuracy: 0.9551 - val_loss: 0.3993 - val_accuracy: 0.9472\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1799 - accuracy: 0.9570 - val_loss: 0.3521 - val_accuracy: 0.9518\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1806 - accuracy: 0.9560 - val_loss: 0.3677 - val_accuracy: 0.9437\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1644 - accuracy: 0.9596 - val_loss: 0.3285 - val_accuracy: 0.9597\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1646 - accuracy: 0.9591 - val_loss: 0.3536 - val_accuracy: 0.9538\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1600 - accuracy: 0.9617 - val_loss: 0.3381 - val_accuracy: 0.9531\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1521 - accuracy: 0.9617 - val_loss: 0.3555 - val_accuracy: 0.9492\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1574 - accuracy: 0.9613 - val_loss: 0.3385 - val_accuracy: 0.9545\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1507 - accuracy: 0.9635 - val_loss: 0.3308 - val_accuracy: 0.9589\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1439 - accuracy: 0.9656 - val_loss: 0.3234 - val_accuracy: 0.9602\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1464 - accuracy: 0.9625 - val_loss: 0.3234 - val_accuracy: 0.9668\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1399 - accuracy: 0.9659 - val_loss: 0.3299 - val_accuracy: 0.9549\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1397 - accuracy: 0.9655 - val_loss: 0.3095 - val_accuracy: 0.9567\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1288 - accuracy: 0.9682 - val_loss: 0.3614 - val_accuracy: 0.9461\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1366 - accuracy: 0.9664 - val_loss: 0.3867 - val_accuracy: 0.9307\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1300 - accuracy: 0.9668 - val_loss: 0.2988 - val_accuracy: 0.9685\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1293 - accuracy: 0.9673 - val_loss: 0.2993 - val_accuracy: 0.9694\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1335 - accuracy: 0.9673 - val_loss: 0.2982 - val_accuracy: 0.9602\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1166 - accuracy: 0.9711 - val_loss: 0.3024 - val_accuracy: 0.9685\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1233 - accuracy: 0.9715 - val_loss: 0.3111 - val_accuracy: 0.9628\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1200 - accuracy: 0.9694 - val_loss: 0.2852 - val_accuracy: 0.9725\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1141 - accuracy: 0.9729 - val_loss: 0.2883 - val_accuracy: 0.9727\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1174 - accuracy: 0.9725 - val_loss: 0.2842 - val_accuracy: 0.9723\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1122 - accuracy: 0.9726 - val_loss: 0.3150 - val_accuracy: 0.9556\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1078 - accuracy: 0.9730 - val_loss: 0.2998 - val_accuracy: 0.9683\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.9363 - accuracy: 0.2487 - val_loss: 2.7720 - val_accuracy: 0.4937\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8742 - accuracy: 0.6390 - val_loss: 1.6628 - val_accuracy: 0.7415\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0543 - accuracy: 0.7852 - val_loss: 1.2558 - val_accuracy: 0.7949\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7015 - accuracy: 0.8492 - val_loss: 0.9183 - val_accuracy: 0.8702\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5252 - accuracy: 0.8841 - val_loss: 0.8169 - val_accuracy: 0.8854\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4371 - accuracy: 0.8962 - val_loss: 0.7014 - val_accuracy: 0.8970\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3780 - accuracy: 0.9083 - val_loss: 0.6138 - val_accuracy: 0.9078\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3354 - accuracy: 0.9167 - val_loss: 0.5752 - val_accuracy: 0.9120\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3060 - accuracy: 0.9220 - val_loss: 0.5130 - val_accuracy: 0.9177\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2816 - accuracy: 0.9254 - val_loss: 0.4944 - val_accuracy: 0.9184\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2610 - accuracy: 0.9311 - val_loss: 0.5164 - val_accuracy: 0.8893\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2457 - accuracy: 0.9354 - val_loss: 0.4786 - val_accuracy: 0.9166\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2308 - accuracy: 0.9417 - val_loss: 0.4298 - val_accuracy: 0.9327\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2186 - accuracy: 0.9440 - val_loss: 0.4686 - val_accuracy: 0.9261\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2104 - accuracy: 0.9464 - val_loss: 0.4676 - val_accuracy: 0.9173\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1970 - accuracy: 0.9504 - val_loss: 0.4280 - val_accuracy: 0.9303\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1972 - accuracy: 0.9486 - val_loss: 0.3892 - val_accuracy: 0.9483\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1845 - accuracy: 0.9558 - val_loss: 0.3955 - val_accuracy: 0.9388\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1816 - accuracy: 0.9542 - val_loss: 0.3936 - val_accuracy: 0.9503\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1730 - accuracy: 0.9569 - val_loss: 0.3648 - val_accuracy: 0.9520\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1709 - accuracy: 0.9584 - val_loss: 0.3783 - val_accuracy: 0.9470\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1580 - accuracy: 0.9606 - val_loss: 0.4052 - val_accuracy: 0.9344\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1566 - accuracy: 0.9593 - val_loss: 0.3803 - val_accuracy: 0.9584\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1592 - accuracy: 0.9598 - val_loss: 0.4186 - val_accuracy: 0.9221\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1503 - accuracy: 0.9610 - val_loss: 0.3602 - val_accuracy: 0.9567\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1481 - accuracy: 0.9623 - val_loss: 0.3437 - val_accuracy: 0.9597\n","Epoch 27/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1439 - accuracy: 0.9642 - val_loss: 0.3753 - val_accuracy: 0.9531\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1445 - accuracy: 0.9648 - val_loss: 0.3334 - val_accuracy: 0.9628\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1421 - accuracy: 0.9621 - val_loss: 0.3437 - val_accuracy: 0.9595\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1333 - accuracy: 0.9685 - val_loss: 0.3341 - val_accuracy: 0.9560\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1345 - accuracy: 0.9675 - val_loss: 0.3554 - val_accuracy: 0.9496\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1287 - accuracy: 0.9685 - val_loss: 0.3438 - val_accuracy: 0.9547\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1276 - accuracy: 0.9686 - val_loss: 0.3250 - val_accuracy: 0.9593\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1278 - accuracy: 0.9682 - val_loss: 0.3474 - val_accuracy: 0.9446\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1245 - accuracy: 0.9702 - val_loss: 0.3164 - val_accuracy: 0.9672\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1221 - accuracy: 0.9717 - val_loss: 0.3049 - val_accuracy: 0.9692\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1156 - accuracy: 0.9707 - val_loss: 0.3349 - val_accuracy: 0.9569\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1204 - accuracy: 0.9705 - val_loss: 0.3252 - val_accuracy: 0.9633\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1247 - accuracy: 0.9684 - val_loss: 0.3051 - val_accuracy: 0.9681\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1145 - accuracy: 0.9720 - val_loss: 0.3154 - val_accuracy: 0.9589\n","Average Validation Accuracy: 0.9688848257064819\n","Average Validation Loss: 0.18048403412103653\n","Average Test Accuracy: 0.9696322083473206\n","------------------------------------------------------------------------\n","\n","Number of input features: 14\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7327 - accuracy: 0.2990 - val_loss: 2.4625 - val_accuracy: 0.5688\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6473 - accuracy: 0.7003 - val_loss: 1.4421 - val_accuracy: 0.7274\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9163 - accuracy: 0.8088 - val_loss: 0.9670 - val_accuracy: 0.8345\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5750 - accuracy: 0.8662 - val_loss: 0.7855 - val_accuracy: 0.8653\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4229 - accuracy: 0.8970 - val_loss: 0.6320 - val_accuracy: 0.8939\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3435 - accuracy: 0.9130 - val_loss: 0.6439 - val_accuracy: 0.8926\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3010 - accuracy: 0.9266 - val_loss: 0.4992 - val_accuracy: 0.9212\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2658 - accuracy: 0.9333 - val_loss: 0.4684 - val_accuracy: 0.9256\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2440 - accuracy: 0.9404 - val_loss: 0.4559 - val_accuracy: 0.9344\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2280 - accuracy: 0.9423 - val_loss: 0.4444 - val_accuracy: 0.9384\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2175 - accuracy: 0.9463 - val_loss: 0.4248 - val_accuracy: 0.9364\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2020 - accuracy: 0.9500 - val_loss: 0.4202 - val_accuracy: 0.9373\n","Epoch 13/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1990 - accuracy: 0.9502 - val_loss: 0.3959 - val_accuracy: 0.9391\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1824 - accuracy: 0.9545 - val_loss: 0.3818 - val_accuracy: 0.9443\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1779 - accuracy: 0.9577 - val_loss: 0.3593 - val_accuracy: 0.9567\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1731 - accuracy: 0.9563 - val_loss: 0.3736 - val_accuracy: 0.9534\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1660 - accuracy: 0.9588 - val_loss: 0.3508 - val_accuracy: 0.9496\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1528 - accuracy: 0.9641 - val_loss: 0.3778 - val_accuracy: 0.9446\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1538 - accuracy: 0.9610 - val_loss: 0.3320 - val_accuracy: 0.9657\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1536 - accuracy: 0.9622 - val_loss: 0.3381 - val_accuracy: 0.9622\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1451 - accuracy: 0.9646 - val_loss: 0.3662 - val_accuracy: 0.9439\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1455 - accuracy: 0.9631 - val_loss: 0.3373 - val_accuracy: 0.9547\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1454 - accuracy: 0.9641 - val_loss: 0.3421 - val_accuracy: 0.9505\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1333 - accuracy: 0.9670 - val_loss: 0.3272 - val_accuracy: 0.9589\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1389 - accuracy: 0.9640 - val_loss: 0.3377 - val_accuracy: 0.9589\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1296 - accuracy: 0.9678 - val_loss: 0.3280 - val_accuracy: 0.9608\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1428 - accuracy: 0.9657 - val_loss: 0.3038 - val_accuracy: 0.9710\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1191 - accuracy: 0.9723 - val_loss: 0.3334 - val_accuracy: 0.9595\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1295 - accuracy: 0.9677 - val_loss: 0.3100 - val_accuracy: 0.9650\n","Epoch 30/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1191 - accuracy: 0.9717 - val_loss: 0.3347 - val_accuracy: 0.9619\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1224 - accuracy: 0.9701 - val_loss: 0.3382 - val_accuracy: 0.9540\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1246 - accuracy: 0.9690 - val_loss: 0.3352 - val_accuracy: 0.9611\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1155 - accuracy: 0.9708 - val_loss: 0.3203 - val_accuracy: 0.9628\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1186 - accuracy: 0.9713 - val_loss: 0.3219 - val_accuracy: 0.9611\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1141 - accuracy: 0.9720 - val_loss: 0.3084 - val_accuracy: 0.9773\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1114 - accuracy: 0.9739 - val_loss: 0.3105 - val_accuracy: 0.9714\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1114 - accuracy: 0.9733 - val_loss: 0.3123 - val_accuracy: 0.9705\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1138 - accuracy: 0.9718 - val_loss: 0.3255 - val_accuracy: 0.9626\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1082 - accuracy: 0.9739 - val_loss: 0.3233 - val_accuracy: 0.9701\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1124 - accuracy: 0.9734 - val_loss: 0.3006 - val_accuracy: 0.9760\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.9167 - accuracy: 0.2631 - val_loss: 2.8108 - val_accuracy: 0.5463\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7808 - accuracy: 0.6777 - val_loss: 1.5864 - val_accuracy: 0.7529\n","Epoch 3/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.9301 - accuracy: 0.8041 - val_loss: 1.1004 - val_accuracy: 0.8233\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5985 - accuracy: 0.8629 - val_loss: 0.8274 - val_accuracy: 0.8777\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4501 - accuracy: 0.8921 - val_loss: 0.7226 - val_accuracy: 0.8906\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3748 - accuracy: 0.9089 - val_loss: 0.6153 - val_accuracy: 0.8999\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3198 - accuracy: 0.9210 - val_loss: 0.5649 - val_accuracy: 0.9078\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2986 - accuracy: 0.9242 - val_loss: 0.5155 - val_accuracy: 0.9098\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2603 - accuracy: 0.9323 - val_loss: 0.4662 - val_accuracy: 0.9248\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2383 - accuracy: 0.9397 - val_loss: 0.4575 - val_accuracy: 0.9223\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2270 - accuracy: 0.9420 - val_loss: 0.4245 - val_accuracy: 0.9382\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2116 - accuracy: 0.9484 - val_loss: 0.3824 - val_accuracy: 0.9430\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2036 - accuracy: 0.9504 - val_loss: 0.4243 - val_accuracy: 0.9309\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1874 - accuracy: 0.9534 - val_loss: 0.3601 - val_accuracy: 0.9446\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1869 - accuracy: 0.9525 - val_loss: 0.3750 - val_accuracy: 0.9454\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1734 - accuracy: 0.9581 - val_loss: 0.3682 - val_accuracy: 0.9443\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1726 - accuracy: 0.9583 - val_loss: 0.3345 - val_accuracy: 0.9496\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1624 - accuracy: 0.9609 - val_loss: 0.3236 - val_accuracy: 0.9523\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1514 - accuracy: 0.9639 - val_loss: 0.3406 - val_accuracy: 0.9461\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1521 - accuracy: 0.9614 - val_loss: 0.3162 - val_accuracy: 0.9538\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1469 - accuracy: 0.9645 - val_loss: 0.3333 - val_accuracy: 0.9509\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1420 - accuracy: 0.9659 - val_loss: 0.3069 - val_accuracy: 0.9514\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1390 - accuracy: 0.9661 - val_loss: 0.3439 - val_accuracy: 0.9463\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1304 - accuracy: 0.9691 - val_loss: 0.3077 - val_accuracy: 0.9501\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1308 - accuracy: 0.9679 - val_loss: 0.3038 - val_accuracy: 0.9582\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1338 - accuracy: 0.9685 - val_loss: 0.2866 - val_accuracy: 0.9701\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1175 - accuracy: 0.9736 - val_loss: 0.2953 - val_accuracy: 0.9567\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1277 - accuracy: 0.9704 - val_loss: 0.2831 - val_accuracy: 0.9655\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1201 - accuracy: 0.9711 - val_loss: 0.2782 - val_accuracy: 0.9633\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1157 - accuracy: 0.9744 - val_loss: 0.3145 - val_accuracy: 0.9503\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1219 - accuracy: 0.9703 - val_loss: 0.2832 - val_accuracy: 0.9646\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1147 - accuracy: 0.9725 - val_loss: 0.2825 - val_accuracy: 0.9622\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1128 - accuracy: 0.9733 - val_loss: 0.2889 - val_accuracy: 0.9580\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1066 - accuracy: 0.9764 - val_loss: 0.2647 - val_accuracy: 0.9681\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1081 - accuracy: 0.9752 - val_loss: 0.2797 - val_accuracy: 0.9637\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1123 - accuracy: 0.9740 - val_loss: 0.2790 - val_accuracy: 0.9655\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1023 - accuracy: 0.9768 - val_loss: 0.2899 - val_accuracy: 0.9582\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1095 - accuracy: 0.9756 - val_loss: 0.2722 - val_accuracy: 0.9602\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1023 - accuracy: 0.9777 - val_loss: 0.2596 - val_accuracy: 0.9688\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0967 - accuracy: 0.9789 - val_loss: 0.2903 - val_accuracy: 0.9538\n","Average Validation Accuracy: 0.9724428355693817\n","Average Validation Loss: 0.16685474663972855\n","Average Test Accuracy: 0.9725805521011353\n","------------------------------------------------------------------------\n","\n","Number of input features: 15\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.7572 - accuracy: 0.3031 - val_loss: 2.5474 - val_accuracy: 0.5347\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6475 - accuracy: 0.6964 - val_loss: 1.4464 - val_accuracy: 0.7512\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8640 - accuracy: 0.8219 - val_loss: 1.0120 - val_accuracy: 0.8268\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5472 - accuracy: 0.8754 - val_loss: 0.8031 - val_accuracy: 0.8473\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4091 - accuracy: 0.9008 - val_loss: 0.6210 - val_accuracy: 0.8906\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3337 - accuracy: 0.9161 - val_loss: 0.5486 - val_accuracy: 0.9168\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2960 - accuracy: 0.9281 - val_loss: 0.4961 - val_accuracy: 0.9287\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2678 - accuracy: 0.9323 - val_loss: 0.5051 - val_accuracy: 0.9195\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2435 - accuracy: 0.9371 - val_loss: 0.4947 - val_accuracy: 0.9278\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2282 - accuracy: 0.9454 - val_loss: 0.4368 - val_accuracy: 0.9276\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2137 - accuracy: 0.9462 - val_loss: 0.4186 - val_accuracy: 0.9254\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2059 - accuracy: 0.9470 - val_loss: 0.4123 - val_accuracy: 0.9349\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1953 - accuracy: 0.9530 - val_loss: 0.3687 - val_accuracy: 0.9483\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1816 - accuracy: 0.9569 - val_loss: 0.3922 - val_accuracy: 0.9404\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1865 - accuracy: 0.9539 - val_loss: 0.3898 - val_accuracy: 0.9410\n","Epoch 16/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1676 - accuracy: 0.9601 - val_loss: 0.3697 - val_accuracy: 0.9366\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1627 - accuracy: 0.9612 - val_loss: 0.3408 - val_accuracy: 0.9556\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1685 - accuracy: 0.9584 - val_loss: 0.3404 - val_accuracy: 0.9498\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1501 - accuracy: 0.9641 - val_loss: 0.3386 - val_accuracy: 0.9487\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1543 - accuracy: 0.9612 - val_loss: 0.3535 - val_accuracy: 0.9479\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1516 - accuracy: 0.9609 - val_loss: 0.3321 - val_accuracy: 0.9540\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1493 - accuracy: 0.9634 - val_loss: 0.3501 - val_accuracy: 0.9470\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1352 - accuracy: 0.9684 - val_loss: 0.3191 - val_accuracy: 0.9556\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1404 - accuracy: 0.9654 - val_loss: 0.3114 - val_accuracy: 0.9573\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1328 - accuracy: 0.9678 - val_loss: 0.3457 - val_accuracy: 0.9578\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1399 - accuracy: 0.9659 - val_loss: 0.3311 - val_accuracy: 0.9591\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1294 - accuracy: 0.9684 - val_loss: 0.3321 - val_accuracy: 0.9540\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1252 - accuracy: 0.9700 - val_loss: 0.3393 - val_accuracy: 0.9540\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1283 - accuracy: 0.9678 - val_loss: 0.2959 - val_accuracy: 0.9633\n","Epoch 30/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1218 - accuracy: 0.9718 - val_loss: 0.3022 - val_accuracy: 0.9641\n","Epoch 31/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1226 - accuracy: 0.9682 - val_loss: 0.3127 - val_accuracy: 0.9600\n","Epoch 32/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1182 - accuracy: 0.9714 - val_loss: 0.3207 - val_accuracy: 0.9591\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1222 - accuracy: 0.9697 - val_loss: 0.3115 - val_accuracy: 0.9650\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1160 - accuracy: 0.9718 - val_loss: 0.2928 - val_accuracy: 0.9685\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1107 - accuracy: 0.9720 - val_loss: 0.2790 - val_accuracy: 0.9718\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1167 - accuracy: 0.9708 - val_loss: 0.3052 - val_accuracy: 0.9659\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1046 - accuracy: 0.9758 - val_loss: 0.2923 - val_accuracy: 0.9751\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1095 - accuracy: 0.9742 - val_loss: 0.3002 - val_accuracy: 0.9668\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1082 - accuracy: 0.9731 - val_loss: 0.2925 - val_accuracy: 0.9732\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1029 - accuracy: 0.9758 - val_loss: 0.3064 - val_accuracy: 0.9602\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7796 - accuracy: 0.2890 - val_loss: 2.6287 - val_accuracy: 0.5705\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7668 - accuracy: 0.6663 - val_loss: 1.6241 - val_accuracy: 0.7292\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9896 - accuracy: 0.7959 - val_loss: 1.2313 - val_accuracy: 0.7824\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6509 - accuracy: 0.8576 - val_loss: 0.8740 - val_accuracy: 0.8840\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.4901 - accuracy: 0.8828 - val_loss: 0.7487 - val_accuracy: 0.8766\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3879 - accuracy: 0.9065 - val_loss: 0.6212 - val_accuracy: 0.9074\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3429 - accuracy: 0.9117 - val_loss: 0.5566 - val_accuracy: 0.9142\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3053 - accuracy: 0.9194 - val_loss: 0.5407 - val_accuracy: 0.9164\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2798 - accuracy: 0.9272 - val_loss: 0.5075 - val_accuracy: 0.9195\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2521 - accuracy: 0.9344 - val_loss: 0.5216 - val_accuracy: 0.9072\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2402 - accuracy: 0.9399 - val_loss: 0.4749 - val_accuracy: 0.9281\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2230 - accuracy: 0.9425 - val_loss: 0.4260 - val_accuracy: 0.9369\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.2154 - accuracy: 0.9465 - val_loss: 0.4407 - val_accuracy: 0.9261\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2014 - accuracy: 0.9494 - val_loss: 0.3935 - val_accuracy: 0.9494\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1939 - accuracy: 0.9509 - val_loss: 0.3850 - val_accuracy: 0.9432\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1879 - accuracy: 0.9533 - val_loss: 0.3717 - val_accuracy: 0.9494\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1748 - accuracy: 0.9556 - val_loss: 0.3848 - val_accuracy: 0.9430\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1754 - accuracy: 0.9579 - val_loss: 0.3565 - val_accuracy: 0.9479\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1605 - accuracy: 0.9620 - val_loss: 0.4446 - val_accuracy: 0.9320\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1624 - accuracy: 0.9584 - val_loss: 0.3404 - val_accuracy: 0.9538\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1550 - accuracy: 0.9627 - val_loss: 0.3638 - val_accuracy: 0.9470\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1469 - accuracy: 0.9649 - val_loss: 0.4247 - val_accuracy: 0.9395\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1446 - accuracy: 0.9646 - val_loss: 0.3468 - val_accuracy: 0.9452\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1465 - accuracy: 0.9630 - val_loss: 0.3372 - val_accuracy: 0.9547\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1411 - accuracy: 0.9651 - val_loss: 0.3093 - val_accuracy: 0.9650\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1297 - accuracy: 0.9694 - val_loss: 0.3360 - val_accuracy: 0.9556\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1315 - accuracy: 0.9684 - val_loss: 0.3259 - val_accuracy: 0.9560\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1293 - accuracy: 0.9682 - val_loss: 0.3513 - val_accuracy: 0.9492\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1225 - accuracy: 0.9686 - val_loss: 0.3092 - val_accuracy: 0.9591\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1325 - accuracy: 0.9671 - val_loss: 0.3318 - val_accuracy: 0.9547\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1178 - accuracy: 0.9707 - val_loss: 0.3206 - val_accuracy: 0.9525\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1183 - accuracy: 0.9708 - val_loss: 0.3203 - val_accuracy: 0.9602\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1206 - accuracy: 0.9718 - val_loss: 0.3157 - val_accuracy: 0.9615\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1073 - accuracy: 0.9755 - val_loss: 0.2977 - val_accuracy: 0.9659\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1108 - accuracy: 0.9743 - val_loss: 0.2955 - val_accuracy: 0.9597\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1120 - accuracy: 0.9741 - val_loss: 0.3004 - val_accuracy: 0.9701\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1080 - accuracy: 0.9737 - val_loss: 0.2957 - val_accuracy: 0.9652\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0998 - accuracy: 0.9775 - val_loss: 0.3041 - val_accuracy: 0.9641\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1074 - accuracy: 0.9751 - val_loss: 0.3126 - val_accuracy: 0.9536\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0971 - accuracy: 0.9780 - val_loss: 0.3013 - val_accuracy: 0.9646\n","Average Validation Accuracy: 0.9681589901447296\n","Average Validation Loss: 0.17293847352266312\n","Average Test Accuracy: 0.9684897065162659\n","------------------------------------------------------------------------\n","\n","Number of input features: 16\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7471 - accuracy: 0.2944 - val_loss: 2.6290 - val_accuracy: 0.5947\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6813 - accuracy: 0.6954 - val_loss: 1.4848 - val_accuracy: 0.7457\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9222 - accuracy: 0.8143 - val_loss: 1.0132 - val_accuracy: 0.8024\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6128 - accuracy: 0.8645 - val_loss: 0.7757 - val_accuracy: 0.8768\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4571 - accuracy: 0.8913 - val_loss: 0.6380 - val_accuracy: 0.9025\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3717 - accuracy: 0.9138 - val_loss: 0.6085 - val_accuracy: 0.8915\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3142 - accuracy: 0.9246 - val_loss: 0.5462 - val_accuracy: 0.9100\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2765 - accuracy: 0.9333 - val_loss: 0.4581 - val_accuracy: 0.9311\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2513 - accuracy: 0.9395 - val_loss: 0.4114 - val_accuracy: 0.9366\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.2228 - accuracy: 0.9473 - val_loss: 0.4513 - val_accuracy: 0.9289\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2086 - accuracy: 0.9488 - val_loss: 0.4067 - val_accuracy: 0.9322\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1893 - accuracy: 0.9548 - val_loss: 0.3951 - val_accuracy: 0.9388\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1806 - accuracy: 0.9558 - val_loss: 0.3622 - val_accuracy: 0.9512\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1713 - accuracy: 0.9579 - val_loss: 0.3533 - val_accuracy: 0.9542\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1535 - accuracy: 0.9637 - val_loss: 0.3698 - val_accuracy: 0.9424\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1564 - accuracy: 0.9610 - val_loss: 0.3083 - val_accuracy: 0.9591\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1369 - accuracy: 0.9697 - val_loss: 0.3204 - val_accuracy: 0.9611\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1377 - accuracy: 0.9670 - val_loss: 0.2994 - val_accuracy: 0.9622\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1354 - accuracy: 0.9682 - val_loss: 0.2951 - val_accuracy: 0.9657\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1339 - accuracy: 0.9704 - val_loss: 0.3240 - val_accuracy: 0.9490\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1210 - accuracy: 0.9719 - val_loss: 0.2863 - val_accuracy: 0.9688\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1188 - accuracy: 0.9718 - val_loss: 0.3138 - val_accuracy: 0.9567\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1185 - accuracy: 0.9702 - val_loss: 0.2964 - val_accuracy: 0.9677\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1076 - accuracy: 0.9760 - val_loss: 0.2717 - val_accuracy: 0.9703\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1150 - accuracy: 0.9729 - val_loss: 0.2950 - val_accuracy: 0.9633\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1073 - accuracy: 0.9752 - val_loss: 0.3178 - val_accuracy: 0.9657\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1043 - accuracy: 0.9759 - val_loss: 0.2659 - val_accuracy: 0.9736\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1025 - accuracy: 0.9754 - val_loss: 0.3130 - val_accuracy: 0.9595\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1006 - accuracy: 0.9768 - val_loss: 0.2934 - val_accuracy: 0.9589\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0900 - accuracy: 0.9801 - val_loss: 0.2595 - val_accuracy: 0.9716\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0996 - accuracy: 0.9779 - val_loss: 0.2452 - val_accuracy: 0.9824\n","Epoch 32/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0920 - accuracy: 0.9770 - val_loss: 0.3051 - val_accuracy: 0.9624\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0931 - accuracy: 0.9784 - val_loss: 0.2916 - val_accuracy: 0.9762\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0881 - accuracy: 0.9793 - val_loss: 0.2864 - val_accuracy: 0.9714\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0849 - accuracy: 0.9797 - val_loss: 0.2874 - val_accuracy: 0.9606\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0935 - accuracy: 0.9781 - val_loss: 0.2910 - val_accuracy: 0.9701\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0778 - accuracy: 0.9824 - val_loss: 0.2815 - val_accuracy: 0.9743\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0877 - accuracy: 0.9794 - val_loss: 0.2767 - val_accuracy: 0.9727\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0821 - accuracy: 0.9814 - val_loss: 0.2766 - val_accuracy: 0.9767\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0853 - accuracy: 0.9796 - val_loss: 0.2795 - val_accuracy: 0.9679\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.7488 - accuracy: 0.2860 - val_loss: 2.5000 - val_accuracy: 0.6059\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5463 - accuracy: 0.7248 - val_loss: 1.4387 - val_accuracy: 0.7756\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7767 - accuracy: 0.8524 - val_loss: 0.9158 - val_accuracy: 0.8785\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4957 - accuracy: 0.8985 - val_loss: 0.7854 - val_accuracy: 0.8862\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3642 - accuracy: 0.9215 - val_loss: 0.6002 - val_accuracy: 0.9168\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2838 - accuracy: 0.9387 - val_loss: 0.4742 - val_accuracy: 0.9351\n","Epoch 7/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2452 - accuracy: 0.9456 - val_loss: 0.4684 - val_accuracy: 0.9307\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2166 - accuracy: 0.9513 - val_loss: 0.4183 - val_accuracy: 0.9432\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1967 - accuracy: 0.9558 - val_loss: 0.3492 - val_accuracy: 0.9571\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1829 - accuracy: 0.9594 - val_loss: 0.3539 - val_accuracy: 0.9432\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1699 - accuracy: 0.9626 - val_loss: 0.3517 - val_accuracy: 0.9397\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1548 - accuracy: 0.9671 - val_loss: 0.2986 - val_accuracy: 0.9597\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1558 - accuracy: 0.9640 - val_loss: 0.2744 - val_accuracy: 0.9622\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1339 - accuracy: 0.9699 - val_loss: 0.4322 - val_accuracy: 0.9355\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1355 - accuracy: 0.9690 - val_loss: 0.2714 - val_accuracy: 0.9589\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1322 - accuracy: 0.9704 - val_loss: 0.3030 - val_accuracy: 0.9494\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1243 - accuracy: 0.9736 - val_loss: 0.2774 - val_accuracy: 0.9558\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1155 - accuracy: 0.9751 - val_loss: 0.2594 - val_accuracy: 0.9558\n","Epoch 19/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1205 - accuracy: 0.9703 - val_loss: 0.2245 - val_accuracy: 0.9608\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1060 - accuracy: 0.9763 - val_loss: 0.2427 - val_accuracy: 0.9641\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1138 - accuracy: 0.9757 - val_loss: 0.2269 - val_accuracy: 0.9639\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0997 - accuracy: 0.9766 - val_loss: 0.2175 - val_accuracy: 0.9611\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0958 - accuracy: 0.9811 - val_loss: 0.2446 - val_accuracy: 0.9648\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1024 - accuracy: 0.9776 - val_loss: 0.2047 - val_accuracy: 0.9701\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0958 - accuracy: 0.9786 - val_loss: 0.2151 - val_accuracy: 0.9690\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0903 - accuracy: 0.9802 - val_loss: 0.2131 - val_accuracy: 0.9703\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0861 - accuracy: 0.9807 - val_loss: 0.2394 - val_accuracy: 0.9569\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0973 - accuracy: 0.9789 - val_loss: 0.1995 - val_accuracy: 0.9716\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0890 - accuracy: 0.9796 - val_loss: 0.2049 - val_accuracy: 0.9685\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0804 - accuracy: 0.9834 - val_loss: 0.1922 - val_accuracy: 0.9738\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0815 - accuracy: 0.9813 - val_loss: 0.2365 - val_accuracy: 0.9668\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0856 - accuracy: 0.9815 - val_loss: 0.1723 - val_accuracy: 0.9811\n","Epoch 33/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0745 - accuracy: 0.9832 - val_loss: 0.1897 - val_accuracy: 0.9758\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0825 - accuracy: 0.9818 - val_loss: 0.1843 - val_accuracy: 0.9701\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0778 - accuracy: 0.9823 - val_loss: 0.1919 - val_accuracy: 0.9652\n","Epoch 36/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0740 - accuracy: 0.9844 - val_loss: 0.1960 - val_accuracy: 0.9681\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0834 - accuracy: 0.9808 - val_loss: 0.1838 - val_accuracy: 0.9769\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0691 - accuracy: 0.9860 - val_loss: 0.1868 - val_accuracy: 0.9692\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0719 - accuracy: 0.9843 - val_loss: 0.1798 - val_accuracy: 0.9743\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0781 - accuracy: 0.9818 - val_loss: 0.1868 - val_accuracy: 0.9672\n","Average Validation Accuracy: 0.975492924451828\n","Average Validation Loss: 0.12901245430111885\n","Average Test Accuracy: 0.9761185348033905\n","------------------------------------------------------------------------\n","\n","Number of input features: 17\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7390 - accuracy: 0.2853 - val_loss: 2.4741 - val_accuracy: 0.5430\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6249 - accuracy: 0.6861 - val_loss: 1.4182 - val_accuracy: 0.7487\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8759 - accuracy: 0.8125 - val_loss: 0.9872 - val_accuracy: 0.8288\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5765 - accuracy: 0.8701 - val_loss: 0.7704 - val_accuracy: 0.8695\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4427 - accuracy: 0.8925 - val_loss: 0.6707 - val_accuracy: 0.8799\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3611 - accuracy: 0.9133 - val_loss: 0.6321 - val_accuracy: 0.8825\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3100 - accuracy: 0.9225 - val_loss: 0.6119 - val_accuracy: 0.8942\n","Epoch 8/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2705 - accuracy: 0.9329 - val_loss: 0.5154 - val_accuracy: 0.9175\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2409 - accuracy: 0.9377 - val_loss: 0.4516 - val_accuracy: 0.9318\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2148 - accuracy: 0.9466 - val_loss: 0.4623 - val_accuracy: 0.9292\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2007 - accuracy: 0.9502 - val_loss: 0.4463 - val_accuracy: 0.9193\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1837 - accuracy: 0.9557 - val_loss: 0.4054 - val_accuracy: 0.9454\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1693 - accuracy: 0.9601 - val_loss: 0.3660 - val_accuracy: 0.9516\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1650 - accuracy: 0.9583 - val_loss: 0.3707 - val_accuracy: 0.9494\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1499 - accuracy: 0.9654 - val_loss: 0.3498 - val_accuracy: 0.9593\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1447 - accuracy: 0.9662 - val_loss: 0.3469 - val_accuracy: 0.9575\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1306 - accuracy: 0.9694 - val_loss: 0.3320 - val_accuracy: 0.9613\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1346 - accuracy: 0.9695 - val_loss: 0.3326 - val_accuracy: 0.9586\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1282 - accuracy: 0.9718 - val_loss: 0.3163 - val_accuracy: 0.9589\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1172 - accuracy: 0.9729 - val_loss: 0.3059 - val_accuracy: 0.9696\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1207 - accuracy: 0.9717 - val_loss: 0.3719 - val_accuracy: 0.9531\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1086 - accuracy: 0.9750 - val_loss: 0.3308 - val_accuracy: 0.9608\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1093 - accuracy: 0.9750 - val_loss: 0.2955 - val_accuracy: 0.9716\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1095 - accuracy: 0.9743 - val_loss: 0.2932 - val_accuracy: 0.9747\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0951 - accuracy: 0.9796 - val_loss: 0.3127 - val_accuracy: 0.9668\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1067 - accuracy: 0.9758 - val_loss: 0.2975 - val_accuracy: 0.9714\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0945 - accuracy: 0.9791 - val_loss: 0.2884 - val_accuracy: 0.9798\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0929 - accuracy: 0.9798 - val_loss: 0.3126 - val_accuracy: 0.9670\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0915 - accuracy: 0.9807 - val_loss: 0.2743 - val_accuracy: 0.9798\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0838 - accuracy: 0.9821 - val_loss: 0.3181 - val_accuracy: 0.9619\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0915 - accuracy: 0.9795 - val_loss: 0.2897 - val_accuracy: 0.9703\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0816 - accuracy: 0.9834 - val_loss: 0.3040 - val_accuracy: 0.9707\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0819 - accuracy: 0.9811 - val_loss: 0.2823 - val_accuracy: 0.9760\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0848 - accuracy: 0.9803 - val_loss: 0.3098 - val_accuracy: 0.9688\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0724 - accuracy: 0.9839 - val_loss: 0.2990 - val_accuracy: 0.9663\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0808 - accuracy: 0.9804 - val_loss: 0.2883 - val_accuracy: 0.9787\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0685 - accuracy: 0.9856 - val_loss: 0.2777 - val_accuracy: 0.9800\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0804 - accuracy: 0.9823 - val_loss: 0.2787 - val_accuracy: 0.9809\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0733 - accuracy: 0.9827 - val_loss: 0.3061 - val_accuracy: 0.9694\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0763 - accuracy: 0.9820 - val_loss: 0.3302 - val_accuracy: 0.9655\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.6471 - accuracy: 0.3269 - val_loss: 2.2858 - val_accuracy: 0.6249\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4058 - accuracy: 0.7363 - val_loss: 1.2389 - val_accuracy: 0.7822\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6908 - accuracy: 0.8605 - val_loss: 0.8522 - val_accuracy: 0.8766\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4359 - accuracy: 0.9042 - val_loss: 0.6181 - val_accuracy: 0.9019\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3255 - accuracy: 0.9209 - val_loss: 0.5308 - val_accuracy: 0.9197\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2721 - accuracy: 0.9366 - val_loss: 0.4585 - val_accuracy: 0.9226\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2228 - accuracy: 0.9467 - val_loss: 0.4442 - val_accuracy: 0.9292\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1996 - accuracy: 0.9524 - val_loss: 0.3722 - val_accuracy: 0.9490\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1840 - accuracy: 0.9563 - val_loss: 0.4006 - val_accuracy: 0.9311\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1651 - accuracy: 0.9620 - val_loss: 0.3553 - val_accuracy: 0.9481\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1557 - accuracy: 0.9638 - val_loss: 0.3190 - val_accuracy: 0.9496\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1484 - accuracy: 0.9661 - val_loss: 0.3378 - val_accuracy: 0.9586\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1341 - accuracy: 0.9711 - val_loss: 0.3391 - val_accuracy: 0.9556\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1393 - accuracy: 0.9682 - val_loss: 0.3015 - val_accuracy: 0.9558\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1136 - accuracy: 0.9759 - val_loss: 0.3142 - val_accuracy: 0.9615\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1206 - accuracy: 0.9744 - val_loss: 0.2852 - val_accuracy: 0.9591\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1146 - accuracy: 0.9731 - val_loss: 0.2634 - val_accuracy: 0.9663\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1088 - accuracy: 0.9749 - val_loss: 0.3283 - val_accuracy: 0.9501\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1043 - accuracy: 0.9771 - val_loss: 0.2972 - val_accuracy: 0.9573\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0972 - accuracy: 0.9792 - val_loss: 0.2877 - val_accuracy: 0.9628\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1047 - accuracy: 0.9746 - val_loss: 0.2704 - val_accuracy: 0.9710\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0944 - accuracy: 0.9803 - val_loss: 0.2714 - val_accuracy: 0.9703\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0890 - accuracy: 0.9814 - val_loss: 0.2648 - val_accuracy: 0.9688\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0939 - accuracy: 0.9783 - val_loss: 0.3195 - val_accuracy: 0.9531\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0857 - accuracy: 0.9807 - val_loss: 0.2756 - val_accuracy: 0.9727\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0877 - accuracy: 0.9822 - val_loss: 0.2767 - val_accuracy: 0.9677\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0835 - accuracy: 0.9829 - val_loss: 0.2671 - val_accuracy: 0.9670\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0816 - accuracy: 0.9826 - val_loss: 0.2502 - val_accuracy: 0.9714\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0807 - accuracy: 0.9815 - val_loss: 0.2906 - val_accuracy: 0.9626\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0861 - accuracy: 0.9808 - val_loss: 0.2551 - val_accuracy: 0.9716\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0750 - accuracy: 0.9822 - val_loss: 0.2659 - val_accuracy: 0.9694\n","Epoch 32/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0789 - accuracy: 0.9824 - val_loss: 0.2601 - val_accuracy: 0.9670\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0750 - accuracy: 0.9829 - val_loss: 0.2486 - val_accuracy: 0.9780\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0820 - accuracy: 0.9800 - val_loss: 0.2477 - val_accuracy: 0.9721\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0729 - accuracy: 0.9827 - val_loss: 0.2700 - val_accuracy: 0.9666\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0684 - accuracy: 0.9845 - val_loss: 0.2918 - val_accuracy: 0.9582\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0722 - accuracy: 0.9837 - val_loss: 0.2693 - val_accuracy: 0.9672\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0733 - accuracy: 0.9837 - val_loss: 0.2534 - val_accuracy: 0.9762\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0689 - accuracy: 0.9847 - val_loss: 0.2305 - val_accuracy: 0.9789\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0699 - accuracy: 0.9841 - val_loss: 0.2446 - val_accuracy: 0.9762\n","Average Validation Accuracy: 0.9777078330516815\n","Average Validation Loss: 0.14893997088074684\n","Average Test Accuracy: 0.9790668487548828\n","------------------------------------------------------------------------\n","\n","Number of input features: 18\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.6715 - accuracy: 0.2981 - val_loss: 2.3332 - val_accuracy: 0.5833\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.6344 - accuracy: 0.6818 - val_loss: 1.4261 - val_accuracy: 0.7531\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9921 - accuracy: 0.7924 - val_loss: 1.0275 - val_accuracy: 0.8196\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6787 - accuracy: 0.8475 - val_loss: 0.7936 - val_accuracy: 0.8552\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5194 - accuracy: 0.8785 - val_loss: 0.7633 - val_accuracy: 0.8528\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4312 - accuracy: 0.8950 - val_loss: 0.6079 - val_accuracy: 0.8922\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3575 - accuracy: 0.9098 - val_loss: 0.5514 - val_accuracy: 0.9017\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3209 - accuracy: 0.9163 - val_loss: 0.5139 - val_accuracy: 0.9087\n","Epoch 9/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2843 - accuracy: 0.9251 - val_loss: 0.4903 - val_accuracy: 0.9072\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2566 - accuracy: 0.9339 - val_loss: 0.4427 - val_accuracy: 0.9276\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2394 - accuracy: 0.9369 - val_loss: 0.4283 - val_accuracy: 0.9305\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2250 - accuracy: 0.9403 - val_loss: 0.4478 - val_accuracy: 0.9182\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2141 - accuracy: 0.9424 - val_loss: 0.3840 - val_accuracy: 0.9413\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1935 - accuracy: 0.9478 - val_loss: 0.3958 - val_accuracy: 0.9461\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1920 - accuracy: 0.9489 - val_loss: 0.4504 - val_accuracy: 0.9285\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1834 - accuracy: 0.9522 - val_loss: 0.3674 - val_accuracy: 0.9498\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1751 - accuracy: 0.9537 - val_loss: 0.4090 - val_accuracy: 0.9369\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1705 - accuracy: 0.9562 - val_loss: 0.3405 - val_accuracy: 0.9591\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1579 - accuracy: 0.9602 - val_loss: 0.3623 - val_accuracy: 0.9446\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1588 - accuracy: 0.9598 - val_loss: 0.3869 - val_accuracy: 0.9417\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1510 - accuracy: 0.9607 - val_loss: 0.3540 - val_accuracy: 0.9509\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1417 - accuracy: 0.9639 - val_loss: 0.3192 - val_accuracy: 0.9613\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1427 - accuracy: 0.9622 - val_loss: 0.3679 - val_accuracy: 0.9355\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1379 - accuracy: 0.9653 - val_loss: 0.3482 - val_accuracy: 0.9472\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1298 - accuracy: 0.9684 - val_loss: 0.3318 - val_accuracy: 0.9602\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1358 - accuracy: 0.9659 - val_loss: 0.2880 - val_accuracy: 0.9688\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1235 - accuracy: 0.9694 - val_loss: 0.3012 - val_accuracy: 0.9626\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1161 - accuracy: 0.9711 - val_loss: 0.3020 - val_accuracy: 0.9637\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1305 - accuracy: 0.9678 - val_loss: 0.2987 - val_accuracy: 0.9650\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1213 - accuracy: 0.9686 - val_loss: 0.2945 - val_accuracy: 0.9639\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1160 - accuracy: 0.9715 - val_loss: 0.2952 - val_accuracy: 0.9663\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1179 - accuracy: 0.9710 - val_loss: 0.2897 - val_accuracy: 0.9661\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1115 - accuracy: 0.9729 - val_loss: 0.2670 - val_accuracy: 0.9712\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1067 - accuracy: 0.9752 - val_loss: 0.3074 - val_accuracy: 0.9670\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1164 - accuracy: 0.9719 - val_loss: 0.2823 - val_accuracy: 0.9696\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0964 - accuracy: 0.9769 - val_loss: 0.2624 - val_accuracy: 0.9767\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1145 - accuracy: 0.9720 - val_loss: 0.2853 - val_accuracy: 0.9745\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0927 - accuracy: 0.9782 - val_loss: 0.2914 - val_accuracy: 0.9677\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1019 - accuracy: 0.9757 - val_loss: 0.2951 - val_accuracy: 0.9633\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0952 - accuracy: 0.9767 - val_loss: 0.3470 - val_accuracy: 0.9600\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.3576 - accuracy: 0.3702 - val_loss: 2.1147 - val_accuracy: 0.6422\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3595 - accuracy: 0.7498 - val_loss: 1.3189 - val_accuracy: 0.8002\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7300 - accuracy: 0.8589 - val_loss: 0.9087 - val_accuracy: 0.8612\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4492 - accuracy: 0.9089 - val_loss: 0.7121 - val_accuracy: 0.9034\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3256 - accuracy: 0.9304 - val_loss: 0.6442 - val_accuracy: 0.9186\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2634 - accuracy: 0.9426 - val_loss: 0.5953 - val_accuracy: 0.8975\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2193 - accuracy: 0.9537 - val_loss: 0.4777 - val_accuracy: 0.9362\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1875 - accuracy: 0.9600 - val_loss: 0.4374 - val_accuracy: 0.9446\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1779 - accuracy: 0.9607 - val_loss: 0.3743 - val_accuracy: 0.9501\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1583 - accuracy: 0.9665 - val_loss: 0.3568 - val_accuracy: 0.9551\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1457 - accuracy: 0.9660 - val_loss: 0.3356 - val_accuracy: 0.9608\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1393 - accuracy: 0.9694 - val_loss: 0.3583 - val_accuracy: 0.9551\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1299 - accuracy: 0.9717 - val_loss: 0.3137 - val_accuracy: 0.9571\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1325 - accuracy: 0.9705 - val_loss: 0.3995 - val_accuracy: 0.9395\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1170 - accuracy: 0.9773 - val_loss: 0.3021 - val_accuracy: 0.9659\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1171 - accuracy: 0.9745 - val_loss: 0.2975 - val_accuracy: 0.9670\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1032 - accuracy: 0.9784 - val_loss: 0.2699 - val_accuracy: 0.9714\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1079 - accuracy: 0.9776 - val_loss: 0.2686 - val_accuracy: 0.9674\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1015 - accuracy: 0.9791 - val_loss: 0.2624 - val_accuracy: 0.9714\n","Epoch 20/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1023 - accuracy: 0.9778 - val_loss: 0.2500 - val_accuracy: 0.9736\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0937 - accuracy: 0.9794 - val_loss: 0.2561 - val_accuracy: 0.9747\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0922 - accuracy: 0.9804 - val_loss: 0.2444 - val_accuracy: 0.9716\n","Epoch 23/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.2820 - val_accuracy: 0.9602\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0884 - accuracy: 0.9805 - val_loss: 0.2315 - val_accuracy: 0.9740\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0825 - accuracy: 0.9821 - val_loss: 0.2951 - val_accuracy: 0.9619\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0833 - accuracy: 0.9824 - val_loss: 0.2260 - val_accuracy: 0.9754\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0803 - accuracy: 0.9841 - val_loss: 0.2362 - val_accuracy: 0.9754\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0750 - accuracy: 0.9854 - val_loss: 0.2374 - val_accuracy: 0.9747\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0793 - accuracy: 0.9844 - val_loss: 0.2365 - val_accuracy: 0.9699\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0864 - accuracy: 0.9828 - val_loss: 0.2057 - val_accuracy: 0.9747\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0694 - accuracy: 0.9863 - val_loss: 0.2302 - val_accuracy: 0.9705\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0740 - accuracy: 0.9844 - val_loss: 0.2201 - val_accuracy: 0.9701\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0691 - accuracy: 0.9859 - val_loss: 0.2234 - val_accuracy: 0.9712\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0712 - accuracy: 0.9837 - val_loss: 0.2157 - val_accuracy: 0.9736\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0660 - accuracy: 0.9870 - val_loss: 0.2482 - val_accuracy: 0.9747\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0753 - accuracy: 0.9843 - val_loss: 0.2004 - val_accuracy: 0.9776\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0653 - accuracy: 0.9870 - val_loss: 0.2214 - val_accuracy: 0.9696\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0646 - accuracy: 0.9868 - val_loss: 0.1943 - val_accuracy: 0.9793\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0650 - accuracy: 0.9868 - val_loss: 0.2002 - val_accuracy: 0.9773\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0698 - accuracy: 0.9846 - val_loss: 0.2649 - val_accuracy: 0.9659\n","Average Validation Accuracy: 0.971317708492279\n","Average Validation Loss: 0.1824219971895218\n","Average Test Accuracy: 0.9708115458488464\n","------------------------------------------------------------------------\n","\n","Number of input features: 19\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 3.5371 - accuracy: 0.3241 - val_loss: 2.2363 - val_accuracy: 0.6130\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5410 - accuracy: 0.7180 - val_loss: 1.3408 - val_accuracy: 0.7718\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9365 - accuracy: 0.8166 - val_loss: 1.0277 - val_accuracy: 0.8240\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6401 - accuracy: 0.8612 - val_loss: 0.8501 - val_accuracy: 0.8678\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4856 - accuracy: 0.8866 - val_loss: 0.7792 - val_accuracy: 0.8722\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3861 - accuracy: 0.9046 - val_loss: 0.6734 - val_accuracy: 0.9083\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3293 - accuracy: 0.9169 - val_loss: 0.6573 - val_accuracy: 0.9080\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2784 - accuracy: 0.9320 - val_loss: 0.5501 - val_accuracy: 0.9267\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2532 - accuracy: 0.9351 - val_loss: 0.5357 - val_accuracy: 0.9311\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2211 - accuracy: 0.9422 - val_loss: 0.5523 - val_accuracy: 0.9245\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2084 - accuracy: 0.9445 - val_loss: 0.5276 - val_accuracy: 0.9254\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1898 - accuracy: 0.9519 - val_loss: 0.4782 - val_accuracy: 0.9531\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1765 - accuracy: 0.9561 - val_loss: 0.5083 - val_accuracy: 0.9413\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1694 - accuracy: 0.9609 - val_loss: 0.4678 - val_accuracy: 0.9512\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1648 - accuracy: 0.9620 - val_loss: 0.4651 - val_accuracy: 0.9454\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1421 - accuracy: 0.9661 - val_loss: 0.4098 - val_accuracy: 0.9688\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1517 - accuracy: 0.9617 - val_loss: 0.4834 - val_accuracy: 0.9439\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1431 - accuracy: 0.9652 - val_loss: 0.4170 - val_accuracy: 0.9648\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1358 - accuracy: 0.9675 - val_loss: 0.4301 - val_accuracy: 0.9503\n","Epoch 20/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1326 - accuracy: 0.9712 - val_loss: 0.4100 - val_accuracy: 0.9652\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1339 - accuracy: 0.9678 - val_loss: 0.3843 - val_accuracy: 0.9716\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1217 - accuracy: 0.9732 - val_loss: 0.4210 - val_accuracy: 0.9608\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1281 - accuracy: 0.9715 - val_loss: 0.4040 - val_accuracy: 0.9692\n","Epoch 24/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1145 - accuracy: 0.9739 - val_loss: 0.3952 - val_accuracy: 0.9729\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1196 - accuracy: 0.9727 - val_loss: 0.4128 - val_accuracy: 0.9648\n","Epoch 26/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1034 - accuracy: 0.9773 - val_loss: 0.4194 - val_accuracy: 0.9540\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1076 - accuracy: 0.9773 - val_loss: 0.4083 - val_accuracy: 0.9655\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0988 - accuracy: 0.9793 - val_loss: 0.3732 - val_accuracy: 0.9751\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1190 - accuracy: 0.9733 - val_loss: 0.3542 - val_accuracy: 0.9800\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1055 - accuracy: 0.9798 - val_loss: 0.3540 - val_accuracy: 0.9760\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1012 - accuracy: 0.9784 - val_loss: 0.3619 - val_accuracy: 0.9747\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0950 - accuracy: 0.9788 - val_loss: 0.3766 - val_accuracy: 0.9692\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1027 - accuracy: 0.9783 - val_loss: 0.3532 - val_accuracy: 0.9762\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0947 - accuracy: 0.9789 - val_loss: 0.3461 - val_accuracy: 0.9813\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0962 - accuracy: 0.9799 - val_loss: 0.4198 - val_accuracy: 0.9485\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0913 - accuracy: 0.9802 - val_loss: 0.3365 - val_accuracy: 0.9773\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0838 - accuracy: 0.9827 - val_loss: 0.3236 - val_accuracy: 0.9793\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0983 - accuracy: 0.9794 - val_loss: 0.4763 - val_accuracy: 0.9417\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0882 - accuracy: 0.9814 - val_loss: 0.3716 - val_accuracy: 0.9683\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0881 - accuracy: 0.9801 - val_loss: 0.3435 - val_accuracy: 0.9811\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.5366 - accuracy: 0.3268 - val_loss: 2.2134 - val_accuracy: 0.6178\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4382 - accuracy: 0.7345 - val_loss: 1.3744 - val_accuracy: 0.7844\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8945 - accuracy: 0.8244 - val_loss: 1.0235 - val_accuracy: 0.8299\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6291 - accuracy: 0.8632 - val_loss: 0.8284 - val_accuracy: 0.8576\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4847 - accuracy: 0.8887 - val_loss: 0.6892 - val_accuracy: 0.8884\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3924 - accuracy: 0.9111 - val_loss: 0.6292 - val_accuracy: 0.8997\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3312 - accuracy: 0.9239 - val_loss: 0.5105 - val_accuracy: 0.9245\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2824 - accuracy: 0.9337 - val_loss: 0.5524 - val_accuracy: 0.8990\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2518 - accuracy: 0.9425 - val_loss: 0.4167 - val_accuracy: 0.9364\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2252 - accuracy: 0.9459 - val_loss: 0.4081 - val_accuracy: 0.9406\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2092 - accuracy: 0.9506 - val_loss: 0.3910 - val_accuracy: 0.9507\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1894 - accuracy: 0.9566 - val_loss: 0.3769 - val_accuracy: 0.9399\n","Epoch 13/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1818 - accuracy: 0.9600 - val_loss: 0.3420 - val_accuracy: 0.9540\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1717 - accuracy: 0.9625 - val_loss: 0.3514 - val_accuracy: 0.9505\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1665 - accuracy: 0.9620 - val_loss: 0.3495 - val_accuracy: 0.9428\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1567 - accuracy: 0.9659 - val_loss: 0.3611 - val_accuracy: 0.9472\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1387 - accuracy: 0.9701 - val_loss: 0.3260 - val_accuracy: 0.9492\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1427 - accuracy: 0.9674 - val_loss: 0.3082 - val_accuracy: 0.9633\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1203 - accuracy: 0.9762 - val_loss: 0.3231 - val_accuracy: 0.9512\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1310 - accuracy: 0.9728 - val_loss: 0.2916 - val_accuracy: 0.9602\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1253 - accuracy: 0.9719 - val_loss: 0.2709 - val_accuracy: 0.9661\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1225 - accuracy: 0.9740 - val_loss: 0.2486 - val_accuracy: 0.9749\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1020 - accuracy: 0.9798 - val_loss: 0.3267 - val_accuracy: 0.9490\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1155 - accuracy: 0.9771 - val_loss: 0.3436 - val_accuracy: 0.9534\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1110 - accuracy: 0.9765 - val_loss: 0.2651 - val_accuracy: 0.9637\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1036 - accuracy: 0.9790 - val_loss: 0.2599 - val_accuracy: 0.9721\n","Epoch 27/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1108 - accuracy: 0.9765 - val_loss: 0.2307 - val_accuracy: 0.9767\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0977 - accuracy: 0.9813 - val_loss: 0.2766 - val_accuracy: 0.9688\n","Epoch 29/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0941 - accuracy: 0.9803 - val_loss: 0.2447 - val_accuracy: 0.9688\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0886 - accuracy: 0.9832 - val_loss: 0.2321 - val_accuracy: 0.9767\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1018 - accuracy: 0.9779 - val_loss: 0.2152 - val_accuracy: 0.9771\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0926 - accuracy: 0.9820 - val_loss: 0.2343 - val_accuracy: 0.9756\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1003 - accuracy: 0.9773 - val_loss: 0.2241 - val_accuracy: 0.9679\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0798 - accuracy: 0.9858 - val_loss: 0.2116 - val_accuracy: 0.9751\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0869 - accuracy: 0.9815 - val_loss: 0.2662 - val_accuracy: 0.9633\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0862 - accuracy: 0.9826 - val_loss: 0.2180 - val_accuracy: 0.9789\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0907 - accuracy: 0.9804 - val_loss: 0.2509 - val_accuracy: 0.9657\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0737 - accuracy: 0.9867 - val_loss: 0.2009 - val_accuracy: 0.9782\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0795 - accuracy: 0.9850 - val_loss: 0.2219 - val_accuracy: 0.9738\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0857 - accuracy: 0.9831 - val_loss: 0.2043 - val_accuracy: 0.9813\n","Average Validation Accuracy: 0.9867843389511108\n","Average Validation Loss: 0.13902495428919792\n","Average Test Accuracy: 0.9871379137039185\n","------------------------------------------------------------------------\n","\n","Number of input features: 20\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 5ms/step - loss: 3.7029 - accuracy: 0.3085 - val_loss: 2.3053 - val_accuracy: 0.5749\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5739 - accuracy: 0.7179 - val_loss: 1.3878 - val_accuracy: 0.7560\n","Epoch 3/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.9384 - accuracy: 0.8210 - val_loss: 0.9781 - val_accuracy: 0.8433\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6153 - accuracy: 0.8737 - val_loss: 0.7633 - val_accuracy: 0.8772\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4398 - accuracy: 0.9044 - val_loss: 0.6134 - val_accuracy: 0.9036\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3393 - accuracy: 0.9201 - val_loss: 0.5287 - val_accuracy: 0.9166\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2797 - accuracy: 0.9334 - val_loss: 0.5686 - val_accuracy: 0.9030\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2465 - accuracy: 0.9416 - val_loss: 0.4584 - val_accuracy: 0.9355\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2203 - accuracy: 0.9476 - val_loss: 0.4119 - val_accuracy: 0.9430\n","Epoch 10/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1844 - accuracy: 0.9561 - val_loss: 0.4145 - val_accuracy: 0.9424\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1855 - accuracy: 0.9549 - val_loss: 0.3648 - val_accuracy: 0.9547\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1636 - accuracy: 0.9626 - val_loss: 0.3511 - val_accuracy: 0.9558\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1523 - accuracy: 0.9642 - val_loss: 0.3739 - val_accuracy: 0.9512\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1512 - accuracy: 0.9675 - val_loss: 0.3427 - val_accuracy: 0.9639\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1475 - accuracy: 0.9662 - val_loss: 0.3249 - val_accuracy: 0.9641\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1390 - accuracy: 0.9689 - val_loss: 0.3459 - val_accuracy: 0.9637\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1312 - accuracy: 0.9707 - val_loss: 0.3307 - val_accuracy: 0.9655\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1308 - accuracy: 0.9710 - val_loss: 0.3333 - val_accuracy: 0.9685\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1193 - accuracy: 0.9743 - val_loss: 0.3286 - val_accuracy: 0.9608\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1278 - accuracy: 0.9707 - val_loss: 0.3260 - val_accuracy: 0.9630\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1094 - accuracy: 0.9781 - val_loss: 0.3278 - val_accuracy: 0.9692\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1157 - accuracy: 0.9744 - val_loss: 0.2913 - val_accuracy: 0.9787\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1042 - accuracy: 0.9788 - val_loss: 0.3020 - val_accuracy: 0.9736\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1126 - accuracy: 0.9755 - val_loss: 0.3292 - val_accuracy: 0.9644\n","Epoch 25/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1065 - accuracy: 0.9758 - val_loss: 0.3307 - val_accuracy: 0.9648\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1032 - accuracy: 0.9773 - val_loss: 0.3112 - val_accuracy: 0.9681\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0908 - accuracy: 0.9807 - val_loss: 0.3559 - val_accuracy: 0.9556\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0959 - accuracy: 0.9796 - val_loss: 0.3057 - val_accuracy: 0.9701\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1000 - accuracy: 0.9792 - val_loss: 0.3006 - val_accuracy: 0.9690\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0938 - accuracy: 0.9799 - val_loss: 0.2696 - val_accuracy: 0.9751\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0924 - accuracy: 0.9798 - val_loss: 0.2878 - val_accuracy: 0.9738\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0827 - accuracy: 0.9844 - val_loss: 0.2672 - val_accuracy: 0.9811\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0899 - accuracy: 0.9815 - val_loss: 0.2662 - val_accuracy: 0.9771\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0829 - accuracy: 0.9820 - val_loss: 0.3607 - val_accuracy: 0.9604\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0834 - accuracy: 0.9846 - val_loss: 0.2806 - val_accuracy: 0.9729\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0845 - accuracy: 0.9827 - val_loss: 0.2773 - val_accuracy: 0.9736\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0830 - accuracy: 0.9821 - val_loss: 0.2827 - val_accuracy: 0.9677\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0795 - accuracy: 0.9839 - val_loss: 0.2560 - val_accuracy: 0.9760\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0744 - accuracy: 0.9857 - val_loss: 0.2956 - val_accuracy: 0.9666\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0766 - accuracy: 0.9839 - val_loss: 0.2513 - val_accuracy: 0.9798\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.4180 - accuracy: 0.3472 - val_loss: 2.1079 - val_accuracy: 0.6323\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4055 - accuracy: 0.7407 - val_loss: 1.3242 - val_accuracy: 0.7938\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8453 - accuracy: 0.8392 - val_loss: 1.0435 - val_accuracy: 0.8420\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5783 - accuracy: 0.8841 - val_loss: 0.7860 - val_accuracy: 0.8854\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4246 - accuracy: 0.9112 - val_loss: 0.6514 - val_accuracy: 0.9098\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3199 - accuracy: 0.9325 - val_loss: 0.5789 - val_accuracy: 0.9217\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2506 - accuracy: 0.9484 - val_loss: 0.4984 - val_accuracy: 0.9344\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2163 - accuracy: 0.9544 - val_loss: 0.4549 - val_accuracy: 0.9496\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1799 - accuracy: 0.9625 - val_loss: 0.4480 - val_accuracy: 0.9285\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1645 - accuracy: 0.9662 - val_loss: 0.4265 - val_accuracy: 0.9399\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1522 - accuracy: 0.9666 - val_loss: 0.3545 - val_accuracy: 0.9591\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1346 - accuracy: 0.9729 - val_loss: 0.3358 - val_accuracy: 0.9553\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1340 - accuracy: 0.9726 - val_loss: 0.3132 - val_accuracy: 0.9694\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1215 - accuracy: 0.9751 - val_loss: 0.3211 - val_accuracy: 0.9626\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1089 - accuracy: 0.9780 - val_loss: 0.3115 - val_accuracy: 0.9635\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1113 - accuracy: 0.9778 - val_loss: 0.2834 - val_accuracy: 0.9652\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1066 - accuracy: 0.9772 - val_loss: 0.2937 - val_accuracy: 0.9624\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0951 - accuracy: 0.9821 - val_loss: 0.2683 - val_accuracy: 0.9780\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0975 - accuracy: 0.9813 - val_loss: 0.2514 - val_accuracy: 0.9800\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0917 - accuracy: 0.9820 - val_loss: 0.2571 - val_accuracy: 0.9760\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1062 - accuracy: 0.9763 - val_loss: 0.2771 - val_accuracy: 0.9716\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0830 - accuracy: 0.9850 - val_loss: 0.2876 - val_accuracy: 0.9622\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0870 - accuracy: 0.9837 - val_loss: 0.2308 - val_accuracy: 0.9791\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0955 - accuracy: 0.9813 - val_loss: 0.2395 - val_accuracy: 0.9749\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0842 - accuracy: 0.9840 - val_loss: 0.2303 - val_accuracy: 0.9800\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0752 - accuracy: 0.9870 - val_loss: 0.2321 - val_accuracy: 0.9756\n","Epoch 27/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0847 - accuracy: 0.9830 - val_loss: 0.2605 - val_accuracy: 0.9672\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0726 - accuracy: 0.9862 - val_loss: 0.2332 - val_accuracy: 0.9782\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0840 - accuracy: 0.9849 - val_loss: 0.2515 - val_accuracy: 0.9657\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0722 - accuracy: 0.9856 - val_loss: 0.2304 - val_accuracy: 0.9760\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0769 - accuracy: 0.9850 - val_loss: 0.2237 - val_accuracy: 0.9789\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0640 - accuracy: 0.9883 - val_loss: 0.2247 - val_accuracy: 0.9765\n","Epoch 33/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0723 - accuracy: 0.9850 - val_loss: 0.2002 - val_accuracy: 0.9837\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0724 - accuracy: 0.9862 - val_loss: 0.2123 - val_accuracy: 0.9712\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0643 - accuracy: 0.9881 - val_loss: 0.2110 - val_accuracy: 0.9745\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0698 - accuracy: 0.9865 - val_loss: 0.1967 - val_accuracy: 0.9778\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0549 - accuracy: 0.9910 - val_loss: 0.2337 - val_accuracy: 0.9721\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0793 - accuracy: 0.9849 - val_loss: 0.1950 - val_accuracy: 0.9789\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0621 - accuracy: 0.9881 - val_loss: 0.1803 - val_accuracy: 0.9802\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0626 - accuracy: 0.9878 - val_loss: 0.2010 - val_accuracy: 0.9771\n","Average Validation Accuracy: 0.9841701686382294\n","Average Validation Loss: 0.122109055519104\n","Average Test Accuracy: 0.983194500207901\n","------------------------------------------------------------------------\n"]}],"source":["# Define the number of folds for k-fold cross-validation\n","k = 2\n","\n","# Define the cross-validation method\n","cv_method = StratifiedKFold(n_splits=k)\n","\n","# Initialize the list to store the history, train & validation(accuracy & loss) for each model\n","models = []\n","model_history = []\n","model_accuracy = []\n","model_train_acc = []\n","model_train_loss = []\n","model_val_acc = []\n","model_val_loss = []\n","\n","for i in range(1, 21):\n","\n","  models_fold = []\n","  hist = []\n","  train_accuracy = []\n","  train_loss = []\n","  val_accuracy = []\n","  val_loss = []\n","  test_accuracy = []\n","\n","  print(\"\\nNumber of input features:\", i)\n","\n","  # Select the input features from the input data\n","  X_train_selected = X_train[:, :i]\n","  X_test_selected = X_test[:, :i]\n","\n","  X_train_selected = X_train_selected.reshape(27543, i, 1, 1)\n","  X_test_selected = X_test_selected.reshape(13567, i, 1, 1)\n","\n","  # Loop over the folds\n","  for fold, (train_index, val_index) in enumerate(cv_method.split(X_train_selected, y_train)):\n","\n","    print(\"Fold:\", fold+1)\n","\n","    # Build the model\n","    model = Sequential()\n","    model.add(Conv2D(60, kernel_size=(5,5), activation='relu',bias_initializer='normal', input_shape=X_train_selected.shape[1:], padding= \"same\")) #keeps the output size same as input size (prevent down or upsampling)\n","    model.add(MaxPooling2D(pool_size=(1,1))) #pool size 2 error, because 1 (1 feature) minus 2 (pool size) is negative)\n","    model.add(Flatten())\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(373, kernel_initializer='normal', activation='softmax'))\n","\n","    # compile model\n","    model.compile(loss = \"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy']) \n","\n","    # # Fit the model to the training data for the current fold\n","    history = model.fit(X_train_selected[train_index], to_categorical(y_train_enc[train_index], num_classes=373), batch_size = 5, epochs = 40, verbose = 1, validation_split = 0.33)\n","\n","    # Evaluate the model on the validation data for the current fold\n","    val_scores = model.evaluate(X_train_selected[val_index], to_categorical(y_train_enc[val_index],num_classes=373), verbose=0)\n","    val_accuracy.append(val_scores[1])\n","    val_loss.append(val_scores[0])\n","\n","    # Evaluate the model on the test data for the current fold\n","    test_scores = model.evaluate(X_test_selected, to_categorical(y_test_enc, num_classes=373), verbose=0)\n","    test_accuracy.append(test_scores[1])\n","\n","    # add the model to the list of models\n","    models_fold.append(model)\n","    hist.append(history)\n","\n","    # store the training accuracy and loss for each fold\n","    train_accuracy.append(history.history['accuracy'])\n","    train_loss.append(history.history['loss'])\n","  \n","  # Calculate the average test and validation accuracy and loss across all folds\n","  avg_test_acc = sum(test_accuracy) / len(test_accuracy)\n","  avg_val_acc = sum(val_accuracy) / len(val_accuracy)\n","  avg_val_loss = sum(val_loss) / len(val_loss)\n","\n","  # Print the average validation and test accuracy and loss\n","  print(\"Average Validation Accuracy:\", avg_val_acc)\n","  print(\"Average Validation Loss:\",avg_val_loss)\n","  print(\"Average Test Accuracy:\", avg_test_acc)\n","\n","  best_fold_index = test_accuracy.index(max(test_accuracy))\n","  model_accuracy.append(test_accuracy[best_fold_index])\n","  models.append(models_fold[best_fold_index])\n","  model_history.append(hist[best_fold_index])\n","  model_train_acc.append(train_accuracy[best_fold_index])\n","  model_train_loss.append(train_loss[best_fold_index])\n","  model_val_acc.append(val_accuracy[best_fold_index])\n","  model_val_loss.append(val_loss[best_fold_index])\n","  print('------------------------------------------------------------------------')"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"ZG29fO-C4TJH"},"outputs":[],"source":["#to show the no of input features and its corresponding model accuracy\n","model_list = []\n","\n","#Iterate through each model's accuracy \n","for i in range (len(model_accuracy)):\n","    #get the number of input features for the current model\n","    no_features = i + 1\n","\n","    #round the model accuries to 3 d.p.\n","    rounded_model_acc = round(model_accuracy[i], 3)\n","    \n","    model_list.append([no_features, rounded_model_acc])\n","\n","models_df = pd.DataFrame(model_list, columns=[\"No of input features\", \"Model accuracy\"])"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"M1aBlP3GmZ9o"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Final Test Accuracy: 0.9884278178215027\n"]}],"source":["# Select the final model based on the max test accuracy across all models\n","\n","best_model_index = model_accuracy.index(max(model_accuracy))\n","\n","best_model = models[best_model_index]\n","best_model_history = model_history[best_model_index]\n","best_model_train_acc = model_train_acc[best_model_index]\n","best_model_train_loss = model_train_loss[best_model_index]\n","best_model_val_acc = model_val_acc[best_model_index]\n","best_model_val_loss = model_val_loss[best_model_index]\n","\n","# summarize history for accuracy  \n","plt.subplot(211)  \n","plt.plot(best_model_history.history['accuracy'])  \n","plt.plot(best_model_history.history['val_accuracy'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='lower right')  \n","\n","# summarize history for loss\n","plt.subplot(212)  \n","plt.plot(best_model_history.history['loss'])  \n","plt.plot(best_model_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='upper right')  \n","plt.subplots_adjust(hspace=0.7)\n","\n","plt.show() \n","\n","print(\"Final Test Accuracy:\", model_accuracy[best_model_index])"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"RMkWBkrYmZ9s"},"outputs":[{"name":"stdout","output_type":"stream","text":["424/424 [==============================] - 1s 2ms/step\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       591\n","           1       1.00      1.00      1.00       430\n","           2       1.00      1.00      1.00       419\n","           3       1.00      1.00      1.00       384\n","           4       1.00      1.00      1.00       339\n","           5       1.00      1.00      1.00       342\n","           6       1.00      1.00      1.00       310\n","           7       1.00      1.00      1.00       325\n","           8       1.00      1.00      1.00       294\n","           9       1.00      1.00      1.00       269\n","          10       1.00      1.00      1.00       296\n","          11       1.00      1.00      1.00       258\n","          12       1.00      1.00      1.00       247\n","          13       1.00      1.00      1.00       237\n","          14       1.00      1.00      1.00       239\n","          15       1.00      1.00      1.00       235\n","          16       1.00      1.00      1.00       213\n","          17       1.00      1.00      1.00       202\n","          18       1.00      1.00      1.00       196\n","          19       1.00      1.00      1.00       181\n","          20       1.00      1.00      1.00       177\n","          21       1.00      1.00      1.00       177\n","          22       1.00      1.00      1.00       155\n","          23       1.00      1.00      1.00       155\n","          24       1.00      1.00      1.00       144\n","          25       1.00      1.00      1.00       126\n","          26       1.00      1.00      1.00       121\n","          27       1.00      1.00      1.00       108\n","          28       1.00      1.00      1.00        95\n","          29       1.00      1.00      1.00       102\n","          30       1.00      1.00      1.00       106\n","          31       1.00      1.00      1.00        86\n","          32       1.00      1.00      1.00       108\n","          33       1.00      1.00      1.00        88\n","          34       1.00      1.00      1.00       102\n","          35       1.00      1.00      1.00        88\n","          36       1.00      1.00      1.00        83\n","          37       1.00      1.00      1.00        93\n","          38       1.00      1.00      1.00        76\n","          39       1.00      1.00      1.00        85\n","          40       1.00      1.00      1.00        86\n","          41       1.00      1.00      1.00        85\n","          42       1.00      1.00      1.00        68\n","          43       1.00      1.00      1.00        75\n","          44       1.00      1.00      1.00        71\n","          45       0.81      1.00      0.89        58\n","          46       1.00      1.00      1.00        71\n","          47       0.78      0.63      0.70        57\n","          48       1.00      1.00      1.00        67\n","          49       0.94      0.96      0.95        47\n","          50       1.00      1.00      1.00        47\n","          51       1.00      1.00      1.00        48\n","          52       1.00      1.00      1.00        43\n","          53       1.00      1.00      1.00        51\n","          54       1.00      1.00      1.00        44\n","          55       1.00      1.00      1.00        51\n","          56       1.00      1.00      1.00        44\n","          57       1.00      1.00      1.00        45\n","          58       1.00      1.00      1.00        41\n","          59       1.00      1.00      1.00        52\n","          60       1.00      1.00      1.00        41\n","          61       1.00      1.00      1.00        43\n","          62       1.00      1.00      1.00        43\n","          63       0.93      1.00      0.96        37\n","          64       1.00      1.00      1.00        46\n","          65       1.00      1.00      1.00        42\n","          66       1.00      1.00      1.00        43\n","          67       1.00      1.00      1.00        44\n","          68       1.00      1.00      1.00        40\n","          69       1.00      1.00      1.00        43\n","          70       1.00      1.00      1.00        33\n","          71       1.00      1.00      1.00        38\n","          72       1.00      1.00      1.00        45\n","          73       1.00      1.00      1.00        38\n","          74       1.00      1.00      1.00        42\n","          75       1.00      1.00      1.00        39\n","          76       1.00      0.77      0.87        30\n","          77       1.00      1.00      1.00        28\n","          78       1.00      1.00      1.00        28\n","          79       1.00      1.00      1.00        35\n","          80       1.00      1.00      1.00        32\n","          81       1.00      1.00      1.00        33\n","          82       1.00      1.00      1.00        31\n","          83       1.00      1.00      1.00        36\n","          84       1.00      1.00      1.00        39\n","          85       1.00      1.00      1.00        27\n","          86       1.00      1.00      1.00        31\n","          87       1.00      1.00      1.00        28\n","          88       1.00      1.00      1.00        20\n","          89       1.00      1.00      1.00        33\n","          90       1.00      1.00      1.00        22\n","          91       1.00      1.00      1.00        24\n","          92       1.00      1.00      1.00        35\n","          93       1.00      1.00      1.00        26\n","          94       1.00      1.00      1.00        27\n","          95       1.00      1.00      1.00        23\n","          96       1.00      1.00      1.00        27\n","          97       1.00      1.00      1.00        28\n","          98       0.94      1.00      0.97        16\n","          99       1.00      1.00      1.00        35\n","         100       1.00      1.00      1.00        28\n","         101       1.00      1.00      1.00        25\n","         102       1.00      1.00      1.00        26\n","         103       1.00      1.00      1.00        26\n","         104       1.00      1.00      1.00        33\n","         105       1.00      1.00      1.00        24\n","         106       1.00      1.00      1.00        22\n","         107       1.00      1.00      1.00        26\n","         108       1.00      1.00      1.00        25\n","         109       1.00      1.00      1.00        18\n","         110       0.00      0.00      0.00        23\n","         111       1.00      1.00      1.00        20\n","         112       1.00      1.00      1.00        26\n","         113       1.00      1.00      1.00        16\n","         114       1.00      1.00      1.00        25\n","         115       1.00      1.00      1.00        18\n","         116       1.00      1.00      1.00        16\n","         117       1.00      1.00      1.00        19\n","         118       1.00      1.00      1.00        26\n","         119       0.88      1.00      0.94        22\n","         120       0.91      1.00      0.95        21\n","         121       1.00      1.00      1.00        27\n","         122       1.00      1.00      1.00        22\n","         123       1.00      1.00      1.00        18\n","         124       1.00      1.00      1.00        14\n","         125       1.00      1.00      1.00        20\n","         126       1.00      1.00      1.00        15\n","         127       1.00      1.00      1.00        19\n","         128       1.00      1.00      1.00        17\n","         129       1.00      1.00      1.00        26\n","         130       1.00      1.00      1.00        18\n","         131       1.00      1.00      1.00        18\n","         132       1.00      1.00      1.00        20\n","         133       1.00      1.00      1.00        23\n","         134       0.00      0.00      0.00        11\n","         135       1.00      1.00      1.00        23\n","         136       1.00      1.00      1.00        14\n","         137       1.00      1.00      1.00        20\n","         138       1.00      1.00      1.00        19\n","         139       1.00      1.00      1.00        16\n","         140       1.00      1.00      1.00        14\n","         141       1.00      1.00      1.00        14\n","         142       1.00      1.00      1.00        13\n","         143       1.00      1.00      1.00        23\n","         144       1.00      1.00      1.00        22\n","         145       1.00      1.00      1.00        19\n","         146       1.00      0.94      0.97        16\n","         147       1.00      1.00      1.00        24\n","         148       1.00      1.00      1.00        17\n","         149       1.00      1.00      1.00        15\n","         150       1.00      1.00      1.00        24\n","         151       1.00      1.00      1.00        19\n","         152       1.00      1.00      1.00        11\n","         153       1.00      1.00      1.00        20\n","         154       1.00      1.00      1.00        17\n","         155       1.00      1.00      1.00        11\n","         156       1.00      1.00      1.00        12\n","         157       1.00      1.00      1.00        18\n","         158       1.00      1.00      1.00        20\n","         159       1.00      1.00      1.00        20\n","         160       1.00      1.00      1.00        18\n","         161       1.00      1.00      1.00        16\n","         162       1.00      1.00      1.00        15\n","         163       1.00      1.00      1.00        15\n","         164       1.00      1.00      1.00        13\n","         165       1.00      1.00      1.00        19\n","         166       1.00      1.00      1.00        11\n","         167       1.00      1.00      1.00        11\n","         168       1.00      1.00      1.00        18\n","         169       1.00      1.00      1.00        15\n","         170       1.00      1.00      1.00         9\n","         171       1.00      1.00      1.00        11\n","         172       0.95      1.00      0.98        21\n","         173       1.00      1.00      1.00        10\n","         174       1.00      1.00      1.00        16\n","         175       1.00      1.00      1.00        11\n","         176       1.00      1.00      1.00        10\n","         177       1.00      1.00      1.00        15\n","         178       1.00      1.00      1.00        11\n","         179       1.00      1.00      1.00        15\n","         180       1.00      1.00      1.00        13\n","         181       1.00      1.00      1.00        15\n","         182       0.00      0.00      0.00        12\n","         183       1.00      1.00      1.00         9\n","         184       1.00      1.00      1.00         8\n","         185       1.00      1.00      1.00        16\n","         186       1.00      1.00      1.00        14\n","         187       1.00      1.00      1.00        15\n","         188       1.00      1.00      1.00        15\n","         189       0.55      0.92      0.69        13\n","         190       1.00      1.00      1.00         9\n","         191       1.00      1.00      1.00        10\n","         192       1.00      1.00      1.00         9\n","         193       0.67      1.00      0.80         4\n","         194       0.85      1.00      0.92        11\n","         195       1.00      1.00      1.00        17\n","         196       0.33      1.00      0.50         7\n","         197       1.00      1.00      1.00        12\n","         198       1.00      1.00      1.00        14\n","         199       1.00      1.00      1.00         7\n","         200       1.00      1.00      1.00         6\n","         201       1.00      1.00      1.00        12\n","         202       0.79      1.00      0.88        11\n","         203       1.00      1.00      1.00        14\n","         204       1.00      1.00      1.00         9\n","         205       1.00      1.00      1.00         6\n","         206       1.00      1.00      1.00        12\n","         207       1.00      1.00      1.00         7\n","         208       1.00      1.00      1.00        14\n","         209       1.00      1.00      1.00         7\n","         210       1.00      1.00      1.00        19\n","         211       1.00      1.00      1.00         9\n","         212       1.00      1.00      1.00        11\n","         213       1.00      1.00      1.00         7\n","         214       1.00      1.00      1.00        12\n","         215       1.00      1.00      1.00         7\n","         216       1.00      1.00      1.00         6\n","         217       0.00      0.00      0.00         9\n","         218       0.31      1.00      0.47         4\n","         219       1.00      1.00      1.00         6\n","         220       1.00      1.00      1.00         5\n","         221       1.00      1.00      1.00         8\n","         222       1.00      1.00      1.00        12\n","         223       1.00      1.00      1.00        10\n","         224       1.00      1.00      1.00         4\n","         225       0.76      1.00      0.87        13\n","         226       1.00      1.00      1.00        12\n","         227       0.56      1.00      0.72        14\n","         228       1.00      1.00      1.00        13\n","         229       1.00      1.00      1.00         6\n","         230       1.00      1.00      1.00        11\n","         231       1.00      1.00      1.00         5\n","         232       1.00      1.00      1.00         7\n","         233       0.32      0.67      0.43         9\n","         234       0.00      0.00      0.00         8\n","         235       1.00      1.00      1.00         6\n","         236       1.00      1.00      1.00         8\n","         237       1.00      1.00      1.00        10\n","         238       1.00      1.00      1.00        10\n","         239       1.00      1.00      1.00         7\n","         240       1.00      1.00      1.00         8\n","         241       1.00      1.00      1.00         8\n","         242       1.00      1.00      1.00         4\n","         243       1.00      1.00      1.00         9\n","         244       1.00      1.00      1.00         9\n","         245       1.00      1.00      1.00         7\n","         246       1.00      1.00      1.00        10\n","         247       1.00      1.00      1.00         6\n","         248       1.00      1.00      1.00         7\n","         249       1.00      1.00      1.00        10\n","         250       1.00      0.71      0.83         7\n","         251       1.00      1.00      1.00         9\n","         252       1.00      1.00      1.00         7\n","         253       1.00      1.00      1.00         5\n","         254       1.00      1.00      1.00        11\n","         255       1.00      1.00      1.00        12\n","         256       1.00      1.00      1.00         4\n","         257       1.00      1.00      1.00         2\n","         258       1.00      1.00      1.00         9\n","         259       1.00      1.00      1.00         6\n","         260       1.00      1.00      1.00         8\n","         261       1.00      1.00      1.00         5\n","         262       0.00      0.00      0.00         3\n","         263       1.00      1.00      1.00         7\n","         264       1.00      1.00      1.00         5\n","         265       0.24      1.00      0.39         9\n","         266       1.00      1.00      1.00        10\n","         267       1.00      1.00      1.00         7\n","         268       1.00      1.00      1.00         8\n","         269       1.00      0.80      0.89        10\n","         270       1.00      1.00      1.00         9\n","         271       1.00      1.00      1.00         3\n","         272       1.00      1.00      1.00         6\n","         273       1.00      1.00      1.00         4\n","         274       1.00      1.00      1.00         5\n","         275       0.00      0.00      0.00         4\n","         276       1.00      1.00      1.00         3\n","         277       1.00      1.00      1.00         7\n","         278       1.00      1.00      1.00         6\n","         279       1.00      1.00      1.00         4\n","         280       0.43      0.60      0.50         5\n","         281       1.00      1.00      1.00        11\n","         282       1.00      1.00      1.00         6\n","         283       1.00      1.00      1.00         2\n","         284       1.00      1.00      1.00         9\n","         285       1.00      0.57      0.73         7\n","         286       1.00      1.00      1.00         7\n","         287       1.00      1.00      1.00         7\n","         288       1.00      1.00      1.00         5\n","         289       1.00      1.00      1.00         6\n","         290       1.00      1.00      1.00         6\n","         291       1.00      1.00      1.00         4\n","         292       0.64      1.00      0.78         7\n","         293       1.00      1.00      1.00         6\n","         294       1.00      1.00      1.00         6\n","         295       1.00      0.67      0.80         3\n","         296       1.00      1.00      1.00         8\n","         297       1.00      1.00      1.00         8\n","         298       1.00      1.00      1.00         3\n","         299       1.00      1.00      1.00         5\n","         300       0.00      0.00      0.00         5\n","         301       1.00      1.00      1.00         4\n","         302       1.00      1.00      1.00         8\n","         303       1.00      1.00      1.00         6\n","         304       1.00      1.00      1.00         5\n","         305       1.00      1.00      1.00         2\n","         306       0.00      0.00      0.00         9\n","         307       1.00      1.00      1.00         7\n","         308       1.00      1.00      1.00         4\n","         309       1.00      1.00      1.00         4\n","         310       1.00      1.00      1.00         6\n","         311       1.00      1.00      1.00        10\n","         312       1.00      1.00      1.00         6\n","         313       1.00      1.00      1.00         4\n","         314       1.00      1.00      1.00         4\n","         315       1.00      1.00      1.00         6\n","         316       1.00      1.00      1.00         4\n","         317       1.00      1.00      1.00         7\n","         318       1.00      1.00      1.00         3\n","         319       1.00      1.00      1.00         6\n","         320       1.00      1.00      1.00         8\n","         321       1.00      1.00      1.00         8\n","         322       1.00      1.00      1.00         6\n","         323       1.00      1.00      1.00         8\n","         324       1.00      1.00      1.00         2\n","         325       1.00      1.00      1.00         4\n","         326       1.00      1.00      1.00         7\n","         327       1.00      1.00      1.00         7\n","         328       1.00      1.00      1.00         4\n","         329       0.00      0.00      0.00         6\n","         330       1.00      1.00      1.00         6\n","         331       1.00      1.00      1.00         3\n","         332       1.00      1.00      1.00         1\n","         333       1.00      1.00      1.00         8\n","         334       0.50      1.00      0.67         3\n","         335       1.00      1.00      1.00         4\n","         336       1.00      1.00      1.00         3\n","         337       1.00      1.00      1.00         4\n","         338       1.00      1.00      1.00         2\n","         339       1.00      1.00      1.00         7\n","         340       1.00      1.00      1.00         4\n","         341       1.00      1.00      1.00         4\n","         342       1.00      1.00      1.00         5\n","         343       1.00      0.50      0.67         4\n","         344       1.00      1.00      1.00         3\n","         345       1.00      1.00      1.00         2\n","         346       1.00      1.00      1.00         7\n","         347       1.00      1.00      1.00         2\n","         348       1.00      1.00      1.00         4\n","         349       0.00      0.00      0.00         1\n","         350       1.00      1.00      1.00         6\n","         351       1.00      1.00      1.00         7\n","         352       1.00      1.00      1.00         4\n","         353       1.00      1.00      1.00         5\n","         354       1.00      1.00      1.00         6\n","         355       1.00      1.00      1.00         4\n","         356       1.00      1.00      1.00         3\n","         357       0.00      0.00      0.00         4\n","         358       1.00      1.00      1.00         1\n","         359       1.00      1.00      1.00         1\n","         360       0.00      0.00      0.00         3\n","         361       1.00      1.00      1.00         1\n","         362       0.00      0.00      0.00         3\n","         363       0.00      0.00      0.00         2\n","         364       1.00      1.00      1.00         3\n","         365       0.00      0.00      0.00         3\n","         366       0.00      0.00      0.00         4\n","         367       1.00      1.00      1.00         2\n","         368       1.00      1.00      1.00         3\n","         369       1.00      1.00      1.00         3\n","         370       1.00      1.00      1.00         2\n","         371       1.00      1.00      1.00         2\n","\n","    accuracy                           0.99     13567\n","   macro avg       0.94      0.95      0.94     13567\n","weighted avg       0.99      0.99      0.99     13567\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["#Select only the optimal number of input features for X_test\n","X_test = X_test[:,:(best_model_index+1)]\n","\n","X_test = X_test.reshape(13567, best_model_index+1, 1, 1)\n","\n","# Evaluate the best model on the test data\n","y_pred = best_model.predict(X_test)\n","\n","# np.argmax() is used to convert the one-hot encoded predictions and test labels to class labels.\n","y_pred_label = np.argmax(y_pred, axis = 1)\n","\n","# Print the classification report\n","print(\"Classification report:\\n\", classification_report(y_test_enc, y_pred_label))"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"FeifaQpJmZ9u"},"outputs":[{"name":"stdout","output_type":"stream","text":["           OsID  True Class  Predicted Class  True/False\n","0  Os06g0708400         330              330        True\n","1  Os01g0173100         161              161        True\n","2  Os01g0686800          17               17        True\n","3  Os04g0107900          34               34        True\n","4  Os04g0517100           7                7        True\n"]}],"source":["# extract class labels from test data\n","class_test = y_test_enc\n","\n","# Invert OsID_labels dictionary\n","inv_OsID_labels = {v: k for k, v in OsID_labels.items()}\n","\n","# map OsID values to the class labels\n","OsID_test = [inv_OsID_labels.get(value, 'Unknown') for value in class_test]\n","\n","# create dataframe with OsID, true class, predicted class, and true/false columns\n","results = pd.DataFrame({\n","    'OsID': OsID_test,\n","    'True Class': y_test_enc,\n","    'Predicted Class': y_pred_label,\n","    'True/False': class_test == y_pred_label\n","})\n","\n","# display dataframe\n","print(results.head())\n","\n","# save results_df to a CSV file\n","results.to_csv('MLP_gene classification.csv', index=False)"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"HcBceHUp0-TI"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>No of input features</th>\n","      <th>Model accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.525</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.825</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.916</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.952</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.969</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.972</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.980</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>0.974</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>0.971</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0.978</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>0.979</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0.973</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.979</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>0.970</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>0.976</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>0.983</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>0.974</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>0.988</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>0.985</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    No of input features  Model accuracy\n","0                      1           0.525\n","1                      2           0.825\n","2                      3           0.916\n","3                      4           0.952\n","4                      5           0.969\n","5                      6           0.972\n","6                      7           0.981\n","7                      8           0.980\n","8                      9           0.974\n","9                     10           0.971\n","10                    11           0.978\n","11                    12           0.979\n","12                    13           0.973\n","13                    14           0.979\n","14                    15           0.970\n","15                    16           0.976\n","16                    17           0.983\n","17                    18           0.974\n","18                    19           0.988\n","19                    20           0.985"]},"metadata":{},"output_type":"display_data"}],"source":["display(models_df)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
