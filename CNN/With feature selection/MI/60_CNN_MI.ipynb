{"cells":[{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":5905,"status":"ok","timestamp":1682739389732,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"UsLpi_0MmZ9Z"},"outputs":[],"source":["from itertools import cycle\n","\n","import numpy as np\n","import pandas as pd \n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Model ,Sequential #for CNN\n","from keras.layers import Dense \n","from sklearn.model_selection import KFold\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from keras.layers import Conv2D, Input, MaxPooling2D, Dropout, Flatten, Dense, Activation\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.model_selection import StratifiedKFold\n","from keras import regularizers"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":16,"status":"ok","timestamp":1682739389734,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"B95hUV4pmZ9g"},"outputs":[],"source":["#fixed random seed for reproducibility \n","np.random.seed(0)"]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"elapsed":238974,"status":"ok","timestamp":1682739628693,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"EECGNCI3mZ9i","outputId":"7a2768e1-3a29-4fbc-bb15-15b09b57c30c"},"outputs":[],"source":["# load dataset (input variables = X, output variables = Y)\n","df = pd.read_csv(\"TrainingData.csv\")\n","\n","#count the number of occurances for each osID\n","OsID_counts = df['OsID'].value_counts()\n","\n","#filter for osIDs that have 10 or more occurances\n","OsID_counts_filtered = OsID_counts[OsID_counts >= 10]\n","\n","#assign a label for each osID \n","OsID_labels = {}\n","class_no = 1\n","for osID in OsID_counts_filtered.index:\n","    OsID_labels[osID] = class_no\n","    class_no +=1\n","\n","#filter the dataset with osID that contain 10 or more occurances\n","dataGene = df[df['OsID'].isin(OsID_counts_filtered.index)]\n","\n","dataGene = dataGene.drop(['Class', 'Trait'],axis=1)\n","\n","# Add a new column 'class' to the filtered dataset\n","dataGene['class'] = dataGene['OsID'].map(OsID_labels)\n","\n","#print(\"Summary of dataGene:\\n\",dataGene.describe())"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":23,"status":"ok","timestamp":1682739628694,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"Vuf_bBJBUC1h","outputId":"6735bffa-c3c0-466f-d672-34d142eaba7d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X:\n"," (41110, 20)\n","Shape of Y:\n"," (41110,)\n","class\n","1.0      1800\n","2.0      1296\n","3.0      1260\n","4.0      1218\n","5.0      1026\n","6.0      1008\n","7.0       930\n","8.0       912\n","9.0       880\n","10.0      798\n","11.0      792\n","12.0      759\n","13.0      729\n","14.0      720\n","15.0      702\n","16.0      693\n","17.0      672\n","18.0      640\n","19.0      625\n","20.0      570\n","21.0      546\n","22.0      506\n","23.0      483\n","24.0      448\n","25.0      432\n","26.0      384\n","27.0      360\n","28.0      360\n","29.0      320\n","30.0      312\n","         ... \n","344.0      12\n","345.0      12\n","346.0      12\n","347.0      12\n","348.0      12\n","349.0      12\n","350.0      12\n","351.0      12\n","352.0      12\n","353.0      12\n","354.0      12\n","355.0      12\n","356.0      11\n","357.0      11\n","358.0      11\n","359.0      11\n","360.0      11\n","361.0      11\n","362.0      10\n","363.0      10\n","364.0      10\n","365.0      10\n","366.0      10\n","367.0      10\n","368.0      10\n","369.0      10\n","370.0      10\n","371.0      10\n","372.0      10\n","373.0      10\n","Length: 373, dtype: int64\n"]}],"source":["X = dataGene.drop(['class','OsID'], axis=1) # exclude class & OsID column\n","Y = dataGene['class']\n","\n","#input feature names in order of descending importance scores in MI feature selection method\n","feature_names = ['Root10DaysSeedling', 'Shoot10DaysSeedling', 'Root35DaysSeedling', 'Leaf45DaysOldPlant', 'Shoot35DaysSeedling', \n","                 'Root14DaysSeedling', 'Root24DaysSeedling', 'Root17DaysSeedling', 'Root21DaysSeedling', 'Shoot3DaysSeedling', \n","                 'Shoot21DaysSeedling', 'PCC', 'Shoot14DaysSeedling', 'Root52DaysSeedling', 'Shoot17DaysSeedling', \n","                 'Leaf21DaysSeedling', 'log_2FoldChange', 'ET', 'PPI', 'CoExpression' ]\n","\n","X_fs = X.reindex(columns=feature_names)\n","\n","print(\"Shape of X:\\n\",X_fs.shape)\n","print(\"Shape of Y:\\n\",Y.shape)\n","\n","# Statistical summary of the variables\n","#print(\"Summary of X:\\n\",X_fs.describe())\n","#print(\"Summary of Y:\\n\",Y.describe())\n","\n","# Check for class imbalance\n","print(df.groupby(Y).size())\n","\n","# change both input and target variables datatype to ndarray\n","X_fs = X_fs.values # 2-D array\n","\n","# select target variable \n","\n","Y = Y.values #1-D array\n","Y = Y.reshape(-1, 1)"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"executionInfo":{"elapsed":1590,"status":"ok","timestamp":1682739630270,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"W5zIyx8RVDJu","outputId":"3b50bdef-9a58-4044-b5db-65745e766b49"},"outputs":[{"name":"stdout","output_type":"stream","text":["Class=0, n=1800 (4.378%)\n","Class=1, n=1296 (3.153%)\n","Class=2, n=1260 (3.065%)\n","Class=3, n=1218 (2.963%)\n","Class=4, n=1026 (2.496%)\n","Class=5, n=1008 (2.452%)\n","Class=6, n=930 (2.262%)\n","Class=7, n=912 (2.218%)\n","Class=8, n=880 (2.141%)\n","Class=9, n=798 (1.941%)\n","Class=10, n=792 (1.927%)\n","Class=11, n=759 (1.846%)\n","Class=12, n=729 (1.773%)\n","Class=13, n=720 (1.751%)\n","Class=14, n=702 (1.708%)\n","Class=15, n=693 (1.686%)\n","Class=16, n=672 (1.635%)\n","Class=17, n=640 (1.557%)\n","Class=18, n=625 (1.520%)\n","Class=19, n=570 (1.387%)\n","Class=20, n=546 (1.328%)\n","Class=21, n=506 (1.231%)\n","Class=22, n=483 (1.175%)\n","Class=23, n=448 (1.090%)\n","Class=24, n=432 (1.051%)\n","Class=25, n=384 (0.934%)\n","Class=26, n=360 (0.876%)\n","Class=27, n=360 (0.876%)\n","Class=28, n=320 (0.778%)\n","Class=29, n=312 (0.759%)\n","Class=30, n=312 (0.759%)\n","Class=31, n=306 (0.744%)\n","Class=32, n=304 (0.739%)\n","Class=33, n=299 (0.727%)\n","Class=34, n=297 (0.722%)\n","Class=35, n=296 (0.720%)\n","Class=36, n=280 (0.681%)\n","Class=37, n=264 (0.642%)\n","Class=38, n=260 (0.632%)\n","Class=39, n=253 (0.615%)\n","Class=40, n=252 (0.613%)\n","Class=41, n=248 (0.603%)\n","Class=42, n=242 (0.589%)\n","Class=43, n=228 (0.555%)\n","Class=44, n=216 (0.525%)\n","Class=45, n=210 (0.511%)\n","Class=46, n=200 (0.486%)\n","Class=47, n=192 (0.467%)\n","Class=48, n=180 (0.438%)\n","Class=49, n=171 (0.416%)\n","Class=50, n=168 (0.409%)\n","Class=51, n=168 (0.409%)\n","Class=52, n=162 (0.394%)\n","Class=53, n=150 (0.365%)\n","Class=54, n=148 (0.360%)\n","Class=55, n=138 (0.336%)\n","Class=56, n=135 (0.328%)\n","Class=57, n=135 (0.328%)\n","Class=58, n=133 (0.324%)\n","Class=59, n=132 (0.321%)\n","Class=60, n=132 (0.321%)\n","Class=61, n=130 (0.316%)\n","Class=62, n=130 (0.316%)\n","Class=63, n=130 (0.316%)\n","Class=64, n=128 (0.311%)\n","Class=65, n=128 (0.311%)\n","Class=66, n=126 (0.306%)\n","Class=67, n=124 (0.302%)\n","Class=68, n=124 (0.302%)\n","Class=69, n=124 (0.302%)\n","Class=70, n=120 (0.292%)\n","Class=71, n=120 (0.292%)\n","Class=72, n=118 (0.287%)\n","Class=73, n=116 (0.282%)\n","Class=74, n=114 (0.277%)\n","Class=75, n=105 (0.255%)\n","Class=76, n=104 (0.253%)\n","Class=77, n=102 (0.248%)\n","Class=78, n=99 (0.241%)\n","Class=79, n=98 (0.238%)\n","Class=80, n=98 (0.238%)\n","Class=81, n=98 (0.238%)\n","Class=82, n=98 (0.238%)\n","Class=83, n=96 (0.234%)\n","Class=84, n=96 (0.234%)\n","Class=85, n=96 (0.234%)\n","Class=86, n=93 (0.226%)\n","Class=87, n=92 (0.224%)\n","Class=88, n=92 (0.224%)\n","Class=89, n=91 (0.221%)\n","Class=90, n=88 (0.214%)\n","Class=91, n=88 (0.214%)\n","Class=92, n=86 (0.209%)\n","Class=93, n=86 (0.209%)\n","Class=94, n=84 (0.204%)\n","Class=95, n=84 (0.204%)\n","Class=96, n=84 (0.204%)\n","Class=97, n=78 (0.190%)\n","Class=98, n=78 (0.190%)\n","Class=99, n=76 (0.185%)\n","Class=100, n=75 (0.182%)\n","Class=101, n=75 (0.182%)\n","Class=102, n=73 (0.178%)\n","Class=103, n=72 (0.175%)\n","Class=104, n=72 (0.175%)\n","Class=105, n=70 (0.170%)\n","Class=106, n=69 (0.168%)\n","Class=107, n=68 (0.165%)\n","Class=108, n=67 (0.163%)\n","Class=109, n=66 (0.161%)\n","Class=110, n=66 (0.161%)\n","Class=111, n=66 (0.161%)\n","Class=112, n=66 (0.161%)\n","Class=113, n=66 (0.161%)\n","Class=114, n=65 (0.158%)\n","Class=115, n=64 (0.156%)\n","Class=116, n=63 (0.153%)\n","Class=117, n=63 (0.153%)\n","Class=118, n=62 (0.151%)\n","Class=119, n=61 (0.148%)\n","Class=120, n=60 (0.146%)\n","Class=121, n=60 (0.146%)\n","Class=122, n=60 (0.146%)\n","Class=123, n=60 (0.146%)\n","Class=124, n=60 (0.146%)\n","Class=125, n=60 (0.146%)\n","Class=126, n=60 (0.146%)\n","Class=127, n=60 (0.146%)\n","Class=128, n=60 (0.146%)\n","Class=129, n=60 (0.146%)\n","Class=130, n=59 (0.144%)\n","Class=131, n=59 (0.144%)\n","Class=132, n=58 (0.141%)\n","Class=133, n=56 (0.136%)\n","Class=134, n=56 (0.136%)\n","Class=135, n=56 (0.136%)\n","Class=136, n=56 (0.136%)\n","Class=137, n=56 (0.136%)\n","Class=138, n=56 (0.136%)\n","Class=139, n=56 (0.136%)\n","Class=140, n=56 (0.136%)\n","Class=141, n=56 (0.136%)\n","Class=142, n=55 (0.134%)\n","Class=143, n=55 (0.134%)\n","Class=144, n=54 (0.131%)\n","Class=145, n=54 (0.131%)\n","Class=146, n=54 (0.131%)\n","Class=147, n=54 (0.131%)\n","Class=148, n=54 (0.131%)\n","Class=149, n=53 (0.129%)\n","Class=150, n=52 (0.126%)\n","Class=151, n=52 (0.126%)\n","Class=152, n=52 (0.126%)\n","Class=153, n=52 (0.126%)\n","Class=154, n=50 (0.122%)\n","Class=155, n=50 (0.122%)\n","Class=156, n=49 (0.119%)\n","Class=157, n=49 (0.119%)\n","Class=158, n=48 (0.117%)\n","Class=159, n=48 (0.117%)\n","Class=160, n=48 (0.117%)\n","Class=161, n=46 (0.112%)\n","Class=162, n=45 (0.109%)\n","Class=163, n=44 (0.107%)\n","Class=164, n=44 (0.107%)\n","Class=165, n=44 (0.107%)\n","Class=166, n=42 (0.102%)\n","Class=167, n=42 (0.102%)\n","Class=168, n=42 (0.102%)\n","Class=169, n=42 (0.102%)\n","Class=170, n=42 (0.102%)\n","Class=171, n=42 (0.102%)\n","Class=172, n=42 (0.102%)\n","Class=173, n=41 (0.100%)\n","Class=174, n=41 (0.100%)\n","Class=175, n=40 (0.097%)\n","Class=176, n=40 (0.097%)\n","Class=177, n=39 (0.095%)\n","Class=178, n=39 (0.095%)\n","Class=179, n=38 (0.092%)\n","Class=180, n=37 (0.090%)\n","Class=181, n=36 (0.088%)\n","Class=182, n=35 (0.085%)\n","Class=183, n=35 (0.085%)\n","Class=184, n=35 (0.085%)\n","Class=185, n=35 (0.085%)\n","Class=186, n=34 (0.083%)\n","Class=187, n=34 (0.083%)\n","Class=188, n=34 (0.083%)\n","Class=189, n=34 (0.083%)\n","Class=190, n=32 (0.078%)\n","Class=191, n=32 (0.078%)\n","Class=192, n=32 (0.078%)\n","Class=193, n=32 (0.078%)\n","Class=194, n=32 (0.078%)\n","Class=195, n=32 (0.078%)\n","Class=196, n=31 (0.075%)\n","Class=197, n=31 (0.075%)\n","Class=198, n=31 (0.075%)\n","Class=199, n=31 (0.075%)\n","Class=200, n=30 (0.073%)\n","Class=201, n=30 (0.073%)\n","Class=202, n=30 (0.073%)\n","Class=203, n=30 (0.073%)\n","Class=204, n=30 (0.073%)\n","Class=205, n=30 (0.073%)\n","Class=206, n=30 (0.073%)\n","Class=207, n=30 (0.073%)\n","Class=208, n=30 (0.073%)\n","Class=209, n=29 (0.071%)\n","Class=210, n=29 (0.071%)\n","Class=211, n=28 (0.068%)\n","Class=212, n=28 (0.068%)\n","Class=213, n=28 (0.068%)\n","Class=214, n=28 (0.068%)\n","Class=215, n=28 (0.068%)\n","Class=216, n=28 (0.068%)\n","Class=217, n=27 (0.066%)\n","Class=218, n=27 (0.066%)\n","Class=219, n=27 (0.066%)\n","Class=220, n=27 (0.066%)\n","Class=221, n=27 (0.066%)\n","Class=222, n=27 (0.066%)\n","Class=223, n=26 (0.063%)\n","Class=224, n=26 (0.063%)\n","Class=225, n=26 (0.063%)\n","Class=226, n=26 (0.063%)\n","Class=227, n=26 (0.063%)\n","Class=228, n=25 (0.061%)\n","Class=229, n=25 (0.061%)\n","Class=230, n=25 (0.061%)\n","Class=231, n=25 (0.061%)\n","Class=232, n=24 (0.058%)\n","Class=233, n=24 (0.058%)\n","Class=234, n=24 (0.058%)\n","Class=235, n=24 (0.058%)\n","Class=236, n=24 (0.058%)\n","Class=237, n=24 (0.058%)\n","Class=238, n=24 (0.058%)\n","Class=239, n=24 (0.058%)\n","Class=240, n=24 (0.058%)\n","Class=241, n=24 (0.058%)\n","Class=242, n=24 (0.058%)\n","Class=243, n=24 (0.058%)\n","Class=244, n=23 (0.056%)\n","Class=245, n=23 (0.056%)\n","Class=246, n=22 (0.054%)\n","Class=247, n=22 (0.054%)\n","Class=248, n=22 (0.054%)\n","Class=249, n=22 (0.054%)\n","Class=250, n=22 (0.054%)\n","Class=251, n=22 (0.054%)\n","Class=252, n=22 (0.054%)\n","Class=253, n=22 (0.054%)\n","Class=254, n=22 (0.054%)\n","Class=255, n=22 (0.054%)\n","Class=256, n=22 (0.054%)\n","Class=257, n=22 (0.054%)\n","Class=258, n=22 (0.054%)\n","Class=259, n=22 (0.054%)\n","Class=260, n=22 (0.054%)\n","Class=261, n=22 (0.054%)\n","Class=262, n=22 (0.054%)\n","Class=263, n=22 (0.054%)\n","Class=264, n=21 (0.051%)\n","Class=265, n=21 (0.051%)\n","Class=266, n=21 (0.051%)\n","Class=267, n=21 (0.051%)\n","Class=268, n=21 (0.051%)\n","Class=269, n=20 (0.049%)\n","Class=270, n=20 (0.049%)\n","Class=271, n=20 (0.049%)\n","Class=272, n=20 (0.049%)\n","Class=273, n=20 (0.049%)\n","Class=274, n=20 (0.049%)\n","Class=275, n=20 (0.049%)\n","Class=276, n=20 (0.049%)\n","Class=277, n=20 (0.049%)\n","Class=278, n=20 (0.049%)\n","Class=279, n=20 (0.049%)\n","Class=280, n=19 (0.046%)\n","Class=281, n=19 (0.046%)\n","Class=282, n=19 (0.046%)\n","Class=283, n=18 (0.044%)\n","Class=284, n=18 (0.044%)\n","Class=285, n=18 (0.044%)\n","Class=286, n=18 (0.044%)\n","Class=287, n=18 (0.044%)\n","Class=288, n=18 (0.044%)\n","Class=289, n=18 (0.044%)\n","Class=290, n=18 (0.044%)\n","Class=291, n=18 (0.044%)\n","Class=292, n=17 (0.041%)\n","Class=293, n=17 (0.041%)\n","Class=294, n=17 (0.041%)\n","Class=295, n=17 (0.041%)\n","Class=296, n=17 (0.041%)\n","Class=297, n=17 (0.041%)\n","Class=298, n=16 (0.039%)\n","Class=299, n=16 (0.039%)\n","Class=300, n=16 (0.039%)\n","Class=301, n=16 (0.039%)\n","Class=302, n=16 (0.039%)\n","Class=303, n=16 (0.039%)\n","Class=304, n=16 (0.039%)\n","Class=305, n=16 (0.039%)\n","Class=306, n=15 (0.036%)\n","Class=307, n=15 (0.036%)\n","Class=308, n=15 (0.036%)\n","Class=309, n=15 (0.036%)\n","Class=310, n=15 (0.036%)\n","Class=311, n=14 (0.034%)\n","Class=312, n=14 (0.034%)\n","Class=313, n=14 (0.034%)\n","Class=314, n=14 (0.034%)\n","Class=315, n=14 (0.034%)\n","Class=316, n=14 (0.034%)\n","Class=317, n=14 (0.034%)\n","Class=318, n=14 (0.034%)\n","Class=319, n=14 (0.034%)\n","Class=320, n=14 (0.034%)\n","Class=321, n=14 (0.034%)\n","Class=322, n=14 (0.034%)\n","Class=323, n=14 (0.034%)\n","Class=324, n=14 (0.034%)\n","Class=325, n=14 (0.034%)\n","Class=326, n=14 (0.034%)\n","Class=327, n=14 (0.034%)\n","Class=328, n=13 (0.032%)\n","Class=329, n=13 (0.032%)\n","Class=330, n=13 (0.032%)\n","Class=331, n=13 (0.032%)\n","Class=332, n=13 (0.032%)\n","Class=333, n=13 (0.032%)\n","Class=334, n=13 (0.032%)\n","Class=335, n=13 (0.032%)\n","Class=336, n=13 (0.032%)\n","Class=337, n=12 (0.029%)\n","Class=338, n=12 (0.029%)\n","Class=339, n=12 (0.029%)\n","Class=340, n=12 (0.029%)\n","Class=341, n=12 (0.029%)\n","Class=342, n=12 (0.029%)\n","Class=343, n=12 (0.029%)\n","Class=344, n=12 (0.029%)\n","Class=345, n=12 (0.029%)\n","Class=346, n=12 (0.029%)\n","Class=347, n=12 (0.029%)\n","Class=348, n=12 (0.029%)\n","Class=349, n=12 (0.029%)\n","Class=350, n=12 (0.029%)\n","Class=351, n=12 (0.029%)\n","Class=352, n=12 (0.029%)\n","Class=353, n=12 (0.029%)\n","Class=354, n=12 (0.029%)\n","Class=355, n=11 (0.027%)\n","Class=356, n=11 (0.027%)\n","Class=357, n=11 (0.027%)\n","Class=358, n=11 (0.027%)\n","Class=359, n=11 (0.027%)\n","Class=360, n=11 (0.027%)\n","Class=361, n=10 (0.024%)\n","Class=362, n=10 (0.024%)\n","Class=363, n=10 (0.024%)\n","Class=364, n=10 (0.024%)\n","Class=365, n=10 (0.024%)\n","Class=366, n=10 (0.024%)\n","Class=367, n=10 (0.024%)\n","Class=368, n=10 (0.024%)\n","Class=369, n=10 (0.024%)\n","Class=370, n=10 (0.024%)\n","Class=371, n=10 (0.024%)\n","Class=372, n=10 (0.024%)\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3deZhcVZnH8e+PsMm+JGJIgCQYdpkALTKDIgpoABWZQQzDEhEm4oCMwDxjEARGZWQc0QEXGJCwiewgIKAssriwJIEQwp6EKCEhCSCENZLwzh/nFKl0quveJF1Ld/8+z1NP3Xvu9tbtrnrrLHWvIgIzM7N6Vmp1AGZm1v6cLMzMrJCThZmZFXKyMDOzQk4WZmZWyMnCzMwKOVn0AZLOlfStbtrXppJel9Qvz98t6cju2Hfe362SRnfX/pbhuN+V9KKkF5p97GaTdJSkO1odRxEl4yVt06LjryHpKUnrt+L47cbJooeTNEPSW5Jek/SKpD/lD4P3/rYRcVREfKfkvvast05E/CUi1oqIRd0Q+2mSftFp/3tHxMUruu9ljGMT4ARgm4j4QKdlB+fk+Ho+z+9Wzb/ezDhzPKU+6CXtK+kP+f9irqTfSdq7GTF2owOA5yPi8UqBpO0l3Sxpfn5td0j6cJmdSbpf0iF5emSnv+Vzki6XtENl/Yh4E7gM+Pdufl09kpNF7/DZiFgb2Aw4A/gGcEF3H0TSyt29zzaxGfBSRMztvCAiLsvJcS1gb2BWZT6XLZNmnENJBwO/BM4HBgEDgdOB/Rp97G52FHBpZUbSVsDvgQdJf7NBwK3AXZJ2Wo79T89/w3WAfwCeBf4k6WNV61wGHNGL//fLiwg/evADmAHs2alsZ+BdYLs8fxHw3TzdH/g18ArwMunNtxLpTfku8BbwOvAfwBAggCOAvwD3VpWtnPd3N/A90hv4VeAGYIO8bHdgZq14gZHA34B38vEeqdrfkXl6JeBk4M/AXOASYN28rBLH6Bzbi8BJdc7Tunn7eXl/J+f975lf87s5jovq7GOp15PLTyF90LwGTAH2rVp2FPA74KfAX/NxVwbOBl4CpgHHAgurttkgx/oC8Bxwao51B+BtYGGO9YUasayct/tanddxFHBH1fw5wExgfv477lK1bFfg4bzsBeB7uXxN4Ir8P/QK8ACwfr3487KtgD/k/5V5wCVdxLhG/t/oX1V2NXBdjXUvBG4rEdf9wCF5eiQwtca+fg78oVPZc8BHWv1eb/XDNYteKCIeJL35P1Zj8Ql52QBgI+CbaZM4lPSh+9lI35q/X7XNx4GtgU93ccjDgC8DG5M+yM4uEeNvgP8CrszH+7saq30pPz4BDAPWAn7SaZ2PAlsCewCnSNq6i0P+mJQwhuXXcxhweETcwZI1hi8VxV7DU6RvpusC/w1cIal/1fLdgEmkRH0mcEyOYTtSYj+g0/4uI32YDsvLPw8cGhEPA18H7s6xfoClbUf6u16zDPHfB3wI2JCU7K+WtEpe9hPgvyJiHWA48KtcfiQpMQ3Kr+sYUvLvMv687Ht5H+sBmwL/10VMWwPzI+LFqrK9SAmjs6uA3fO3/3pxlXEdsEvV6wd4Aqj1/9mnOFn0XrNI3/A6e4fULLFZRLwTEb+P/PWpjtMi4o2IeKuL5ZdGxJSIeAP4FnBgpQN8BR0M/DAipkfE68CJwKhOTQL/GRFvRcQjwCPUeFPnWL4InBgRr0XEDNKH9qGd110eEXFlRMyOiHcj4lLgeaC6WWR6RJwfEYvyOTwwv67ZEfES8F5ilrQZKbkcHxFvRsRsUvIdVTKcDUk1rjnLEP8lEfHXiHiHlMA3JH3QQ/p/2ULShvncPVBVPgDYPCIWRsT4iHijRPzvkGqFH8h/tz92EdZ6pJoa8N7fcF1gdo11ZwOr5OU14yp7Lkjvm36kpqmK13I8fZqTRe81iFQV7+x/gKnAbZKmSxpbYl/PLcPyP5PeuP27WHdZbJz3V73vlUnfnCuqRy+9Sap9dNYfWLXGvgZ1Q4xIOkLS5DzA4BXggyz5+jufv407lVVPbwasDsyr2t9ZLPma63kJ0DKsj6QT86ifV0lNZatXxT8a2B54WtIDkiq1ywuAe4BrJM2U9F/5A70o/uNITUwP53N2SBdh/RVYuzITaUDFq6QvOp0NJCWJ+XXiKmsQsCjvq2JtUpNWn+Zk0Qvl0SGDSG3DS8jfDk+IiGHAZ4HjJe1RWdzFLotqHptUTW9KeuO+CLxB+mCoxNWP9K2v7H5nkT58qve9kGX41py9mGPqvK/nl3E/S5G0BamJawypr2Y9UjJW1WqdX+dsYHDVfPX5e47UH7F+RKyXH+tExI5d7KuzKaTz808l498L+BqwP+nb8wakPhwBRMQTEfFF4P2kGsJ1klaNiAURcUpEbEWqSXyBVHuoG39EPB8RXyZ9wB8LjJO0aY3QngDW7tScd0c+TmcHAvfmmnJXcZW1P3B/rmVVbE2qtfZpTha9iKR1JH2G1MH3i4h4tMY6n5H0QUkifXtalB+QPmSGdd6mhEMkbSNpDeDbwDX5m+DTwOp5GOcqpM7d1aq2mwMMqR7m28nlwHGShkpai8V9HAuXJbgcy1XA6ZLWzk0lxwO/qL9lKWuROsfnAStJOopUs6jnKtLr+oCkDakamhkRz5I6Yr+fY11J0nBJH82rzAE26dSmTtX2C/P+vivp0Kp9fFzSz2pssjYpkc4j1b6+TaoZACDpsNwEVflmH8C7kvbMf/OVSP9HC4FFRfFL+qKkjXPTZ+Xb+lJ/z9xcdzfpA7/iFGBPSadKWi//v59AShYn5v3XjKvWuap6jZI0WNJ3gEOAk6qWDcvnZWK9ffQFTha9w02SXiN9qzsJ+CFweBfrDid9Q3ud1LH5s4i4Oy/7HnBybj5YlrHll5JGXL1A+qA5FiAiXgX+lTTC5HlSTWNm1XaVzsqXJD1UY7/j8r7vJY02epv0LXh5fC0ffzqpxvXLvP8VEhEPAecCE0g1hqF5up6fAH8CHgfGk0anLahafhDpW/6TpKbEK1ncjPMb0oiyuZKqz2V1TL8gfegdlWN6gTQi6YYaq99EOr/TSOfmRVLiqPgM8FT+//oecGBOSIPy/iojwG4hJcGi+P8emKj0G5WrgTERMavmWUqd3+/1K0X6vcVuwC6k//XngX2BPSJifF6tXlydDctxvE4aNbUl8NGIuKdqnYOBC5b1C0pvpOK+TTNrJEn7A2dExJatjqWd5NrvA8CXouqHeU08/hqkYcN/HxG1+v/6FCcLsyaTtDbpG/adpG/C1wO3R0SZwQZmLeFkYdZkktYF7gK2IDWN3Qgcl4cHm7UlJwszMyvkDm4zMyvUay+O1b9//xgyZEirwzAz6zEmTpz4YkQMqLWs1yaLIUOGMGFC0QhGMzOrkPTnrpa5GcrMzAo5WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrIwM7NCThZmZlbIycLMzAo5WZiZWSEnCzMzK9SwZCFpnKS5kqZUlV0paVJ+zJA0KZcPkfRW1bJzq7bZSdKjkqZKOjvfPcvMzJqokRcSvIh0r+FLKgUR8cXKtKQzSTeAr5gWESNq7OccYAzpJvC3ACOBWxsQr5mZdaFhNYuIuJd0s/al5NrBgcDl9fYhaSCwTkTcF+kuTZcAn+/uWM3MrL5W9Vl8DJgTEc9UlQ2V9LCkeyR9LJcNAmZWrTMzl9UkaYykCZImzJs3r/ujNjPro1qVLA5iyVrFbGDTiNgBOB74paR1gFr9E13eBzYizouIjojoGDCg5v07zMxsOTT95keSVgb+EdipUhYRC4AFeXqipGmkm9nPBAZXbT4YmNW8aM3MDFpTs9gTeDIi3mtekjRAUr88PQwYDkyPiNnAa5J2yf0chwE3tCBmM7M+rZFDZy8H7gO2lDRT0hF50SiW7tjeDZgs6RHgGuCoiKh0jn8V+DkwFZiGR0KZmTWd0iCj3qejoyN8D24zs/IkTYyIjlrL/AtuMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFnCzMzKyQk4WZmRVqWLKQNE7SXElTqspOk/S8pEn5sU/VshMlTZX0lKRPV5WPzGVTJY1tVLxmZta1RtYsLgJG1ij/UUSMyI9bACRtA4wCts3b/ExSP0n9gJ8CewPbAAfldc3MrIlWbtSOI+JeSUNKrr4fcEVELACelTQV2DkvmxoR0wEkXZHXfbybwzUzszpa0WdxjKTJuZlq/Vw2CHiuap2Zuayr8pokjZE0QdKEefPmdXfcZmZ9VrOTxTnA5sAIYDZwZi5XjXWjTnlNEXFeRHRERMeAAQNWNFYzM8sa1gxVS0TMqUxLOh/4dZ6dCWxStepgYFae7qrczMyapKk1C0kDq2b3ByojpW4ERklaTdJQYDjwIDAeGC5pqKRVSZ3gNzYzZjMza2DNQtLlwO5Af0kzgVOB3SWNIDUlzQC+AhARj0m6itRxvRA4OiIW5f0cA/wW6AeMi4jHGhWzmZnVpoguuwB6tI6OjpgwYUKrwzAz6zEkTYyIjlrL/AtuMzMr5GRhZmaFnCzMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZmJlZIScLMzMr5GRhZmaFCpOFpM0lrZand5d0rKT1Gh+amZm1izI1i2uBRZI+CFwADAV+2dCozMysrZRJFu9GxELSJcX/NyKOAwYWbGNmZr1ImWTxjqSDgNEsvlnRKo0LyczM2k2ZZHE48PfA6RHxbL450S8aG5aZmbWTwpsfRcTjkr4BbJrnnwXOaHRgZmbWPsqMhvosMAn4TZ4fIcm3NjUz60PKNEOdBuwMvAIQEZNII6LMzKyPKJMsFkbEq53Keue9WM3MrKbCPgtgiqR/BvpJGg4cC/ypsWGZmVk7KVOz+BqwLbAAuByYD3y9aCNJ4yTNlTSlqux/JD0pabKk6yu/BJc0RNJbkiblx7lV2+wk6VFJUyWdLUnL+iLNzGzFFCaLiHgzIk6KiA9HREeefrvEvi8CRnYqux3YLiK2B54GTqxaNi0iRuTHUVXl5wBjgOH50XmfZmbWYF02Q0m6iTp9ExHxuXo7joh7JQ3pVHZb1ez9wAH19iFpILBORNyX5y8BPg/cWm+77jBk7M3MOGPfRh/GzKxHqNdn8YMGH/vLwJVV80MlPUxq5jo5In4PDAJmVq0zM5fVJGkMqRbCpptu2u0Bm5n1VV0mi4i4pzItaVVgK1JN46mI+NuKHFTSScBC4LJcNBvYNCJekrQT8CtJ2wK1+ifq1XbOA84D6Ojo8IgtM7NuUjgaStK+wLnANNKH91BJX4mI5WoKkjQa+AywR0QEQEQsIHWgExETJU0DtiDVJAZXbT4YmLU8xzUzs+VXZujsmcAnImIqpPtbADezHP0GkkYC3wA+HhFvVpUPAF6OiEWShpE6sqdHxMuSXpO0C/AAcBjw42U9rpmZrZgyQ2fnVhJFNh2YW7SRpMuB+4AtJc2UdATwE2Bt4PZOQ2R3AyZLegS4BjgqIl7Oy74K/ByYSqrdNLxzu2LI2JubdSgzs7ZWpmbxmKRbgKtI/QVfAMZL+keAiLiu1kYRcVCN4gu6WPda0k2Wai2bAGxXIk4zM2uQMslidWAO8PE8Pw/YAPgsKXnUTBZmZtZ7lLlE+eHNCMTMzNpXmdFQQ0mX/BhSvX7Rj/LMzKz3KNMM9StSX8NNwLuNDcfMzNpRmWTxdkSc3fBIzMysbZVJFmdJOhW4jfzDOYCIeKhhUZmZWVspkyw+BBwKfJLFzVCR583MrA8okyz2B4at6PWgzMys5yrzC+5HgPUaHYiZmbWvMjWLjYAnJY1nyT4LD501M+sjyiSLUxsehZmZtbUyv+C+p2gdMzPr3Qr7LCTtImm8pNcl/U3SIknzmxGcmZm1hzId3D8BDgKeAd4HHJnLzMysjyjTZ0FETJXULyIWARdK+lOD4zIzszZSJlm8me/BPUnS90n3y16zsWGZmVk7KdMMdWhe7xjgDWAT4J8aGZSZmbWXMqOh/pwn35Z0NrBJp9usmplZL1dmNNTdktaRtAHp19wXSvph40MzM7N2UaYZat2ImA/8I3BhROwE7NnYsMzMrJ2USRYrSxoIHAj8ell2LmmcpLmSplSVbSDpdknP5Of1c7kknS1pqqTJknas2mZ0Xv8ZSaOXJYYVNWTszc08nJlZWyqTLL4N/BaYGhHjJQ0j/eaijIuAkZ3KxgJ3RsRw4M48D7A3MDw/xgDnQEoupEuOfATYGTi1kmDMzKw5CpNFRFwdEdtHxL/m+ekRUWo0VETcC7zcqXg/4OI8fTHw+arySyK5H1gv12g+DdweES9HxF+B21k6ATWUaxdm1teVqVl0t40iYjZAfn5/Lh8EPFe13sxc1lX5UiSNkTRB0oR58+Z1e+BmZn1VK5JFV1SjLOqUL10YcV5EdEREx4ABA7o1ODOzvqwVyWJObl4iP8/N5TNJP/irGAzMqlNuZmZNUuZ3FhtJukDSrXl+G0lHrMAxbwQqI5pGAzdUlR+WR0XtAryam6l+C3xK0vq5Y/tTuczMzJqkTM3iItKH88Z5/mng62V2Luly4D5gS0kzc5I5A9hL0jPAXnke4BZgOjAVOB+odKi/DHwHGJ8f385lZmbWJGUuJNg/Iq6SdCJARCyUtKjMziPioC4W7VFj3QCO7mI/44BxZY5pZmbdr0zN4g1JG5I7lStNRA2NyszM2kqZmsXxpP6EzSX9ERgAHNDQqMzMrK2UuersQ5I+DmxJGsb6VES80/DIzMysbZS6Ux7pMhtD8vo7SiIiLmlYVGZm1lYKk4WkS4HNgUlApWM7ACcLM7M+okzNogPYJo9WMjOzPqjMaKgpwAcaHYiZmbWvUr+zAB6X9CCwoFIYEZ9rWFRmZtZWyiSL0xodRE8xZOzNzDhj31aHYWbWdGWGzt4jaTNgeETcIWkNoF/jQzMzs3ZR5kKC/wJcA/xfLhoE/KqRQZmZWXsp08F9NLArMB8gIp5h8Q2LzMysDyiTLBZExN8qM5JWpoubD5mZWe9UJlncI+mbwPsk7QVcDdzU2LDMzKydlEkWY4F5wKPAV0j3nTi5kUGZmVl7KTMa6l3SzYjOb3w4ZmbWjspcG+pRlu6jeBWYAHw3Il5qRGBmZtY+yjRD3QrcDBycHzcB9wIvkG652qcMGXtzq0MwM2u6Mr/g3jUidq2af1TSHyNiV0mHNCqwduZfcptZX1OmZrGWpI9UZiTtDKyVZxcu6wElbSlpUtVjvqSvSzpN0vNV5ftUbXOipKmSnpL06WU9ppmZrZgyNYsjgXGSKgniNeAISWsC31vWA0bEU8AIAEn9gOeB64HDgR9FxA+q15e0DTAK2BbYGLhD0hYRsQgzM2uKMqOhxgMfkrQuoIh4pWrxVSt4/D2AaRHxZ0ldrbMfcEVELACelTSVdOe++1bw2GZmVlKZZigAIuLVTomiO4wCLq+aP0bSZEnjJK2fywYBz1WtMzOXmZlZk5ROFt1N0qrA50i/CAc4h3T71hHAbODMyqo1Nq95uRFJYyRNkDRh3rx53RyxmVnf1WWykPSF/Dy0QcfeG3goIuYARMSciFhU9SPAnfN6M4FNqrYbDMyqtcOIOC8iOiKiY8CAAQ0K28ys76lXszgxP1/boGMfRFUTlKSBVcv2J93OFeBGYJSk1XLiGg482KCYzMyshnod3C9JugsYKunGzgtX5Laq+QZKe5GuNVXxfUkjSE1MMyrLIuIxSVcBj5OG6h7dLiOh/HsLM+sr6iWLfYEdgUtZ3H/QLSLiTWDDTmWH1ln/dOD07ozBzMzK6zJZ5HtY3C/pHyJinqS1U3G83rzw2p9rF2bWF5QZDbWRpIdJfQiPS5ooabsGx9Wj+HpRZtbblUkW5wHHR8RmEbEpcEIuMzOzPqJMslgzIu6qzETE3cCaDYuoh3Ltwsx6szLXhpou6Vukjm6AQ4BnGxeSmZm1mzI1iy8DA4Dr8qM/6aJ/ZmbWR5S5kOBfgWObEIuZmbWpll0byszMeg4nCzMzK+Rk0Y08IsrMeqvCZCFpsKTrJc2TNEfStZIGNyM4MzNrD2VqFheSrvw6kHTToZtymZmZ9RFlksWAiLgwIhbmx0WkobRmZtZHlEkWL0o6RFK//DgEeKnRgZmZWfso+6O8A4EXSLc7PSCXmZlZH1GYLCLiLxHxuYgYEBHvj4jPR8SfmxFcT+QRUWbWG3X5C25Jp9TZLiLiOw2Ix8zM2lC9y328UaNsTeAI0l3unCzMzPqILpuhIuLMyoN0/4r3kS4geAUwrEnx9UhuijKz3qbuhQQlbQAcDxwMXAzsmC8saGZmfUiXNQtJ/wOMB14DPhQRp3VnopA0Q9KjkiZJmpDLNpB0u6Rn8vP6uVySzpY0VdJkSTt2VxxmZlas3mioE4CNgZOBWZLm58drkuZ30/E/EREjIqIjz48F7oyI4cCdeR5gb2B4fowBzumm45uZWQldNkNFRCsuMrgfsHuevhi4G/hGLr8kIgK4X9J6kgZGxOwWxGhm1ue08qqzAdwmaaKkMblso0oCyM/vz+WDgOeqtp2Zy5YgaYykCZImzJs3r4GhF3Mnt5n1JmXuwd0ou0bELEnvB26X9GSddVWjLJYqiDiPNHKLjo6OpZabmdnyaVnNIiJm5ee5wPXAzsAcSQMB8vPcvPpMYJOqzQcDs5oXrZlZ39aSZCFpTUlrV6aBTwFTSJdCH51XGw3ckKdvBA7Lo6J2AV51f4WZWfO0qhlqI+B6SZUYfhkRv5E0HrhK0hHAX4Av5PVvAfYBpgJvkn4caGZmTdKSZBER04G/q1H+ErBHjfIAjm5CaGZmVoPvwW1mZoWcLMzMrJCTRYP59xZm1hs4WZiZWSEnCzMzK+RkYWZmhZwszMyskJOFmZkVcrJoAo+IMrOezsnCzMwKOVk0iWsXZtaTOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFXKyaLIhY2/2yCgz63GcLFrEScPMehInizbgpGFm7c7JwszMCjU9WUjaRNJdkp6Q9Jikf8vlp0l6XtKk/NinapsTJU2V9JSkTzc75mZw7cLM2lkrahYLgRMiYmtgF+BoSdvkZT+KiBH5cQtAXjYK2BYYCfxMUr8WxN1wThhm1q6aniwiYnZEPJSnXwOeAAbV2WQ/4IqIWBARzwJTgZ0bH6mZmVW0tM9C0hBgB+CBXHSMpMmSxklaP5cNAp6r2mwmXSQXSWMkTZA0Yd68eQ2KuvE8UsrM2k3LkoWktYBrga9HxHzgHGBzYAQwGzizsmqNzaPWPiPivIjoiIiOAQMGNCDq5nLCMLN20ZJkIWkVUqK4LCKuA4iIORGxKCLeBc5ncVPTTGCTqs0HA7OaGa+ZWV/XitFQAi4AnoiIH1aVD6xabX9gSp6+ERglaTVJQ4HhwIPNirfVXLsws3awcguOuStwKPCopEm57JvAQZJGkJqYZgBfAYiIxyRdBTxOGkl1dEQsanrUZmZ9WNOTRUT8gdr9ELfU2eZ04PSGBWVmZnX5F9w9hJujzKyVnCx6ECcMM2sVJ4sexgnDzFrByaKHctIws2ZysujBnDDMrFmcLMzMrJCTRQ/n60iZWTM4WfQiThxm1iit+AW3NdiQsTcz44x9l0ocM87Yt0URmVlP52TRh9RKHpXEYmZWj5uhzE1XZlbIycKAxQnDicPManEzlC2lOmF07vtw05VZ3+RkYculq4TiJGLWO7kZyrpVdXOWh/Ka9R6uWVjD1RrK66G9Zj2Lk4W1ja6G9nY1vyzrmNmKcbKwPmF5k44TjVniZGFWR5mRYfU42Vhv4WRh1mDd1ZTmEWjWSj0mWUgaCZwF9AN+HhFntDgks7ZQnTSWp+bT6GS2LOvUis/aQ49IFpL6AT8F9gJmAuMl3RgRj7c2MjNrtHZPZo06drvpEckC2BmYGhHTASRdAewHOFmYWa/UbiP/FBEN23l3kXQAMDIijszzhwIfiYhjOq03BhiTZ7cEnlrOQ/YHXlzObZvFMXaPdo+x3eMDx9hd2iHGzSJiQK0FPaVmoRplS2W5iDgPOG+FDyZNiIiOFd1PIznG7tHuMbZ7fOAYu0u7x9hTLvcxE9ikan4wMKtFsZiZ9Tk9JVmMB4ZLGippVWAUcGOLYzIz6zN6RDNURCyUdAzwW9LQ2XER8VgDD7nCTVlN4Bi7R7vH2O7xgWPsLm0dY4/o4DYzs9bqKc1QZmbWQk4WZmZWyMmiE0kjJT0laaqksa2OB0DSDEmPSpokaUIu20DS7ZKeyc/rNzmmcZLmSppSVVYzJiVn53M6WdKOLYzxNEnP53M5SdI+VctOzDE+JenTTYpxE0l3SXpC0mOS/i2Xt8W5rBNf25xHSatLelDSIznG/8zlQyU9kM/hlXlwDJJWy/NT8/IhLYzxIknPVp3HEbm8Je+ZuiLCj/wgdZ5PA4YBqwKPANu0QVwzgP6dyr4PjM3TY4H/bnJMuwE7AlOKYgL2AW4l/V5mF+CBFsZ4GvDvNdbdJv+9VwOG5v+Dfk2IcSCwY55eG3g6x9IW57JOfG1zHvO5WCtPrwI8kM/NVcCoXH4u8NU8/a/AuXl6FHBlE/7OXcV4EXBAjfVb8p6p93DNYknvXVYkIv4GVC4r0o72Ay7O0xcDn2/mwSPiXuDlkjHtB1wSyf3AepIGtijGruwHXBERCyLiWWAq6f+hoSJidkQ8lKdfA54ABtEm57JOfF1p+nnM5+L1PLtKfgTwSeCaXN75HFbO7TXAHpJq/fC3GTF2pSXvmXqcLJY0CHiuan4m9d8YzRLAbZIm5kuaAGwUEbMhvaGB97csusW6iqndzusxuWo/rqr5ruUx5uaQHUjfOtvuXHaKD9roPErqJ2kSMBe4nVSjeSUiFtaI470Y8/JXgQ2bHWNEVM7j6fk8/kjSap1jrBF/SzhZLKnUZUVaYNeI2BHYGzha0m6tDmgZtdN5PQfYHBgBzAbOzOUtjVHSWsC1wNcjYn69VWuUNTzOGvG11XmMiEURMYJ0dYedga3rxNEWMfLiIjYAAAXTSURBVEraDjgR2Ar4MLAB8I1WxliPk8WS2vKyIhExKz/PBa4nvRnmVKql+Xlu6yJ8T1cxtc15jYg5+U37LnA+i5tIWhajpFVIH8SXRcR1ubhtzmWt+NrxPOa4XgHuJrXzryep8sPj6jjeizEvX5fyzZXdGePI3MwXEbEAuJA2OY+1OFksqe0uKyJpTUlrV6aBTwFTclyj82qjgRtaE+ESuorpRuCwPMJjF+DVShNLs3Vq992fdC4hxTgqj5QZCgwHHmxCPAIuAJ6IiB9WLWqLc9lVfO10HiUNkLRenn4fsCepb+Uu4IC8WudzWDm3BwC/i9yr3OQYn6z6QiBSn0r1eWyL98x7Wt3D3m4P0iiEp0ltnie1QTzDSKNLHgEeq8REamO9E3gmP2/Q5LguJzU/vEP6FnREVzGRqtQ/zef0UaCjhTFemmOYTHpDDqxa/6Qc41PA3k2K8aOk5oXJwKT82KddzmWd+NrmPALbAw/nWKYAp+TyYaRENRW4Glgtl6+e56fm5cNaGOPv8nmcAvyCxSOmWvKeqffw5T7MzKyQm6HMzKyQk4WZmRVysjAzs0JOFmZmVsjJwszMCjlZWI8k6QOSrpA0TdLjkm6RtIWkIaq6ymw3H/M0Sf++jNvcLamjEfHk/X8sX8V0Uh6/X71ssKQb8lVXp0k6q3Ll1Tr7ez0/D5H0lqSHla44+6Ck0fW2td7NycJ6nPwDpuuBuyNi84jYBvgmsFFrI2uJg4EfRMSIiHirUpjP0XXAryJiOLAFsBZw+jLse1pE7BARW5N+oHqcpMO7MXbrQZwsrCf6BPBORJxbKYiISRHx++qV8rfj30t6KD/+IZcPlHRv/jY+JX8776d0b4EpSvcOOa5eALnG8N/5G/fTkj6Wy9+XazyTJV0JvK9qm09Jui/HcrWktSStq3Tfhy3zOpdL+pcax9sjf8t/VOnCfatJOhI4EDhF0mWdNvkk8HZEXJjPzyLgOODLktaQtG2OfVKOdXi91xsR04HjgWPrrWe918rFq5i1ne2AiSXWmwvsFRFv5w/Dy4EO4J+B30bE6ZL6AWuQLog3KCK2A6hcmqHAyhGxs9KNf04lXcLhq8CbEbG9pO2Bh/L++gMnA3tGxBuSvgEcHxHflnQMcJGks4D1I+L86oNIWp1034M9IuJpSZeQ7s3wv5I+Cvw6Iq5hSdt2PkcRMV/SX4APAv8CnBURl+WmqX4lXu9DpIveWR/kZGG92SrAT5TuPraI1BQD6Rpg45QukPeriJgkaTowTNKPgZuB20rsv3LRv4nAkDy9G3A2QERMljQ5l+9CujHQH1MLEasC9+X1bpf0BdLlHf6uxnG2BJ6NiKfz/MXA0cD/1olN1L5KaaX8PuAkSYOB6yLimbqvdPG21ke5Gcp6oseAnUqsdxwwh/QB3EH6gCbSTZF2A54HLpV0WET8Na93N+mD+Ocl9r8gPy9iyS9eXX1I3577FkZExDYRcQSApJVIl9R+i3SZ6lrbLqvHSK958U6kdUhXMp0WEb8EPpeP+VtJnyyxzx1IF+izPsjJwnqi3wGrVbftS/qwpI93Wm9dYHaky2gfSm5qkbQZMDc391wA7JibiVaKiGuBb5Fux7o87iV1OqN0v4Ltc/n9wK6SPpiXrSGpUtM5jvQhfBCLazzVngSGVLbNr+WegjjuBNaQdFg+Xj/SPScuiog3JQ0DpkfE2aQLAW7f9a7eu/HRD4AfFxzXeiknC+txIl39cn9grzwk9DHSPaE7X+//Z8BoSfeTmqDeyOW7A5MkPQz8E3AW6S5kdyvdyewi0k1plsc5wFq5+ek/yJfnjoh5wJeAy/Oy+4GtcsI4Ejghd9DfS+rbqH69bwOHA1dLehR4l3RP6S5VnaMvSHqGdCXlt0mjxgC+CEzJr3cr4JIau9m8MnSWdD/rH1c6zK3v8VVnzcyskGsWZmZWyMnCzMwKOVmYmVkhJwszMyvkZGFmZoWcLMzMrJCThZmZFfp/04duEU3GcywAAAAASUVORK5CYII=","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["y_labelenc = LabelEncoder().fit_transform(Y)\n","\n","from collections import Counter\n","# summarize distribution\n","counter = Counter(y_labelenc)\n","\n","# sort counter by keys\n","counter = dict(sorted(counter.items()))\n","\n","\n","for k,v in counter.items():\n"," per = v / len(y_labelenc) * 100\n"," print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n","# plot the distribution\n","plt.bar( counter.keys(), counter.values())\n","\n","plt.ylabel('No of gene samples')\n","plt.xlabel('Class Index of OsID')\n","plt.title('Distribution of Target Classes (OsID)')\n","plt.show()"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":13,"status":"ok","timestamp":1682739630271,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"W1WdWupjmZ9l"},"outputs":[],"source":["# prepare target data\n","def prepare_targets(y_train, y_test):\n","\tle = LabelEncoder()\n","\t\n","\t#fit the encoders only to the training data and then transform both train and test data\n","\ty_train_enc = le.fit_transform(y_train)\n","\ty_test_enc = le.transform(y_test)\n","\n","\treturn y_train_enc, y_test_enc"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1682739630271,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"JjjBaPUOtmlx","outputId":"10ebe3b7-e849-4104-fd5e-871649020289"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_fs, Y, test_size=0.33, random_state=1)\n","\n","# prepare output data\n","y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"POiHy56emZ9m","outputId":"b45f4937-b684-42aa-ac0f-fbc0d3e6edb4"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of input features: 1\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 6s 2ms/step - loss: 4.7892 - accuracy: 0.0731 - val_loss: 4.4323 - val_accuracy: 0.1232\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 4.0705 - accuracy: 0.1398 - val_loss: 4.0038 - val_accuracy: 0.1701\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.6925 - accuracy: 0.1949 - val_loss: 3.7233 - val_accuracy: 0.2227\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.4051 - accuracy: 0.2292 - val_loss: 3.4574 - val_accuracy: 0.2642\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.1598 - accuracy: 0.2558 - val_loss: 3.2875 - val_accuracy: 0.2609\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.9618 - accuracy: 0.2816 - val_loss: 3.1333 - val_accuracy: 0.2660\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.7933 - accuracy: 0.3208 - val_loss: 2.9923 - val_accuracy: 0.3151\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.6555 - accuracy: 0.3553 - val_loss: 2.9149 - val_accuracy: 0.3641\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.5593 - accuracy: 0.3732 - val_loss: 2.8661 - val_accuracy: 0.2935\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.4775 - accuracy: 0.3820 - val_loss: 2.8321 - val_accuracy: 0.3646\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4198 - accuracy: 0.3949 - val_loss: 2.7170 - val_accuracy: 0.4084\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.3629 - accuracy: 0.4052 - val_loss: 2.6809 - val_accuracy: 0.3974\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.3245 - accuracy: 0.4067 - val_loss: 2.6615 - val_accuracy: 0.4070\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.2826 - accuracy: 0.4215 - val_loss: 2.6483 - val_accuracy: 0.4451\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2432 - accuracy: 0.4222 - val_loss: 2.6227 - val_accuracy: 0.3993\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2171 - accuracy: 0.4263 - val_loss: 2.5577 - val_accuracy: 0.4323\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.1954 - accuracy: 0.4258 - val_loss: 2.5304 - val_accuracy: 0.3949\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1723 - accuracy: 0.4349 - val_loss: 2.4770 - val_accuracy: 0.4004\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1424 - accuracy: 0.4402 - val_loss: 2.4851 - val_accuracy: 0.3650\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1409 - accuracy: 0.4345 - val_loss: 2.4251 - val_accuracy: 0.4273\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1096 - accuracy: 0.4396 - val_loss: 2.4368 - val_accuracy: 0.3886\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1037 - accuracy: 0.4434 - val_loss: 2.3715 - val_accuracy: 0.4092\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0750 - accuracy: 0.4519 - val_loss: 2.3786 - val_accuracy: 0.4552\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0707 - accuracy: 0.4532 - val_loss: 2.3825 - val_accuracy: 0.4418\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0586 - accuracy: 0.4495 - val_loss: 2.4574 - val_accuracy: 0.4035\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0542 - accuracy: 0.4507 - val_loss: 2.3714 - val_accuracy: 0.4561\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0258 - accuracy: 0.4545 - val_loss: 2.3872 - val_accuracy: 0.4328\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0314 - accuracy: 0.4487 - val_loss: 2.3431 - val_accuracy: 0.4202\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0175 - accuracy: 0.4507 - val_loss: 2.3395 - val_accuracy: 0.4590\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9954 - accuracy: 0.4570 - val_loss: 2.3102 - val_accuracy: 0.4774\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9954 - accuracy: 0.4618 - val_loss: 2.3162 - val_accuracy: 0.4334\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0023 - accuracy: 0.4562 - val_loss: 2.2848 - val_accuracy: 0.4508\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9736 - accuracy: 0.4648 - val_loss: 2.2761 - val_accuracy: 0.4491\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9739 - accuracy: 0.4652 - val_loss: 2.3040 - val_accuracy: 0.3879\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9657 - accuracy: 0.4640 - val_loss: 2.2468 - val_accuracy: 0.4517\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9583 - accuracy: 0.4668 - val_loss: 2.2902 - val_accuracy: 0.4480\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9594 - accuracy: 0.4613 - val_loss: 2.2336 - val_accuracy: 0.4614\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9428 - accuracy: 0.4672 - val_loss: 2.2460 - val_accuracy: 0.4862\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9469 - accuracy: 0.4701 - val_loss: 2.2046 - val_accuracy: 0.4895\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.9319 - accuracy: 0.4715 - val_loss: 2.2959 - val_accuracy: 0.3952\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9234 - accuracy: 0.4717 - val_loss: 2.2480 - val_accuracy: 0.4563\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9199 - accuracy: 0.4693 - val_loss: 2.1775 - val_accuracy: 0.4713\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9256 - accuracy: 0.4699 - val_loss: 2.1836 - val_accuracy: 0.5142\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9101 - accuracy: 0.4747 - val_loss: 2.1827 - val_accuracy: 0.4726\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8982 - accuracy: 0.4770 - val_loss: 2.1721 - val_accuracy: 0.4689\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8955 - accuracy: 0.4781 - val_loss: 2.2114 - val_accuracy: 0.4612\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8958 - accuracy: 0.4801 - val_loss: 2.1962 - val_accuracy: 0.4656\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8783 - accuracy: 0.4806 - val_loss: 2.1747 - val_accuracy: 0.4609\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8880 - accuracy: 0.4810 - val_loss: 2.2843 - val_accuracy: 0.3773\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8766 - accuracy: 0.4794 - val_loss: 2.1177 - val_accuracy: 0.5028\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8709 - accuracy: 0.4827 - val_loss: 2.2909 - val_accuracy: 0.4453\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8741 - accuracy: 0.4819 - val_loss: 2.1827 - val_accuracy: 0.4365\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8692 - accuracy: 0.4818 - val_loss: 2.1754 - val_accuracy: 0.4491\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8637 - accuracy: 0.4828 - val_loss: 2.3794 - val_accuracy: 0.4543\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8584 - accuracy: 0.4904 - val_loss: 2.1018 - val_accuracy: 0.5010\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8523 - accuracy: 0.4855 - val_loss: 2.1237 - val_accuracy: 0.4587\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8580 - accuracy: 0.4810 - val_loss: 2.2569 - val_accuracy: 0.4180\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.8468 - accuracy: 0.4839 - val_loss: 2.1191 - val_accuracy: 0.4374\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8381 - accuracy: 0.4921 - val_loss: 2.1289 - val_accuracy: 0.4561\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.8362 - accuracy: 0.4884 - val_loss: 2.2076 - val_accuracy: 0.4510\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.6413 - accuracy: 0.0836 - val_loss: 4.2646 - val_accuracy: 0.1182\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.9006 - accuracy: 0.1448 - val_loss: 3.9427 - val_accuracy: 0.1580\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.5993 - accuracy: 0.1962 - val_loss: 3.7155 - val_accuracy: 0.2301\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.3445 - accuracy: 0.2284 - val_loss: 3.5413 - val_accuracy: 0.2702\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.1235 - accuracy: 0.2518 - val_loss: 3.3699 - val_accuracy: 0.2902\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.9537 - accuracy: 0.2790 - val_loss: 3.2829 - val_accuracy: 0.3602\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.8150 - accuracy: 0.3030 - val_loss: 3.1971 - val_accuracy: 0.3270\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7063 - accuracy: 0.3223 - val_loss: 3.1348 - val_accuracy: 0.3223\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6205 - accuracy: 0.3535 - val_loss: 3.0403 - val_accuracy: 0.3234\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5431 - accuracy: 0.3664 - val_loss: 3.0386 - val_accuracy: 0.3883\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4858 - accuracy: 0.3788 - val_loss: 2.9460 - val_accuracy: 0.4183\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4347 - accuracy: 0.3914 - val_loss: 2.8912 - val_accuracy: 0.3899\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3903 - accuracy: 0.4002 - val_loss: 2.8536 - val_accuracy: 0.3738\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3525 - accuracy: 0.4075 - val_loss: 2.8658 - val_accuracy: 0.3872\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3306 - accuracy: 0.4103 - val_loss: 2.7882 - val_accuracy: 0.3897\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2942 - accuracy: 0.4171 - val_loss: 2.8086 - val_accuracy: 0.4345\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2697 - accuracy: 0.4235 - val_loss: 2.7762 - val_accuracy: 0.4178\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2392 - accuracy: 0.4282 - val_loss: 2.7314 - val_accuracy: 0.4037\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2194 - accuracy: 0.4307 - val_loss: 2.6661 - val_accuracy: 0.4704\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.2053 - accuracy: 0.4278 - val_loss: 2.6659 - val_accuracy: 0.4293\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1850 - accuracy: 0.4356 - val_loss: 2.6739 - val_accuracy: 0.4557\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1638 - accuracy: 0.4448 - val_loss: 2.6022 - val_accuracy: 0.4392\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1495 - accuracy: 0.4404 - val_loss: 2.6050 - val_accuracy: 0.4471\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1358 - accuracy: 0.4453 - val_loss: 2.6428 - val_accuracy: 0.4114\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1288 - accuracy: 0.4388 - val_loss: 2.5598 - val_accuracy: 0.4101\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1132 - accuracy: 0.4489 - val_loss: 2.5302 - val_accuracy: 0.4557\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1074 - accuracy: 0.4467 - val_loss: 2.5151 - val_accuracy: 0.4700\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0821 - accuracy: 0.4512 - val_loss: 2.5356 - val_accuracy: 0.4629\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0738 - accuracy: 0.4530 - val_loss: 2.5942 - val_accuracy: 0.4044\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0634 - accuracy: 0.4538 - val_loss: 2.5657 - val_accuracy: 0.4433\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0569 - accuracy: 0.4538 - val_loss: 2.4631 - val_accuracy: 0.4691\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0473 - accuracy: 0.4553 - val_loss: 2.5395 - val_accuracy: 0.4123\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0430 - accuracy: 0.4592 - val_loss: 2.4668 - val_accuracy: 0.4510\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0298 - accuracy: 0.4588 - val_loss: 2.4577 - val_accuracy: 0.4572\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0271 - accuracy: 0.4603 - val_loss: 2.4882 - val_accuracy: 0.4209\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0246 - accuracy: 0.4645 - val_loss: 2.5897 - val_accuracy: 0.4189\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0234 - accuracy: 0.4591 - val_loss: 2.4366 - val_accuracy: 0.4583\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.0050 - accuracy: 0.4614 - val_loss: 2.4633 - val_accuracy: 0.4064\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0023 - accuracy: 0.4641 - val_loss: 2.4089 - val_accuracy: 0.4471\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9908 - accuracy: 0.4683 - val_loss: 2.3849 - val_accuracy: 0.4453\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9816 - accuracy: 0.4630 - val_loss: 2.4292 - val_accuracy: 0.4427\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9770 - accuracy: 0.4611 - val_loss: 2.4199 - val_accuracy: 0.4515\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9913 - accuracy: 0.4630 - val_loss: 2.4446 - val_accuracy: 0.4612\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9694 - accuracy: 0.4659 - val_loss: 2.3563 - val_accuracy: 0.4669\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9756 - accuracy: 0.4653 - val_loss: 2.3555 - val_accuracy: 0.5019\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9658 - accuracy: 0.4633 - val_loss: 2.3780 - val_accuracy: 0.4781\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9575 - accuracy: 0.4674 - val_loss: 2.4419 - val_accuracy: 0.4645\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9510 - accuracy: 0.4720 - val_loss: 2.3719 - val_accuracy: 0.4392\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9535 - accuracy: 0.4740 - val_loss: 2.3424 - val_accuracy: 0.4570\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9447 - accuracy: 0.4776 - val_loss: 2.3108 - val_accuracy: 0.4746\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9366 - accuracy: 0.4765 - val_loss: 2.4216 - val_accuracy: 0.3954\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9484 - accuracy: 0.4735 - val_loss: 2.3393 - val_accuracy: 0.3947\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9316 - accuracy: 0.4695 - val_loss: 2.3343 - val_accuracy: 0.4477\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9265 - accuracy: 0.4797 - val_loss: 2.3533 - val_accuracy: 0.4634\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9329 - accuracy: 0.4746 - val_loss: 2.2829 - val_accuracy: 0.4851\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9149 - accuracy: 0.4813 - val_loss: 2.3581 - val_accuracy: 0.4825\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9262 - accuracy: 0.4730 - val_loss: 2.2745 - val_accuracy: 0.4779\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9119 - accuracy: 0.4796 - val_loss: 2.2849 - val_accuracy: 0.4301\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9012 - accuracy: 0.4771 - val_loss: 2.6053 - val_accuracy: 0.3309\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9085 - accuracy: 0.4769 - val_loss: 2.3692 - val_accuracy: 0.4812\n","Average Validation Accuracy: 0.4744587391614914\n","Average Validation Loss: 2.028918147087097\n","Average Test Accuracy: 0.47143805027008057\n","------------------------------------------------------------------------\n","\n","Number of input features: 2\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 4.3353 - accuracy: 0.1509 - val_loss: 3.6995 - val_accuracy: 0.3384\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0432 - accuracy: 0.3804 - val_loss: 2.8215 - val_accuracy: 0.4669\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2712 - accuracy: 0.5112 - val_loss: 2.2406 - val_accuracy: 0.5578\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.7902 - accuracy: 0.5852 - val_loss: 1.8844 - val_accuracy: 0.5930\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4824 - accuracy: 0.6334 - val_loss: 1.6487 - val_accuracy: 0.6372\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3086 - accuracy: 0.6610 - val_loss: 1.5117 - val_accuracy: 0.6543\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2061 - accuracy: 0.6823 - val_loss: 1.4093 - val_accuracy: 0.7162\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1242 - accuracy: 0.6925 - val_loss: 1.3651 - val_accuracy: 0.6752\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0757 - accuracy: 0.7053 - val_loss: 1.3539 - val_accuracy: 0.6898\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0290 - accuracy: 0.7154 - val_loss: 1.2558 - val_accuracy: 0.7124\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9859 - accuracy: 0.7266 - val_loss: 1.1880 - val_accuracy: 0.7353\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9670 - accuracy: 0.7237 - val_loss: 1.1895 - val_accuracy: 0.7206\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9297 - accuracy: 0.7368 - val_loss: 1.2285 - val_accuracy: 0.7034\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9133 - accuracy: 0.7360 - val_loss: 1.1256 - val_accuracy: 0.7485\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8870 - accuracy: 0.7480 - val_loss: 1.1349 - val_accuracy: 0.7228\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8886 - accuracy: 0.7432 - val_loss: 1.0615 - val_accuracy: 0.7589\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8494 - accuracy: 0.7553 - val_loss: 1.0730 - val_accuracy: 0.7534\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.8330 - accuracy: 0.7574 - val_loss: 1.0310 - val_accuracy: 0.7655\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8307 - accuracy: 0.7550 - val_loss: 0.9962 - val_accuracy: 0.7914\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8112 - accuracy: 0.7667 - val_loss: 1.0480 - val_accuracy: 0.7644\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7972 - accuracy: 0.7662 - val_loss: 1.0579 - val_accuracy: 0.7408\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7889 - accuracy: 0.7710 - val_loss: 0.9889 - val_accuracy: 0.7833\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7755 - accuracy: 0.7787 - val_loss: 0.9790 - val_accuracy: 0.7690\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7591 - accuracy: 0.7762 - val_loss: 1.0363 - val_accuracy: 0.7580\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7473 - accuracy: 0.7785 - val_loss: 1.0272 - val_accuracy: 0.7347\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7375 - accuracy: 0.7842 - val_loss: 0.9857 - val_accuracy: 0.7611\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7372 - accuracy: 0.7817 - val_loss: 0.9473 - val_accuracy: 0.7787\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7385 - accuracy: 0.7759 - val_loss: 0.9536 - val_accuracy: 0.7941\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7104 - accuracy: 0.7928 - val_loss: 0.9024 - val_accuracy: 0.8086\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7106 - accuracy: 0.7874 - val_loss: 0.9784 - val_accuracy: 0.7542\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6938 - accuracy: 0.7963 - val_loss: 1.0143 - val_accuracy: 0.7454\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6774 - accuracy: 0.7966 - val_loss: 1.0222 - val_accuracy: 0.7523\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6726 - accuracy: 0.7996 - val_loss: 0.9038 - val_accuracy: 0.7822\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6814 - accuracy: 0.7946 - val_loss: 0.9419 - val_accuracy: 0.7868\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6596 - accuracy: 0.8003 - val_loss: 0.8717 - val_accuracy: 0.8108\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6655 - accuracy: 0.8024 - val_loss: 0.8793 - val_accuracy: 0.8090\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6641 - accuracy: 0.8001 - val_loss: 0.8475 - val_accuracy: 0.8198\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6425 - accuracy: 0.8105 - val_loss: 0.8708 - val_accuracy: 0.8176\n","Epoch 39/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6450 - accuracy: 0.8061 - val_loss: 0.8446 - val_accuracy: 0.8301\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6423 - accuracy: 0.8101 - val_loss: 0.8276 - val_accuracy: 0.8229\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6226 - accuracy: 0.8178 - val_loss: 0.9082 - val_accuracy: 0.7945\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6307 - accuracy: 0.8124 - val_loss: 0.8710 - val_accuracy: 0.7756\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.6124 - accuracy: 0.8147 - val_loss: 0.8621 - val_accuracy: 0.8139\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6204 - accuracy: 0.8091 - val_loss: 0.8102 - val_accuracy: 0.8249\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6206 - accuracy: 0.8158 - val_loss: 0.8469 - val_accuracy: 0.8134\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6011 - accuracy: 0.8163 - val_loss: 0.8988 - val_accuracy: 0.8090\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6075 - accuracy: 0.8174 - val_loss: 0.8736 - val_accuracy: 0.8007\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5890 - accuracy: 0.8231 - val_loss: 0.8937 - val_accuracy: 0.7919\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6069 - accuracy: 0.8182 - val_loss: 0.8269 - val_accuracy: 0.8077\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5982 - accuracy: 0.8196 - val_loss: 0.8076 - val_accuracy: 0.8515\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5801 - accuracy: 0.8268 - val_loss: 0.7613 - val_accuracy: 0.8579\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5829 - accuracy: 0.8231 - val_loss: 0.8005 - val_accuracy: 0.8205\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6001 - accuracy: 0.8218 - val_loss: 0.8086 - val_accuracy: 0.8409\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5612 - accuracy: 0.8300 - val_loss: 0.8399 - val_accuracy: 0.8095\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5681 - accuracy: 0.8267 - val_loss: 0.8837 - val_accuracy: 0.7897\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5705 - accuracy: 0.8283 - val_loss: 0.7259 - val_accuracy: 0.8409\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5588 - accuracy: 0.8347 - val_loss: 0.7933 - val_accuracy: 0.8403\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5650 - accuracy: 0.8266 - val_loss: 0.8151 - val_accuracy: 0.8068\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5600 - accuracy: 0.8344 - val_loss: 0.7528 - val_accuracy: 0.8339\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.5591 - accuracy: 0.8344 - val_loss: 0.7424 - val_accuracy: 0.8526\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.5530 - accuracy: 0.1117 - val_loss: 3.9615 - val_accuracy: 0.2286\n","Epoch 2/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.3405 - accuracy: 0.3186 - val_loss: 3.1525 - val_accuracy: 0.3969\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5791 - accuracy: 0.4530 - val_loss: 2.6730 - val_accuracy: 0.4915\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0924 - accuracy: 0.5289 - val_loss: 2.3622 - val_accuracy: 0.5388\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.7757 - accuracy: 0.5809 - val_loss: 2.1535 - val_accuracy: 0.5879\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5742 - accuracy: 0.6085 - val_loss: 2.0119 - val_accuracy: 0.6090\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4481 - accuracy: 0.6296 - val_loss: 1.9598 - val_accuracy: 0.6319\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3566 - accuracy: 0.6485 - val_loss: 1.7783 - val_accuracy: 0.6726\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2868 - accuracy: 0.6632 - val_loss: 1.7132 - val_accuracy: 0.6801\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2254 - accuracy: 0.6744 - val_loss: 1.6964 - val_accuracy: 0.6704\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1712 - accuracy: 0.6862 - val_loss: 1.5876 - val_accuracy: 0.6790\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1365 - accuracy: 0.6931 - val_loss: 1.6634 - val_accuracy: 0.6614\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1067 - accuracy: 0.6973 - val_loss: 1.4907 - val_accuracy: 0.7107\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0780 - accuracy: 0.7117 - val_loss: 1.5062 - val_accuracy: 0.7052\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0458 - accuracy: 0.7149 - val_loss: 1.5445 - val_accuracy: 0.6539\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0223 - accuracy: 0.7179 - val_loss: 1.3928 - val_accuracy: 0.7391\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0100 - accuracy: 0.7167 - val_loss: 1.3641 - val_accuracy: 0.7410\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9748 - accuracy: 0.7270 - val_loss: 1.3291 - val_accuracy: 0.7474\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9710 - accuracy: 0.7294 - val_loss: 1.3774 - val_accuracy: 0.7208\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9499 - accuracy: 0.7365 - val_loss: 1.4502 - val_accuracy: 0.7164\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9390 - accuracy: 0.7378 - val_loss: 1.3741 - val_accuracy: 0.6928\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9295 - accuracy: 0.7365 - val_loss: 1.3078 - val_accuracy: 0.7311\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9076 - accuracy: 0.7459 - val_loss: 1.3164 - val_accuracy: 0.7657\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9089 - accuracy: 0.7444 - val_loss: 1.2634 - val_accuracy: 0.7498\n","Epoch 25/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8917 - accuracy: 0.7430 - val_loss: 1.2782 - val_accuracy: 0.7450\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8782 - accuracy: 0.7500 - val_loss: 1.3651 - val_accuracy: 0.6609\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8714 - accuracy: 0.7477 - val_loss: 1.2950 - val_accuracy: 0.7450\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8618 - accuracy: 0.7552 - val_loss: 1.4297 - val_accuracy: 0.6825\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8431 - accuracy: 0.7615 - val_loss: 1.2869 - val_accuracy: 0.7443\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8545 - accuracy: 0.7502 - val_loss: 1.1707 - val_accuracy: 0.7710\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8250 - accuracy: 0.7638 - val_loss: 1.2817 - val_accuracy: 0.7507\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8305 - accuracy: 0.7604 - val_loss: 1.1801 - val_accuracy: 0.7729\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8197 - accuracy: 0.7612 - val_loss: 1.1574 - val_accuracy: 0.7866\n","Epoch 34/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8073 - accuracy: 0.7668 - val_loss: 1.1831 - val_accuracy: 0.7718\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7995 - accuracy: 0.7672 - val_loss: 1.1956 - val_accuracy: 0.7602\n","Epoch 36/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8066 - accuracy: 0.7674 - val_loss: 1.2078 - val_accuracy: 0.7582\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7859 - accuracy: 0.7747 - val_loss: 1.1562 - val_accuracy: 0.7707\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7942 - accuracy: 0.7697 - val_loss: 1.1717 - val_accuracy: 0.7426\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7795 - accuracy: 0.7757 - val_loss: 1.1487 - val_accuracy: 0.7826\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7763 - accuracy: 0.7761 - val_loss: 1.1175 - val_accuracy: 0.7791\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7596 - accuracy: 0.7776 - val_loss: 1.1327 - val_accuracy: 0.7613\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7608 - accuracy: 0.7828 - val_loss: 1.2098 - val_accuracy: 0.7056\n","Epoch 43/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7565 - accuracy: 0.7789 - val_loss: 1.0935 - val_accuracy: 0.7831\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7570 - accuracy: 0.7792 - val_loss: 1.2151 - val_accuracy: 0.7050\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7361 - accuracy: 0.7830 - val_loss: 1.1165 - val_accuracy: 0.7894\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7495 - accuracy: 0.7838 - val_loss: 1.0891 - val_accuracy: 0.7681\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7137 - accuracy: 0.7903 - val_loss: 1.0588 - val_accuracy: 0.7923\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7345 - accuracy: 0.7864 - val_loss: 1.0661 - val_accuracy: 0.7855\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7332 - accuracy: 0.7832 - val_loss: 1.0580 - val_accuracy: 0.7740\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7237 - accuracy: 0.7884 - val_loss: 1.0437 - val_accuracy: 0.7890\n","Epoch 51/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7239 - accuracy: 0.7861 - val_loss: 1.0294 - val_accuracy: 0.8051\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7037 - accuracy: 0.7918 - val_loss: 1.0761 - val_accuracy: 0.8033\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6985 - accuracy: 0.7958 - val_loss: 1.0061 - val_accuracy: 0.8110\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6989 - accuracy: 0.7971 - val_loss: 1.3274 - val_accuracy: 0.7305\n","Epoch 55/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7139 - accuracy: 0.7927 - val_loss: 1.0828 - val_accuracy: 0.7910\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6894 - accuracy: 0.7993 - val_loss: 1.0472 - val_accuracy: 0.7769\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6973 - accuracy: 0.7967 - val_loss: 0.9816 - val_accuracy: 0.8220\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6690 - accuracy: 0.8032 - val_loss: 1.0657 - val_accuracy: 0.7839\n","Epoch 59/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7081 - accuracy: 0.7972 - val_loss: 1.0375 - val_accuracy: 0.7886\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6919 - accuracy: 0.7970 - val_loss: 1.0384 - val_accuracy: 0.8154\n","Average Validation Accuracy: 0.8413746058940887\n","Average Validation Loss: 0.6729016304016113\n","Average Test Accuracy: 0.835004061460495\n","------------------------------------------------------------------------\n","\n","Number of input features: 3\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.0483 - accuracy: 0.2201 - val_loss: 3.2279 - val_accuracy: 0.4011\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4969 - accuracy: 0.5088 - val_loss: 2.2926 - val_accuracy: 0.5932\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7369 - accuracy: 0.6312 - val_loss: 1.7302 - val_accuracy: 0.6777\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2661 - accuracy: 0.7089 - val_loss: 1.4600 - val_accuracy: 0.7179\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0047 - accuracy: 0.7493 - val_loss: 1.2623 - val_accuracy: 0.7740\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8507 - accuracy: 0.7781 - val_loss: 1.1899 - val_accuracy: 0.7765\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7569 - accuracy: 0.7967 - val_loss: 1.0534 - val_accuracy: 0.7932\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7100 - accuracy: 0.8074 - val_loss: 0.9927 - val_accuracy: 0.8042\n","Epoch 9/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6351 - accuracy: 0.8239 - val_loss: 0.9439 - val_accuracy: 0.8132\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6116 - accuracy: 0.8300 - val_loss: 0.8708 - val_accuracy: 0.8286\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5778 - accuracy: 0.8421 - val_loss: 0.8239 - val_accuracy: 0.8411\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5485 - accuracy: 0.8447 - val_loss: 0.8500 - val_accuracy: 0.8220\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5259 - accuracy: 0.8512 - val_loss: 0.7790 - val_accuracy: 0.8469\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5201 - accuracy: 0.8519 - val_loss: 0.8053 - val_accuracy: 0.8304\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4856 - accuracy: 0.8625 - val_loss: 0.8471 - val_accuracy: 0.8180\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4829 - accuracy: 0.8649 - val_loss: 0.7445 - val_accuracy: 0.8326\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4601 - accuracy: 0.8688 - val_loss: 0.7420 - val_accuracy: 0.8603\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4566 - accuracy: 0.8726 - val_loss: 0.6938 - val_accuracy: 0.8526\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4363 - accuracy: 0.8724 - val_loss: 0.7632 - val_accuracy: 0.8651\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4347 - accuracy: 0.8773 - val_loss: 0.6714 - val_accuracy: 0.8770\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4195 - accuracy: 0.8810 - val_loss: 0.6654 - val_accuracy: 0.8761\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4077 - accuracy: 0.8873 - val_loss: 0.6500 - val_accuracy: 0.8814\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3963 - accuracy: 0.8912 - val_loss: 0.7398 - val_accuracy: 0.8627\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3993 - accuracy: 0.8867 - val_loss: 0.5960 - val_accuracy: 0.8937\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3892 - accuracy: 0.8919 - val_loss: 0.6016 - val_accuracy: 0.8909\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3759 - accuracy: 0.8912 - val_loss: 0.6828 - val_accuracy: 0.8766\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3788 - accuracy: 0.8961 - val_loss: 0.6171 - val_accuracy: 0.8801\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3596 - accuracy: 0.9019 - val_loss: 0.6889 - val_accuracy: 0.8541\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3715 - accuracy: 0.8977 - val_loss: 0.5879 - val_accuracy: 0.8948\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3527 - accuracy: 0.9010 - val_loss: 0.6346 - val_accuracy: 0.8895\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3486 - accuracy: 0.9016 - val_loss: 0.5732 - val_accuracy: 0.8911\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3468 - accuracy: 0.9039 - val_loss: 0.5619 - val_accuracy: 0.8913\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3328 - accuracy: 0.9092 - val_loss: 0.5354 - val_accuracy: 0.9052\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3319 - accuracy: 0.9091 - val_loss: 0.5496 - val_accuracy: 0.8994\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3290 - accuracy: 0.9084 - val_loss: 0.5592 - val_accuracy: 0.8847\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3283 - accuracy: 0.9047 - val_loss: 0.5485 - val_accuracy: 0.8972\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3211 - accuracy: 0.9116 - val_loss: 0.5342 - val_accuracy: 0.9160\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3140 - accuracy: 0.9148 - val_loss: 0.5361 - val_accuracy: 0.8922\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3166 - accuracy: 0.9109 - val_loss: 0.5276 - val_accuracy: 0.8986\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3042 - accuracy: 0.9132 - val_loss: 0.5069 - val_accuracy: 0.9131\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3107 - accuracy: 0.9163 - val_loss: 0.5202 - val_accuracy: 0.9124\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3046 - accuracy: 0.9146 - val_loss: 0.5084 - val_accuracy: 0.9201\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3024 - accuracy: 0.9179 - val_loss: 0.4786 - val_accuracy: 0.9164\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3018 - accuracy: 0.9203 - val_loss: 0.4984 - val_accuracy: 0.9102\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2945 - accuracy: 0.9200 - val_loss: 0.4970 - val_accuracy: 0.9153\n","Epoch 46/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2939 - accuracy: 0.9203 - val_loss: 0.4833 - val_accuracy: 0.9105\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2862 - accuracy: 0.9207 - val_loss: 0.5090 - val_accuracy: 0.9122\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2832 - accuracy: 0.9219 - val_loss: 0.4949 - val_accuracy: 0.9124\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2831 - accuracy: 0.9234 - val_loss: 0.5533 - val_accuracy: 0.9028\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2820 - accuracy: 0.9246 - val_loss: 0.4988 - val_accuracy: 0.9089\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2864 - accuracy: 0.9189 - val_loss: 0.5393 - val_accuracy: 0.9127\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2693 - accuracy: 0.9262 - val_loss: 0.4595 - val_accuracy: 0.9316\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2727 - accuracy: 0.9247 - val_loss: 0.4578 - val_accuracy: 0.9270\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2805 - accuracy: 0.9210 - val_loss: 0.5149 - val_accuracy: 0.9087\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2680 - accuracy: 0.9276 - val_loss: 0.5021 - val_accuracy: 0.9023\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2743 - accuracy: 0.9261 - val_loss: 0.4484 - val_accuracy: 0.9316\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2686 - accuracy: 0.9240 - val_loss: 0.4756 - val_accuracy: 0.9171\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2751 - accuracy: 0.9256 - val_loss: 0.4403 - val_accuracy: 0.9287\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2605 - accuracy: 0.9279 - val_loss: 0.4830 - val_accuracy: 0.9135\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2642 - accuracy: 0.9279 - val_loss: 0.4216 - val_accuracy: 0.9298\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.1624 - accuracy: 0.1726 - val_loss: 3.3920 - val_accuracy: 0.3578\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.6541 - accuracy: 0.4673 - val_loss: 2.4386 - val_accuracy: 0.5193\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7889 - accuracy: 0.6329 - val_loss: 1.8685 - val_accuracy: 0.6684\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3008 - accuracy: 0.7203 - val_loss: 1.5625 - val_accuracy: 0.7248\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0372 - accuracy: 0.7610 - val_loss: 1.3879 - val_accuracy: 0.7512\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8889 - accuracy: 0.7856 - val_loss: 1.2464 - val_accuracy: 0.7817\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7895 - accuracy: 0.7982 - val_loss: 1.1491 - val_accuracy: 0.7877\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7177 - accuracy: 0.8174 - val_loss: 1.0475 - val_accuracy: 0.8165\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6592 - accuracy: 0.8253 - val_loss: 1.0390 - val_accuracy: 0.8108\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6167 - accuracy: 0.8374 - val_loss: 0.9476 - val_accuracy: 0.8132\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5863 - accuracy: 0.8408 - val_loss: 0.9012 - val_accuracy: 0.8359\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5661 - accuracy: 0.8479 - val_loss: 0.8704 - val_accuracy: 0.8561\n","Epoch 13/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5294 - accuracy: 0.8563 - val_loss: 0.8908 - val_accuracy: 0.8484\n","Epoch 14/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5128 - accuracy: 0.8584 - val_loss: 0.7814 - val_accuracy: 0.8653\n","Epoch 15/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4943 - accuracy: 0.8646 - val_loss: 1.0239 - val_accuracy: 0.8185\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4860 - accuracy: 0.8649 - val_loss: 0.8094 - val_accuracy: 0.8458\n","Epoch 17/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4732 - accuracy: 0.8707 - val_loss: 0.7812 - val_accuracy: 0.8598\n","Epoch 18/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4572 - accuracy: 0.8740 - val_loss: 0.7670 - val_accuracy: 0.8605\n","Epoch 19/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4436 - accuracy: 0.8754 - val_loss: 0.7355 - val_accuracy: 0.8807\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4367 - accuracy: 0.8802 - val_loss: 0.7557 - val_accuracy: 0.8574\n","Epoch 21/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4239 - accuracy: 0.8828 - val_loss: 0.7510 - val_accuracy: 0.8662\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4188 - accuracy: 0.8844 - val_loss: 0.7766 - val_accuracy: 0.8620\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4058 - accuracy: 0.8870 - val_loss: 0.7086 - val_accuracy: 0.8737\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4188 - accuracy: 0.8835 - val_loss: 0.6677 - val_accuracy: 0.8928\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3865 - accuracy: 0.8934 - val_loss: 0.6593 - val_accuracy: 0.8920\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3893 - accuracy: 0.8921 - val_loss: 0.6941 - val_accuracy: 0.8834\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3845 - accuracy: 0.8911 - val_loss: 0.6827 - val_accuracy: 0.8810\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3671 - accuracy: 0.8986 - val_loss: 0.6447 - val_accuracy: 0.8836\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3858 - accuracy: 0.8938 - val_loss: 0.6726 - val_accuracy: 0.8805\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3714 - accuracy: 0.8966 - val_loss: 0.6716 - val_accuracy: 0.8805\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3711 - accuracy: 0.8937 - val_loss: 0.6446 - val_accuracy: 0.8933\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3588 - accuracy: 0.8993 - val_loss: 0.6291 - val_accuracy: 0.8878\n","Epoch 33/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3476 - accuracy: 0.9000 - val_loss: 0.6488 - val_accuracy: 0.8909\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3527 - accuracy: 0.9007 - val_loss: 0.6787 - val_accuracy: 0.8873\n","Epoch 35/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3482 - accuracy: 0.9047 - val_loss: 0.6534 - val_accuracy: 0.8920\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3434 - accuracy: 0.9043 - val_loss: 0.6852 - val_accuracy: 0.8697\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3434 - accuracy: 0.9038 - val_loss: 0.6415 - val_accuracy: 0.8827\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3349 - accuracy: 0.9060 - val_loss: 0.6256 - val_accuracy: 0.9006\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3364 - accuracy: 0.9076 - val_loss: 0.6306 - val_accuracy: 0.8796\n","Epoch 40/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3327 - accuracy: 0.9060 - val_loss: 0.6314 - val_accuracy: 0.8884\n","Epoch 41/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3374 - accuracy: 0.9076 - val_loss: 0.6504 - val_accuracy: 0.8854\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3212 - accuracy: 0.9123 - val_loss: 0.7423 - val_accuracy: 0.8495\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3168 - accuracy: 0.9124 - val_loss: 0.5924 - val_accuracy: 0.8598\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3162 - accuracy: 0.9113 - val_loss: 0.5577 - val_accuracy: 0.9003\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3260 - accuracy: 0.9106 - val_loss: 0.5562 - val_accuracy: 0.9021\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3031 - accuracy: 0.9164 - val_loss: 0.6002 - val_accuracy: 0.8777\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3258 - accuracy: 0.9097 - val_loss: 0.6547 - val_accuracy: 0.8796\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2982 - accuracy: 0.9190 - val_loss: 0.5240 - val_accuracy: 0.9109\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3076 - accuracy: 0.9147 - val_loss: 0.6082 - val_accuracy: 0.8878\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3025 - accuracy: 0.9150 - val_loss: 0.5391 - val_accuracy: 0.9080\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2971 - accuracy: 0.9173 - val_loss: 0.6213 - val_accuracy: 0.8909\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2993 - accuracy: 0.9158 - val_loss: 0.5308 - val_accuracy: 0.9052\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2908 - accuracy: 0.9163 - val_loss: 0.5504 - val_accuracy: 0.8988\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3002 - accuracy: 0.9149 - val_loss: 0.5615 - val_accuracy: 0.8869\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2892 - accuracy: 0.9180 - val_loss: 0.5079 - val_accuracy: 0.9173\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2898 - accuracy: 0.9192 - val_loss: 0.5024 - val_accuracy: 0.9124\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2902 - accuracy: 0.9180 - val_loss: 0.5516 - val_accuracy: 0.9017\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2940 - accuracy: 0.9176 - val_loss: 0.5413 - val_accuracy: 0.8997\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2805 - accuracy: 0.9227 - val_loss: 0.5268 - val_accuracy: 0.9076\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2818 - accuracy: 0.9212 - val_loss: 0.5052 - val_accuracy: 0.9094\n","Average Validation Accuracy: 0.9317066669464111\n","Average Validation Loss: 0.3067966401576996\n","Average Test Accuracy: 0.9281712770462036\n","------------------------------------------------------------------------\n","\n","Number of input features: 4\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.1724 - accuracy: 0.1915 - val_loss: 3.3419 - val_accuracy: 0.3604\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4905 - accuracy: 0.5331 - val_loss: 2.1242 - val_accuracy: 0.6222\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5122 - accuracy: 0.6826 - val_loss: 1.4859 - val_accuracy: 0.7179\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0011 - accuracy: 0.7677 - val_loss: 1.1580 - val_accuracy: 0.7833\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7502 - accuracy: 0.8180 - val_loss: 0.9594 - val_accuracy: 0.8306\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6147 - accuracy: 0.8447 - val_loss: 0.8809 - val_accuracy: 0.8431\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5388 - accuracy: 0.8555 - val_loss: 0.7743 - val_accuracy: 0.8623\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4819 - accuracy: 0.8694 - val_loss: 0.7412 - val_accuracy: 0.8574\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4392 - accuracy: 0.8761 - val_loss: 0.7308 - val_accuracy: 0.8524\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4107 - accuracy: 0.8848 - val_loss: 0.7014 - val_accuracy: 0.8524\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3907 - accuracy: 0.8880 - val_loss: 0.6578 - val_accuracy: 0.8814\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3721 - accuracy: 0.8958 - val_loss: 0.6326 - val_accuracy: 0.8801\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3475 - accuracy: 0.9008 - val_loss: 0.5978 - val_accuracy: 0.8843\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3401 - accuracy: 0.9030 - val_loss: 0.5721 - val_accuracy: 0.9006\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3171 - accuracy: 0.9110 - val_loss: 0.5768 - val_accuracy: 0.8986\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3031 - accuracy: 0.9177 - val_loss: 0.5730 - val_accuracy: 0.8935\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3032 - accuracy: 0.9176 - val_loss: 0.5384 - val_accuracy: 0.9127\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2834 - accuracy: 0.9250 - val_loss: 0.5082 - val_accuracy: 0.9237\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2832 - accuracy: 0.9211 - val_loss: 0.4999 - val_accuracy: 0.9168\n","Epoch 20/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2677 - accuracy: 0.9277 - val_loss: 0.4834 - val_accuracy: 0.9322\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2670 - accuracy: 0.9289 - val_loss: 0.4864 - val_accuracy: 0.9296\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2581 - accuracy: 0.9295 - val_loss: 0.5104 - val_accuracy: 0.9168\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2599 - accuracy: 0.9291 - val_loss: 0.4813 - val_accuracy: 0.9289\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2554 - accuracy: 0.9297 - val_loss: 0.4523 - val_accuracy: 0.9402\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2424 - accuracy: 0.9327 - val_loss: 0.4655 - val_accuracy: 0.9184\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2406 - accuracy: 0.9328 - val_loss: 0.4396 - val_accuracy: 0.9364\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2407 - accuracy: 0.9332 - val_loss: 0.4634 - val_accuracy: 0.9259\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2390 - accuracy: 0.9337 - val_loss: 0.4426 - val_accuracy: 0.9177\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2221 - accuracy: 0.9408 - val_loss: 0.4750 - val_accuracy: 0.9157\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2266 - accuracy: 0.9365 - val_loss: 0.4258 - val_accuracy: 0.9263\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2245 - accuracy: 0.9370 - val_loss: 0.4898 - val_accuracy: 0.9281\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2123 - accuracy: 0.9419 - val_loss: 0.4295 - val_accuracy: 0.9245\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2136 - accuracy: 0.9417 - val_loss: 0.4324 - val_accuracy: 0.9329\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2156 - accuracy: 0.9416 - val_loss: 0.4124 - val_accuracy: 0.9384\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2192 - accuracy: 0.9387 - val_loss: 0.4058 - val_accuracy: 0.9338\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1982 - accuracy: 0.9475 - val_loss: 0.4855 - val_accuracy: 0.9122\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2085 - accuracy: 0.9421 - val_loss: 0.4804 - val_accuracy: 0.9221\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1985 - accuracy: 0.9442 - val_loss: 0.4029 - val_accuracy: 0.9404\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2015 - accuracy: 0.9454 - val_loss: 0.4039 - val_accuracy: 0.9424\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1961 - accuracy: 0.9462 - val_loss: 0.3811 - val_accuracy: 0.9415\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2003 - accuracy: 0.9442 - val_loss: 0.4014 - val_accuracy: 0.9223\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1974 - accuracy: 0.9454 - val_loss: 0.4229 - val_accuracy: 0.9369\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1924 - accuracy: 0.9453 - val_loss: 0.3636 - val_accuracy: 0.9408\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1874 - accuracy: 0.9507 - val_loss: 0.3745 - val_accuracy: 0.9457\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1876 - accuracy: 0.9510 - val_loss: 0.3665 - val_accuracy: 0.9487\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1805 - accuracy: 0.9525 - val_loss: 0.3876 - val_accuracy: 0.9408\n","Epoch 47/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1795 - accuracy: 0.9514 - val_loss: 0.3479 - val_accuracy: 0.9516\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1796 - accuracy: 0.9495 - val_loss: 0.4276 - val_accuracy: 0.9292\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1804 - accuracy: 0.9522 - val_loss: 0.3585 - val_accuracy: 0.9490\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1740 - accuracy: 0.9524 - val_loss: 0.3432 - val_accuracy: 0.9586\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1764 - accuracy: 0.9526 - val_loss: 0.3635 - val_accuracy: 0.9430\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1635 - accuracy: 0.9560 - val_loss: 0.3452 - val_accuracy: 0.9494\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1789 - accuracy: 0.9523 - val_loss: 0.3602 - val_accuracy: 0.9404\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1689 - accuracy: 0.9540 - val_loss: 0.3368 - val_accuracy: 0.9503\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1660 - accuracy: 0.9549 - val_loss: 0.3544 - val_accuracy: 0.9377\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1741 - accuracy: 0.9534 - val_loss: 0.3323 - val_accuracy: 0.9523\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1645 - accuracy: 0.9553 - val_loss: 0.3505 - val_accuracy: 0.9355\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1599 - accuracy: 0.9586 - val_loss: 0.3524 - val_accuracy: 0.9287\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1624 - accuracy: 0.9545 - val_loss: 0.3195 - val_accuracy: 0.9512\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1627 - accuracy: 0.9552 - val_loss: 0.3098 - val_accuracy: 0.9542\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 7s 3ms/step - loss: 4.0224 - accuracy: 0.2329 - val_loss: 3.0128 - val_accuracy: 0.4394\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1332 - accuracy: 0.5855 - val_loss: 1.9908 - val_accuracy: 0.6728\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3059 - accuracy: 0.7242 - val_loss: 1.5480 - val_accuracy: 0.7523\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9087 - accuracy: 0.7984 - val_loss: 1.2260 - val_accuracy: 0.7886\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7161 - accuracy: 0.8302 - val_loss: 1.0403 - val_accuracy: 0.8381\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5932 - accuracy: 0.8508 - val_loss: 0.9158 - val_accuracy: 0.8636\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5236 - accuracy: 0.8662 - val_loss: 0.8708 - val_accuracy: 0.8768\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4775 - accuracy: 0.8800 - val_loss: 0.7927 - val_accuracy: 0.8658\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4319 - accuracy: 0.8887 - val_loss: 0.7435 - val_accuracy: 0.8785\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4094 - accuracy: 0.8917 - val_loss: 0.6912 - val_accuracy: 0.8730\n","Epoch 11/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3786 - accuracy: 0.8982 - val_loss: 0.6738 - val_accuracy: 0.8836\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3565 - accuracy: 0.9039 - val_loss: 0.6335 - val_accuracy: 0.9001\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3482 - accuracy: 0.9054 - val_loss: 0.5998 - val_accuracy: 0.9034\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3263 - accuracy: 0.9123 - val_loss: 0.5980 - val_accuracy: 0.9074\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3164 - accuracy: 0.9136 - val_loss: 0.5697 - val_accuracy: 0.9102\n","Epoch 16/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3110 - accuracy: 0.9147 - val_loss: 0.6023 - val_accuracy: 0.9056\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2954 - accuracy: 0.9180 - val_loss: 0.5799 - val_accuracy: 0.8950\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2881 - accuracy: 0.9189 - val_loss: 0.5893 - val_accuracy: 0.8981\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2838 - accuracy: 0.9219 - val_loss: 0.5806 - val_accuracy: 0.8983\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2700 - accuracy: 0.9266 - val_loss: 0.5319 - val_accuracy: 0.9184\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2659 - accuracy: 0.9273 - val_loss: 0.4874 - val_accuracy: 0.9300\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2566 - accuracy: 0.9287 - val_loss: 0.5119 - val_accuracy: 0.9151\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2397 - accuracy: 0.9348 - val_loss: 0.5238 - val_accuracy: 0.9243\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2448 - accuracy: 0.9332 - val_loss: 0.4687 - val_accuracy: 0.9351\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2412 - accuracy: 0.9353 - val_loss: 0.4558 - val_accuracy: 0.9366\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2405 - accuracy: 0.9340 - val_loss: 0.5315 - val_accuracy: 0.9100\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2306 - accuracy: 0.9370 - val_loss: 0.4644 - val_accuracy: 0.9325\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2231 - accuracy: 0.9410 - val_loss: 0.4759 - val_accuracy: 0.9316\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2258 - accuracy: 0.9389 - val_loss: 0.4173 - val_accuracy: 0.9342\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2140 - accuracy: 0.9418 - val_loss: 0.4240 - val_accuracy: 0.9386\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2187 - accuracy: 0.9396 - val_loss: 0.4264 - val_accuracy: 0.9413\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2069 - accuracy: 0.9468 - val_loss: 0.4420 - val_accuracy: 0.9417\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2103 - accuracy: 0.9435 - val_loss: 0.4217 - val_accuracy: 0.9351\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1951 - accuracy: 0.9495 - val_loss: 0.3972 - val_accuracy: 0.9430\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2020 - accuracy: 0.9467 - val_loss: 0.4546 - val_accuracy: 0.9391\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1985 - accuracy: 0.9475 - val_loss: 0.3999 - val_accuracy: 0.9430\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1923 - accuracy: 0.9494 - val_loss: 0.4172 - val_accuracy: 0.9351\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1897 - accuracy: 0.9503 - val_loss: 0.3814 - val_accuracy: 0.9483\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1899 - accuracy: 0.9498 - val_loss: 0.3903 - val_accuracy: 0.9391\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1848 - accuracy: 0.9510 - val_loss: 0.4216 - val_accuracy: 0.9402\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1908 - accuracy: 0.9505 - val_loss: 0.3743 - val_accuracy: 0.9514\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1871 - accuracy: 0.9499 - val_loss: 0.3914 - val_accuracy: 0.9406\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1789 - accuracy: 0.9533 - val_loss: 0.3827 - val_accuracy: 0.9529\n","Epoch 44/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1807 - accuracy: 0.9532 - val_loss: 0.4231 - val_accuracy: 0.9406\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1814 - accuracy: 0.9526 - val_loss: 0.3850 - val_accuracy: 0.9560\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1746 - accuracy: 0.9546 - val_loss: 0.3896 - val_accuracy: 0.9364\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1806 - accuracy: 0.9501 - val_loss: 0.3611 - val_accuracy: 0.9509\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1639 - accuracy: 0.9577 - val_loss: 0.3857 - val_accuracy: 0.9388\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1735 - accuracy: 0.9548 - val_loss: 0.3594 - val_accuracy: 0.9512\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1748 - accuracy: 0.9549 - val_loss: 0.3920 - val_accuracy: 0.9364\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1598 - accuracy: 0.9588 - val_loss: 0.3708 - val_accuracy: 0.9417\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1559 - accuracy: 0.9597 - val_loss: 0.3646 - val_accuracy: 0.9538\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1690 - accuracy: 0.9544 - val_loss: 0.3812 - val_accuracy: 0.9542\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1609 - accuracy: 0.9584 - val_loss: 0.3558 - val_accuracy: 0.9520\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1609 - accuracy: 0.9590 - val_loss: 0.3512 - val_accuracy: 0.9582\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1545 - accuracy: 0.9589 - val_loss: 0.3432 - val_accuracy: 0.9562\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1649 - accuracy: 0.9556 - val_loss: 0.3415 - val_accuracy: 0.9547\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1545 - accuracy: 0.9614 - val_loss: 0.3512 - val_accuracy: 0.9538\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1588 - accuracy: 0.9600 - val_loss: 0.4071 - val_accuracy: 0.9380\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1528 - accuracy: 0.9616 - val_loss: 0.4768 - val_accuracy: 0.9186\n","Average Validation Accuracy: 0.9401655793190002\n","Average Validation Loss: 0.26075898110866547\n","Average Test Accuracy: 0.9415493607521057\n","------------------------------------------------------------------------\n","\n","Number of input features: 5\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.9465 - accuracy: 0.2543 - val_loss: 2.8262 - val_accuracy: 0.4774\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.8888 - accuracy: 0.6611 - val_loss: 1.5996 - val_accuracy: 0.7391\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0404 - accuracy: 0.8003 - val_loss: 1.1030 - val_accuracy: 0.7949\n","Epoch 4/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6818 - accuracy: 0.8531 - val_loss: 0.8810 - val_accuracy: 0.8429\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5338 - accuracy: 0.8763 - val_loss: 0.7193 - val_accuracy: 0.8845\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4445 - accuracy: 0.8916 - val_loss: 0.6232 - val_accuracy: 0.8924\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3933 - accuracy: 0.8978 - val_loss: 0.6402 - val_accuracy: 0.8799\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3529 - accuracy: 0.9077 - val_loss: 0.5784 - val_accuracy: 0.8957\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3149 - accuracy: 0.9150 - val_loss: 0.5376 - val_accuracy: 0.8986\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2986 - accuracy: 0.9212 - val_loss: 0.5791 - val_accuracy: 0.8783\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2797 - accuracy: 0.9255 - val_loss: 0.4522 - val_accuracy: 0.9168\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2690 - accuracy: 0.9285 - val_loss: 0.4317 - val_accuracy: 0.9294\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2500 - accuracy: 0.9346 - val_loss: 0.4076 - val_accuracy: 0.9307\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2467 - accuracy: 0.9359 - val_loss: 0.4204 - val_accuracy: 0.9234\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2336 - accuracy: 0.9397 - val_loss: 0.3910 - val_accuracy: 0.9327\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2237 - accuracy: 0.9416 - val_loss: 0.4058 - val_accuracy: 0.9316\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2164 - accuracy: 0.9429 - val_loss: 0.3664 - val_accuracy: 0.9483\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2140 - accuracy: 0.9446 - val_loss: 0.3913 - val_accuracy: 0.9355\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2078 - accuracy: 0.9479 - val_loss: 0.3596 - val_accuracy: 0.9329\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2074 - accuracy: 0.9471 - val_loss: 0.4060 - val_accuracy: 0.9250\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1959 - accuracy: 0.9508 - val_loss: 0.3560 - val_accuracy: 0.9558\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1950 - accuracy: 0.9499 - val_loss: 0.3374 - val_accuracy: 0.9564\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1916 - accuracy: 0.9510 - val_loss: 0.3667 - val_accuracy: 0.9505\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1822 - accuracy: 0.9540 - val_loss: 0.3379 - val_accuracy: 0.9575\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1848 - accuracy: 0.9548 - val_loss: 0.3353 - val_accuracy: 0.9584\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1757 - accuracy: 0.9570 - val_loss: 0.3611 - val_accuracy: 0.9443\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1840 - accuracy: 0.9531 - val_loss: 0.3179 - val_accuracy: 0.9507\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1741 - accuracy: 0.9569 - val_loss: 0.2994 - val_accuracy: 0.9663\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1688 - accuracy: 0.9581 - val_loss: 0.3119 - val_accuracy: 0.9641\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1706 - accuracy: 0.9571 - val_loss: 0.3170 - val_accuracy: 0.9545\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1583 - accuracy: 0.9607 - val_loss: 0.3069 - val_accuracy: 0.9608\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1663 - accuracy: 0.9563 - val_loss: 0.3124 - val_accuracy: 0.9556\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1532 - accuracy: 0.9625 - val_loss: 0.3063 - val_accuracy: 0.9602\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1634 - accuracy: 0.9575 - val_loss: 0.3048 - val_accuracy: 0.9564\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1657 - accuracy: 0.9558 - val_loss: 0.3097 - val_accuracy: 0.9646\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1496 - accuracy: 0.9652 - val_loss: 0.3149 - val_accuracy: 0.9463\n","Epoch 37/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1508 - accuracy: 0.9611 - val_loss: 0.3708 - val_accuracy: 0.9413\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1509 - accuracy: 0.9625 - val_loss: 0.3152 - val_accuracy: 0.9514\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1455 - accuracy: 0.9664 - val_loss: 0.2952 - val_accuracy: 0.9593\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1430 - accuracy: 0.9631 - val_loss: 0.2820 - val_accuracy: 0.9604\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1438 - accuracy: 0.9647 - val_loss: 0.3014 - val_accuracy: 0.9492\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1442 - accuracy: 0.9636 - val_loss: 0.3052 - val_accuracy: 0.9593\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1395 - accuracy: 0.9652 - val_loss: 0.3153 - val_accuracy: 0.9498\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1443 - accuracy: 0.9621 - val_loss: 0.2878 - val_accuracy: 0.9644\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1444 - accuracy: 0.9623 - val_loss: 0.2957 - val_accuracy: 0.9650\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1298 - accuracy: 0.9679 - val_loss: 0.2703 - val_accuracy: 0.9767\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1422 - accuracy: 0.9640 - val_loss: 0.2859 - val_accuracy: 0.9652\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1355 - accuracy: 0.9649 - val_loss: 0.3156 - val_accuracy: 0.9454\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1383 - accuracy: 0.9648 - val_loss: 0.3028 - val_accuracy: 0.9564\n","Epoch 50/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1330 - accuracy: 0.9666 - val_loss: 0.2994 - val_accuracy: 0.9591\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1305 - accuracy: 0.9668 - val_loss: 0.2771 - val_accuracy: 0.9701\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1273 - accuracy: 0.9692 - val_loss: 0.2684 - val_accuracy: 0.9747\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1295 - accuracy: 0.9684 - val_loss: 0.3194 - val_accuracy: 0.9391\n","Epoch 54/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1299 - accuracy: 0.9669 - val_loss: 0.3002 - val_accuracy: 0.9509\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1260 - accuracy: 0.9675 - val_loss: 0.3073 - val_accuracy: 0.9538\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1251 - accuracy: 0.9700 - val_loss: 0.2820 - val_accuracy: 0.9657\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1238 - accuracy: 0.9691 - val_loss: 0.2813 - val_accuracy: 0.9690\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1212 - accuracy: 0.9703 - val_loss: 0.2852 - val_accuracy: 0.9659\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1275 - accuracy: 0.9685 - val_loss: 0.2648 - val_accuracy: 0.9729\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1240 - accuracy: 0.9685 - val_loss: 0.2675 - val_accuracy: 0.9615\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.8924 - accuracy: 0.2660 - val_loss: 2.8830 - val_accuracy: 0.4865\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.9335 - accuracy: 0.6526 - val_loss: 1.8324 - val_accuracy: 0.7232\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1188 - accuracy: 0.7865 - val_loss: 1.3657 - val_accuracy: 0.7883\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7546 - accuracy: 0.8409 - val_loss: 1.1000 - val_accuracy: 0.8268\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5767 - accuracy: 0.8652 - val_loss: 0.8962 - val_accuracy: 0.8526\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4756 - accuracy: 0.8831 - val_loss: 0.8250 - val_accuracy: 0.8601\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4173 - accuracy: 0.8921 - val_loss: 0.7294 - val_accuracy: 0.8748\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3685 - accuracy: 0.9028 - val_loss: 0.6608 - val_accuracy: 0.8917\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3418 - accuracy: 0.9099 - val_loss: 0.5841 - val_accuracy: 0.9109\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3120 - accuracy: 0.9151 - val_loss: 0.5433 - val_accuracy: 0.9050\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2897 - accuracy: 0.9240 - val_loss: 0.5443 - val_accuracy: 0.9155\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2795 - accuracy: 0.9275 - val_loss: 0.5737 - val_accuracy: 0.9008\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2591 - accuracy: 0.9320 - val_loss: 0.4856 - val_accuracy: 0.9234\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2506 - accuracy: 0.9344 - val_loss: 0.4794 - val_accuracy: 0.9272\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2397 - accuracy: 0.9368 - val_loss: 0.4563 - val_accuracy: 0.9303\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2314 - accuracy: 0.9397 - val_loss: 0.4671 - val_accuracy: 0.9265\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2228 - accuracy: 0.9410 - val_loss: 0.4510 - val_accuracy: 0.9300\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2196 - accuracy: 0.9420 - val_loss: 0.4544 - val_accuracy: 0.9325\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2141 - accuracy: 0.9417 - val_loss: 0.4483 - val_accuracy: 0.9201\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2064 - accuracy: 0.9447 - val_loss: 0.5570 - val_accuracy: 0.9111\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2031 - accuracy: 0.9464 - val_loss: 0.4110 - val_accuracy: 0.9364\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1943 - accuracy: 0.9490 - val_loss: 0.4174 - val_accuracy: 0.9314\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1954 - accuracy: 0.9468 - val_loss: 0.4018 - val_accuracy: 0.9457\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1838 - accuracy: 0.9499 - val_loss: 0.4327 - val_accuracy: 0.9373\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1891 - accuracy: 0.9487 - val_loss: 0.3687 - val_accuracy: 0.9545\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1755 - accuracy: 0.9536 - val_loss: 0.3868 - val_accuracy: 0.9358\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1780 - accuracy: 0.9518 - val_loss: 0.3940 - val_accuracy: 0.9287\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1788 - accuracy: 0.9511 - val_loss: 0.4424 - val_accuracy: 0.9188\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1684 - accuracy: 0.9547 - val_loss: 0.3364 - val_accuracy: 0.9551\n","Epoch 30/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1642 - accuracy: 0.9569 - val_loss: 0.4372 - val_accuracy: 0.9303\n","Epoch 31/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1753 - accuracy: 0.9530 - val_loss: 0.3261 - val_accuracy: 0.9531\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1620 - accuracy: 0.9568 - val_loss: 0.3545 - val_accuracy: 0.9404\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1555 - accuracy: 0.9569 - val_loss: 0.3391 - val_accuracy: 0.9468\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1528 - accuracy: 0.9602 - val_loss: 0.3262 - val_accuracy: 0.9529\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1532 - accuracy: 0.9595 - val_loss: 0.3384 - val_accuracy: 0.9459\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1502 - accuracy: 0.9617 - val_loss: 0.3634 - val_accuracy: 0.9371\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1521 - accuracy: 0.9606 - val_loss: 0.3401 - val_accuracy: 0.9498\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1501 - accuracy: 0.9604 - val_loss: 0.3191 - val_accuracy: 0.9553\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1472 - accuracy: 0.9614 - val_loss: 0.3171 - val_accuracy: 0.9534\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1422 - accuracy: 0.9628 - val_loss: 0.3072 - val_accuracy: 0.9589\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1352 - accuracy: 0.9666 - val_loss: 0.3537 - val_accuracy: 0.9479\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1408 - accuracy: 0.9622 - val_loss: 0.3025 - val_accuracy: 0.9571\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1375 - accuracy: 0.9642 - val_loss: 0.3415 - val_accuracy: 0.9503\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1344 - accuracy: 0.9637 - val_loss: 0.4813 - val_accuracy: 0.9421\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1378 - accuracy: 0.9630 - val_loss: 0.3020 - val_accuracy: 0.9604\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1292 - accuracy: 0.9655 - val_loss: 0.3179 - val_accuracy: 0.9556\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1363 - accuracy: 0.9636 - val_loss: 0.2971 - val_accuracy: 0.9679\n","Epoch 48/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1249 - accuracy: 0.9684 - val_loss: 0.3444 - val_accuracy: 0.9463\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1290 - accuracy: 0.9672 - val_loss: 0.3037 - val_accuracy: 0.9567\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1292 - accuracy: 0.9669 - val_loss: 0.2846 - val_accuracy: 0.9663\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1216 - accuracy: 0.9686 - val_loss: 0.2794 - val_accuracy: 0.9677\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1227 - accuracy: 0.9666 - val_loss: 0.2951 - val_accuracy: 0.9575\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1210 - accuracy: 0.9691 - val_loss: 0.2884 - val_accuracy: 0.9562\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1219 - accuracy: 0.9667 - val_loss: 0.3062 - val_accuracy: 0.9573\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1157 - accuracy: 0.9702 - val_loss: 0.3150 - val_accuracy: 0.9534\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1124 - accuracy: 0.9714 - val_loss: 0.2918 - val_accuracy: 0.9637\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1205 - accuracy: 0.9692 - val_loss: 0.2874 - val_accuracy: 0.9677\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1188 - accuracy: 0.9700 - val_loss: 0.2853 - val_accuracy: 0.9663\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1100 - accuracy: 0.9716 - val_loss: 0.3110 - val_accuracy: 0.9549\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1163 - accuracy: 0.9687 - val_loss: 0.2726 - val_accuracy: 0.9784\n","Average Validation Accuracy: 0.9723708927631378\n","Average Validation Loss: 0.16165850311517715\n","Average Test Accuracy: 0.9719540178775787\n","------------------------------------------------------------------------\n","\n","Number of input features: 6\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7851 - accuracy: 0.2977 - val_loss: 2.4418 - val_accuracy: 0.5712\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6171 - accuracy: 0.7040 - val_loss: 1.4214 - val_accuracy: 0.7525\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9128 - accuracy: 0.8103 - val_loss: 0.9878 - val_accuracy: 0.8275\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6333 - accuracy: 0.8573 - val_loss: 0.8493 - val_accuracy: 0.8480\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4958 - accuracy: 0.8802 - val_loss: 0.6915 - val_accuracy: 0.8612\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4075 - accuracy: 0.8975 - val_loss: 0.5794 - val_accuracy: 0.8926\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3514 - accuracy: 0.9121 - val_loss: 0.4856 - val_accuracy: 0.9052\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3319 - accuracy: 0.9139 - val_loss: 0.4637 - val_accuracy: 0.9076\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2949 - accuracy: 0.9200 - val_loss: 0.4220 - val_accuracy: 0.9116\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2790 - accuracy: 0.9261 - val_loss: 0.3946 - val_accuracy: 0.9219\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2616 - accuracy: 0.9316 - val_loss: 0.3816 - val_accuracy: 0.9193\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2486 - accuracy: 0.9342 - val_loss: 0.3785 - val_accuracy: 0.9175\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2407 - accuracy: 0.9344 - val_loss: 0.3313 - val_accuracy: 0.9353\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2296 - accuracy: 0.9397 - val_loss: 0.3569 - val_accuracy: 0.9278\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2195 - accuracy: 0.9416 - val_loss: 0.3338 - val_accuracy: 0.9404\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2094 - accuracy: 0.9449 - val_loss: 0.3252 - val_accuracy: 0.9468\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2043 - accuracy: 0.9471 - val_loss: 0.3447 - val_accuracy: 0.9206\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2015 - accuracy: 0.9472 - val_loss: 0.3308 - val_accuracy: 0.9399\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1898 - accuracy: 0.9483 - val_loss: 0.3149 - val_accuracy: 0.9490\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1966 - accuracy: 0.9454 - val_loss: 0.3238 - val_accuracy: 0.9443\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1800 - accuracy: 0.9523 - val_loss: 0.2996 - val_accuracy: 0.9505\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1799 - accuracy: 0.9535 - val_loss: 0.3003 - val_accuracy: 0.9443\n","Epoch 23/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1763 - accuracy: 0.9546 - val_loss: 0.3008 - val_accuracy: 0.9529\n","Epoch 24/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1706 - accuracy: 0.9532 - val_loss: 0.3343 - val_accuracy: 0.9366\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1673 - accuracy: 0.9545 - val_loss: 0.3003 - val_accuracy: 0.9487\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1727 - accuracy: 0.9520 - val_loss: 0.2717 - val_accuracy: 0.9564\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1553 - accuracy: 0.9596 - val_loss: 0.3081 - val_accuracy: 0.9452\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1579 - accuracy: 0.9587 - val_loss: 0.2867 - val_accuracy: 0.9452\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1587 - accuracy: 0.9577 - val_loss: 0.2929 - val_accuracy: 0.9520\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1480 - accuracy: 0.9644 - val_loss: 0.2917 - val_accuracy: 0.9516\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1479 - accuracy: 0.9615 - val_loss: 0.2758 - val_accuracy: 0.9602\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1414 - accuracy: 0.9639 - val_loss: 0.3207 - val_accuracy: 0.9481\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1469 - accuracy: 0.9622 - val_loss: 0.2741 - val_accuracy: 0.9525\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1457 - accuracy: 0.9622 - val_loss: 0.2867 - val_accuracy: 0.9560\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1395 - accuracy: 0.9646 - val_loss: 0.2867 - val_accuracy: 0.9641\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1385 - accuracy: 0.9642 - val_loss: 0.2719 - val_accuracy: 0.9628\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1366 - accuracy: 0.9657 - val_loss: 0.2708 - val_accuracy: 0.9615\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1412 - accuracy: 0.9623 - val_loss: 0.2965 - val_accuracy: 0.9507\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1377 - accuracy: 0.9644 - val_loss: 0.2837 - val_accuracy: 0.9595\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1261 - accuracy: 0.9672 - val_loss: 0.2479 - val_accuracy: 0.9644\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1268 - accuracy: 0.9687 - val_loss: 0.2927 - val_accuracy: 0.9540\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1266 - accuracy: 0.9665 - val_loss: 0.2673 - val_accuracy: 0.9712\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1248 - accuracy: 0.9705 - val_loss: 0.2649 - val_accuracy: 0.9703\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1254 - accuracy: 0.9687 - val_loss: 0.3010 - val_accuracy: 0.9575\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1197 - accuracy: 0.9688 - val_loss: 0.2858 - val_accuracy: 0.9619\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1238 - accuracy: 0.9688 - val_loss: 0.2639 - val_accuracy: 0.9679\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1186 - accuracy: 0.9704 - val_loss: 0.2753 - val_accuracy: 0.9652\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1191 - accuracy: 0.9692 - val_loss: 0.2515 - val_accuracy: 0.9683\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1219 - accuracy: 0.9685 - val_loss: 0.2566 - val_accuracy: 0.9657\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1148 - accuracy: 0.9714 - val_loss: 0.2768 - val_accuracy: 0.9553\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1176 - accuracy: 0.9703 - val_loss: 0.2910 - val_accuracy: 0.9622\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.1129 - accuracy: 0.9716 - val_loss: 0.2879 - val_accuracy: 0.9641\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1119 - accuracy: 0.9720 - val_loss: 0.2877 - val_accuracy: 0.9639\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1071 - accuracy: 0.9747 - val_loss: 0.2664 - val_accuracy: 0.9670\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1141 - accuracy: 0.9705 - val_loss: 0.2712 - val_accuracy: 0.9661\n","Epoch 56/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1070 - accuracy: 0.9734 - val_loss: 0.2592 - val_accuracy: 0.9765\n","Epoch 57/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1132 - accuracy: 0.9723 - val_loss: 0.2683 - val_accuracy: 0.9672\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1023 - accuracy: 0.9753 - val_loss: 0.2970 - val_accuracy: 0.9591\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9736 - val_loss: 0.2602 - val_accuracy: 0.9701\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1008 - accuracy: 0.9758 - val_loss: 0.2846 - val_accuracy: 0.9683\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7034 - accuracy: 0.3144 - val_loss: 2.3954 - val_accuracy: 0.5883\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5389 - accuracy: 0.7081 - val_loss: 1.3673 - val_accuracy: 0.7976\n","Epoch 3/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8580 - accuracy: 0.8176 - val_loss: 1.0254 - val_accuracy: 0.8169\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5939 - accuracy: 0.8607 - val_loss: 0.8331 - val_accuracy: 0.8642\n","Epoch 5/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4766 - accuracy: 0.8768 - val_loss: 0.7123 - val_accuracy: 0.8675\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4014 - accuracy: 0.8964 - val_loss: 0.6482 - val_accuracy: 0.8766\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3582 - accuracy: 0.9039 - val_loss: 0.5464 - val_accuracy: 0.8997\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3253 - accuracy: 0.9121 - val_loss: 0.5309 - val_accuracy: 0.9058\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2905 - accuracy: 0.9228 - val_loss: 0.4957 - val_accuracy: 0.9069\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2826 - accuracy: 0.9221 - val_loss: 0.4685 - val_accuracy: 0.9250\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2599 - accuracy: 0.9313 - val_loss: 0.4277 - val_accuracy: 0.9210\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2401 - accuracy: 0.9372 - val_loss: 0.4595 - val_accuracy: 0.9146\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2353 - accuracy: 0.9385 - val_loss: 0.4363 - val_accuracy: 0.9256\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2250 - accuracy: 0.9418 - val_loss: 0.4624 - val_accuracy: 0.9210\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2249 - accuracy: 0.9418 - val_loss: 0.5219 - val_accuracy: 0.9122\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2109 - accuracy: 0.9446 - val_loss: 0.4178 - val_accuracy: 0.9318\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2022 - accuracy: 0.9482 - val_loss: 0.4330 - val_accuracy: 0.9406\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1939 - accuracy: 0.9499 - val_loss: 0.4017 - val_accuracy: 0.9316\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1936 - accuracy: 0.9487 - val_loss: 0.3736 - val_accuracy: 0.9516\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1807 - accuracy: 0.9543 - val_loss: 0.3686 - val_accuracy: 0.9518\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1813 - accuracy: 0.9537 - val_loss: 0.3654 - val_accuracy: 0.9516\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1851 - accuracy: 0.9536 - val_loss: 0.4278 - val_accuracy: 0.9245\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1659 - accuracy: 0.9576 - val_loss: 0.3576 - val_accuracy: 0.9556\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1705 - accuracy: 0.9577 - val_loss: 0.3620 - val_accuracy: 0.9461\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1669 - accuracy: 0.9578 - val_loss: 0.3510 - val_accuracy: 0.9641\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1664 - accuracy: 0.9598 - val_loss: 0.3559 - val_accuracy: 0.9509\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1583 - accuracy: 0.9601 - val_loss: 0.4327 - val_accuracy: 0.9322\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1514 - accuracy: 0.9630 - val_loss: 0.3423 - val_accuracy: 0.9527\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1514 - accuracy: 0.9630 - val_loss: 0.3346 - val_accuracy: 0.9553\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1526 - accuracy: 0.9625 - val_loss: 0.3714 - val_accuracy: 0.9424\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1457 - accuracy: 0.9638 - val_loss: 0.3831 - val_accuracy: 0.9232\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1508 - accuracy: 0.9624 - val_loss: 0.3366 - val_accuracy: 0.9586\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1405 - accuracy: 0.9660 - val_loss: 0.3165 - val_accuracy: 0.9611\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1402 - accuracy: 0.9663 - val_loss: 0.3455 - val_accuracy: 0.9512\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1389 - accuracy: 0.9673 - val_loss: 0.3185 - val_accuracy: 0.9578\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1460 - accuracy: 0.9654 - val_loss: 0.3300 - val_accuracy: 0.9490\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1328 - accuracy: 0.9663 - val_loss: 0.3166 - val_accuracy: 0.9666\n","Epoch 38/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1312 - accuracy: 0.9702 - val_loss: 0.3154 - val_accuracy: 0.9567\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1318 - accuracy: 0.9679 - val_loss: 0.3039 - val_accuracy: 0.9685\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1259 - accuracy: 0.9680 - val_loss: 0.2955 - val_accuracy: 0.9679\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1320 - accuracy: 0.9677 - val_loss: 0.3304 - val_accuracy: 0.9633\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1267 - accuracy: 0.9692 - val_loss: 0.3202 - val_accuracy: 0.9600\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1166 - accuracy: 0.9723 - val_loss: 0.2942 - val_accuracy: 0.9630\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1202 - accuracy: 0.9711 - val_loss: 0.2929 - val_accuracy: 0.9622\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1305 - accuracy: 0.9680 - val_loss: 0.2964 - val_accuracy: 0.9655\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1125 - accuracy: 0.9723 - val_loss: 0.2846 - val_accuracy: 0.9652\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1227 - accuracy: 0.9707 - val_loss: 0.2774 - val_accuracy: 0.9738\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1168 - accuracy: 0.9720 - val_loss: 0.2954 - val_accuracy: 0.9624\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1188 - accuracy: 0.9723 - val_loss: 0.2869 - val_accuracy: 0.9639\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1094 - accuracy: 0.9742 - val_loss: 0.2701 - val_accuracy: 0.9721\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1144 - accuracy: 0.9726 - val_loss: 0.2789 - val_accuracy: 0.9696\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1127 - accuracy: 0.9714 - val_loss: 0.2596 - val_accuracy: 0.9727\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1065 - accuracy: 0.9734 - val_loss: 0.2775 - val_accuracy: 0.9716\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1146 - accuracy: 0.9720 - val_loss: 0.2865 - val_accuracy: 0.9615\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9750 - val_loss: 0.2713 - val_accuracy: 0.9745\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1045 - accuracy: 0.9755 - val_loss: 0.2836 - val_accuracy: 0.9685\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1090 - accuracy: 0.9741 - val_loss: 0.2801 - val_accuracy: 0.9685\n","Epoch 58/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1034 - accuracy: 0.9772 - val_loss: 0.2836 - val_accuracy: 0.9569\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1089 - accuracy: 0.9749 - val_loss: 0.2503 - val_accuracy: 0.9756\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1056 - accuracy: 0.9746 - val_loss: 0.2651 - val_accuracy: 0.9626\n","Average Validation Accuracy: 0.9697200059890747\n","Average Validation Loss: 0.1623932123184204\n","Average Test Accuracy: 0.9694479405879974\n","------------------------------------------------------------------------\n","\n","Number of input features: 7\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.8598 - accuracy: 0.2848 - val_loss: 2.5954 - val_accuracy: 0.5688\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7374 - accuracy: 0.6793 - val_loss: 1.4654 - val_accuracy: 0.7300\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9736 - accuracy: 0.8028 - val_loss: 1.0086 - val_accuracy: 0.8040\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6502 - accuracy: 0.8542 - val_loss: 0.8236 - val_accuracy: 0.8548\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5045 - accuracy: 0.8789 - val_loss: 0.7103 - val_accuracy: 0.8796\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4245 - accuracy: 0.8954 - val_loss: 0.6171 - val_accuracy: 0.8990\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3793 - accuracy: 0.9023 - val_loss: 0.6652 - val_accuracy: 0.8818\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3372 - accuracy: 0.9145 - val_loss: 0.5520 - val_accuracy: 0.8854\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3053 - accuracy: 0.9232 - val_loss: 0.4937 - val_accuracy: 0.9142\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2847 - accuracy: 0.9264 - val_loss: 0.4724 - val_accuracy: 0.9217\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2673 - accuracy: 0.9325 - val_loss: 0.4417 - val_accuracy: 0.9210\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2426 - accuracy: 0.9384 - val_loss: 0.4362 - val_accuracy: 0.9331\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2406 - accuracy: 0.9365 - val_loss: 0.4187 - val_accuracy: 0.9287\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2249 - accuracy: 0.9444 - val_loss: 0.3916 - val_accuracy: 0.9479\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2141 - accuracy: 0.9443 - val_loss: 0.3505 - val_accuracy: 0.9472\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1999 - accuracy: 0.9484 - val_loss: 0.3716 - val_accuracy: 0.9426\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2047 - accuracy: 0.9480 - val_loss: 0.3867 - val_accuracy: 0.9122\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1894 - accuracy: 0.9524 - val_loss: 0.3570 - val_accuracy: 0.9353\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1840 - accuracy: 0.9512 - val_loss: 0.3380 - val_accuracy: 0.9441\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1793 - accuracy: 0.9523 - val_loss: 0.3174 - val_accuracy: 0.9540\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1685 - accuracy: 0.9586 - val_loss: 0.2953 - val_accuracy: 0.9551\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1731 - accuracy: 0.9540 - val_loss: 0.2929 - val_accuracy: 0.9558\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1580 - accuracy: 0.9576 - val_loss: 0.3614 - val_accuracy: 0.9237\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1634 - accuracy: 0.9577 - val_loss: 0.2807 - val_accuracy: 0.9567\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1534 - accuracy: 0.9614 - val_loss: 0.3265 - val_accuracy: 0.9408\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1461 - accuracy: 0.9635 - val_loss: 0.2889 - val_accuracy: 0.9644\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1441 - accuracy: 0.9647 - val_loss: 0.2849 - val_accuracy: 0.9615\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1481 - accuracy: 0.9628 - val_loss: 0.2590 - val_accuracy: 0.9668\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1370 - accuracy: 0.9634 - val_loss: 0.2880 - val_accuracy: 0.9611\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1401 - accuracy: 0.9620 - val_loss: 0.2747 - val_accuracy: 0.9641\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1361 - accuracy: 0.9651 - val_loss: 0.2959 - val_accuracy: 0.9531\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1290 - accuracy: 0.9675 - val_loss: 0.2650 - val_accuracy: 0.9633\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1299 - accuracy: 0.9663 - val_loss: 0.2751 - val_accuracy: 0.9516\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1332 - accuracy: 0.9674 - val_loss: 0.2448 - val_accuracy: 0.9754\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1234 - accuracy: 0.9666 - val_loss: 0.2730 - val_accuracy: 0.9624\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1320 - accuracy: 0.9667 - val_loss: 0.2656 - val_accuracy: 0.9672\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1165 - accuracy: 0.9702 - val_loss: 0.2566 - val_accuracy: 0.9668\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1182 - accuracy: 0.9711 - val_loss: 0.2722 - val_accuracy: 0.9644\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1217 - accuracy: 0.9707 - val_loss: 0.2572 - val_accuracy: 0.9692\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1189 - accuracy: 0.9693 - val_loss: 0.2613 - val_accuracy: 0.9657\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1115 - accuracy: 0.9727 - val_loss: 0.2460 - val_accuracy: 0.9690\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1146 - accuracy: 0.9725 - val_loss: 0.2538 - val_accuracy: 0.9743\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1126 - accuracy: 0.9711 - val_loss: 0.2831 - val_accuracy: 0.9547\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1080 - accuracy: 0.9747 - val_loss: 0.2801 - val_accuracy: 0.9567\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1117 - accuracy: 0.9721 - val_loss: 0.2469 - val_accuracy: 0.9736\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1047 - accuracy: 0.9765 - val_loss: 0.2558 - val_accuracy: 0.9736\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1048 - accuracy: 0.9746 - val_loss: 0.2465 - val_accuracy: 0.9784\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1062 - accuracy: 0.9740 - val_loss: 0.2456 - val_accuracy: 0.9828\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0985 - accuracy: 0.9772 - val_loss: 0.2689 - val_accuracy: 0.9685\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1094 - accuracy: 0.9745 - val_loss: 0.2429 - val_accuracy: 0.9734\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1068 - accuracy: 0.9745 - val_loss: 0.2341 - val_accuracy: 0.9743\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0957 - accuracy: 0.9782 - val_loss: 0.2648 - val_accuracy: 0.9690\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0974 - accuracy: 0.9766 - val_loss: 0.2423 - val_accuracy: 0.9773\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0945 - accuracy: 0.9770 - val_loss: 0.3084 - val_accuracy: 0.9580\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0986 - accuracy: 0.9747 - val_loss: 0.2411 - val_accuracy: 0.9747\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0959 - accuracy: 0.9760 - val_loss: 0.2830 - val_accuracy: 0.9657\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0953 - accuracy: 0.9781 - val_loss: 0.2415 - val_accuracy: 0.9738\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0923 - accuracy: 0.9777 - val_loss: 0.3554 - val_accuracy: 0.9523\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0995 - accuracy: 0.9760 - val_loss: 0.2404 - val_accuracy: 0.9791\n","Epoch 60/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0887 - accuracy: 0.9788 - val_loss: 0.2583 - val_accuracy: 0.9670\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.7263 - accuracy: 0.3095 - val_loss: 2.5310 - val_accuracy: 0.6004\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6209 - accuracy: 0.6904 - val_loss: 1.4446 - val_accuracy: 0.7956\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8489 - accuracy: 0.8193 - val_loss: 1.0605 - val_accuracy: 0.8238\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5706 - accuracy: 0.8684 - val_loss: 0.8290 - val_accuracy: 0.8598\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4332 - accuracy: 0.8958 - val_loss: 0.6897 - val_accuracy: 0.8937\n","Epoch 6/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3644 - accuracy: 0.9068 - val_loss: 0.5715 - val_accuracy: 0.9173\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3153 - accuracy: 0.9161 - val_loss: 0.5148 - val_accuracy: 0.9190\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2791 - accuracy: 0.9265 - val_loss: 0.4529 - val_accuracy: 0.9294\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2615 - accuracy: 0.9326 - val_loss: 0.4483 - val_accuracy: 0.9100\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2415 - accuracy: 0.9359 - val_loss: 0.4047 - val_accuracy: 0.9267\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2245 - accuracy: 0.9390 - val_loss: 0.3974 - val_accuracy: 0.9349\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2204 - accuracy: 0.9407 - val_loss: 0.3609 - val_accuracy: 0.9351\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2095 - accuracy: 0.9440 - val_loss: 0.3373 - val_accuracy: 0.9509\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1939 - accuracy: 0.9497 - val_loss: 0.3604 - val_accuracy: 0.9243\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1924 - accuracy: 0.9486 - val_loss: 0.3716 - val_accuracy: 0.9303\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1775 - accuracy: 0.9544 - val_loss: 0.3156 - val_accuracy: 0.9569\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1822 - accuracy: 0.9526 - val_loss: 0.3098 - val_accuracy: 0.9509\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1655 - accuracy: 0.9575 - val_loss: 0.3304 - val_accuracy: 0.9516\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1647 - accuracy: 0.9571 - val_loss: 0.3009 - val_accuracy: 0.9470\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1612 - accuracy: 0.9598 - val_loss: 0.3258 - val_accuracy: 0.9483\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1473 - accuracy: 0.9633 - val_loss: 0.3101 - val_accuracy: 0.9501\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1484 - accuracy: 0.9629 - val_loss: 0.3024 - val_accuracy: 0.9545\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1494 - accuracy: 0.9635 - val_loss: 0.3283 - val_accuracy: 0.9366\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1343 - accuracy: 0.9664 - val_loss: 0.3000 - val_accuracy: 0.9602\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1461 - accuracy: 0.9637 - val_loss: 0.2877 - val_accuracy: 0.9542\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1311 - accuracy: 0.9678 - val_loss: 0.2941 - val_accuracy: 0.9527\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1297 - accuracy: 0.9685 - val_loss: 0.2876 - val_accuracy: 0.9514\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1282 - accuracy: 0.9680 - val_loss: 0.3073 - val_accuracy: 0.9558\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1250 - accuracy: 0.9704 - val_loss: 0.2704 - val_accuracy: 0.9648\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1256 - accuracy: 0.9713 - val_loss: 0.2809 - val_accuracy: 0.9494\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1246 - accuracy: 0.9707 - val_loss: 0.3653 - val_accuracy: 0.9413\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1167 - accuracy: 0.9736 - val_loss: 0.2728 - val_accuracy: 0.9582\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1157 - accuracy: 0.9730 - val_loss: 0.2540 - val_accuracy: 0.9639\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1248 - accuracy: 0.9711 - val_loss: 0.2559 - val_accuracy: 0.9615\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1152 - accuracy: 0.9710 - val_loss: 0.2964 - val_accuracy: 0.9549\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1036 - accuracy: 0.9764 - val_loss: 0.2398 - val_accuracy: 0.9672\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1133 - accuracy: 0.9746 - val_loss: 0.2463 - val_accuracy: 0.9655\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9741 - val_loss: 0.2618 - val_accuracy: 0.9547\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1024 - accuracy: 0.9769 - val_loss: 0.2477 - val_accuracy: 0.9617\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1033 - accuracy: 0.9770 - val_loss: 0.2441 - val_accuracy: 0.9551\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0933 - accuracy: 0.9790 - val_loss: 0.2512 - val_accuracy: 0.9604\n","Epoch 42/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1052 - accuracy: 0.9755 - val_loss: 0.2278 - val_accuracy: 0.9694\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0975 - accuracy: 0.9773 - val_loss: 0.2333 - val_accuracy: 0.9613\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0936 - accuracy: 0.9788 - val_loss: 0.2301 - val_accuracy: 0.9672\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0985 - accuracy: 0.9759 - val_loss: 0.2439 - val_accuracy: 0.9721\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9803 - val_loss: 0.2287 - val_accuracy: 0.9721\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0939 - accuracy: 0.9791 - val_loss: 0.2238 - val_accuracy: 0.9655\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0964 - accuracy: 0.9782 - val_loss: 0.2172 - val_accuracy: 0.9762\n","Epoch 49/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0921 - accuracy: 0.9778 - val_loss: 0.2274 - val_accuracy: 0.9703\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0948 - accuracy: 0.9778 - val_loss: 0.2442 - val_accuracy: 0.9644\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0962 - accuracy: 0.9781 - val_loss: 0.2206 - val_accuracy: 0.9767\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0851 - accuracy: 0.9813 - val_loss: 0.2146 - val_accuracy: 0.9749\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0888 - accuracy: 0.9786 - val_loss: 0.2126 - val_accuracy: 0.9804\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0831 - accuracy: 0.9815 - val_loss: 0.2140 - val_accuracy: 0.9677\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0884 - accuracy: 0.9794 - val_loss: 0.2177 - val_accuracy: 0.9734\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0856 - accuracy: 0.9803 - val_loss: 0.2225 - val_accuracy: 0.9705\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0885 - accuracy: 0.9800 - val_loss: 0.2142 - val_accuracy: 0.9705\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0769 - accuracy: 0.9831 - val_loss: 0.2260 - val_accuracy: 0.9694\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0821 - accuracy: 0.9804 - val_loss: 0.1904 - val_accuracy: 0.9804\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0812 - accuracy: 0.9810 - val_loss: 0.2161 - val_accuracy: 0.9723\n","Average Validation Accuracy: 0.9747669398784637\n","Average Validation Loss: 0.13983222842216492\n","Average Test Accuracy: 0.9742758274078369\n","------------------------------------------------------------------------\n","\n","Number of input features: 8\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7482 - accuracy: 0.3046 - val_loss: 2.5021 - val_accuracy: 0.5549\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.6076 - accuracy: 0.6976 - val_loss: 1.3335 - val_accuracy: 0.7525\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8336 - accuracy: 0.8203 - val_loss: 0.9017 - val_accuracy: 0.8295\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5371 - accuracy: 0.8754 - val_loss: 0.7061 - val_accuracy: 0.8603\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4174 - accuracy: 0.9015 - val_loss: 0.6084 - val_accuracy: 0.8847\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3494 - accuracy: 0.9127 - val_loss: 0.4905 - val_accuracy: 0.9162\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3075 - accuracy: 0.9228 - val_loss: 0.4679 - val_accuracy: 0.9056\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2819 - accuracy: 0.9284 - val_loss: 0.4285 - val_accuracy: 0.9232\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2490 - accuracy: 0.9402 - val_loss: 0.3933 - val_accuracy: 0.9320\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2489 - accuracy: 0.9371 - val_loss: 0.3727 - val_accuracy: 0.9364\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2180 - accuracy: 0.9461 - val_loss: 0.3724 - val_accuracy: 0.9384\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2188 - accuracy: 0.9448 - val_loss: 0.3457 - val_accuracy: 0.9426\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2015 - accuracy: 0.9494 - val_loss: 0.3654 - val_accuracy: 0.9443\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1997 - accuracy: 0.9478 - val_loss: 0.3214 - val_accuracy: 0.9406\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1912 - accuracy: 0.9517 - val_loss: 0.3061 - val_accuracy: 0.9507\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1753 - accuracy: 0.9557 - val_loss: 0.3097 - val_accuracy: 0.9465\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1803 - accuracy: 0.9542 - val_loss: 0.3219 - val_accuracy: 0.9457\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1695 - accuracy: 0.9582 - val_loss: 0.3133 - val_accuracy: 0.9358\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1594 - accuracy: 0.9603 - val_loss: 0.3121 - val_accuracy: 0.9494\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1651 - accuracy: 0.9575 - val_loss: 0.3083 - val_accuracy: 0.9457\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1505 - accuracy: 0.9622 - val_loss: 0.2755 - val_accuracy: 0.9672\n","Epoch 22/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1476 - accuracy: 0.9641 - val_loss: 0.4181 - val_accuracy: 0.9232\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1515 - accuracy: 0.9617 - val_loss: 0.2763 - val_accuracy: 0.9586\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1380 - accuracy: 0.9662 - val_loss: 0.3040 - val_accuracy: 0.9549\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1428 - accuracy: 0.9642 - val_loss: 0.2575 - val_accuracy: 0.9705\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1347 - accuracy: 0.9674 - val_loss: 0.2904 - val_accuracy: 0.9595\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1348 - accuracy: 0.9668 - val_loss: 0.2641 - val_accuracy: 0.9663\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1223 - accuracy: 0.9716 - val_loss: 0.2760 - val_accuracy: 0.9518\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1321 - accuracy: 0.9687 - val_loss: 0.2597 - val_accuracy: 0.9639\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1253 - accuracy: 0.9693 - val_loss: 0.2619 - val_accuracy: 0.9633\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1184 - accuracy: 0.9711 - val_loss: 0.2942 - val_accuracy: 0.9501\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1225 - accuracy: 0.9700 - val_loss: 0.2381 - val_accuracy: 0.9679\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1140 - accuracy: 0.9732 - val_loss: 0.2525 - val_accuracy: 0.9551\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1118 - accuracy: 0.9729 - val_loss: 0.2413 - val_accuracy: 0.9767\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1123 - accuracy: 0.9740 - val_loss: 0.2284 - val_accuracy: 0.9800\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1233 - accuracy: 0.9697 - val_loss: 0.2711 - val_accuracy: 0.9626\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1048 - accuracy: 0.9753 - val_loss: 0.2812 - val_accuracy: 0.9424\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1045 - accuracy: 0.9753 - val_loss: 0.2790 - val_accuracy: 0.9672\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1062 - accuracy: 0.9740 - val_loss: 0.2690 - val_accuracy: 0.9681\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1077 - accuracy: 0.9737 - val_loss: 0.2299 - val_accuracy: 0.9683\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1041 - accuracy: 0.9745 - val_loss: 0.2489 - val_accuracy: 0.9663\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1032 - accuracy: 0.9768 - val_loss: 0.2374 - val_accuracy: 0.9767\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1073 - accuracy: 0.9747 - val_loss: 0.2281 - val_accuracy: 0.9789\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0911 - accuracy: 0.9809 - val_loss: 0.2179 - val_accuracy: 0.9776\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0956 - accuracy: 0.9782 - val_loss: 0.2256 - val_accuracy: 0.9809\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0960 - accuracy: 0.9783 - val_loss: 0.2640 - val_accuracy: 0.9641\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0929 - accuracy: 0.9780 - val_loss: 0.2346 - val_accuracy: 0.9707\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0961 - accuracy: 0.9788 - val_loss: 0.2602 - val_accuracy: 0.9668\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0928 - accuracy: 0.9782 - val_loss: 0.2128 - val_accuracy: 0.9826\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0847 - accuracy: 0.9811 - val_loss: 0.2351 - val_accuracy: 0.9767\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0935 - accuracy: 0.9780 - val_loss: 0.2311 - val_accuracy: 0.9745\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0867 - accuracy: 0.9803 - val_loss: 0.2187 - val_accuracy: 0.9813\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0901 - accuracy: 0.9783 - val_loss: 0.2191 - val_accuracy: 0.9844\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0795 - accuracy: 0.9815 - val_loss: 0.2226 - val_accuracy: 0.9842\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0922 - accuracy: 0.9783 - val_loss: 0.2428 - val_accuracy: 0.9681\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0849 - accuracy: 0.9794 - val_loss: 0.2376 - val_accuracy: 0.9648\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0841 - accuracy: 0.9810 - val_loss: 0.2270 - val_accuracy: 0.9817\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0849 - accuracy: 0.9807 - val_loss: 0.2467 - val_accuracy: 0.9641\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0808 - accuracy: 0.9805 - val_loss: 0.2210 - val_accuracy: 0.9824\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0840 - accuracy: 0.9798 - val_loss: 0.2218 - val_accuracy: 0.9822\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.8372 - accuracy: 0.2774 - val_loss: 2.7600 - val_accuracy: 0.5349\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.8475 - accuracy: 0.6576 - val_loss: 1.6929 - val_accuracy: 0.7454\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0256 - accuracy: 0.7908 - val_loss: 1.1173 - val_accuracy: 0.8244\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6521 - accuracy: 0.8553 - val_loss: 0.8634 - val_accuracy: 0.8636\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4841 - accuracy: 0.8817 - val_loss: 0.7552 - val_accuracy: 0.8827\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3930 - accuracy: 0.9041 - val_loss: 0.6509 - val_accuracy: 0.8893\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3481 - accuracy: 0.9098 - val_loss: 0.5955 - val_accuracy: 0.9032\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3022 - accuracy: 0.9219 - val_loss: 0.5304 - val_accuracy: 0.9098\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2796 - accuracy: 0.9272 - val_loss: 0.4852 - val_accuracy: 0.9226\n","Epoch 10/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2539 - accuracy: 0.9351 - val_loss: 0.4317 - val_accuracy: 0.9298\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2363 - accuracy: 0.9394 - val_loss: 0.4366 - val_accuracy: 0.9263\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2318 - accuracy: 0.9429 - val_loss: 0.3868 - val_accuracy: 0.9369\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2068 - accuracy: 0.9465 - val_loss: 0.4079 - val_accuracy: 0.9226\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2020 - accuracy: 0.9486 - val_loss: 0.3819 - val_accuracy: 0.9369\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1876 - accuracy: 0.9497 - val_loss: 0.3359 - val_accuracy: 0.9512\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1790 - accuracy: 0.9546 - val_loss: 0.3742 - val_accuracy: 0.9419\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1747 - accuracy: 0.9548 - val_loss: 0.3196 - val_accuracy: 0.9501\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1648 - accuracy: 0.9587 - val_loss: 0.3036 - val_accuracy: 0.9525\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1548 - accuracy: 0.9608 - val_loss: 0.2993 - val_accuracy: 0.9514\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1584 - accuracy: 0.9587 - val_loss: 0.2745 - val_accuracy: 0.9540\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1568 - accuracy: 0.9607 - val_loss: 0.3037 - val_accuracy: 0.9496\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1412 - accuracy: 0.9662 - val_loss: 0.2831 - val_accuracy: 0.9593\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1414 - accuracy: 0.9630 - val_loss: 0.2684 - val_accuracy: 0.9542\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1386 - accuracy: 0.9651 - val_loss: 0.2513 - val_accuracy: 0.9567\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1360 - accuracy: 0.9672 - val_loss: 0.2847 - val_accuracy: 0.9514\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1309 - accuracy: 0.9684 - val_loss: 0.2469 - val_accuracy: 0.9578\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1315 - accuracy: 0.9663 - val_loss: 0.2761 - val_accuracy: 0.9556\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1225 - accuracy: 0.9688 - val_loss: 0.2405 - val_accuracy: 0.9659\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1205 - accuracy: 0.9689 - val_loss: 0.2327 - val_accuracy: 0.9648\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1156 - accuracy: 0.9737 - val_loss: 0.2323 - val_accuracy: 0.9657\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1185 - accuracy: 0.9690 - val_loss: 0.2230 - val_accuracy: 0.9668\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9732 - val_loss: 0.2257 - val_accuracy: 0.9668\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1175 - accuracy: 0.9703 - val_loss: 0.2171 - val_accuracy: 0.9644\n","Epoch 34/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1097 - accuracy: 0.9732 - val_loss: 0.2376 - val_accuracy: 0.9536\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1089 - accuracy: 0.9739 - val_loss: 0.2199 - val_accuracy: 0.9712\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1080 - accuracy: 0.9739 - val_loss: 0.3197 - val_accuracy: 0.9518\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1046 - accuracy: 0.9766 - val_loss: 0.2423 - val_accuracy: 0.9580\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1037 - accuracy: 0.9747 - val_loss: 0.2134 - val_accuracy: 0.9674\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1043 - accuracy: 0.9751 - val_loss: 0.2089 - val_accuracy: 0.9679\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1007 - accuracy: 0.9757 - val_loss: 0.1985 - val_accuracy: 0.9725\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0993 - accuracy: 0.9763 - val_loss: 0.2171 - val_accuracy: 0.9655\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1030 - accuracy: 0.9762 - val_loss: 0.2018 - val_accuracy: 0.9725\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0899 - accuracy: 0.9789 - val_loss: 0.1931 - val_accuracy: 0.9705\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1009 - accuracy: 0.9743 - val_loss: 0.2015 - val_accuracy: 0.9703\n","Epoch 45/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0845 - accuracy: 0.9801 - val_loss: 0.1952 - val_accuracy: 0.9729\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0990 - accuracy: 0.9762 - val_loss: 0.2183 - val_accuracy: 0.9657\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0874 - accuracy: 0.9794 - val_loss: 0.2149 - val_accuracy: 0.9681\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0930 - accuracy: 0.9775 - val_loss: 0.2088 - val_accuracy: 0.9668\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0849 - accuracy: 0.9810 - val_loss: 0.2048 - val_accuracy: 0.9729\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9797 - val_loss: 0.2084 - val_accuracy: 0.9659\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0910 - accuracy: 0.9797 - val_loss: 0.1828 - val_accuracy: 0.9789\n","Epoch 52/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0875 - accuracy: 0.9807 - val_loss: 0.2015 - val_accuracy: 0.9701\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0811 - accuracy: 0.9817 - val_loss: 0.2044 - val_accuracy: 0.9630\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0850 - accuracy: 0.9793 - val_loss: 0.1924 - val_accuracy: 0.9754\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0917 - accuracy: 0.9801 - val_loss: 0.2229 - val_accuracy: 0.9646\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0732 - accuracy: 0.9848 - val_loss: 0.2020 - val_accuracy: 0.9655\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0828 - accuracy: 0.9819 - val_loss: 0.1995 - val_accuracy: 0.9655\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0779 - accuracy: 0.9829 - val_loss: 0.1936 - val_accuracy: 0.9710\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0775 - accuracy: 0.9824 - val_loss: 0.1846 - val_accuracy: 0.9760\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0779 - accuracy: 0.9823 - val_loss: 0.1963 - val_accuracy: 0.9718\n","Average Validation Accuracy: 0.982681542634964\n","Average Validation Loss: 0.1185755543410778\n","Average Test Accuracy: 0.9801724851131439\n","------------------------------------------------------------------------\n","\n","Number of input features: 9\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.6354 - accuracy: 0.3319 - val_loss: 2.3203 - val_accuracy: 0.6202\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5038 - accuracy: 0.7232 - val_loss: 1.2819 - val_accuracy: 0.7815\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8195 - accuracy: 0.8302 - val_loss: 0.8724 - val_accuracy: 0.8372\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5243 - accuracy: 0.8770 - val_loss: 0.6749 - val_accuracy: 0.8730\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4039 - accuracy: 0.9036 - val_loss: 0.5649 - val_accuracy: 0.8944\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3356 - accuracy: 0.9172 - val_loss: 0.5228 - val_accuracy: 0.8955\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3012 - accuracy: 0.9258 - val_loss: 0.4637 - val_accuracy: 0.9138\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2674 - accuracy: 0.9338 - val_loss: 0.4172 - val_accuracy: 0.9234\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2561 - accuracy: 0.9357 - val_loss: 0.3619 - val_accuracy: 0.9362\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2252 - accuracy: 0.9413 - val_loss: 0.3649 - val_accuracy: 0.9404\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2197 - accuracy: 0.9445 - val_loss: 0.3373 - val_accuracy: 0.9369\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2021 - accuracy: 0.9499 - val_loss: 0.3425 - val_accuracy: 0.9479\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1950 - accuracy: 0.9540 - val_loss: 0.3430 - val_accuracy: 0.9410\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1827 - accuracy: 0.9560 - val_loss: 0.3637 - val_accuracy: 0.9329\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1795 - accuracy: 0.9582 - val_loss: 0.2904 - val_accuracy: 0.9705\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1699 - accuracy: 0.9609 - val_loss: 0.2850 - val_accuracy: 0.9461\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1608 - accuracy: 0.9615 - val_loss: 0.2780 - val_accuracy: 0.9551\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1656 - accuracy: 0.9616 - val_loss: 0.2539 - val_accuracy: 0.9732\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1476 - accuracy: 0.9673 - val_loss: 0.2888 - val_accuracy: 0.9430\n","Epoch 20/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1500 - accuracy: 0.9653 - val_loss: 0.2740 - val_accuracy: 0.9564\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1502 - accuracy: 0.9656 - val_loss: 0.2465 - val_accuracy: 0.9582\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1344 - accuracy: 0.9699 - val_loss: 0.2471 - val_accuracy: 0.9644\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1358 - accuracy: 0.9697 - val_loss: 0.2469 - val_accuracy: 0.9624\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1320 - accuracy: 0.9693 - val_loss: 0.2762 - val_accuracy: 0.9527\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1325 - accuracy: 0.9703 - val_loss: 0.2570 - val_accuracy: 0.9635\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1279 - accuracy: 0.9716 - val_loss: 0.2443 - val_accuracy: 0.9628\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1180 - accuracy: 0.9745 - val_loss: 0.2495 - val_accuracy: 0.9637\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1272 - accuracy: 0.9712 - val_loss: 0.2291 - val_accuracy: 0.9696\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1163 - accuracy: 0.9734 - val_loss: 0.2243 - val_accuracy: 0.9756\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1183 - accuracy: 0.9730 - val_loss: 0.2230 - val_accuracy: 0.9734\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1128 - accuracy: 0.9736 - val_loss: 0.2496 - val_accuracy: 0.9666\n","Epoch 32/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1167 - accuracy: 0.9737 - val_loss: 0.2845 - val_accuracy: 0.9624\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1076 - accuracy: 0.9756 - val_loss: 0.2401 - val_accuracy: 0.9578\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1022 - accuracy: 0.9772 - val_loss: 0.2318 - val_accuracy: 0.9740\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1113 - accuracy: 0.9742 - val_loss: 0.2230 - val_accuracy: 0.9745\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1018 - accuracy: 0.9772 - val_loss: 0.2729 - val_accuracy: 0.9525\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1011 - accuracy: 0.9771 - val_loss: 0.2518 - val_accuracy: 0.9562\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1017 - accuracy: 0.9775 - val_loss: 0.2239 - val_accuracy: 0.9716\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0932 - accuracy: 0.9797 - val_loss: 0.2180 - val_accuracy: 0.9809\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1043 - accuracy: 0.9769 - val_loss: 0.2798 - val_accuracy: 0.9754\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0941 - accuracy: 0.9778 - val_loss: 0.2149 - val_accuracy: 0.9749\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0941 - accuracy: 0.9786 - val_loss: 0.2274 - val_accuracy: 0.9754\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0972 - accuracy: 0.9770 - val_loss: 0.2117 - val_accuracy: 0.9771\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0846 - accuracy: 0.9816 - val_loss: 0.2477 - val_accuracy: 0.9672\n","Epoch 45/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1030 - accuracy: 0.9763 - val_loss: 0.2241 - val_accuracy: 0.9727\n","Epoch 46/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0887 - accuracy: 0.9811 - val_loss: 0.2199 - val_accuracy: 0.9776\n","Epoch 47/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0889 - accuracy: 0.9805 - val_loss: 0.3583 - val_accuracy: 0.9452\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0911 - accuracy: 0.9797 - val_loss: 0.2313 - val_accuracy: 0.9784\n","Epoch 49/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0849 - accuracy: 0.9812 - val_loss: 0.3020 - val_accuracy: 0.9604\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0884 - accuracy: 0.9793 - val_loss: 0.2148 - val_accuracy: 0.9815\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0886 - accuracy: 0.9789 - val_loss: 0.2739 - val_accuracy: 0.9670\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0877 - accuracy: 0.9802 - val_loss: 0.2394 - val_accuracy: 0.9729\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0892 - accuracy: 0.9797 - val_loss: 0.2093 - val_accuracy: 0.9795\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0805 - accuracy: 0.9817 - val_loss: 0.2832 - val_accuracy: 0.9415\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0897 - accuracy: 0.9790 - val_loss: 0.2661 - val_accuracy: 0.9567\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0804 - accuracy: 0.9823 - val_loss: 0.2180 - val_accuracy: 0.9824\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0800 - accuracy: 0.9803 - val_loss: 0.2751 - val_accuracy: 0.9626\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0838 - accuracy: 0.9805 - val_loss: 0.2858 - val_accuracy: 0.9666\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0797 - accuracy: 0.9822 - val_loss: 0.2150 - val_accuracy: 0.9795\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0800 - accuracy: 0.9814 - val_loss: 0.2322 - val_accuracy: 0.9835\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.6854 - accuracy: 0.3185 - val_loss: 2.5079 - val_accuracy: 0.5336\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6906 - accuracy: 0.6671 - val_loss: 1.6107 - val_accuracy: 0.7322\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 1.0048 - accuracy: 0.7855 - val_loss: 1.1791 - val_accuracy: 0.8081\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6739 - accuracy: 0.8464 - val_loss: 0.9529 - val_accuracy: 0.8497\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5116 - accuracy: 0.8784 - val_loss: 0.8153 - val_accuracy: 0.8887\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4197 - accuracy: 0.8952 - val_loss: 0.6807 - val_accuracy: 0.8970\n","Epoch 7/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3580 - accuracy: 0.9094 - val_loss: 0.6035 - val_accuracy: 0.9105\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.3142 - accuracy: 0.9189 - val_loss: 0.5741 - val_accuracy: 0.9105\n","Epoch 9/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2897 - accuracy: 0.9231 - val_loss: 0.5040 - val_accuracy: 0.9217\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.2645 - accuracy: 0.9330 - val_loss: 0.5295 - val_accuracy: 0.9001\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2512 - accuracy: 0.9342 - val_loss: 0.4296 - val_accuracy: 0.9437\n","Epoch 12/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2233 - accuracy: 0.9426 - val_loss: 0.4301 - val_accuracy: 0.9311\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2252 - accuracy: 0.9397 - val_loss: 0.4264 - val_accuracy: 0.9289\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2003 - accuracy: 0.9484 - val_loss: 0.3980 - val_accuracy: 0.9386\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1954 - accuracy: 0.9504 - val_loss: 0.3887 - val_accuracy: 0.9406\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1912 - accuracy: 0.9510 - val_loss: 0.3797 - val_accuracy: 0.9406\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1777 - accuracy: 0.9538 - val_loss: 0.3713 - val_accuracy: 0.9439\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1797 - accuracy: 0.9548 - val_loss: 0.3537 - val_accuracy: 0.9362\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1761 - accuracy: 0.9548 - val_loss: 0.3642 - val_accuracy: 0.9443\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1657 - accuracy: 0.9582 - val_loss: 0.3335 - val_accuracy: 0.9441\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1561 - accuracy: 0.9600 - val_loss: 0.3257 - val_accuracy: 0.9514\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1592 - accuracy: 0.9589 - val_loss: 0.3359 - val_accuracy: 0.9501\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1507 - accuracy: 0.9597 - val_loss: 0.3235 - val_accuracy: 0.9582\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1386 - accuracy: 0.9655 - val_loss: 0.3138 - val_accuracy: 0.9593\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1439 - accuracy: 0.9647 - val_loss: 0.3167 - val_accuracy: 0.9569\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1416 - accuracy: 0.9650 - val_loss: 0.3199 - val_accuracy: 0.9492\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1321 - accuracy: 0.9672 - val_loss: 0.3109 - val_accuracy: 0.9457\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1370 - accuracy: 0.9652 - val_loss: 0.3185 - val_accuracy: 0.9450\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1295 - accuracy: 0.9680 - val_loss: 0.3201 - val_accuracy: 0.9523\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1311 - accuracy: 0.9671 - val_loss: 0.3023 - val_accuracy: 0.9615\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1281 - accuracy: 0.9684 - val_loss: 0.3538 - val_accuracy: 0.9406\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1162 - accuracy: 0.9737 - val_loss: 0.2799 - val_accuracy: 0.9637\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1151 - accuracy: 0.9726 - val_loss: 0.2812 - val_accuracy: 0.9606\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1229 - accuracy: 0.9704 - val_loss: 0.2653 - val_accuracy: 0.9553\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1122 - accuracy: 0.9728 - val_loss: 0.2641 - val_accuracy: 0.9646\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1069 - accuracy: 0.9750 - val_loss: 0.2795 - val_accuracy: 0.9527\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1124 - accuracy: 0.9742 - val_loss: 0.2602 - val_accuracy: 0.9694\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1084 - accuracy: 0.9757 - val_loss: 0.3000 - val_accuracy: 0.9459\n","Epoch 39/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1057 - accuracy: 0.9746 - val_loss: 0.2490 - val_accuracy: 0.9683\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1039 - accuracy: 0.9759 - val_loss: 0.2593 - val_accuracy: 0.9670\n","Epoch 41/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0992 - accuracy: 0.9773 - val_loss: 0.2442 - val_accuracy: 0.9690\n","Epoch 42/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0995 - accuracy: 0.9773 - val_loss: 0.2655 - val_accuracy: 0.9562\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0939 - accuracy: 0.9793 - val_loss: 0.2521 - val_accuracy: 0.9677\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1001 - accuracy: 0.9754 - val_loss: 0.2620 - val_accuracy: 0.9575\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0974 - accuracy: 0.9773 - val_loss: 0.2532 - val_accuracy: 0.9677\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0954 - accuracy: 0.9783 - val_loss: 0.2426 - val_accuracy: 0.9736\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0898 - accuracy: 0.9796 - val_loss: 0.2399 - val_accuracy: 0.9701\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0964 - accuracy: 0.9772 - val_loss: 0.2248 - val_accuracy: 0.9756\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0899 - accuracy: 0.9795 - val_loss: 0.2292 - val_accuracy: 0.9705\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0879 - accuracy: 0.9786 - val_loss: 0.2189 - val_accuracy: 0.9725\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0941 - accuracy: 0.9781 - val_loss: 0.2282 - val_accuracy: 0.9663\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0914 - accuracy: 0.9784 - val_loss: 0.2297 - val_accuracy: 0.9762\n","Epoch 53/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0908 - accuracy: 0.9782 - val_loss: 0.2134 - val_accuracy: 0.9776\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0812 - accuracy: 0.9807 - val_loss: 0.3026 - val_accuracy: 0.9551\n","Epoch 55/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0953 - accuracy: 0.9770 - val_loss: 0.2240 - val_accuracy: 0.9714\n","Epoch 56/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0827 - accuracy: 0.9815 - val_loss: 0.2274 - val_accuracy: 0.9716\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0833 - accuracy: 0.9797 - val_loss: 0.2380 - val_accuracy: 0.9688\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0866 - accuracy: 0.9794 - val_loss: 0.6180 - val_accuracy: 0.9384\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0872 - accuracy: 0.9806 - val_loss: 0.2214 - val_accuracy: 0.9721\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0865 - accuracy: 0.9794 - val_loss: 0.2210 - val_accuracy: 0.9754\n","Average Validation Accuracy: 0.9834803640842438\n","Average Validation Loss: 0.12764133140444756\n","Average Test Accuracy: 0.981720358133316\n","------------------------------------------------------------------------\n","\n","Number of input features: 10\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7933 - accuracy: 0.2894 - val_loss: 2.5642 - val_accuracy: 0.5723\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6721 - accuracy: 0.6852 - val_loss: 1.4022 - val_accuracy: 0.7615\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9006 - accuracy: 0.8096 - val_loss: 0.9826 - val_accuracy: 0.8235\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5803 - accuracy: 0.8695 - val_loss: 0.7720 - val_accuracy: 0.8735\n","Epoch 5/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.4373 - accuracy: 0.8962 - val_loss: 0.6644 - val_accuracy: 0.8926\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3595 - accuracy: 0.9118 - val_loss: 0.5230 - val_accuracy: 0.9124\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3065 - accuracy: 0.9267 - val_loss: 0.4850 - val_accuracy: 0.9219\n","Epoch 8/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.2715 - accuracy: 0.9326 - val_loss: 0.4672 - val_accuracy: 0.9248\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2444 - accuracy: 0.9378 - val_loss: 0.4400 - val_accuracy: 0.9212\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2259 - accuracy: 0.9428 - val_loss: 0.4074 - val_accuracy: 0.9342\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2140 - accuracy: 0.9483 - val_loss: 0.4001 - val_accuracy: 0.9481\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2017 - accuracy: 0.9526 - val_loss: 0.5054 - val_accuracy: 0.9144\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1970 - accuracy: 0.9497 - val_loss: 0.3738 - val_accuracy: 0.9393\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1834 - accuracy: 0.9535 - val_loss: 0.3686 - val_accuracy: 0.9413\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1812 - accuracy: 0.9552 - val_loss: 0.3661 - val_accuracy: 0.9430\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1692 - accuracy: 0.9563 - val_loss: 0.3901 - val_accuracy: 0.9237\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1641 - accuracy: 0.9590 - val_loss: 0.3612 - val_accuracy: 0.9342\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1607 - accuracy: 0.9597 - val_loss: 0.3121 - val_accuracy: 0.9538\n","Epoch 19/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1521 - accuracy: 0.9630 - val_loss: 0.3409 - val_accuracy: 0.9496\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1508 - accuracy: 0.9615 - val_loss: 0.2994 - val_accuracy: 0.9650\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1507 - accuracy: 0.9628 - val_loss: 0.2895 - val_accuracy: 0.9611\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1393 - accuracy: 0.9662 - val_loss: 0.2961 - val_accuracy: 0.9551\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1402 - accuracy: 0.9643 - val_loss: 0.3049 - val_accuracy: 0.9589\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1357 - accuracy: 0.9682 - val_loss: 0.2873 - val_accuracy: 0.9602\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1327 - accuracy: 0.9668 - val_loss: 0.2699 - val_accuracy: 0.9661\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1327 - accuracy: 0.9656 - val_loss: 0.2782 - val_accuracy: 0.9703\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1229 - accuracy: 0.9689 - val_loss: 0.2821 - val_accuracy: 0.9639\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1305 - accuracy: 0.9689 - val_loss: 0.2726 - val_accuracy: 0.9721\n","Epoch 29/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1154 - accuracy: 0.9725 - val_loss: 0.2688 - val_accuracy: 0.9754\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1209 - accuracy: 0.9714 - val_loss: 0.2736 - val_accuracy: 0.9701\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1154 - accuracy: 0.9729 - val_loss: 0.2919 - val_accuracy: 0.9694\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1156 - accuracy: 0.9720 - val_loss: 0.2797 - val_accuracy: 0.9646\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1144 - accuracy: 0.9723 - val_loss: 0.2594 - val_accuracy: 0.9694\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1113 - accuracy: 0.9727 - val_loss: 0.2638 - val_accuracy: 0.9736\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1062 - accuracy: 0.9751 - val_loss: 0.2591 - val_accuracy: 0.9705\n","Epoch 36/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1028 - accuracy: 0.9753 - val_loss: 0.2423 - val_accuracy: 0.9745\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1067 - accuracy: 0.9750 - val_loss: 0.2526 - val_accuracy: 0.9710\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1023 - accuracy: 0.9763 - val_loss: 0.2876 - val_accuracy: 0.9492\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0989 - accuracy: 0.9766 - val_loss: 0.2497 - val_accuracy: 0.9765\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1025 - accuracy: 0.9759 - val_loss: 0.2486 - val_accuracy: 0.9817\n","Epoch 41/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0984 - accuracy: 0.9759 - val_loss: 0.2669 - val_accuracy: 0.9646\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0960 - accuracy: 0.9779 - val_loss: 0.2458 - val_accuracy: 0.9835\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0909 - accuracy: 0.9797 - val_loss: 0.3634 - val_accuracy: 0.9652\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1003 - accuracy: 0.9759 - val_loss: 0.2484 - val_accuracy: 0.9725\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0887 - accuracy: 0.9791 - val_loss: 0.2525 - val_accuracy: 0.9817\n","Epoch 46/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0944 - accuracy: 0.9776 - val_loss: 0.2379 - val_accuracy: 0.9776\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0838 - accuracy: 0.9819 - val_loss: 0.2734 - val_accuracy: 0.9771\n","Epoch 48/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0946 - accuracy: 0.9767 - val_loss: 0.2408 - val_accuracy: 0.9806\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0841 - accuracy: 0.9812 - val_loss: 0.2485 - val_accuracy: 0.9806\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0862 - accuracy: 0.9789 - val_loss: 0.2490 - val_accuracy: 0.9820\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0886 - accuracy: 0.9797 - val_loss: 0.2498 - val_accuracy: 0.9800\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0832 - accuracy: 0.9806 - val_loss: 0.2357 - val_accuracy: 0.9855\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0815 - accuracy: 0.9810 - val_loss: 0.2368 - val_accuracy: 0.9844\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0873 - accuracy: 0.9797 - val_loss: 0.2424 - val_accuracy: 0.9828\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0796 - accuracy: 0.9821 - val_loss: 0.2458 - val_accuracy: 0.9738\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0808 - accuracy: 0.9802 - val_loss: 0.2505 - val_accuracy: 0.9762\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0799 - accuracy: 0.9812 - val_loss: 0.2502 - val_accuracy: 0.9804\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9822 - val_loss: 0.2344 - val_accuracy: 0.9864\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0842 - accuracy: 0.9805 - val_loss: 0.2417 - val_accuracy: 0.9844\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0762 - accuracy: 0.9818 - val_loss: 0.2351 - val_accuracy: 0.9793\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.6884 - accuracy: 0.3193 - val_loss: 2.3886 - val_accuracy: 0.5989\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4910 - accuracy: 0.7217 - val_loss: 1.3497 - val_accuracy: 0.7914\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8109 - accuracy: 0.8308 - val_loss: 0.9994 - val_accuracy: 0.8348\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5537 - accuracy: 0.8703 - val_loss: 0.8266 - val_accuracy: 0.8671\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4388 - accuracy: 0.8930 - val_loss: 0.7914 - val_accuracy: 0.8594\n","Epoch 6/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3699 - accuracy: 0.9123 - val_loss: 0.6074 - val_accuracy: 0.8983\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3187 - accuracy: 0.9208 - val_loss: 0.5295 - val_accuracy: 0.9157\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2812 - accuracy: 0.9290 - val_loss: 0.4964 - val_accuracy: 0.9186\n","Epoch 9/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2537 - accuracy: 0.9353 - val_loss: 0.4893 - val_accuracy: 0.9184\n","Epoch 10/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2405 - accuracy: 0.9402 - val_loss: 0.4744 - val_accuracy: 0.9212\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2227 - accuracy: 0.9446 - val_loss: 0.4357 - val_accuracy: 0.9329\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2076 - accuracy: 0.9473 - val_loss: 0.4071 - val_accuracy: 0.9415\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1921 - accuracy: 0.9518 - val_loss: 0.4182 - val_accuracy: 0.9347\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1889 - accuracy: 0.9520 - val_loss: 0.3805 - val_accuracy: 0.9452\n","Epoch 15/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1816 - accuracy: 0.9532 - val_loss: 0.3673 - val_accuracy: 0.9494\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1680 - accuracy: 0.9577 - val_loss: 0.3409 - val_accuracy: 0.9538\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1609 - accuracy: 0.9607 - val_loss: 0.3347 - val_accuracy: 0.9446\n","Epoch 18/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1537 - accuracy: 0.9627 - val_loss: 0.3173 - val_accuracy: 0.9639\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1526 - accuracy: 0.9598 - val_loss: 0.3532 - val_accuracy: 0.9542\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1486 - accuracy: 0.9643 - val_loss: 0.3332 - val_accuracy: 0.9503\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1408 - accuracy: 0.9651 - val_loss: 0.3116 - val_accuracy: 0.9597\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1359 - accuracy: 0.9653 - val_loss: 0.3480 - val_accuracy: 0.9509\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1413 - accuracy: 0.9662 - val_loss: 0.3802 - val_accuracy: 0.9406\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1337 - accuracy: 0.9676 - val_loss: 0.3063 - val_accuracy: 0.9562\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1197 - accuracy: 0.9716 - val_loss: 0.4154 - val_accuracy: 0.9443\n","Epoch 26/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1283 - accuracy: 0.9678 - val_loss: 0.3093 - val_accuracy: 0.9560\n","Epoch 27/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1214 - accuracy: 0.9695 - val_loss: 0.2865 - val_accuracy: 0.9650\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1184 - accuracy: 0.9724 - val_loss: 0.2902 - val_accuracy: 0.9729\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1139 - accuracy: 0.9729 - val_loss: 0.3272 - val_accuracy: 0.9578\n","Epoch 30/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1195 - accuracy: 0.9705 - val_loss: 0.3067 - val_accuracy: 0.9573\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1106 - accuracy: 0.9740 - val_loss: 0.2899 - val_accuracy: 0.9608\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1079 - accuracy: 0.9753 - val_loss: 0.2842 - val_accuracy: 0.9619\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1088 - accuracy: 0.9744 - val_loss: 0.2958 - val_accuracy: 0.9677\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1082 - accuracy: 0.9752 - val_loss: 0.2924 - val_accuracy: 0.9586\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1028 - accuracy: 0.9772 - val_loss: 0.2781 - val_accuracy: 0.9657\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1006 - accuracy: 0.9767 - val_loss: 0.2692 - val_accuracy: 0.9758\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1025 - accuracy: 0.9765 - val_loss: 0.2855 - val_accuracy: 0.9652\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0969 - accuracy: 0.9772 - val_loss: 0.2976 - val_accuracy: 0.9703\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0974 - accuracy: 0.9779 - val_loss: 0.2597 - val_accuracy: 0.9707\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0990 - accuracy: 0.9762 - val_loss: 0.2636 - val_accuracy: 0.9714\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0967 - accuracy: 0.9772 - val_loss: 0.2602 - val_accuracy: 0.9727\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0947 - accuracy: 0.9788 - val_loss: 0.2829 - val_accuracy: 0.9716\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0916 - accuracy: 0.9795 - val_loss: 0.2863 - val_accuracy: 0.9646\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0914 - accuracy: 0.9790 - val_loss: 0.2616 - val_accuracy: 0.9727\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0901 - accuracy: 0.9792 - val_loss: 0.2670 - val_accuracy: 0.9683\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0909 - accuracy: 0.9793 - val_loss: 0.2494 - val_accuracy: 0.9771\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0914 - accuracy: 0.9803 - val_loss: 0.2538 - val_accuracy: 0.9740\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0871 - accuracy: 0.9820 - val_loss: 0.2399 - val_accuracy: 0.9734\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0894 - accuracy: 0.9790 - val_loss: 0.2555 - val_accuracy: 0.9723\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0789 - accuracy: 0.9834 - val_loss: 0.2552 - val_accuracy: 0.9729\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0866 - accuracy: 0.9800 - val_loss: 0.2922 - val_accuracy: 0.9573\n","Epoch 52/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0826 - accuracy: 0.9802 - val_loss: 0.2417 - val_accuracy: 0.9699\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9782 - val_loss: 0.2463 - val_accuracy: 0.9756\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0750 - accuracy: 0.9843 - val_loss: 0.2422 - val_accuracy: 0.9727\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0821 - accuracy: 0.9821 - val_loss: 0.2511 - val_accuracy: 0.9699\n","Epoch 56/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0816 - accuracy: 0.9818 - val_loss: 0.2503 - val_accuracy: 0.9703\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0804 - accuracy: 0.9810 - val_loss: 0.2363 - val_accuracy: 0.9718\n","Epoch 58/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0844 - accuracy: 0.9792 - val_loss: 0.2437 - val_accuracy: 0.9690\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0764 - accuracy: 0.9831 - val_loss: 0.2236 - val_accuracy: 0.9765\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9808 - val_loss: 0.2280 - val_accuracy: 0.9791\n","Average Validation Accuracy: 0.9832989275455475\n","Average Validation Loss: 0.12229323759675026\n","Average Test Accuracy: 0.9820151925086975\n","------------------------------------------------------------------------\n","\n","Number of input features: 11\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.7505 - accuracy: 0.3218 - val_loss: 2.4272 - val_accuracy: 0.5919\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6146 - accuracy: 0.7016 - val_loss: 1.4207 - val_accuracy: 0.7567\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9174 - accuracy: 0.8088 - val_loss: 0.9754 - val_accuracy: 0.8183\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5969 - accuracy: 0.8636 - val_loss: 0.7632 - val_accuracy: 0.8695\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4598 - accuracy: 0.8891 - val_loss: 0.6569 - val_accuracy: 0.8704\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3728 - accuracy: 0.9065 - val_loss: 0.5851 - val_accuracy: 0.8915\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3291 - accuracy: 0.9172 - val_loss: 0.4933 - val_accuracy: 0.9131\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2864 - accuracy: 0.9282 - val_loss: 0.4505 - val_accuracy: 0.9230\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2655 - accuracy: 0.9334 - val_loss: 0.4612 - val_accuracy: 0.9036\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2439 - accuracy: 0.9376 - val_loss: 0.5033 - val_accuracy: 0.9155\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2286 - accuracy: 0.9430 - val_loss: 0.3848 - val_accuracy: 0.9305\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2145 - accuracy: 0.9472 - val_loss: 0.3941 - val_accuracy: 0.9362\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2034 - accuracy: 0.9487 - val_loss: 0.3916 - val_accuracy: 0.9448\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1869 - accuracy: 0.9537 - val_loss: 0.3595 - val_accuracy: 0.9589\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1864 - accuracy: 0.9531 - val_loss: 0.3498 - val_accuracy: 0.9551\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1745 - accuracy: 0.9546 - val_loss: 0.3450 - val_accuracy: 0.9496\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1723 - accuracy: 0.9563 - val_loss: 0.3542 - val_accuracy: 0.9446\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1640 - accuracy: 0.9598 - val_loss: 0.3350 - val_accuracy: 0.9595\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1627 - accuracy: 0.9582 - val_loss: 0.3160 - val_accuracy: 0.9443\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1474 - accuracy: 0.9628 - val_loss: 0.3017 - val_accuracy: 0.9602\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1500 - accuracy: 0.9615 - val_loss: 0.3321 - val_accuracy: 0.9452\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1498 - accuracy: 0.9630 - val_loss: 0.3096 - val_accuracy: 0.9525\n","Epoch 23/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1446 - accuracy: 0.9635 - val_loss: 0.3536 - val_accuracy: 0.9441\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1391 - accuracy: 0.9654 - val_loss: 0.3054 - val_accuracy: 0.9556\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1305 - accuracy: 0.9664 - val_loss: 0.3041 - val_accuracy: 0.9512\n","Epoch 26/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1297 - accuracy: 0.9679 - val_loss: 0.2879 - val_accuracy: 0.9525\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1248 - accuracy: 0.9689 - val_loss: 0.3043 - val_accuracy: 0.9578\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1301 - accuracy: 0.9657 - val_loss: 0.2837 - val_accuracy: 0.9586\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1216 - accuracy: 0.9687 - val_loss: 0.2961 - val_accuracy: 0.9589\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1193 - accuracy: 0.9708 - val_loss: 0.2673 - val_accuracy: 0.9762\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1174 - accuracy: 0.9723 - val_loss: 0.2887 - val_accuracy: 0.9615\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1142 - accuracy: 0.9726 - val_loss: 0.2877 - val_accuracy: 0.9723\n","Epoch 33/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1072 - accuracy: 0.9745 - val_loss: 0.2835 - val_accuracy: 0.9600\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1160 - accuracy: 0.9724 - val_loss: 0.2606 - val_accuracy: 0.9804\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1013 - accuracy: 0.9754 - val_loss: 0.2742 - val_accuracy: 0.9773\n","Epoch 36/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1068 - accuracy: 0.9755 - val_loss: 0.2844 - val_accuracy: 0.9659\n","Epoch 37/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1003 - accuracy: 0.9758 - val_loss: 0.2554 - val_accuracy: 0.9822\n","Epoch 38/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9754 - val_loss: 0.2981 - val_accuracy: 0.9685\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0957 - accuracy: 0.9784 - val_loss: 0.2650 - val_accuracy: 0.9787\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1018 - accuracy: 0.9747 - val_loss: 0.2664 - val_accuracy: 0.9734\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0954 - accuracy: 0.9781 - val_loss: 0.2553 - val_accuracy: 0.9848\n","Epoch 42/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1016 - accuracy: 0.9758 - val_loss: 0.2692 - val_accuracy: 0.9767\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0886 - accuracy: 0.9798 - val_loss: 0.2704 - val_accuracy: 0.9773\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0895 - accuracy: 0.9798 - val_loss: 0.2716 - val_accuracy: 0.9692\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0961 - accuracy: 0.9773 - val_loss: 0.2773 - val_accuracy: 0.9773\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0863 - accuracy: 0.9805 - val_loss: 0.2747 - val_accuracy: 0.9723\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0909 - accuracy: 0.9785 - val_loss: 0.2920 - val_accuracy: 0.9611\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0884 - accuracy: 0.9785 - val_loss: 0.2515 - val_accuracy: 0.9837\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0854 - accuracy: 0.9791 - val_loss: 0.2761 - val_accuracy: 0.9769\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0865 - accuracy: 0.9797 - val_loss: 0.2497 - val_accuracy: 0.9859\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0781 - accuracy: 0.9830 - val_loss: 0.2608 - val_accuracy: 0.9820\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0873 - accuracy: 0.9790 - val_loss: 0.3373 - val_accuracy: 0.9540\n","Epoch 53/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0839 - accuracy: 0.9796 - val_loss: 0.2586 - val_accuracy: 0.9815\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0794 - accuracy: 0.9827 - val_loss: 0.2779 - val_accuracy: 0.9745\n","Epoch 55/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0842 - accuracy: 0.9801 - val_loss: 0.2574 - val_accuracy: 0.9782\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0813 - accuracy: 0.9811 - val_loss: 0.2555 - val_accuracy: 0.9809\n","Epoch 57/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0758 - accuracy: 0.9831 - val_loss: 0.2961 - val_accuracy: 0.9710\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0827 - accuracy: 0.9797 - val_loss: 0.2589 - val_accuracy: 0.9844\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0754 - accuracy: 0.9835 - val_loss: 0.2793 - val_accuracy: 0.9685\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0793 - accuracy: 0.9820 - val_loss: 0.2675 - val_accuracy: 0.9743\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.5642 - accuracy: 0.3664 - val_loss: 2.2224 - val_accuracy: 0.6636\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4096 - accuracy: 0.7359 - val_loss: 1.3233 - val_accuracy: 0.7978\n","Epoch 3/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7635 - accuracy: 0.8455 - val_loss: 0.9176 - val_accuracy: 0.8717\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5052 - accuracy: 0.8825 - val_loss: 0.7452 - val_accuracy: 0.8796\n","Epoch 5/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.3849 - accuracy: 0.9087 - val_loss: 0.5968 - val_accuracy: 0.8979\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3237 - accuracy: 0.9183 - val_loss: 0.5379 - val_accuracy: 0.9186\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2731 - accuracy: 0.9314 - val_loss: 0.4442 - val_accuracy: 0.9184\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2527 - accuracy: 0.9356 - val_loss: 0.4314 - val_accuracy: 0.9311\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2217 - accuracy: 0.9456 - val_loss: 0.4319 - val_accuracy: 0.9204\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2104 - accuracy: 0.9468 - val_loss: 0.3727 - val_accuracy: 0.9331\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2081 - accuracy: 0.9497 - val_loss: 0.3785 - val_accuracy: 0.9393\n","Epoch 12/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1890 - accuracy: 0.9536 - val_loss: 0.3972 - val_accuracy: 0.9272\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1806 - accuracy: 0.9561 - val_loss: 0.3397 - val_accuracy: 0.9450\n","Epoch 14/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1749 - accuracy: 0.9572 - val_loss: 0.3278 - val_accuracy: 0.9479\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1682 - accuracy: 0.9583 - val_loss: 0.3343 - val_accuracy: 0.9450\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1643 - accuracy: 0.9584 - val_loss: 0.3043 - val_accuracy: 0.9578\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1538 - accuracy: 0.9623 - val_loss: 0.3193 - val_accuracy: 0.9336\n","Epoch 18/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1495 - accuracy: 0.9638 - val_loss: 0.3074 - val_accuracy: 0.9538\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1442 - accuracy: 0.9646 - val_loss: 0.2908 - val_accuracy: 0.9549\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1438 - accuracy: 0.9646 - val_loss: 0.3063 - val_accuracy: 0.9602\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1316 - accuracy: 0.9698 - val_loss: 0.2843 - val_accuracy: 0.9600\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1364 - accuracy: 0.9674 - val_loss: 0.2820 - val_accuracy: 0.9580\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1198 - accuracy: 0.9712 - val_loss: 0.3059 - val_accuracy: 0.9443\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1327 - accuracy: 0.9690 - val_loss: 0.2691 - val_accuracy: 0.9681\n","Epoch 25/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1195 - accuracy: 0.9716 - val_loss: 0.2606 - val_accuracy: 0.9710\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1181 - accuracy: 0.9733 - val_loss: 0.2804 - val_accuracy: 0.9578\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1127 - accuracy: 0.9733 - val_loss: 0.2729 - val_accuracy: 0.9657\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1145 - accuracy: 0.9740 - val_loss: 0.2770 - val_accuracy: 0.9542\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1096 - accuracy: 0.9749 - val_loss: 0.2577 - val_accuracy: 0.9745\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1080 - accuracy: 0.9762 - val_loss: 0.2776 - val_accuracy: 0.9611\n","Epoch 31/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1083 - accuracy: 0.9763 - val_loss: 0.2776 - val_accuracy: 0.9641\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1022 - accuracy: 0.9758 - val_loss: 0.2780 - val_accuracy: 0.9701\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0991 - accuracy: 0.9790 - val_loss: 0.2750 - val_accuracy: 0.9661\n","Epoch 34/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0929 - accuracy: 0.9805 - val_loss: 0.2569 - val_accuracy: 0.9615\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1063 - accuracy: 0.9751 - val_loss: 0.2645 - val_accuracy: 0.9617\n","Epoch 36/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0893 - accuracy: 0.9814 - val_loss: 0.2579 - val_accuracy: 0.9679\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1065 - accuracy: 0.9759 - val_loss: 0.2444 - val_accuracy: 0.9714\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0909 - accuracy: 0.9784 - val_loss: 0.2530 - val_accuracy: 0.9679\n","Epoch 39/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0908 - accuracy: 0.9807 - val_loss: 0.2670 - val_accuracy: 0.9681\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0920 - accuracy: 0.9793 - val_loss: 0.2539 - val_accuracy: 0.9707\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0901 - accuracy: 0.9791 - val_loss: 0.2673 - val_accuracy: 0.9683\n","Epoch 42/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0857 - accuracy: 0.9814 - val_loss: 0.2597 - val_accuracy: 0.9679\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0857 - accuracy: 0.9815 - val_loss: 0.2697 - val_accuracy: 0.9727\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0904 - accuracy: 0.9798 - val_loss: 0.2438 - val_accuracy: 0.9751\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0822 - accuracy: 0.9816 - val_loss: 0.2500 - val_accuracy: 0.9740\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0778 - accuracy: 0.9829 - val_loss: 0.2840 - val_accuracy: 0.9608\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0837 - accuracy: 0.9803 - val_loss: 0.2658 - val_accuracy: 0.9540\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0842 - accuracy: 0.9803 - val_loss: 0.3041 - val_accuracy: 0.9584\n","Epoch 49/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0775 - accuracy: 0.9830 - val_loss: 0.2679 - val_accuracy: 0.9633\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0782 - accuracy: 0.9819 - val_loss: 0.2514 - val_accuracy: 0.9674\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0827 - accuracy: 0.9806 - val_loss: 0.2551 - val_accuracy: 0.9668\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0750 - accuracy: 0.9816 - val_loss: 0.2837 - val_accuracy: 0.9624\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0784 - accuracy: 0.9819 - val_loss: 0.2546 - val_accuracy: 0.9650\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0786 - accuracy: 0.9818 - val_loss: 0.2393 - val_accuracy: 0.9798\n","Epoch 55/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0772 - accuracy: 0.9823 - val_loss: 0.2709 - val_accuracy: 0.9679\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0771 - accuracy: 0.9826 - val_loss: 0.2745 - val_accuracy: 0.9707\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0807 - accuracy: 0.9816 - val_loss: 0.2625 - val_accuracy: 0.9723\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0710 - accuracy: 0.9837 - val_loss: 0.2452 - val_accuracy: 0.9758\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0714 - accuracy: 0.9835 - val_loss: 0.2444 - val_accuracy: 0.9740\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0787 - accuracy: 0.9815 - val_loss: 0.2413 - val_accuracy: 0.9789\n","Average Validation Accuracy: 0.9817741215229034\n","Average Validation Loss: 0.13208051398396492\n","Average Test Accuracy: 0.980798989534378\n","------------------------------------------------------------------------\n","\n","Number of input features: 12\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.8779 - accuracy: 0.2594 - val_loss: 2.7541 - val_accuracy: 0.5256\n","Epoch 2/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.8301 - accuracy: 0.6636 - val_loss: 1.5405 - val_accuracy: 0.7360\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9720 - accuracy: 0.8040 - val_loss: 1.1493 - val_accuracy: 0.8066\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6384 - accuracy: 0.8571 - val_loss: 0.8254 - val_accuracy: 0.8574\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4793 - accuracy: 0.8880 - val_loss: 0.7534 - val_accuracy: 0.8700\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3930 - accuracy: 0.9044 - val_loss: 0.6973 - val_accuracy: 0.8770\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3386 - accuracy: 0.9158 - val_loss: 0.6030 - val_accuracy: 0.9023\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3058 - accuracy: 0.9248 - val_loss: 0.5622 - val_accuracy: 0.9131\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2833 - accuracy: 0.9278 - val_loss: 0.5091 - val_accuracy: 0.9173\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2602 - accuracy: 0.9353 - val_loss: 0.4604 - val_accuracy: 0.9340\n","Epoch 11/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2470 - accuracy: 0.9371 - val_loss: 0.4372 - val_accuracy: 0.9373\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2321 - accuracy: 0.9416 - val_loss: 0.4124 - val_accuracy: 0.9404\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2221 - accuracy: 0.9427 - val_loss: 0.4191 - val_accuracy: 0.9395\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2086 - accuracy: 0.9487 - val_loss: 0.4128 - val_accuracy: 0.9364\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1967 - accuracy: 0.9510 - val_loss: 0.4080 - val_accuracy: 0.9430\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1906 - accuracy: 0.9518 - val_loss: 0.4213 - val_accuracy: 0.9263\n","Epoch 17/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1927 - accuracy: 0.9504 - val_loss: 0.3961 - val_accuracy: 0.9446\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1732 - accuracy: 0.9571 - val_loss: 0.3685 - val_accuracy: 0.9470\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1643 - accuracy: 0.9592 - val_loss: 0.3723 - val_accuracy: 0.9481\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1748 - accuracy: 0.9551 - val_loss: 0.3831 - val_accuracy: 0.9428\n","Epoch 21/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1554 - accuracy: 0.9591 - val_loss: 0.3590 - val_accuracy: 0.9487\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1528 - accuracy: 0.9621 - val_loss: 0.3702 - val_accuracy: 0.9448\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1518 - accuracy: 0.9625 - val_loss: 0.3771 - val_accuracy: 0.9538\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1424 - accuracy: 0.9646 - val_loss: 0.3554 - val_accuracy: 0.9650\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1495 - accuracy: 0.9626 - val_loss: 0.3476 - val_accuracy: 0.9496\n","Epoch 26/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1373 - accuracy: 0.9666 - val_loss: 0.3273 - val_accuracy: 0.9617\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1370 - accuracy: 0.9676 - val_loss: 0.3254 - val_accuracy: 0.9637\n","Epoch 28/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1322 - accuracy: 0.9688 - val_loss: 0.3262 - val_accuracy: 0.9580\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1320 - accuracy: 0.9680 - val_loss: 0.3221 - val_accuracy: 0.9710\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1263 - accuracy: 0.9689 - val_loss: 0.3283 - val_accuracy: 0.9615\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1314 - accuracy: 0.9676 - val_loss: 0.3265 - val_accuracy: 0.9663\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1200 - accuracy: 0.9721 - val_loss: 0.3312 - val_accuracy: 0.9699\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1295 - accuracy: 0.9681 - val_loss: 0.3220 - val_accuracy: 0.9646\n","Epoch 34/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1150 - accuracy: 0.9726 - val_loss: 0.3290 - val_accuracy: 0.9648\n","Epoch 35/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1169 - accuracy: 0.9731 - val_loss: 0.3219 - val_accuracy: 0.9593\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1107 - accuracy: 0.9734 - val_loss: 0.3250 - val_accuracy: 0.9637\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1154 - accuracy: 0.9718 - val_loss: 0.3295 - val_accuracy: 0.9641\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1072 - accuracy: 0.9739 - val_loss: 0.3201 - val_accuracy: 0.9668\n","Epoch 39/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1124 - accuracy: 0.9732 - val_loss: 0.3192 - val_accuracy: 0.9740\n","Epoch 40/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1051 - accuracy: 0.9759 - val_loss: 0.3062 - val_accuracy: 0.9734\n","Epoch 41/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1062 - accuracy: 0.9755 - val_loss: 0.3051 - val_accuracy: 0.9758\n","Epoch 42/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0976 - accuracy: 0.9784 - val_loss: 0.3404 - val_accuracy: 0.9602\n","Epoch 43/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1107 - accuracy: 0.9747 - val_loss: 0.3003 - val_accuracy: 0.9743\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0929 - accuracy: 0.9798 - val_loss: 0.3013 - val_accuracy: 0.9760\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1014 - accuracy: 0.9767 - val_loss: 0.3084 - val_accuracy: 0.9760\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0901 - accuracy: 0.9794 - val_loss: 0.3224 - val_accuracy: 0.9743\n","Epoch 47/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1094 - accuracy: 0.9746 - val_loss: 0.3185 - val_accuracy: 0.9721\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0897 - accuracy: 0.9792 - val_loss: 0.2931 - val_accuracy: 0.9771\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0988 - accuracy: 0.9775 - val_loss: 0.3185 - val_accuracy: 0.9716\n","Epoch 50/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0859 - accuracy: 0.9809 - val_loss: 0.3198 - val_accuracy: 0.9747\n","Epoch 51/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0914 - accuracy: 0.9803 - val_loss: 0.3124 - val_accuracy: 0.9716\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0948 - accuracy: 0.9770 - val_loss: 0.3002 - val_accuracy: 0.9791\n","Epoch 53/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0829 - accuracy: 0.9812 - val_loss: 0.3034 - val_accuracy: 0.9784\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0889 - accuracy: 0.9796 - val_loss: 0.2929 - val_accuracy: 0.9756\n","Epoch 55/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0865 - accuracy: 0.9801 - val_loss: 0.3062 - val_accuracy: 0.9760\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0864 - accuracy: 0.9799 - val_loss: 0.2909 - val_accuracy: 0.9800\n","Epoch 57/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0818 - accuracy: 0.9825 - val_loss: 0.2997 - val_accuracy: 0.9802\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0881 - accuracy: 0.9804 - val_loss: 0.3155 - val_accuracy: 0.9778\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0842 - accuracy: 0.9820 - val_loss: 0.3017 - val_accuracy: 0.9813\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0816 - accuracy: 0.9810 - val_loss: 0.3883 - val_accuracy: 0.9479\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.5777 - accuracy: 0.3567 - val_loss: 2.2691 - val_accuracy: 0.6495\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3900 - accuracy: 0.7411 - val_loss: 1.3135 - val_accuracy: 0.8134\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7239 - accuracy: 0.8494 - val_loss: 0.9497 - val_accuracy: 0.8618\n","Epoch 4/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4801 - accuracy: 0.8930 - val_loss: 0.7628 - val_accuracy: 0.8860\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3732 - accuracy: 0.9104 - val_loss: 0.6592 - val_accuracy: 0.8957\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3205 - accuracy: 0.9225 - val_loss: 0.5654 - val_accuracy: 0.9135\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2779 - accuracy: 0.9333 - val_loss: 0.4857 - val_accuracy: 0.9298\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2416 - accuracy: 0.9403 - val_loss: 0.4681 - val_accuracy: 0.9322\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2373 - accuracy: 0.9418 - val_loss: 0.4781 - val_accuracy: 0.9267\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2158 - accuracy: 0.9501 - val_loss: 0.4072 - val_accuracy: 0.9406\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2037 - accuracy: 0.9499 - val_loss: 0.4098 - val_accuracy: 0.9331\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1836 - accuracy: 0.9550 - val_loss: 0.3690 - val_accuracy: 0.9494\n","Epoch 13/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1840 - accuracy: 0.9538 - val_loss: 0.3703 - val_accuracy: 0.9443\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1656 - accuracy: 0.9600 - val_loss: 0.3867 - val_accuracy: 0.9437\n","Epoch 15/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1674 - accuracy: 0.9601 - val_loss: 0.3557 - val_accuracy: 0.9534\n","Epoch 16/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1657 - accuracy: 0.9579 - val_loss: 0.3247 - val_accuracy: 0.9597\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1484 - accuracy: 0.9641 - val_loss: 0.3305 - val_accuracy: 0.9527\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1535 - accuracy: 0.9625 - val_loss: 0.3208 - val_accuracy: 0.9494\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1375 - accuracy: 0.9676 - val_loss: 0.3128 - val_accuracy: 0.9628\n","Epoch 20/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1378 - accuracy: 0.9677 - val_loss: 0.3273 - val_accuracy: 0.9496\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1390 - accuracy: 0.9659 - val_loss: 0.3362 - val_accuracy: 0.9481\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1339 - accuracy: 0.9679 - val_loss: 0.3151 - val_accuracy: 0.9628\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1238 - accuracy: 0.9724 - val_loss: 0.3051 - val_accuracy: 0.9619\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1292 - accuracy: 0.9703 - val_loss: 0.3034 - val_accuracy: 0.9580\n","Epoch 25/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1237 - accuracy: 0.9712 - val_loss: 0.3070 - val_accuracy: 0.9611\n","Epoch 26/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1213 - accuracy: 0.9725 - val_loss: 0.3004 - val_accuracy: 0.9637\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1106 - accuracy: 0.9760 - val_loss: 0.2892 - val_accuracy: 0.9666\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1237 - accuracy: 0.9719 - val_loss: 0.3078 - val_accuracy: 0.9650\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1077 - accuracy: 0.9764 - val_loss: 0.3547 - val_accuracy: 0.9479\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1101 - accuracy: 0.9754 - val_loss: 0.2923 - val_accuracy: 0.9655\n","Epoch 31/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1050 - accuracy: 0.9759 - val_loss: 0.2748 - val_accuracy: 0.9718\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1081 - accuracy: 0.9762 - val_loss: 0.2921 - val_accuracy: 0.9637\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1050 - accuracy: 0.9765 - val_loss: 0.2788 - val_accuracy: 0.9597\n","Epoch 34/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1021 - accuracy: 0.9783 - val_loss: 0.2809 - val_accuracy: 0.9681\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1107 - accuracy: 0.9763 - val_loss: 0.2749 - val_accuracy: 0.9701\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0955 - accuracy: 0.9778 - val_loss: 0.2826 - val_accuracy: 0.9602\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0967 - accuracy: 0.9777 - val_loss: 0.2710 - val_accuracy: 0.9633\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0960 - accuracy: 0.9791 - val_loss: 0.2671 - val_accuracy: 0.9725\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0930 - accuracy: 0.9794 - val_loss: 0.2541 - val_accuracy: 0.9773\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0915 - accuracy: 0.9797 - val_loss: 0.2669 - val_accuracy: 0.9690\n","Epoch 41/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0993 - accuracy: 0.9786 - val_loss: 0.2591 - val_accuracy: 0.9707\n","Epoch 42/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0952 - accuracy: 0.9781 - val_loss: 0.2495 - val_accuracy: 0.9712\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0921 - accuracy: 0.9793 - val_loss: 0.2672 - val_accuracy: 0.9694\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0971 - accuracy: 0.9778 - val_loss: 0.2605 - val_accuracy: 0.9710\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0855 - accuracy: 0.9800 - val_loss: 0.2682 - val_accuracy: 0.9661\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0844 - accuracy: 0.9804 - val_loss: 0.2539 - val_accuracy: 0.9701\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0902 - accuracy: 0.9803 - val_loss: 0.2649 - val_accuracy: 0.9670\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0870 - accuracy: 0.9807 - val_loss: 0.2493 - val_accuracy: 0.9714\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0798 - accuracy: 0.9830 - val_loss: 0.2476 - val_accuracy: 0.9738\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0901 - accuracy: 0.9793 - val_loss: 0.2472 - val_accuracy: 0.9776\n","Epoch 51/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0792 - accuracy: 0.9813 - val_loss: 0.2508 - val_accuracy: 0.9784\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0876 - accuracy: 0.9809 - val_loss: 0.2535 - val_accuracy: 0.9745\n","Epoch 53/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0802 - accuracy: 0.9810 - val_loss: 0.2722 - val_accuracy: 0.9655\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0777 - accuracy: 0.9837 - val_loss: 0.2761 - val_accuracy: 0.9531\n","Epoch 55/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0839 - accuracy: 0.9821 - val_loss: 0.2398 - val_accuracy: 0.9734\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0755 - accuracy: 0.9841 - val_loss: 0.2683 - val_accuracy: 0.9694\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0831 - accuracy: 0.9807 - val_loss: 0.2458 - val_accuracy: 0.9758\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0726 - accuracy: 0.9841 - val_loss: 0.2494 - val_accuracy: 0.9734\n","Epoch 59/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0788 - accuracy: 0.9819 - val_loss: 0.2591 - val_accuracy: 0.9707\n","Epoch 60/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0721 - accuracy: 0.9839 - val_loss: 0.2846 - val_accuracy: 0.9619\n","Average Validation Accuracy: 0.9623136818408966\n","Average Validation Loss: 0.1993451863527298\n","Average Test Accuracy: 0.9619665443897247\n","------------------------------------------------------------------------\n","\n","Number of input features: 13\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.5440 - accuracy: 0.3557 - val_loss: 2.2555 - val_accuracy: 0.6438\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4455 - accuracy: 0.7316 - val_loss: 1.4074 - val_accuracy: 0.7492\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8063 - accuracy: 0.8237 - val_loss: 0.8982 - val_accuracy: 0.8420\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5552 - accuracy: 0.8694 - val_loss: 0.7584 - val_accuracy: 0.8777\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4429 - accuracy: 0.8948 - val_loss: 0.6502 - val_accuracy: 0.8733\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3746 - accuracy: 0.9047 - val_loss: 0.5777 - val_accuracy: 0.8902\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3273 - accuracy: 0.9152 - val_loss: 0.5821 - val_accuracy: 0.8964\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3015 - accuracy: 0.9189 - val_loss: 0.5408 - val_accuracy: 0.8909\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2704 - accuracy: 0.9307 - val_loss: 0.4770 - val_accuracy: 0.9234\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2536 - accuracy: 0.9345 - val_loss: 0.4398 - val_accuracy: 0.9340\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2367 - accuracy: 0.9385 - val_loss: 0.4251 - val_accuracy: 0.9263\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2241 - accuracy: 0.9421 - val_loss: 0.4277 - val_accuracy: 0.9355\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2080 - accuracy: 0.9479 - val_loss: 0.4145 - val_accuracy: 0.9305\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1989 - accuracy: 0.9501 - val_loss: 0.3854 - val_accuracy: 0.9494\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1929 - accuracy: 0.9501 - val_loss: 0.3849 - val_accuracy: 0.9457\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1823 - accuracy: 0.9549 - val_loss: 0.3542 - val_accuracy: 0.9518\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1772 - accuracy: 0.9560 - val_loss: 0.3490 - val_accuracy: 0.9483\n","Epoch 18/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1741 - accuracy: 0.9570 - val_loss: 0.3470 - val_accuracy: 0.9459\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1640 - accuracy: 0.9591 - val_loss: 0.3656 - val_accuracy: 0.9443\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1555 - accuracy: 0.9627 - val_loss: 0.3565 - val_accuracy: 0.9540\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1519 - accuracy: 0.9633 - val_loss: 0.3284 - val_accuracy: 0.9635\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1498 - accuracy: 0.9630 - val_loss: 0.3313 - val_accuracy: 0.9595\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1499 - accuracy: 0.9625 - val_loss: 0.3267 - val_accuracy: 0.9560\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1447 - accuracy: 0.9652 - val_loss: 0.3196 - val_accuracy: 0.9578\n","Epoch 25/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1410 - accuracy: 0.9653 - val_loss: 0.3253 - val_accuracy: 0.9582\n","Epoch 26/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1396 - accuracy: 0.9669 - val_loss: 0.3249 - val_accuracy: 0.9571\n","Epoch 27/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1339 - accuracy: 0.9674 - val_loss: 0.3020 - val_accuracy: 0.9683\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1356 - accuracy: 0.9675 - val_loss: 0.3131 - val_accuracy: 0.9608\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1213 - accuracy: 0.9708 - val_loss: 0.2934 - val_accuracy: 0.9712\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1363 - accuracy: 0.9654 - val_loss: 0.3002 - val_accuracy: 0.9668\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1182 - accuracy: 0.9719 - val_loss: 0.3207 - val_accuracy: 0.9604\n","Epoch 32/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1275 - accuracy: 0.9684 - val_loss: 0.3130 - val_accuracy: 0.9608\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1169 - accuracy: 0.9729 - val_loss: 0.3078 - val_accuracy: 0.9619\n","Epoch 34/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1224 - accuracy: 0.9711 - val_loss: 0.2932 - val_accuracy: 0.9740\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1165 - accuracy: 0.9727 - val_loss: 0.2984 - val_accuracy: 0.9688\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1166 - accuracy: 0.9720 - val_loss: 0.3413 - val_accuracy: 0.9545\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1155 - accuracy: 0.9729 - val_loss: 0.3100 - val_accuracy: 0.9644\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1160 - accuracy: 0.9724 - val_loss: 0.3269 - val_accuracy: 0.9644\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1089 - accuracy: 0.9741 - val_loss: 0.2927 - val_accuracy: 0.9696\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1117 - accuracy: 0.9741 - val_loss: 0.2982 - val_accuracy: 0.9696\n","Epoch 41/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1100 - accuracy: 0.9741 - val_loss: 0.3722 - val_accuracy: 0.9481\n","Epoch 42/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1058 - accuracy: 0.9755 - val_loss: 0.3017 - val_accuracy: 0.9705\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1008 - accuracy: 0.9762 - val_loss: 0.3025 - val_accuracy: 0.9683\n","Epoch 44/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0985 - accuracy: 0.9760 - val_loss: 0.2862 - val_accuracy: 0.9694\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1040 - accuracy: 0.9755 - val_loss: 0.2925 - val_accuracy: 0.9729\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0958 - accuracy: 0.9782 - val_loss: 0.2985 - val_accuracy: 0.9727\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1020 - accuracy: 0.9764 - val_loss: 0.2947 - val_accuracy: 0.9760\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0952 - accuracy: 0.9782 - val_loss: 0.3054 - val_accuracy: 0.9688\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0952 - accuracy: 0.9757 - val_loss: 0.3106 - val_accuracy: 0.9633\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0984 - accuracy: 0.9773 - val_loss: 0.2901 - val_accuracy: 0.9762\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0947 - accuracy: 0.9786 - val_loss: 0.3025 - val_accuracy: 0.9716\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0951 - accuracy: 0.9772 - val_loss: 0.3123 - val_accuracy: 0.9714\n","Epoch 53/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0901 - accuracy: 0.9788 - val_loss: 0.2907 - val_accuracy: 0.9751\n","Epoch 54/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0872 - accuracy: 0.9799 - val_loss: 0.3016 - val_accuracy: 0.9732\n","Epoch 55/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0921 - accuracy: 0.9795 - val_loss: 0.3040 - val_accuracy: 0.9725\n","Epoch 56/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0876 - accuracy: 0.9794 - val_loss: 0.2939 - val_accuracy: 0.9767\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0880 - accuracy: 0.9790 - val_loss: 0.2949 - val_accuracy: 0.9773\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0892 - accuracy: 0.9781 - val_loss: 0.2852 - val_accuracy: 0.9798\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0887 - accuracy: 0.9799 - val_loss: 0.3091 - val_accuracy: 0.9758\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0870 - accuracy: 0.9790 - val_loss: 0.3158 - val_accuracy: 0.9773\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.5643 - accuracy: 0.3530 - val_loss: 2.2910 - val_accuracy: 0.6365\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4806 - accuracy: 0.7319 - val_loss: 1.3706 - val_accuracy: 0.7899\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7951 - accuracy: 0.8429 - val_loss: 0.9935 - val_accuracy: 0.8546\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5189 - accuracy: 0.8870 - val_loss: 0.7820 - val_accuracy: 0.8649\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3900 - accuracy: 0.9070 - val_loss: 0.6195 - val_accuracy: 0.9083\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3208 - accuracy: 0.9209 - val_loss: 0.5507 - val_accuracy: 0.9091\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2763 - accuracy: 0.9312 - val_loss: 0.5085 - val_accuracy: 0.9175\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2545 - accuracy: 0.9375 - val_loss: 0.4476 - val_accuracy: 0.9316\n","Epoch 9/60\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.2302 - accuracy: 0.9421 - val_loss: 0.4478 - val_accuracy: 0.9274\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2183 - accuracy: 0.9451 - val_loss: 0.4186 - val_accuracy: 0.9327\n","Epoch 11/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1983 - accuracy: 0.9500 - val_loss: 0.3794 - val_accuracy: 0.9397\n","Epoch 12/60\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1887 - accuracy: 0.9514 - val_loss: 0.3857 - val_accuracy: 0.9366\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1880 - accuracy: 0.9537 - val_loss: 0.3562 - val_accuracy: 0.9432\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1694 - accuracy: 0.9581 - val_loss: 0.3401 - val_accuracy: 0.9498\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1707 - accuracy: 0.9568 - val_loss: 0.3429 - val_accuracy: 0.9461\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1581 - accuracy: 0.9594 - val_loss: 0.3289 - val_accuracy: 0.9564\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1502 - accuracy: 0.9624 - val_loss: 0.3532 - val_accuracy: 0.9459\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1575 - accuracy: 0.9602 - val_loss: 0.3176 - val_accuracy: 0.9569\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1397 - accuracy: 0.9658 - val_loss: 0.3248 - val_accuracy: 0.9551\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1480 - accuracy: 0.9639 - val_loss: 0.3261 - val_accuracy: 0.9589\n","Epoch 21/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1327 - accuracy: 0.9669 - val_loss: 0.3233 - val_accuracy: 0.9523\n","Epoch 22/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1306 - accuracy: 0.9698 - val_loss: 0.3043 - val_accuracy: 0.9619\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1346 - accuracy: 0.9676 - val_loss: 0.2984 - val_accuracy: 0.9602\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1256 - accuracy: 0.9706 - val_loss: 0.3138 - val_accuracy: 0.9562\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1261 - accuracy: 0.9692 - val_loss: 0.3162 - val_accuracy: 0.9571\n","Epoch 26/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1207 - accuracy: 0.9721 - val_loss: 0.3214 - val_accuracy: 0.9573\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1205 - accuracy: 0.9718 - val_loss: 0.3097 - val_accuracy: 0.9613\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1212 - accuracy: 0.9719 - val_loss: 0.3214 - val_accuracy: 0.9628\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1086 - accuracy: 0.9749 - val_loss: 0.3205 - val_accuracy: 0.9600\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1080 - accuracy: 0.9757 - val_loss: 0.2901 - val_accuracy: 0.9677\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1174 - accuracy: 0.9719 - val_loss: 0.3025 - val_accuracy: 0.9666\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1022 - accuracy: 0.9760 - val_loss: 0.2841 - val_accuracy: 0.9745\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1088 - accuracy: 0.9756 - val_loss: 0.3122 - val_accuracy: 0.9624\n","Epoch 34/60\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1047 - accuracy: 0.9762 - val_loss: 0.2974 - val_accuracy: 0.9582\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1021 - accuracy: 0.9782 - val_loss: 0.3093 - val_accuracy: 0.9624\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1059 - accuracy: 0.9756 - val_loss: 0.3150 - val_accuracy: 0.9613\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0988 - accuracy: 0.9771 - val_loss: 0.2932 - val_accuracy: 0.9727\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0979 - accuracy: 0.9779 - val_loss: 0.2920 - val_accuracy: 0.9710\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0954 - accuracy: 0.9785 - val_loss: 0.2772 - val_accuracy: 0.9699\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0955 - accuracy: 0.9775 - val_loss: 0.2868 - val_accuracy: 0.9668\n","Epoch 41/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1001 - accuracy: 0.9772 - val_loss: 0.2842 - val_accuracy: 0.9751\n","Epoch 42/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0859 - accuracy: 0.9815 - val_loss: 0.3008 - val_accuracy: 0.9608\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0934 - accuracy: 0.9776 - val_loss: 0.2822 - val_accuracy: 0.9701\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0968 - accuracy: 0.9775 - val_loss: 0.2761 - val_accuracy: 0.9738\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0848 - accuracy: 0.9815 - val_loss: 0.2912 - val_accuracy: 0.9705\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0886 - accuracy: 0.9816 - val_loss: 0.2633 - val_accuracy: 0.9762\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0911 - accuracy: 0.9796 - val_loss: 0.2701 - val_accuracy: 0.9789\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0862 - accuracy: 0.9816 - val_loss: 0.2627 - val_accuracy: 0.9734\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0860 - accuracy: 0.9807 - val_loss: 0.2623 - val_accuracy: 0.9758\n","Epoch 50/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0832 - accuracy: 0.9815 - val_loss: 0.2684 - val_accuracy: 0.9771\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0885 - accuracy: 0.9810 - val_loss: 0.3157 - val_accuracy: 0.9657\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0831 - accuracy: 0.9817 - val_loss: 0.2930 - val_accuracy: 0.9699\n","Epoch 53/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0809 - accuracy: 0.9816 - val_loss: 0.2646 - val_accuracy: 0.9743\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0815 - accuracy: 0.9813 - val_loss: 0.3111 - val_accuracy: 0.9589\n","Epoch 55/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0795 - accuracy: 0.9819 - val_loss: 0.2672 - val_accuracy: 0.9732\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0790 - accuracy: 0.9824 - val_loss: 0.2664 - val_accuracy: 0.9747\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0834 - accuracy: 0.9810 - val_loss: 0.2695 - val_accuracy: 0.9745\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0747 - accuracy: 0.9836 - val_loss: 0.2622 - val_accuracy: 0.9743\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0771 - accuracy: 0.9830 - val_loss: 0.2716 - val_accuracy: 0.9712\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0813 - accuracy: 0.9817 - val_loss: 0.3244 - val_accuracy: 0.9604\n","Average Validation Accuracy: 0.9747301936149597\n","Average Validation Loss: 0.17393606156110764\n","Average Test Accuracy: 0.9750128984451294\n","------------------------------------------------------------------------\n","\n","Number of input features: 14\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.7400 - accuracy: 0.3003 - val_loss: 2.5829 - val_accuracy: 0.5234\n","Epoch 2/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7434 - accuracy: 0.6825 - val_loss: 1.4703 - val_accuracy: 0.7413\n","Epoch 3/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9819 - accuracy: 0.7992 - val_loss: 1.0214 - val_accuracy: 0.8068\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6444 - accuracy: 0.8544 - val_loss: 0.7886 - val_accuracy: 0.8711\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4858 - accuracy: 0.8829 - val_loss: 0.6461 - val_accuracy: 0.8865\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3886 - accuracy: 0.9064 - val_loss: 0.6249 - val_accuracy: 0.8871\n","Epoch 7/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.3213 - accuracy: 0.9206 - val_loss: 0.5294 - val_accuracy: 0.9043\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2933 - accuracy: 0.9245 - val_loss: 0.4771 - val_accuracy: 0.9153\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2581 - accuracy: 0.9357 - val_loss: 0.4342 - val_accuracy: 0.9276\n","Epoch 10/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2410 - accuracy: 0.9389 - val_loss: 0.4015 - val_accuracy: 0.9384\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2351 - accuracy: 0.9368 - val_loss: 0.4270 - val_accuracy: 0.9204\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2093 - accuracy: 0.9470 - val_loss: 0.3917 - val_accuracy: 0.9386\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2026 - accuracy: 0.9483 - val_loss: 0.3596 - val_accuracy: 0.9406\n","Epoch 14/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1979 - accuracy: 0.9494 - val_loss: 0.3566 - val_accuracy: 0.9388\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1956 - accuracy: 0.9485 - val_loss: 0.3361 - val_accuracy: 0.9512\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1735 - accuracy: 0.9566 - val_loss: 0.3462 - val_accuracy: 0.9501\n","Epoch 17/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1765 - accuracy: 0.9550 - val_loss: 0.4000 - val_accuracy: 0.9307\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1767 - accuracy: 0.9565 - val_loss: 0.3441 - val_accuracy: 0.9437\n","Epoch 19/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1683 - accuracy: 0.9581 - val_loss: 0.3266 - val_accuracy: 0.9483\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1596 - accuracy: 0.9598 - val_loss: 0.3057 - val_accuracy: 0.9527\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1540 - accuracy: 0.9613 - val_loss: 0.3721 - val_accuracy: 0.9386\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1554 - accuracy: 0.9587 - val_loss: 0.3027 - val_accuracy: 0.9569\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1508 - accuracy: 0.9618 - val_loss: 0.2777 - val_accuracy: 0.9602\n","Epoch 24/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1467 - accuracy: 0.9641 - val_loss: 0.3210 - val_accuracy: 0.9472\n","Epoch 25/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1437 - accuracy: 0.9662 - val_loss: 0.2925 - val_accuracy: 0.9547\n","Epoch 26/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1380 - accuracy: 0.9656 - val_loss: 0.3224 - val_accuracy: 0.9531\n","Epoch 27/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1369 - accuracy: 0.9637 - val_loss: 0.2792 - val_accuracy: 0.9602\n","Epoch 28/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1379 - accuracy: 0.9642 - val_loss: 0.2965 - val_accuracy: 0.9553\n","Epoch 29/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1279 - accuracy: 0.9688 - val_loss: 0.2914 - val_accuracy: 0.9613\n","Epoch 30/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1300 - accuracy: 0.9690 - val_loss: 0.2880 - val_accuracy: 0.9655\n","Epoch 31/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1276 - accuracy: 0.9684 - val_loss: 0.3717 - val_accuracy: 0.9443\n","Epoch 32/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1222 - accuracy: 0.9721 - val_loss: 0.3154 - val_accuracy: 0.9523\n","Epoch 33/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1248 - accuracy: 0.9688 - val_loss: 0.3042 - val_accuracy: 0.9578\n","Epoch 34/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1258 - accuracy: 0.9694 - val_loss: 0.2837 - val_accuracy: 0.9630\n","Epoch 35/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1213 - accuracy: 0.9702 - val_loss: 0.2789 - val_accuracy: 0.9661\n","Epoch 36/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1210 - accuracy: 0.9688 - val_loss: 0.3099 - val_accuracy: 0.9604\n","Epoch 37/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1099 - accuracy: 0.9726 - val_loss: 0.2766 - val_accuracy: 0.9710\n","Epoch 38/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1198 - accuracy: 0.9711 - val_loss: 0.2809 - val_accuracy: 0.9668\n","Epoch 39/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1144 - accuracy: 0.9731 - val_loss: 0.2838 - val_accuracy: 0.9644\n","Epoch 40/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1103 - accuracy: 0.9745 - val_loss: 0.2884 - val_accuracy: 0.9663\n","Epoch 41/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1092 - accuracy: 0.9746 - val_loss: 0.3213 - val_accuracy: 0.9547\n","Epoch 42/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1028 - accuracy: 0.9747 - val_loss: 0.2881 - val_accuracy: 0.9679\n","Epoch 43/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1118 - accuracy: 0.9730 - val_loss: 0.2707 - val_accuracy: 0.9725\n","Epoch 44/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1160 - accuracy: 0.9704 - val_loss: 0.2806 - val_accuracy: 0.9723\n","Epoch 45/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1008 - accuracy: 0.9767 - val_loss: 0.2857 - val_accuracy: 0.9747\n","Epoch 46/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0989 - accuracy: 0.9760 - val_loss: 0.2827 - val_accuracy: 0.9648\n","Epoch 47/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1085 - accuracy: 0.9743 - val_loss: 0.2650 - val_accuracy: 0.9793\n","Epoch 48/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0927 - accuracy: 0.9793 - val_loss: 0.2770 - val_accuracy: 0.9701\n","Epoch 49/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0993 - accuracy: 0.9776 - val_loss: 0.2977 - val_accuracy: 0.9677\n","Epoch 50/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0968 - accuracy: 0.9769 - val_loss: 0.2715 - val_accuracy: 0.9712\n","Epoch 51/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0996 - accuracy: 0.9756 - val_loss: 0.2744 - val_accuracy: 0.9692\n","Epoch 52/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0926 - accuracy: 0.9790 - val_loss: 0.2595 - val_accuracy: 0.9789\n","Epoch 53/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0946 - accuracy: 0.9772 - val_loss: 0.2560 - val_accuracy: 0.9811\n","Epoch 54/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0957 - accuracy: 0.9782 - val_loss: 0.2575 - val_accuracy: 0.9760\n","Epoch 55/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0869 - accuracy: 0.9798 - val_loss: 0.2666 - val_accuracy: 0.9771\n","Epoch 56/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0918 - accuracy: 0.9784 - val_loss: 0.2808 - val_accuracy: 0.9688\n","Epoch 57/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0946 - accuracy: 0.9775 - val_loss: 0.2641 - val_accuracy: 0.9773\n","Epoch 58/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0842 - accuracy: 0.9814 - val_loss: 0.2833 - val_accuracy: 0.9683\n","Epoch 59/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0866 - accuracy: 0.9806 - val_loss: 0.2653 - val_accuracy: 0.9820\n","Epoch 60/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0917 - accuracy: 0.9793 - val_loss: 0.2601 - val_accuracy: 0.9787\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 11s 4ms/step - loss: 4.0162 - accuracy: 0.2299 - val_loss: 2.7794 - val_accuracy: 0.5014\n","Epoch 2/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.6819 - accuracy: 0.6846 - val_loss: 1.4802 - val_accuracy: 0.7637\n","Epoch 3/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.8813 - accuracy: 0.8148 - val_loss: 1.0416 - val_accuracy: 0.8453\n","Epoch 4/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5766 - accuracy: 0.8662 - val_loss: 0.7948 - val_accuracy: 0.8821\n","Epoch 5/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4434 - accuracy: 0.8908 - val_loss: 0.6831 - val_accuracy: 0.8849\n","Epoch 6/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3675 - accuracy: 0.9056 - val_loss: 0.6054 - val_accuracy: 0.8909\n","Epoch 7/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3185 - accuracy: 0.9196 - val_loss: 0.5637 - val_accuracy: 0.9056\n","Epoch 8/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2849 - accuracy: 0.9267 - val_loss: 0.5002 - val_accuracy: 0.9226\n","Epoch 9/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2542 - accuracy: 0.9362 - val_loss: 0.4530 - val_accuracy: 0.9281\n","Epoch 10/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2382 - accuracy: 0.9400 - val_loss: 0.4411 - val_accuracy: 0.9263\n","Epoch 11/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2225 - accuracy: 0.9444 - val_loss: 0.4434 - val_accuracy: 0.9263\n","Epoch 12/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2135 - accuracy: 0.9483 - val_loss: 0.4246 - val_accuracy: 0.9371\n","Epoch 13/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1986 - accuracy: 0.9504 - val_loss: 0.5157 - val_accuracy: 0.9256\n","Epoch 14/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1918 - accuracy: 0.9532 - val_loss: 0.3783 - val_accuracy: 0.9459\n","Epoch 15/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1780 - accuracy: 0.9566 - val_loss: 0.3513 - val_accuracy: 0.9459\n","Epoch 16/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1764 - accuracy: 0.9568 - val_loss: 0.3606 - val_accuracy: 0.9441\n","Epoch 17/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1644 - accuracy: 0.9588 - val_loss: 0.3650 - val_accuracy: 0.9395\n","Epoch 18/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1609 - accuracy: 0.9597 - val_loss: 0.3450 - val_accuracy: 0.9509\n","Epoch 19/60\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1555 - accuracy: 0.9604 - val_loss: 0.3187 - val_accuracy: 0.9538\n","Epoch 20/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1470 - accuracy: 0.9646 - val_loss: 0.3134 - val_accuracy: 0.9512\n","Epoch 21/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1547 - accuracy: 0.9611 - val_loss: 0.3289 - val_accuracy: 0.9476\n","Epoch 22/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1383 - accuracy: 0.9650 - val_loss: 0.3069 - val_accuracy: 0.9586\n","Epoch 23/60\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1351 - accuracy: 0.9676 - val_loss: 0.3376 - val_accuracy: 0.9347\n","Epoch 24/60\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1399 - accuracy: 0.9652 - val_loss: 0.3251 - val_accuracy: 0.9549\n","Epoch 25/60\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1337 - accuracy: 0.9663 - val_loss: 0.3016 - val_accuracy: 0.9527\n","Epoch 26/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1294 - accuracy: 0.9687 - val_loss: 0.2950 - val_accuracy: 0.9589\n","Epoch 27/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1220 - accuracy: 0.9697 - val_loss: 0.3057 - val_accuracy: 0.9540\n","Epoch 28/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1239 - accuracy: 0.9686 - val_loss: 0.2844 - val_accuracy: 0.9617\n","Epoch 29/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1315 - accuracy: 0.9663 - val_loss: 0.2818 - val_accuracy: 0.9635\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1141 - accuracy: 0.9710 - val_loss: 0.2953 - val_accuracy: 0.9595\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1156 - accuracy: 0.9712 - val_loss: 0.2566 - val_accuracy: 0.9707\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1286 - accuracy: 0.9679 - val_loss: 0.2650 - val_accuracy: 0.9661\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1094 - accuracy: 0.9744 - val_loss: 0.2756 - val_accuracy: 0.9615\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1082 - accuracy: 0.9747 - val_loss: 0.2584 - val_accuracy: 0.9663\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1080 - accuracy: 0.9738 - val_loss: 0.2853 - val_accuracy: 0.9600\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1131 - accuracy: 0.9716 - val_loss: 0.2671 - val_accuracy: 0.9595\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1050 - accuracy: 0.9729 - val_loss: 0.4336 - val_accuracy: 0.9195\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1064 - accuracy: 0.9728 - val_loss: 0.2694 - val_accuracy: 0.9663\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0985 - accuracy: 0.9760 - val_loss: 0.2534 - val_accuracy: 0.9681\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1077 - accuracy: 0.9727 - val_loss: 0.2882 - val_accuracy: 0.9560\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0955 - accuracy: 0.9770 - val_loss: 0.2582 - val_accuracy: 0.9644\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0975 - accuracy: 0.9755 - val_loss: 0.2716 - val_accuracy: 0.9604\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1050 - accuracy: 0.9750 - val_loss: 0.2584 - val_accuracy: 0.9679\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0895 - accuracy: 0.9778 - val_loss: 0.2834 - val_accuracy: 0.9619\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0969 - accuracy: 0.9768 - val_loss: 0.2385 - val_accuracy: 0.9716\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0965 - accuracy: 0.9767 - val_loss: 0.2699 - val_accuracy: 0.9606\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0922 - accuracy: 0.9779 - val_loss: 0.2546 - val_accuracy: 0.9637\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0885 - accuracy: 0.9795 - val_loss: 0.2507 - val_accuracy: 0.9668\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0947 - accuracy: 0.9767 - val_loss: 0.2482 - val_accuracy: 0.9677\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0870 - accuracy: 0.9789 - val_loss: 0.2461 - val_accuracy: 0.9705\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0913 - accuracy: 0.9778 - val_loss: 0.2424 - val_accuracy: 0.9696\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0918 - accuracy: 0.9765 - val_loss: 0.2591 - val_accuracy: 0.9690\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0836 - accuracy: 0.9801 - val_loss: 0.2389 - val_accuracy: 0.9668\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0813 - accuracy: 0.9801 - val_loss: 0.2454 - val_accuracy: 0.9707\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0912 - accuracy: 0.9781 - val_loss: 0.2711 - val_accuracy: 0.9685\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0852 - accuracy: 0.9795 - val_loss: 0.2570 - val_accuracy: 0.9683\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0787 - accuracy: 0.9822 - val_loss: 0.2515 - val_accuracy: 0.9688\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0817 - accuracy: 0.9813 - val_loss: 0.2662 - val_accuracy: 0.9668\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0786 - accuracy: 0.9814 - val_loss: 0.2468 - val_accuracy: 0.9690\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0840 - accuracy: 0.9806 - val_loss: 0.3733 - val_accuracy: 0.9408\n","Average Validation Accuracy: 0.9649269580841064\n","Average Validation Loss: 0.21078531444072723\n","Average Test Accuracy: 0.9642514884471893\n","------------------------------------------------------------------------\n","\n","Number of input features: 15\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.5590 - accuracy: 0.3605 - val_loss: 2.2159 - val_accuracy: 0.6504\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.4274 - accuracy: 0.7364 - val_loss: 1.2397 - val_accuracy: 0.7723\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.7660 - accuracy: 0.8378 - val_loss: 0.8612 - val_accuracy: 0.8282\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.5190 - accuracy: 0.8772 - val_loss: 0.6842 - val_accuracy: 0.8757\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4070 - accuracy: 0.9002 - val_loss: 0.5973 - val_accuracy: 0.8893\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3462 - accuracy: 0.9111 - val_loss: 0.4945 - val_accuracy: 0.9195\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2983 - accuracy: 0.9240 - val_loss: 0.5075 - val_accuracy: 0.9023\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2680 - accuracy: 0.9319 - val_loss: 0.4658 - val_accuracy: 0.9245\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2412 - accuracy: 0.9417 - val_loss: 0.4935 - val_accuracy: 0.9021\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2274 - accuracy: 0.9417 - val_loss: 0.4061 - val_accuracy: 0.9355\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2126 - accuracy: 0.9469 - val_loss: 0.4301 - val_accuracy: 0.9267\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1971 - accuracy: 0.9515 - val_loss: 0.3520 - val_accuracy: 0.9446\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1971 - accuracy: 0.9500 - val_loss: 0.3644 - val_accuracy: 0.9426\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1842 - accuracy: 0.9534 - val_loss: 0.3363 - val_accuracy: 0.9542\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1766 - accuracy: 0.9569 - val_loss: 0.3457 - val_accuracy: 0.9430\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1661 - accuracy: 0.9600 - val_loss: 0.3203 - val_accuracy: 0.9514\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1708 - accuracy: 0.9571 - val_loss: 0.3372 - val_accuracy: 0.9553\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1570 - accuracy: 0.9604 - val_loss: 0.3508 - val_accuracy: 0.9421\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1482 - accuracy: 0.9639 - val_loss: 0.3153 - val_accuracy: 0.9591\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1494 - accuracy: 0.9653 - val_loss: 0.3229 - val_accuracy: 0.9534\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1437 - accuracy: 0.9642 - val_loss: 0.3243 - val_accuracy: 0.9529\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1434 - accuracy: 0.9640 - val_loss: 0.3130 - val_accuracy: 0.9562\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1342 - accuracy: 0.9677 - val_loss: 0.3034 - val_accuracy: 0.9648\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1332 - accuracy: 0.9673 - val_loss: 0.3050 - val_accuracy: 0.9569\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1350 - accuracy: 0.9689 - val_loss: 0.3266 - val_accuracy: 0.9503\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1302 - accuracy: 0.9682 - val_loss: 0.3232 - val_accuracy: 0.9560\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1287 - accuracy: 0.9686 - val_loss: 0.3152 - val_accuracy: 0.9551\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1275 - accuracy: 0.9687 - val_loss: 0.4825 - val_accuracy: 0.9300\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1245 - accuracy: 0.9690 - val_loss: 0.2855 - val_accuracy: 0.9683\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1265 - accuracy: 0.9682 - val_loss: 0.2959 - val_accuracy: 0.9694\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1109 - accuracy: 0.9742 - val_loss: 0.2897 - val_accuracy: 0.9619\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1187 - accuracy: 0.9699 - val_loss: 0.2886 - val_accuracy: 0.9652\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1204 - accuracy: 0.9712 - val_loss: 0.2670 - val_accuracy: 0.9648\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1109 - accuracy: 0.9737 - val_loss: 0.2984 - val_accuracy: 0.9597\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1196 - accuracy: 0.9700 - val_loss: 0.2702 - val_accuracy: 0.9718\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1051 - accuracy: 0.9753 - val_loss: 0.2780 - val_accuracy: 0.9672\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1156 - accuracy: 0.9703 - val_loss: 0.2696 - val_accuracy: 0.9727\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1040 - accuracy: 0.9746 - val_loss: 0.2622 - val_accuracy: 0.9776\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1077 - accuracy: 0.9740 - val_loss: 0.2992 - val_accuracy: 0.9707\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1065 - accuracy: 0.9744 - val_loss: 0.2705 - val_accuracy: 0.9751\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1004 - accuracy: 0.9763 - val_loss: 0.2791 - val_accuracy: 0.9725\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1116 - accuracy: 0.9728 - val_loss: 0.2835 - val_accuracy: 0.9707\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0954 - accuracy: 0.9785 - val_loss: 0.2511 - val_accuracy: 0.9776\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0997 - accuracy: 0.9760 - val_loss: 0.2525 - val_accuracy: 0.9773\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0953 - accuracy: 0.9773 - val_loss: 0.2788 - val_accuracy: 0.9721\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0985 - accuracy: 0.9758 - val_loss: 0.2689 - val_accuracy: 0.9729\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0946 - accuracy: 0.9782 - val_loss: 0.2727 - val_accuracy: 0.9762\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0949 - accuracy: 0.9771 - val_loss: 0.2760 - val_accuracy: 0.9718\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0969 - accuracy: 0.9782 - val_loss: 0.2898 - val_accuracy: 0.9641\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0911 - accuracy: 0.9779 - val_loss: 0.2530 - val_accuracy: 0.9754\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0988 - accuracy: 0.9765 - val_loss: 0.2564 - val_accuracy: 0.9804\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0852 - accuracy: 0.9808 - val_loss: 0.2612 - val_accuracy: 0.9729\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0895 - accuracy: 0.9791 - val_loss: 0.2560 - val_accuracy: 0.9778\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0849 - accuracy: 0.9808 - val_loss: 0.2602 - val_accuracy: 0.9789\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0900 - accuracy: 0.9788 - val_loss: 0.2628 - val_accuracy: 0.9778\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0847 - accuracy: 0.9817 - val_loss: 0.2673 - val_accuracy: 0.9679\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0820 - accuracy: 0.9805 - val_loss: 0.3155 - val_accuracy: 0.9542\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0844 - accuracy: 0.9801 - val_loss: 0.2468 - val_accuracy: 0.9782\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0804 - accuracy: 0.9820 - val_loss: 0.2668 - val_accuracy: 0.9765\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0845 - accuracy: 0.9796 - val_loss: 0.2350 - val_accuracy: 0.9831\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.6736 - accuracy: 0.3277 - val_loss: 2.4574 - val_accuracy: 0.5820\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.6287 - accuracy: 0.6820 - val_loss: 1.5209 - val_accuracy: 0.7340\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.9404 - accuracy: 0.7934 - val_loss: 1.0779 - val_accuracy: 0.8279\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.6419 - accuracy: 0.8490 - val_loss: 0.8532 - val_accuracy: 0.8669\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4922 - accuracy: 0.8824 - val_loss: 0.6929 - val_accuracy: 0.8713\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4092 - accuracy: 0.8982 - val_loss: 0.6420 - val_accuracy: 0.8876\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3549 - accuracy: 0.9076 - val_loss: 0.5593 - val_accuracy: 0.8939\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3204 - accuracy: 0.9154 - val_loss: 0.5410 - val_accuracy: 0.8961\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2857 - accuracy: 0.9252 - val_loss: 0.5100 - val_accuracy: 0.9124\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2682 - accuracy: 0.9299 - val_loss: 0.4754 - val_accuracy: 0.9074\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2477 - accuracy: 0.9363 - val_loss: 0.4711 - val_accuracy: 0.9168\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2360 - accuracy: 0.9387 - val_loss: 0.3833 - val_accuracy: 0.9272\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2137 - accuracy: 0.9457 - val_loss: 0.4145 - val_accuracy: 0.9155\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2099 - accuracy: 0.9458 - val_loss: 0.3782 - val_accuracy: 0.9399\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1940 - accuracy: 0.9513 - val_loss: 0.4024 - val_accuracy: 0.9241\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1966 - accuracy: 0.9492 - val_loss: 0.3352 - val_accuracy: 0.9424\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1778 - accuracy: 0.9546 - val_loss: 0.3637 - val_accuracy: 0.9373\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1776 - accuracy: 0.9555 - val_loss: 0.3531 - val_accuracy: 0.9452\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1641 - accuracy: 0.9588 - val_loss: 0.3500 - val_accuracy: 0.9366\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1694 - accuracy: 0.9557 - val_loss: 0.3350 - val_accuracy: 0.9399\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1564 - accuracy: 0.9599 - val_loss: 0.3081 - val_accuracy: 0.9527\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1532 - accuracy: 0.9617 - val_loss: 0.2933 - val_accuracy: 0.9553\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1482 - accuracy: 0.9612 - val_loss: 0.3052 - val_accuracy: 0.9450\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1499 - accuracy: 0.9615 - val_loss: 0.3039 - val_accuracy: 0.9520\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1485 - accuracy: 0.9632 - val_loss: 0.2880 - val_accuracy: 0.9602\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1373 - accuracy: 0.9643 - val_loss: 0.2798 - val_accuracy: 0.9584\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1364 - accuracy: 0.9662 - val_loss: 0.2965 - val_accuracy: 0.9474\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1330 - accuracy: 0.9681 - val_loss: 0.3018 - val_accuracy: 0.9507\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1317 - accuracy: 0.9676 - val_loss: 0.2850 - val_accuracy: 0.9496\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1313 - accuracy: 0.9671 - val_loss: 0.2597 - val_accuracy: 0.9663\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1283 - accuracy: 0.9680 - val_loss: 0.2586 - val_accuracy: 0.9635\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1237 - accuracy: 0.9686 - val_loss: 0.2847 - val_accuracy: 0.9529\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1236 - accuracy: 0.9690 - val_loss: 0.2727 - val_accuracy: 0.9608\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1241 - accuracy: 0.9689 - val_loss: 0.2588 - val_accuracy: 0.9648\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1102 - accuracy: 0.9725 - val_loss: 0.2674 - val_accuracy: 0.9615\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1201 - accuracy: 0.9704 - val_loss: 0.2618 - val_accuracy: 0.9661\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1146 - accuracy: 0.9715 - val_loss: 0.2581 - val_accuracy: 0.9681\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1086 - accuracy: 0.9721 - val_loss: 0.2531 - val_accuracy: 0.9659\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1092 - accuracy: 0.9728 - val_loss: 0.2777 - val_accuracy: 0.9602\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1112 - accuracy: 0.9724 - val_loss: 0.2347 - val_accuracy: 0.9637\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1081 - accuracy: 0.9733 - val_loss: 0.2534 - val_accuracy: 0.9604\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1006 - accuracy: 0.9779 - val_loss: 0.2503 - val_accuracy: 0.9639\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1034 - accuracy: 0.9754 - val_loss: 0.2592 - val_accuracy: 0.9602\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1027 - accuracy: 0.9741 - val_loss: 0.2638 - val_accuracy: 0.9611\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0996 - accuracy: 0.9755 - val_loss: 0.2651 - val_accuracy: 0.9589\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0988 - accuracy: 0.9764 - val_loss: 0.2527 - val_accuracy: 0.9661\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0962 - accuracy: 0.9762 - val_loss: 0.2430 - val_accuracy: 0.9690\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0930 - accuracy: 0.9780 - val_loss: 0.2464 - val_accuracy: 0.9703\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0952 - accuracy: 0.9775 - val_loss: 0.2529 - val_accuracy: 0.9646\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0929 - accuracy: 0.9786 - val_loss: 0.2699 - val_accuracy: 0.9580\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0922 - accuracy: 0.9786 - val_loss: 0.2446 - val_accuracy: 0.9661\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0896 - accuracy: 0.9794 - val_loss: 0.2543 - val_accuracy: 0.9611\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0900 - accuracy: 0.9790 - val_loss: 0.2429 - val_accuracy: 0.9683\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0839 - accuracy: 0.9806 - val_loss: 0.2692 - val_accuracy: 0.9578\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0960 - accuracy: 0.9764 - val_loss: 0.2436 - val_accuracy: 0.9721\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0807 - accuracy: 0.9827 - val_loss: 0.2402 - val_accuracy: 0.9718\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0876 - accuracy: 0.9788 - val_loss: 0.2417 - val_accuracy: 0.9688\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0840 - accuracy: 0.9810 - val_loss: 0.2268 - val_accuracy: 0.9732\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0883 - accuracy: 0.9785 - val_loss: 0.2334 - val_accuracy: 0.9723\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0852 - accuracy: 0.9816 - val_loss: 0.2583 - val_accuracy: 0.9681\n","Average Validation Accuracy: 0.9801400601863861\n","Average Validation Loss: 0.13503094017505646\n","Average Test Accuracy: 0.9802461862564087\n","------------------------------------------------------------------------\n","\n","Number of input features: 16\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.8523 - accuracy: 0.2787 - val_loss: 2.7305 - val_accuracy: 0.5481\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.8615 - accuracy: 0.6602 - val_loss: 1.6541 - val_accuracy: 0.7228\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.0465 - accuracy: 0.7992 - val_loss: 1.0842 - val_accuracy: 0.8429\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.6550 - accuracy: 0.8640 - val_loss: 0.8555 - val_accuracy: 0.8576\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4599 - accuracy: 0.8949 - val_loss: 0.6890 - val_accuracy: 0.8763\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3575 - accuracy: 0.9147 - val_loss: 0.5776 - val_accuracy: 0.9127\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3029 - accuracy: 0.9225 - val_loss: 0.5327 - val_accuracy: 0.9228\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2540 - accuracy: 0.9346 - val_loss: 0.5109 - val_accuracy: 0.9061\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2296 - accuracy: 0.9401 - val_loss: 0.4275 - val_accuracy: 0.9336\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2071 - accuracy: 0.9476 - val_loss: 0.4477 - val_accuracy: 0.9292\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1954 - accuracy: 0.9510 - val_loss: 0.4512 - val_accuracy: 0.9305\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1769 - accuracy: 0.9562 - val_loss: 0.3832 - val_accuracy: 0.9509\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1673 - accuracy: 0.9574 - val_loss: 0.4344 - val_accuracy: 0.9265\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1583 - accuracy: 0.9591 - val_loss: 0.3773 - val_accuracy: 0.9525\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1524 - accuracy: 0.9626 - val_loss: 0.4142 - val_accuracy: 0.9245\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1448 - accuracy: 0.9648 - val_loss: 0.3579 - val_accuracy: 0.9529\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1384 - accuracy: 0.9667 - val_loss: 0.3427 - val_accuracy: 0.9613\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1296 - accuracy: 0.9687 - val_loss: 0.3166 - val_accuracy: 0.9685\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1210 - accuracy: 0.9711 - val_loss: 0.3618 - val_accuracy: 0.9604\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1188 - accuracy: 0.9717 - val_loss: 0.3307 - val_accuracy: 0.9589\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1206 - accuracy: 0.9711 - val_loss: 0.3284 - val_accuracy: 0.9597\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1131 - accuracy: 0.9750 - val_loss: 0.3145 - val_accuracy: 0.9644\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1120 - accuracy: 0.9725 - val_loss: 0.3183 - val_accuracy: 0.9567\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1092 - accuracy: 0.9736 - val_loss: 0.2954 - val_accuracy: 0.9690\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1028 - accuracy: 0.9760 - val_loss: 0.3073 - val_accuracy: 0.9635\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1013 - accuracy: 0.9768 - val_loss: 0.2803 - val_accuracy: 0.9734\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0993 - accuracy: 0.9756 - val_loss: 0.2966 - val_accuracy: 0.9685\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0972 - accuracy: 0.9762 - val_loss: 0.3027 - val_accuracy: 0.9648\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0958 - accuracy: 0.9779 - val_loss: 0.2735 - val_accuracy: 0.9778\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0944 - accuracy: 0.9771 - val_loss: 0.2793 - val_accuracy: 0.9655\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0906 - accuracy: 0.9792 - val_loss: 0.2731 - val_accuracy: 0.9769\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0939 - accuracy: 0.9766 - val_loss: 0.2905 - val_accuracy: 0.9668\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0883 - accuracy: 0.9801 - val_loss: 0.2860 - val_accuracy: 0.9626\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0862 - accuracy: 0.9803 - val_loss: 0.2937 - val_accuracy: 0.9650\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0894 - accuracy: 0.9781 - val_loss: 0.2693 - val_accuracy: 0.9758\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0872 - accuracy: 0.9801 - val_loss: 0.2656 - val_accuracy: 0.9778\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0833 - accuracy: 0.9790 - val_loss: 0.3656 - val_accuracy: 0.9408\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0858 - accuracy: 0.9791 - val_loss: 0.2917 - val_accuracy: 0.9699\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0788 - accuracy: 0.9803 - val_loss: 0.2881 - val_accuracy: 0.9738\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0760 - accuracy: 0.9832 - val_loss: 0.2918 - val_accuracy: 0.9681\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0861 - accuracy: 0.9790 - val_loss: 0.2783 - val_accuracy: 0.9718\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0765 - accuracy: 0.9819 - val_loss: 0.2728 - val_accuracy: 0.9804\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0823 - accuracy: 0.9812 - val_loss: 0.2803 - val_accuracy: 0.9692\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0751 - accuracy: 0.9827 - val_loss: 0.2696 - val_accuracy: 0.9721\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0792 - accuracy: 0.9798 - val_loss: 0.2539 - val_accuracy: 0.9820\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0782 - accuracy: 0.9794 - val_loss: 0.2992 - val_accuracy: 0.9613\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0720 - accuracy: 0.9830 - val_loss: 0.2794 - val_accuracy: 0.9723\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0729 - accuracy: 0.9825 - val_loss: 0.2596 - val_accuracy: 0.9791\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0818 - accuracy: 0.9808 - val_loss: 0.2510 - val_accuracy: 0.9795\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0655 - accuracy: 0.9857 - val_loss: 0.2781 - val_accuracy: 0.9716\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0764 - accuracy: 0.9815 - val_loss: 0.2762 - val_accuracy: 0.9820\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0647 - accuracy: 0.9848 - val_loss: 0.2635 - val_accuracy: 0.9826\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0797 - accuracy: 0.9809 - val_loss: 0.2569 - val_accuracy: 0.9789\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0637 - accuracy: 0.9853 - val_loss: 0.2633 - val_accuracy: 0.9791\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0705 - accuracy: 0.9830 - val_loss: 0.2547 - val_accuracy: 0.9822\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0680 - accuracy: 0.9837 - val_loss: 0.2871 - val_accuracy: 0.9701\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0727 - accuracy: 0.9827 - val_loss: 0.2633 - val_accuracy: 0.9798\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0648 - accuracy: 0.9839 - val_loss: 0.3057 - val_accuracy: 0.9681\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0697 - accuracy: 0.9833 - val_loss: 0.2822 - val_accuracy: 0.9668\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0638 - accuracy: 0.9852 - val_loss: 0.2714 - val_accuracy: 0.9734\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.7257 - accuracy: 0.3246 - val_loss: 2.4502 - val_accuracy: 0.5538\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.5284 - accuracy: 0.7200 - val_loss: 1.3966 - val_accuracy: 0.7787\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.8074 - accuracy: 0.8337 - val_loss: 0.9846 - val_accuracy: 0.8598\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.5076 - accuracy: 0.8922 - val_loss: 0.8277 - val_accuracy: 0.8851\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3735 - accuracy: 0.9173 - val_loss: 0.6566 - val_accuracy: 0.9083\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3095 - accuracy: 0.9286 - val_loss: 0.6590 - val_accuracy: 0.9019\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2581 - accuracy: 0.9378 - val_loss: 0.4747 - val_accuracy: 0.9252\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2336 - accuracy: 0.9406 - val_loss: 0.4686 - val_accuracy: 0.9289\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2089 - accuracy: 0.9482 - val_loss: 0.4154 - val_accuracy: 0.9362\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1878 - accuracy: 0.9543 - val_loss: 0.3924 - val_accuracy: 0.9408\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1715 - accuracy: 0.9552 - val_loss: 0.3660 - val_accuracy: 0.9399\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1582 - accuracy: 0.9611 - val_loss: 0.3770 - val_accuracy: 0.9450\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1599 - accuracy: 0.9604 - val_loss: 0.3855 - val_accuracy: 0.9430\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1448 - accuracy: 0.9664 - val_loss: 0.3403 - val_accuracy: 0.9564\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1410 - accuracy: 0.9663 - val_loss: 0.3382 - val_accuracy: 0.9542\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1312 - accuracy: 0.9693 - val_loss: 0.3163 - val_accuracy: 0.9520\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1252 - accuracy: 0.9695 - val_loss: 0.3091 - val_accuracy: 0.9646\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1271 - accuracy: 0.9695 - val_loss: 0.3014 - val_accuracy: 0.9551\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1140 - accuracy: 0.9731 - val_loss: 0.3030 - val_accuracy: 0.9626\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1162 - accuracy: 0.9727 - val_loss: 0.2908 - val_accuracy: 0.9624\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1075 - accuracy: 0.9744 - val_loss: 0.2824 - val_accuracy: 0.9608\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1093 - accuracy: 0.9727 - val_loss: 0.2676 - val_accuracy: 0.9666\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0971 - accuracy: 0.9784 - val_loss: 0.2817 - val_accuracy: 0.9646\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1026 - accuracy: 0.9765 - val_loss: 0.2801 - val_accuracy: 0.9679\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0958 - accuracy: 0.9770 - val_loss: 0.2605 - val_accuracy: 0.9703\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0951 - accuracy: 0.9779 - val_loss: 0.2941 - val_accuracy: 0.9562\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0994 - accuracy: 0.9754 - val_loss: 0.2567 - val_accuracy: 0.9672\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0839 - accuracy: 0.9803 - val_loss: 0.2557 - val_accuracy: 0.9690\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0931 - accuracy: 0.9785 - val_loss: 0.2501 - val_accuracy: 0.9749\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0861 - accuracy: 0.9800 - val_loss: 0.2685 - val_accuracy: 0.9666\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0899 - accuracy: 0.9796 - val_loss: 0.2575 - val_accuracy: 0.9699\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0805 - accuracy: 0.9816 - val_loss: 0.2503 - val_accuracy: 0.9670\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0849 - accuracy: 0.9785 - val_loss: 0.3010 - val_accuracy: 0.9481\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0798 - accuracy: 0.9816 - val_loss: 0.2577 - val_accuracy: 0.9659\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0855 - accuracy: 0.9809 - val_loss: 0.2467 - val_accuracy: 0.9762\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0742 - accuracy: 0.9844 - val_loss: 0.3343 - val_accuracy: 0.9377\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0801 - accuracy: 0.9820 - val_loss: 0.2403 - val_accuracy: 0.9778\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0800 - accuracy: 0.9819 - val_loss: 0.2427 - val_accuracy: 0.9754\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0739 - accuracy: 0.9827 - val_loss: 0.2432 - val_accuracy: 0.9806\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0764 - accuracy: 0.9821 - val_loss: 0.2393 - val_accuracy: 0.9789\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0717 - accuracy: 0.9836 - val_loss: 0.2531 - val_accuracy: 0.9705\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0679 - accuracy: 0.9837 - val_loss: 0.2515 - val_accuracy: 0.9743\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0723 - accuracy: 0.9837 - val_loss: 0.2489 - val_accuracy: 0.9729\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0769 - accuracy: 0.9813 - val_loss: 0.2524 - val_accuracy: 0.9683\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0641 - accuracy: 0.9858 - val_loss: 0.2392 - val_accuracy: 0.9749\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0695 - accuracy: 0.9845 - val_loss: 0.2447 - val_accuracy: 0.9771\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0715 - accuracy: 0.9826 - val_loss: 0.2294 - val_accuracy: 0.9802\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0727 - accuracy: 0.9842 - val_loss: 0.2549 - val_accuracy: 0.9699\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0654 - accuracy: 0.9857 - val_loss: 0.2460 - val_accuracy: 0.9747\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0655 - accuracy: 0.9852 - val_loss: 0.2415 - val_accuracy: 0.9773\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0621 - accuracy: 0.9867 - val_loss: 0.2442 - val_accuracy: 0.9725\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0686 - accuracy: 0.9844 - val_loss: 0.2380 - val_accuracy: 0.9765\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0615 - accuracy: 0.9845 - val_loss: 0.2481 - val_accuracy: 0.9749\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0753 - accuracy: 0.9814 - val_loss: 0.2411 - val_accuracy: 0.9773\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0591 - accuracy: 0.9874 - val_loss: 0.2315 - val_accuracy: 0.9784\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0592 - accuracy: 0.9863 - val_loss: 0.2354 - val_accuracy: 0.9776\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0700 - accuracy: 0.9839 - val_loss: 0.2281 - val_accuracy: 0.9806\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0551 - accuracy: 0.9876 - val_loss: 0.2353 - val_accuracy: 0.9765\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0634 - accuracy: 0.9858 - val_loss: 0.2342 - val_accuracy: 0.9765\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0618 - accuracy: 0.9863 - val_loss: 0.2567 - val_accuracy: 0.9743\n","Average Validation Accuracy: 0.979486733675003\n","Average Validation Loss: 0.13426151126623154\n","Average Test Accuracy: 0.9788457155227661\n","------------------------------------------------------------------------\n","\n","Number of input features: 17\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.5448 - accuracy: 0.3799 - val_loss: 2.2341 - val_accuracy: 0.6121\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.3984 - accuracy: 0.7456 - val_loss: 1.1335 - val_accuracy: 0.8103\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.6693 - accuracy: 0.8603 - val_loss: 0.7482 - val_accuracy: 0.8748\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4229 - accuracy: 0.9023 - val_loss: 0.5857 - val_accuracy: 0.9069\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3112 - accuracy: 0.9253 - val_loss: 0.4986 - val_accuracy: 0.9149\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2596 - accuracy: 0.9383 - val_loss: 0.5667 - val_accuracy: 0.8977\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2287 - accuracy: 0.9442 - val_loss: 0.3812 - val_accuracy: 0.9393\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2075 - accuracy: 0.9491 - val_loss: 0.3746 - val_accuracy: 0.9410\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1859 - accuracy: 0.9556 - val_loss: 0.3867 - val_accuracy: 0.9316\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1655 - accuracy: 0.9620 - val_loss: 0.3657 - val_accuracy: 0.9450\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1660 - accuracy: 0.9625 - val_loss: 0.3282 - val_accuracy: 0.9545\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1471 - accuracy: 0.9669 - val_loss: 0.3230 - val_accuracy: 0.9523\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1376 - accuracy: 0.9678 - val_loss: 0.3305 - val_accuracy: 0.9498\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1358 - accuracy: 0.9668 - val_loss: 0.2811 - val_accuracy: 0.9723\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1264 - accuracy: 0.9741 - val_loss: 0.3082 - val_accuracy: 0.9630\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1312 - accuracy: 0.9703 - val_loss: 0.2670 - val_accuracy: 0.9714\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1111 - accuracy: 0.9749 - val_loss: 0.2847 - val_accuracy: 0.9635\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1134 - accuracy: 0.9738 - val_loss: 0.3552 - val_accuracy: 0.9399\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1076 - accuracy: 0.9760 - val_loss: 0.2698 - val_accuracy: 0.9652\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1075 - accuracy: 0.9756 - val_loss: 0.2791 - val_accuracy: 0.9679\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0952 - accuracy: 0.9782 - val_loss: 0.2614 - val_accuracy: 0.9710\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0938 - accuracy: 0.9801 - val_loss: 0.2597 - val_accuracy: 0.9727\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0926 - accuracy: 0.9795 - val_loss: 0.2757 - val_accuracy: 0.9690\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0988 - accuracy: 0.9783 - val_loss: 0.2629 - val_accuracy: 0.9780\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0785 - accuracy: 0.9833 - val_loss: 0.2455 - val_accuracy: 0.9760\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0976 - accuracy: 0.9771 - val_loss: 0.2476 - val_accuracy: 0.9780\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0820 - accuracy: 0.9844 - val_loss: 0.2638 - val_accuracy: 0.9707\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0802 - accuracy: 0.9831 - val_loss: 0.2525 - val_accuracy: 0.9800\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0852 - accuracy: 0.9802 - val_loss: 0.2700 - val_accuracy: 0.9668\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0810 - accuracy: 0.9811 - val_loss: 0.2645 - val_accuracy: 0.9657\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0775 - accuracy: 0.9830 - val_loss: 0.2584 - val_accuracy: 0.9760\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0816 - accuracy: 0.9806 - val_loss: 0.2424 - val_accuracy: 0.9798\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0785 - accuracy: 0.9827 - val_loss: 0.2428 - val_accuracy: 0.9791\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0753 - accuracy: 0.9841 - val_loss: 0.2433 - val_accuracy: 0.9795\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0777 - accuracy: 0.9830 - val_loss: 0.2403 - val_accuracy: 0.9782\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0687 - accuracy: 0.9846 - val_loss: 0.2658 - val_accuracy: 0.9736\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0694 - accuracy: 0.9843 - val_loss: 0.2322 - val_accuracy: 0.9835\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0774 - accuracy: 0.9833 - val_loss: 0.2643 - val_accuracy: 0.9740\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0656 - accuracy: 0.9862 - val_loss: 0.2437 - val_accuracy: 0.9809\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0726 - accuracy: 0.9833 - val_loss: 0.2470 - val_accuracy: 0.9758\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0667 - accuracy: 0.9845 - val_loss: 0.2490 - val_accuracy: 0.9798\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0669 - accuracy: 0.9860 - val_loss: 0.2503 - val_accuracy: 0.9791\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0643 - accuracy: 0.9857 - val_loss: 0.2622 - val_accuracy: 0.9778\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0670 - accuracy: 0.9849 - val_loss: 0.2423 - val_accuracy: 0.9811\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0722 - accuracy: 0.9827 - val_loss: 0.2380 - val_accuracy: 0.9824\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0563 - accuracy: 0.9873 - val_loss: 0.2595 - val_accuracy: 0.9793\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0678 - accuracy: 0.9839 - val_loss: 0.2444 - val_accuracy: 0.9824\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0560 - accuracy: 0.9894 - val_loss: 0.2397 - val_accuracy: 0.9822\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0628 - accuracy: 0.9849 - val_loss: 0.2598 - val_accuracy: 0.9795\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0574 - accuracy: 0.9893 - val_loss: 0.2658 - val_accuracy: 0.9721\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0555 - accuracy: 0.9879 - val_loss: 0.2668 - val_accuracy: 0.9718\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0683 - accuracy: 0.9845 - val_loss: 0.2443 - val_accuracy: 0.9857\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0535 - accuracy: 0.9896 - val_loss: 0.2604 - val_accuracy: 0.9811\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0607 - accuracy: 0.9860 - val_loss: 0.2703 - val_accuracy: 0.9723\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0533 - accuracy: 0.9885 - val_loss: 0.2565 - val_accuracy: 0.9736\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0580 - accuracy: 0.9878 - val_loss: 0.2479 - val_accuracy: 0.9795\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0573 - accuracy: 0.9862 - val_loss: 0.2349 - val_accuracy: 0.9839\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0599 - accuracy: 0.9876 - val_loss: 0.2454 - val_accuracy: 0.9855\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0522 - accuracy: 0.9884 - val_loss: 0.2407 - val_accuracy: 0.9875\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0593 - accuracy: 0.9865 - val_loss: 0.2355 - val_accuracy: 0.9848\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.7134 - accuracy: 0.3116 - val_loss: 2.5015 - val_accuracy: 0.5776\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.6174 - accuracy: 0.7067 - val_loss: 1.4635 - val_accuracy: 0.7767\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.8641 - accuracy: 0.8293 - val_loss: 1.0379 - val_accuracy: 0.8361\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.5628 - accuracy: 0.8768 - val_loss: 0.8708 - val_accuracy: 0.8629\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4152 - accuracy: 0.9037 - val_loss: 0.6992 - val_accuracy: 0.8942\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3255 - accuracy: 0.9245 - val_loss: 0.6060 - val_accuracy: 0.9050\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2741 - accuracy: 0.9340 - val_loss: 0.5379 - val_accuracy: 0.9256\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2385 - accuracy: 0.9446 - val_loss: 0.5387 - val_accuracy: 0.9217\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2157 - accuracy: 0.9485 - val_loss: 0.4571 - val_accuracy: 0.9349\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1936 - accuracy: 0.9524 - val_loss: 0.4037 - val_accuracy: 0.9468\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1745 - accuracy: 0.9583 - val_loss: 0.4149 - val_accuracy: 0.9485\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1723 - accuracy: 0.9595 - val_loss: 0.3653 - val_accuracy: 0.9487\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1470 - accuracy: 0.9654 - val_loss: 0.3601 - val_accuracy: 0.9523\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1503 - accuracy: 0.9661 - val_loss: 0.3816 - val_accuracy: 0.9377\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1340 - accuracy: 0.9698 - val_loss: 0.3271 - val_accuracy: 0.9560\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1299 - accuracy: 0.9691 - val_loss: 0.3909 - val_accuracy: 0.9329\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1244 - accuracy: 0.9734 - val_loss: 0.3198 - val_accuracy: 0.9582\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1212 - accuracy: 0.9738 - val_loss: 0.3071 - val_accuracy: 0.9622\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1072 - accuracy: 0.9776 - val_loss: 0.3207 - val_accuracy: 0.9589\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1077 - accuracy: 0.9767 - val_loss: 0.2829 - val_accuracy: 0.9657\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1055 - accuracy: 0.9776 - val_loss: 0.2686 - val_accuracy: 0.9727\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1019 - accuracy: 0.9780 - val_loss: 0.2591 - val_accuracy: 0.9703\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0953 - accuracy: 0.9800 - val_loss: 0.2697 - val_accuracy: 0.9683\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0929 - accuracy: 0.9794 - val_loss: 0.2582 - val_accuracy: 0.9721\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0902 - accuracy: 0.9807 - val_loss: 0.2746 - val_accuracy: 0.9626\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0862 - accuracy: 0.9822 - val_loss: 0.2627 - val_accuracy: 0.9672\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0993 - accuracy: 0.9762 - val_loss: 0.2610 - val_accuracy: 0.9707\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0770 - accuracy: 0.9839 - val_loss: 0.2418 - val_accuracy: 0.9767\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0877 - accuracy: 0.9793 - val_loss: 0.2385 - val_accuracy: 0.9782\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0784 - accuracy: 0.9834 - val_loss: 0.2608 - val_accuracy: 0.9683\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0797 - accuracy: 0.9835 - val_loss: 0.2684 - val_accuracy: 0.9679\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0776 - accuracy: 0.9839 - val_loss: 0.2368 - val_accuracy: 0.9727\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0736 - accuracy: 0.9841 - val_loss: 0.2319 - val_accuracy: 0.9745\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0778 - accuracy: 0.9831 - val_loss: 0.2358 - val_accuracy: 0.9738\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0664 - accuracy: 0.9856 - val_loss: 0.2367 - val_accuracy: 0.9769\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0736 - accuracy: 0.9833 - val_loss: 0.2337 - val_accuracy: 0.9754\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0703 - accuracy: 0.9845 - val_loss: 0.2303 - val_accuracy: 0.9776\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0651 - accuracy: 0.9852 - val_loss: 0.2379 - val_accuracy: 0.9710\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0692 - accuracy: 0.9831 - val_loss: 0.2238 - val_accuracy: 0.9758\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0686 - accuracy: 0.9835 - val_loss: 0.2229 - val_accuracy: 0.9740\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0690 - accuracy: 0.9841 - val_loss: 0.2176 - val_accuracy: 0.9804\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0656 - accuracy: 0.9859 - val_loss: 0.2297 - val_accuracy: 0.9738\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0623 - accuracy: 0.9861 - val_loss: 0.2039 - val_accuracy: 0.9809\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0615 - accuracy: 0.9865 - val_loss: 0.2203 - val_accuracy: 0.9729\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0718 - accuracy: 0.9834 - val_loss: 0.2111 - val_accuracy: 0.9802\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0534 - accuracy: 0.9885 - val_loss: 0.2306 - val_accuracy: 0.9743\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0712 - accuracy: 0.9831 - val_loss: 0.2184 - val_accuracy: 0.9793\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0579 - accuracy: 0.9874 - val_loss: 0.2183 - val_accuracy: 0.9795\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0637 - accuracy: 0.9855 - val_loss: 0.2105 - val_accuracy: 0.9765\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0591 - accuracy: 0.9865 - val_loss: 0.2180 - val_accuracy: 0.9782\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0599 - accuracy: 0.9870 - val_loss: 0.2268 - val_accuracy: 0.9780\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0561 - accuracy: 0.9878 - val_loss: 0.2158 - val_accuracy: 0.9758\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0564 - accuracy: 0.9871 - val_loss: 0.2162 - val_accuracy: 0.9787\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0546 - accuracy: 0.9879 - val_loss: 0.2108 - val_accuracy: 0.9765\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0582 - accuracy: 0.9860 - val_loss: 0.2008 - val_accuracy: 0.9824\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0550 - accuracy: 0.9881 - val_loss: 0.2101 - val_accuracy: 0.9769\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0499 - accuracy: 0.9892 - val_loss: 0.2106 - val_accuracy: 0.9784\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0556 - accuracy: 0.9873 - val_loss: 0.2199 - val_accuracy: 0.9793\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0519 - accuracy: 0.9883 - val_loss: 0.2250 - val_accuracy: 0.9716\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0508 - accuracy: 0.9896 - val_loss: 0.1892 - val_accuracy: 0.9831\n","Average Validation Accuracy: 0.9891805946826935\n","Average Validation Loss: 0.10243126377463341\n","Average Test Accuracy: 0.9889068901538849\n","------------------------------------------------------------------------\n","\n","Number of input features: 18\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.5698 - accuracy: 0.3110 - val_loss: 2.2041 - val_accuracy: 0.6286\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.4436 - accuracy: 0.7335 - val_loss: 1.2323 - val_accuracy: 0.7831\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.7930 - accuracy: 0.8356 - val_loss: 0.8261 - val_accuracy: 0.8631\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.5228 - accuracy: 0.8855 - val_loss: 0.6739 - val_accuracy: 0.8884\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3852 - accuracy: 0.9107 - val_loss: 0.5567 - val_accuracy: 0.9173\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3099 - accuracy: 0.9271 - val_loss: 0.5083 - val_accuracy: 0.9239\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2541 - accuracy: 0.9400 - val_loss: 0.4480 - val_accuracy: 0.9287\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2275 - accuracy: 0.9461 - val_loss: 0.3848 - val_accuracy: 0.9481\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2006 - accuracy: 0.9546 - val_loss: 0.3969 - val_accuracy: 0.9362\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1875 - accuracy: 0.9560 - val_loss: 0.3449 - val_accuracy: 0.9553\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1644 - accuracy: 0.9625 - val_loss: 0.3278 - val_accuracy: 0.9580\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1665 - accuracy: 0.9626 - val_loss: 0.3490 - val_accuracy: 0.9556\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1520 - accuracy: 0.9651 - val_loss: 0.3555 - val_accuracy: 0.9525\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1393 - accuracy: 0.9685 - val_loss: 0.3049 - val_accuracy: 0.9597\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1390 - accuracy: 0.9681 - val_loss: 0.3276 - val_accuracy: 0.9505\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1344 - accuracy: 0.9705 - val_loss: 0.2733 - val_accuracy: 0.9712\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1222 - accuracy: 0.9718 - val_loss: 0.2835 - val_accuracy: 0.9648\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1244 - accuracy: 0.9697 - val_loss: 0.2988 - val_accuracy: 0.9633\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1116 - accuracy: 0.9741 - val_loss: 0.2857 - val_accuracy: 0.9582\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1172 - accuracy: 0.9747 - val_loss: 0.2757 - val_accuracy: 0.9655\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1019 - accuracy: 0.9789 - val_loss: 0.3087 - val_accuracy: 0.9551\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1082 - accuracy: 0.9764 - val_loss: 0.2445 - val_accuracy: 0.9729\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1014 - accuracy: 0.9769 - val_loss: 0.2622 - val_accuracy: 0.9681\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1006 - accuracy: 0.9782 - val_loss: 0.2274 - val_accuracy: 0.9771\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1047 - accuracy: 0.9768 - val_loss: 0.2583 - val_accuracy: 0.9668\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0907 - accuracy: 0.9801 - val_loss: 0.2391 - val_accuracy: 0.9727\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0927 - accuracy: 0.9789 - val_loss: 0.2424 - val_accuracy: 0.9734\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0874 - accuracy: 0.9819 - val_loss: 0.2176 - val_accuracy: 0.9743\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0909 - accuracy: 0.9811 - val_loss: 0.2520 - val_accuracy: 0.9703\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0911 - accuracy: 0.9807 - val_loss: 0.2105 - val_accuracy: 0.9800\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0862 - accuracy: 0.9819 - val_loss: 0.2367 - val_accuracy: 0.9718\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0769 - accuracy: 0.9835 - val_loss: 0.2498 - val_accuracy: 0.9727\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0801 - accuracy: 0.9841 - val_loss: 0.2183 - val_accuracy: 0.9791\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0894 - accuracy: 0.9792 - val_loss: 0.2186 - val_accuracy: 0.9802\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0746 - accuracy: 0.9832 - val_loss: 0.2221 - val_accuracy: 0.9734\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0805 - accuracy: 0.9822 - val_loss: 0.2173 - val_accuracy: 0.9811\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0713 - accuracy: 0.9855 - val_loss: 0.2123 - val_accuracy: 0.9793\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0850 - accuracy: 0.9815 - val_loss: 0.2242 - val_accuracy: 0.9754\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0717 - accuracy: 0.9852 - val_loss: 0.2049 - val_accuracy: 0.9822\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0695 - accuracy: 0.9872 - val_loss: 0.2153 - val_accuracy: 0.9793\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0748 - accuracy: 0.9832 - val_loss: 0.2400 - val_accuracy: 0.9767\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0729 - accuracy: 0.9841 - val_loss: 0.2112 - val_accuracy: 0.9837\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0692 - accuracy: 0.9853 - val_loss: 0.2427 - val_accuracy: 0.9767\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0610 - accuracy: 0.9876 - val_loss: 0.2517 - val_accuracy: 0.9740\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0741 - accuracy: 0.9834 - val_loss: 0.2159 - val_accuracy: 0.9822\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0635 - accuracy: 0.9863 - val_loss: 0.2466 - val_accuracy: 0.9771\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0698 - accuracy: 0.9849 - val_loss: 0.2273 - val_accuracy: 0.9780\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0634 - accuracy: 0.9863 - val_loss: 0.2427 - val_accuracy: 0.9732\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0633 - accuracy: 0.9861 - val_loss: 0.2765 - val_accuracy: 0.9723\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0669 - accuracy: 0.9853 - val_loss: 0.2751 - val_accuracy: 0.9721\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0619 - accuracy: 0.9880 - val_loss: 0.2044 - val_accuracy: 0.9848\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0655 - accuracy: 0.9852 - val_loss: 0.2287 - val_accuracy: 0.9791\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0597 - accuracy: 0.9885 - val_loss: 0.2190 - val_accuracy: 0.9778\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0629 - accuracy: 0.9865 - val_loss: 0.2586 - val_accuracy: 0.9712\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0617 - accuracy: 0.9871 - val_loss: 0.2086 - val_accuracy: 0.9804\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0660 - accuracy: 0.9857 - val_loss: 0.2096 - val_accuracy: 0.9782\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0591 - accuracy: 0.9871 - val_loss: 0.2853 - val_accuracy: 0.9619\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0591 - accuracy: 0.9885 - val_loss: 0.2136 - val_accuracy: 0.9842\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0626 - accuracy: 0.9870 - val_loss: 0.2385 - val_accuracy: 0.9760\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0592 - accuracy: 0.9878 - val_loss: 0.2249 - val_accuracy: 0.9765\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.5138 - accuracy: 0.3328 - val_loss: 2.1877 - val_accuracy: 0.6440\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.3408 - accuracy: 0.7476 - val_loss: 1.2069 - val_accuracy: 0.8123\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.6834 - accuracy: 0.8620 - val_loss: 0.8559 - val_accuracy: 0.8796\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4476 - accuracy: 0.9007 - val_loss: 0.7150 - val_accuracy: 0.9074\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3440 - accuracy: 0.9209 - val_loss: 0.6650 - val_accuracy: 0.8959\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2880 - accuracy: 0.9330 - val_loss: 0.5506 - val_accuracy: 0.9256\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2424 - accuracy: 0.9422 - val_loss: 0.4911 - val_accuracy: 0.9362\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2182 - accuracy: 0.9471 - val_loss: 0.4209 - val_accuracy: 0.9443\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1842 - accuracy: 0.9557 - val_loss: 0.4017 - val_accuracy: 0.9432\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1683 - accuracy: 0.9595 - val_loss: 0.3639 - val_accuracy: 0.9602\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1640 - accuracy: 0.9604 - val_loss: 0.3851 - val_accuracy: 0.9459\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1553 - accuracy: 0.9633 - val_loss: 0.3771 - val_accuracy: 0.9490\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1500 - accuracy: 0.9650 - val_loss: 0.3712 - val_accuracy: 0.9560\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1386 - accuracy: 0.9677 - val_loss: 0.3178 - val_accuracy: 0.9666\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1381 - accuracy: 0.9669 - val_loss: 0.3586 - val_accuracy: 0.9518\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1257 - accuracy: 0.9713 - val_loss: 0.3187 - val_accuracy: 0.9589\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1153 - accuracy: 0.9738 - val_loss: 0.3163 - val_accuracy: 0.9613\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1196 - accuracy: 0.9721 - val_loss: 0.3031 - val_accuracy: 0.9692\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1164 - accuracy: 0.9737 - val_loss: 0.3455 - val_accuracy: 0.9545\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1117 - accuracy: 0.9740 - val_loss: 0.3040 - val_accuracy: 0.9650\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1090 - accuracy: 0.9769 - val_loss: 0.2972 - val_accuracy: 0.9681\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9775 - val_loss: 0.2999 - val_accuracy: 0.9608\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0976 - accuracy: 0.9776 - val_loss: 0.3057 - val_accuracy: 0.9628\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1079 - accuracy: 0.9752 - val_loss: 0.3169 - val_accuracy: 0.9573\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0940 - accuracy: 0.9785 - val_loss: 0.2567 - val_accuracy: 0.9734\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0932 - accuracy: 0.9796 - val_loss: 0.2967 - val_accuracy: 0.9641\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0915 - accuracy: 0.9802 - val_loss: 0.3050 - val_accuracy: 0.9593\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0986 - accuracy: 0.9778 - val_loss: 0.2445 - val_accuracy: 0.9776\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0814 - accuracy: 0.9815 - val_loss: 0.2393 - val_accuracy: 0.9767\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0891 - accuracy: 0.9816 - val_loss: 0.2653 - val_accuracy: 0.9696\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0892 - accuracy: 0.9796 - val_loss: 0.2648 - val_accuracy: 0.9756\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0752 - accuracy: 0.9852 - val_loss: 0.2402 - val_accuracy: 0.9740\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0954 - accuracy: 0.9777 - val_loss: 0.2395 - val_accuracy: 0.9780\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0749 - accuracy: 0.9833 - val_loss: 0.2351 - val_accuracy: 0.9778\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0827 - accuracy: 0.9816 - val_loss: 0.2567 - val_accuracy: 0.9749\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0766 - accuracy: 0.9833 - val_loss: 0.2863 - val_accuracy: 0.9626\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0752 - accuracy: 0.9835 - val_loss: 0.3676 - val_accuracy: 0.9388\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0691 - accuracy: 0.9863 - val_loss: 0.2521 - val_accuracy: 0.9712\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0825 - accuracy: 0.9811 - val_loss: 0.2339 - val_accuracy: 0.9725\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0702 - accuracy: 0.9857 - val_loss: 0.2471 - val_accuracy: 0.9758\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0721 - accuracy: 0.9845 - val_loss: 0.2397 - val_accuracy: 0.9756\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0732 - accuracy: 0.9854 - val_loss: 0.2295 - val_accuracy: 0.9743\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0652 - accuracy: 0.9860 - val_loss: 0.2239 - val_accuracy: 0.9778\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0726 - accuracy: 0.9852 - val_loss: 0.2201 - val_accuracy: 0.9817\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0643 - accuracy: 0.9869 - val_loss: 0.2259 - val_accuracy: 0.9820\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0740 - accuracy: 0.9840 - val_loss: 0.2880 - val_accuracy: 0.9545\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0644 - accuracy: 0.9869 - val_loss: 0.2254 - val_accuracy: 0.9773\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0647 - accuracy: 0.9860 - val_loss: 0.2054 - val_accuracy: 0.9855\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0621 - accuracy: 0.9863 - val_loss: 0.2481 - val_accuracy: 0.9738\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0720 - accuracy: 0.9857 - val_loss: 0.2218 - val_accuracy: 0.9822\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0609 - accuracy: 0.9879 - val_loss: 0.2162 - val_accuracy: 0.9793\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0696 - accuracy: 0.9835 - val_loss: 0.2900 - val_accuracy: 0.9562\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0624 - accuracy: 0.9856 - val_loss: 0.2094 - val_accuracy: 0.9802\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0581 - accuracy: 0.9882 - val_loss: 0.2494 - val_accuracy: 0.9732\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0601 - accuracy: 0.9874 - val_loss: 0.2137 - val_accuracy: 0.9793\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0679 - accuracy: 0.9852 - val_loss: 0.3358 - val_accuracy: 0.9496\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0535 - accuracy: 0.9882 - val_loss: 0.2270 - val_accuracy: 0.9776\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0545 - accuracy: 0.9898 - val_loss: 0.2245 - val_accuracy: 0.9762\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0590 - accuracy: 0.9878 - val_loss: 0.2346 - val_accuracy: 0.9762\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0627 - accuracy: 0.9852 - val_loss: 0.2579 - val_accuracy: 0.9712\n","Average Validation Accuracy: 0.9797406792640686\n","Average Validation Loss: 0.12535890564322472\n","Average Test Accuracy: 0.9807621538639069\n","------------------------------------------------------------------------\n","\n","Number of input features: 19\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.7042 - accuracy: 0.2955 - val_loss: 2.3132 - val_accuracy: 0.5927\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.5979 - accuracy: 0.7104 - val_loss: 1.3518 - val_accuracy: 0.7754\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.9470 - accuracy: 0.8195 - val_loss: 0.9918 - val_accuracy: 0.8317\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.6340 - accuracy: 0.8687 - val_loss: 0.7747 - val_accuracy: 0.8686\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4580 - accuracy: 0.9023 - val_loss: 0.6461 - val_accuracy: 0.8964\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3594 - accuracy: 0.9166 - val_loss: 0.6077 - val_accuracy: 0.9047\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2935 - accuracy: 0.9339 - val_loss: 0.5090 - val_accuracy: 0.9311\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2522 - accuracy: 0.9424 - val_loss: 0.4520 - val_accuracy: 0.9426\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2179 - accuracy: 0.9483 - val_loss: 0.4397 - val_accuracy: 0.9375\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1933 - accuracy: 0.9545 - val_loss: 0.4288 - val_accuracy: 0.9505\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1737 - accuracy: 0.9594 - val_loss: 0.3966 - val_accuracy: 0.9573\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1657 - accuracy: 0.9609 - val_loss: 0.3981 - val_accuracy: 0.9476\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1541 - accuracy: 0.9657 - val_loss: 0.3715 - val_accuracy: 0.9573\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1492 - accuracy: 0.9663 - val_loss: 0.4329 - val_accuracy: 0.9435\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1309 - accuracy: 0.9711 - val_loss: 0.3777 - val_accuracy: 0.9531\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1396 - accuracy: 0.9691 - val_loss: 0.3824 - val_accuracy: 0.9586\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1254 - accuracy: 0.9747 - val_loss: 0.4175 - val_accuracy: 0.9459\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1200 - accuracy: 0.9730 - val_loss: 0.3632 - val_accuracy: 0.9604\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1151 - accuracy: 0.9731 - val_loss: 0.3771 - val_accuracy: 0.9593\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1070 - accuracy: 0.9768 - val_loss: 0.3508 - val_accuracy: 0.9650\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1158 - accuracy: 0.9756 - val_loss: 0.3866 - val_accuracy: 0.9589\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1054 - accuracy: 0.9773 - val_loss: 0.3191 - val_accuracy: 0.9762\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1080 - accuracy: 0.9767 - val_loss: 0.3976 - val_accuracy: 0.9509\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0991 - accuracy: 0.9775 - val_loss: 0.3295 - val_accuracy: 0.9716\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0952 - accuracy: 0.9823 - val_loss: 0.3035 - val_accuracy: 0.9749\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1014 - accuracy: 0.9786 - val_loss: 0.3213 - val_accuracy: 0.9688\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0989 - accuracy: 0.9777 - val_loss: 0.2950 - val_accuracy: 0.9780\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0873 - accuracy: 0.9809 - val_loss: 0.2813 - val_accuracy: 0.9782\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0940 - accuracy: 0.9791 - val_loss: 0.3263 - val_accuracy: 0.9692\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0783 - accuracy: 0.9859 - val_loss: 0.3029 - val_accuracy: 0.9670\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0958 - accuracy: 0.9804 - val_loss: 0.3106 - val_accuracy: 0.9740\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0829 - accuracy: 0.9825 - val_loss: 0.3110 - val_accuracy: 0.9707\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0848 - accuracy: 0.9819 - val_loss: 0.2786 - val_accuracy: 0.9804\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0743 - accuracy: 0.9847 - val_loss: 0.3224 - val_accuracy: 0.9615\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0791 - accuracy: 0.9846 - val_loss: 0.2793 - val_accuracy: 0.9773\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0839 - accuracy: 0.9820 - val_loss: 0.2924 - val_accuracy: 0.9703\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0791 - accuracy: 0.9843 - val_loss: 0.2935 - val_accuracy: 0.9690\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0745 - accuracy: 0.9844 - val_loss: 0.2761 - val_accuracy: 0.9806\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0722 - accuracy: 0.9847 - val_loss: 0.3095 - val_accuracy: 0.9749\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0687 - accuracy: 0.9860 - val_loss: 0.2656 - val_accuracy: 0.9820\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0769 - accuracy: 0.9843 - val_loss: 0.2768 - val_accuracy: 0.9798\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0602 - accuracy: 0.9891 - val_loss: 0.2917 - val_accuracy: 0.9743\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0718 - accuracy: 0.9850 - val_loss: 0.2640 - val_accuracy: 0.9743\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0742 - accuracy: 0.9855 - val_loss: 0.2587 - val_accuracy: 0.9850\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0663 - accuracy: 0.9858 - val_loss: 0.2526 - val_accuracy: 0.9817\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0651 - accuracy: 0.9872 - val_loss: 0.2570 - val_accuracy: 0.9791\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0605 - accuracy: 0.9888 - val_loss: 0.2731 - val_accuracy: 0.9789\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0707 - accuracy: 0.9849 - val_loss: 0.2427 - val_accuracy: 0.9855\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0597 - accuracy: 0.9899 - val_loss: 0.2425 - val_accuracy: 0.9886\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0616 - accuracy: 0.9880 - val_loss: 0.2444 - val_accuracy: 0.9817\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0693 - accuracy: 0.9843 - val_loss: 0.2597 - val_accuracy: 0.9776\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0612 - accuracy: 0.9871 - val_loss: 0.2389 - val_accuracy: 0.9815\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0650 - accuracy: 0.9866 - val_loss: 0.2560 - val_accuracy: 0.9800\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0536 - accuracy: 0.9900 - val_loss: 0.2854 - val_accuracy: 0.9718\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0664 - accuracy: 0.9870 - val_loss: 0.2529 - val_accuracy: 0.9842\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0533 - accuracy: 0.9897 - val_loss: 0.2865 - val_accuracy: 0.9721\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0641 - accuracy: 0.9870 - val_loss: 0.2569 - val_accuracy: 0.9800\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0561 - accuracy: 0.9889 - val_loss: 0.2829 - val_accuracy: 0.9760\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0562 - accuracy: 0.9897 - val_loss: 0.2370 - val_accuracy: 0.9894\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0583 - accuracy: 0.9879 - val_loss: 0.2425 - val_accuracy: 0.9875\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.3367 - accuracy: 0.3579 - val_loss: 1.9832 - val_accuracy: 0.6752\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.2568 - accuracy: 0.7686 - val_loss: 1.1509 - val_accuracy: 0.8176\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.7093 - accuracy: 0.8562 - val_loss: 0.7990 - val_accuracy: 0.8823\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4772 - accuracy: 0.9017 - val_loss: 0.6362 - val_accuracy: 0.8898\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3474 - accuracy: 0.9216 - val_loss: 0.5051 - val_accuracy: 0.9265\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2767 - accuracy: 0.9349 - val_loss: 0.4307 - val_accuracy: 0.9340\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2251 - accuracy: 0.9499 - val_loss: 0.3875 - val_accuracy: 0.9454\n","Epoch 8/60\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2078 - accuracy: 0.9510 - val_loss: 0.4001 - val_accuracy: 0.9485\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1791 - accuracy: 0.9581 - val_loss: 0.3781 - val_accuracy: 0.9479\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1543 - accuracy: 0.9662 - val_loss: 0.3538 - val_accuracy: 0.9527\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1644 - accuracy: 0.9625 - val_loss: 0.3992 - val_accuracy: 0.9327\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1384 - accuracy: 0.9684 - val_loss: 0.3614 - val_accuracy: 0.9421\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1375 - accuracy: 0.9695 - val_loss: 0.3023 - val_accuracy: 0.9652\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1297 - accuracy: 0.9723 - val_loss: 0.3258 - val_accuracy: 0.9450\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1207 - accuracy: 0.9745 - val_loss: 0.2812 - val_accuracy: 0.9615\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1218 - accuracy: 0.9737 - val_loss: 0.2606 - val_accuracy: 0.9619\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1143 - accuracy: 0.9776 - val_loss: 0.3011 - val_accuracy: 0.9595\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1154 - accuracy: 0.9753 - val_loss: 0.3127 - val_accuracy: 0.9562\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1119 - accuracy: 0.9764 - val_loss: 0.2389 - val_accuracy: 0.9718\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0930 - accuracy: 0.9801 - val_loss: 0.2832 - val_accuracy: 0.9639\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1018 - accuracy: 0.9788 - val_loss: 0.2418 - val_accuracy: 0.9692\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1015 - accuracy: 0.9789 - val_loss: 0.2215 - val_accuracy: 0.9758\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0909 - accuracy: 0.9810 - val_loss: 0.2763 - val_accuracy: 0.9633\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0938 - accuracy: 0.9795 - val_loss: 0.2224 - val_accuracy: 0.9736\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0913 - accuracy: 0.9810 - val_loss: 0.2507 - val_accuracy: 0.9668\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0850 - accuracy: 0.9819 - val_loss: 0.2913 - val_accuracy: 0.9586\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0879 - accuracy: 0.9811 - val_loss: 0.2476 - val_accuracy: 0.9648\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0898 - accuracy: 0.9818 - val_loss: 0.2231 - val_accuracy: 0.9707\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0855 - accuracy: 0.9822 - val_loss: 0.3213 - val_accuracy: 0.9516\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0765 - accuracy: 0.9850 - val_loss: 0.2086 - val_accuracy: 0.9773\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0780 - accuracy: 0.9841 - val_loss: 0.2121 - val_accuracy: 0.9815\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0756 - accuracy: 0.9855 - val_loss: 0.2167 - val_accuracy: 0.9795\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0768 - accuracy: 0.9841 - val_loss: 0.2466 - val_accuracy: 0.9714\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0712 - accuracy: 0.9854 - val_loss: 0.2247 - val_accuracy: 0.9736\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0695 - accuracy: 0.9859 - val_loss: 0.2370 - val_accuracy: 0.9677\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0759 - accuracy: 0.9835 - val_loss: 0.2345 - val_accuracy: 0.9745\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0728 - accuracy: 0.9853 - val_loss: 0.2132 - val_accuracy: 0.9771\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0660 - accuracy: 0.9884 - val_loss: 0.2043 - val_accuracy: 0.9780\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0738 - accuracy: 0.9844 - val_loss: 0.2140 - val_accuracy: 0.9767\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0615 - accuracy: 0.9884 - val_loss: 0.2195 - val_accuracy: 0.9690\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0688 - accuracy: 0.9865 - val_loss: 0.2475 - val_accuracy: 0.9655\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0661 - accuracy: 0.9861 - val_loss: 0.2110 - val_accuracy: 0.9771\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0675 - accuracy: 0.9855 - val_loss: 0.1982 - val_accuracy: 0.9809\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0640 - accuracy: 0.9876 - val_loss: 0.2061 - val_accuracy: 0.9773\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0608 - accuracy: 0.9888 - val_loss: 0.2031 - val_accuracy: 0.9811\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0646 - accuracy: 0.9860 - val_loss: 0.2206 - val_accuracy: 0.9769\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0647 - accuracy: 0.9870 - val_loss: 0.2030 - val_accuracy: 0.9833\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0500 - accuracy: 0.9919 - val_loss: 0.1874 - val_accuracy: 0.9853\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0628 - accuracy: 0.9880 - val_loss: 0.2016 - val_accuracy: 0.9844\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0564 - accuracy: 0.9897 - val_loss: 0.1943 - val_accuracy: 0.9828\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0598 - accuracy: 0.9878 - val_loss: 0.2240 - val_accuracy: 0.9723\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0581 - accuracy: 0.9869 - val_loss: 0.2110 - val_accuracy: 0.9824\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0531 - accuracy: 0.9888 - val_loss: 0.2236 - val_accuracy: 0.9729\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0561 - accuracy: 0.9875 - val_loss: 0.2047 - val_accuracy: 0.9780\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0542 - accuracy: 0.9901 - val_loss: 0.1840 - val_accuracy: 0.9828\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0595 - accuracy: 0.9879 - val_loss: 0.2131 - val_accuracy: 0.9813\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0487 - accuracy: 0.9908 - val_loss: 0.2223 - val_accuracy: 0.9800\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0520 - accuracy: 0.9896 - val_loss: 0.1994 - val_accuracy: 0.9815\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0582 - accuracy: 0.9882 - val_loss: 0.2105 - val_accuracy: 0.9789\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0524 - accuracy: 0.9884 - val_loss: 0.1854 - val_accuracy: 0.9848\n","Average Validation Accuracy: 0.9908869862556458\n","Average Validation Loss: 0.10051622986793518\n","Average Test Accuracy: 0.9916709661483765\n","------------------------------------------------------------------------\n","\n","Number of input features: 20\n","Fold: 1\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.3904 - accuracy: 0.3368 - val_loss: 1.8647 - val_accuracy: 0.6702\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.1311 - accuracy: 0.7731 - val_loss: 1.0221 - val_accuracy: 0.8130\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.6312 - accuracy: 0.8616 - val_loss: 0.7132 - val_accuracy: 0.8708\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.4352 - accuracy: 0.8935 - val_loss: 0.5517 - val_accuracy: 0.8953\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3342 - accuracy: 0.9168 - val_loss: 0.4822 - val_accuracy: 0.9096\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2810 - accuracy: 0.9269 - val_loss: 0.3963 - val_accuracy: 0.9322\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2367 - accuracy: 0.9418 - val_loss: 0.3769 - val_accuracy: 0.9382\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2085 - accuracy: 0.9498 - val_loss: 0.3426 - val_accuracy: 0.9501\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1893 - accuracy: 0.9531 - val_loss: 0.3249 - val_accuracy: 0.9520\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1820 - accuracy: 0.9549 - val_loss: 0.3041 - val_accuracy: 0.9545\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1546 - accuracy: 0.9633 - val_loss: 0.3478 - val_accuracy: 0.9446\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1510 - accuracy: 0.9629 - val_loss: 0.2996 - val_accuracy: 0.9644\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1430 - accuracy: 0.9656 - val_loss: 0.3345 - val_accuracy: 0.9509\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1256 - accuracy: 0.9711 - val_loss: 0.3479 - val_accuracy: 0.9490\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1298 - accuracy: 0.9664 - val_loss: 0.3189 - val_accuracy: 0.9551\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1216 - accuracy: 0.9719 - val_loss: 0.2821 - val_accuracy: 0.9677\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1188 - accuracy: 0.9737 - val_loss: 0.3031 - val_accuracy: 0.9571\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1156 - accuracy: 0.9737 - val_loss: 0.2926 - val_accuracy: 0.9639\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1006 - accuracy: 0.9789 - val_loss: 0.2683 - val_accuracy: 0.9705\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0989 - accuracy: 0.9775 - val_loss: 0.2529 - val_accuracy: 0.9714\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0961 - accuracy: 0.9784 - val_loss: 0.2636 - val_accuracy: 0.9705\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1009 - accuracy: 0.9775 - val_loss: 0.2494 - val_accuracy: 0.9802\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0965 - accuracy: 0.9776 - val_loss: 0.3820 - val_accuracy: 0.9476\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0863 - accuracy: 0.9806 - val_loss: 0.2728 - val_accuracy: 0.9712\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0961 - accuracy: 0.9791 - val_loss: 0.2930 - val_accuracy: 0.9657\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0848 - accuracy: 0.9809 - val_loss: 0.2643 - val_accuracy: 0.9714\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0838 - accuracy: 0.9818 - val_loss: 0.2548 - val_accuracy: 0.9771\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0852 - accuracy: 0.9822 - val_loss: 0.2520 - val_accuracy: 0.9754\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0795 - accuracy: 0.9836 - val_loss: 0.2399 - val_accuracy: 0.9864\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0777 - accuracy: 0.9834 - val_loss: 0.2714 - val_accuracy: 0.9740\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0794 - accuracy: 0.9833 - val_loss: 0.2436 - val_accuracy: 0.9806\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0791 - accuracy: 0.9832 - val_loss: 0.2474 - val_accuracy: 0.9820\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0723 - accuracy: 0.9850 - val_loss: 0.2670 - val_accuracy: 0.9657\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0750 - accuracy: 0.9830 - val_loss: 0.2302 - val_accuracy: 0.9800\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0712 - accuracy: 0.9849 - val_loss: 0.2641 - val_accuracy: 0.9754\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0736 - accuracy: 0.9860 - val_loss: 0.2425 - val_accuracy: 0.9839\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0758 - accuracy: 0.9840 - val_loss: 0.2406 - val_accuracy: 0.9813\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0624 - accuracy: 0.9882 - val_loss: 0.2420 - val_accuracy: 0.9844\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0706 - accuracy: 0.9837 - val_loss: 0.2341 - val_accuracy: 0.9804\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0612 - accuracy: 0.9885 - val_loss: 0.2457 - val_accuracy: 0.9789\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0682 - accuracy: 0.9871 - val_loss: 0.2481 - val_accuracy: 0.9844\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0571 - accuracy: 0.9894 - val_loss: 0.2255 - val_accuracy: 0.9879\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0719 - accuracy: 0.9840 - val_loss: 0.2458 - val_accuracy: 0.9809\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0624 - accuracy: 0.9871 - val_loss: 0.2460 - val_accuracy: 0.9875\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0600 - accuracy: 0.9879 - val_loss: 0.2411 - val_accuracy: 0.9837\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0585 - accuracy: 0.9883 - val_loss: 0.2578 - val_accuracy: 0.9795\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0594 - accuracy: 0.9886 - val_loss: 0.2834 - val_accuracy: 0.9762\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0535 - accuracy: 0.9888 - val_loss: 0.2494 - val_accuracy: 0.9853\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0637 - accuracy: 0.9861 - val_loss: 0.2453 - val_accuracy: 0.9848\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0564 - accuracy: 0.9875 - val_loss: 0.3200 - val_accuracy: 0.9604\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0563 - accuracy: 0.9887 - val_loss: 0.2405 - val_accuracy: 0.9839\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0559 - accuracy: 0.9894 - val_loss: 0.2394 - val_accuracy: 0.9855\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0490 - accuracy: 0.9908 - val_loss: 0.2437 - val_accuracy: 0.9822\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0579 - accuracy: 0.9876 - val_loss: 0.2362 - val_accuracy: 0.9813\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9889 - val_loss: 0.2206 - val_accuracy: 0.9879\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0578 - accuracy: 0.9878 - val_loss: 0.2533 - val_accuracy: 0.9824\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0485 - accuracy: 0.9908 - val_loss: 0.2351 - val_accuracy: 0.9842\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0481 - accuracy: 0.9906 - val_loss: 0.2447 - val_accuracy: 0.9826\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0528 - accuracy: 0.9892 - val_loss: 0.2364 - val_accuracy: 0.9855\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0514 - accuracy: 0.9885 - val_loss: 0.2334 - val_accuracy: 0.9877\n","Fold: 2\n","Epoch 1/60\n","1846/1846 [==============================] - 5s 2ms/step - loss: 3.2360 - accuracy: 0.3787 - val_loss: 1.8114 - val_accuracy: 0.6948\n","Epoch 2/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 1.0899 - accuracy: 0.7918 - val_loss: 1.0125 - val_accuracy: 0.8363\n","Epoch 3/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.5864 - accuracy: 0.8730 - val_loss: 0.7110 - val_accuracy: 0.8697\n","Epoch 4/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.3846 - accuracy: 0.9143 - val_loss: 0.5294 - val_accuracy: 0.9074\n","Epoch 5/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2915 - accuracy: 0.9337 - val_loss: 0.4272 - val_accuracy: 0.9217\n","Epoch 6/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2403 - accuracy: 0.9429 - val_loss: 0.3474 - val_accuracy: 0.9406\n","Epoch 7/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.2045 - accuracy: 0.9512 - val_loss: 0.3237 - val_accuracy: 0.9408\n","Epoch 8/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1815 - accuracy: 0.9585 - val_loss: 0.3038 - val_accuracy: 0.9476\n","Epoch 9/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1663 - accuracy: 0.9611 - val_loss: 0.2713 - val_accuracy: 0.9617\n","Epoch 10/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1491 - accuracy: 0.9649 - val_loss: 0.2440 - val_accuracy: 0.9652\n","Epoch 11/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1415 - accuracy: 0.9691 - val_loss: 0.2823 - val_accuracy: 0.9580\n","Epoch 12/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1334 - accuracy: 0.9714 - val_loss: 0.2355 - val_accuracy: 0.9639\n","Epoch 13/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1267 - accuracy: 0.9705 - val_loss: 0.2226 - val_accuracy: 0.9710\n","Epoch 14/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1257 - accuracy: 0.9727 - val_loss: 0.2205 - val_accuracy: 0.9681\n","Epoch 15/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1092 - accuracy: 0.9771 - val_loss: 0.2393 - val_accuracy: 0.9600\n","Epoch 16/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1074 - accuracy: 0.9772 - val_loss: 0.2274 - val_accuracy: 0.9652\n","Epoch 17/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1024 - accuracy: 0.9782 - val_loss: 0.2041 - val_accuracy: 0.9729\n","Epoch 18/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.1038 - accuracy: 0.9779 - val_loss: 0.2148 - val_accuracy: 0.9674\n","Epoch 19/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0954 - accuracy: 0.9808 - val_loss: 0.1951 - val_accuracy: 0.9718\n","Epoch 20/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0864 - accuracy: 0.9829 - val_loss: 0.2123 - val_accuracy: 0.9762\n","Epoch 21/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0939 - accuracy: 0.9790 - val_loss: 0.1948 - val_accuracy: 0.9718\n","Epoch 22/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0831 - accuracy: 0.9824 - val_loss: 0.3081 - val_accuracy: 0.9476\n","Epoch 23/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0976 - accuracy: 0.9802 - val_loss: 0.1861 - val_accuracy: 0.9751\n","Epoch 24/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0844 - accuracy: 0.9820 - val_loss: 0.1763 - val_accuracy: 0.9795\n","Epoch 25/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0756 - accuracy: 0.9836 - val_loss: 0.1909 - val_accuracy: 0.9714\n","Epoch 26/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0779 - accuracy: 0.9839 - val_loss: 0.1970 - val_accuracy: 0.9721\n","Epoch 27/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0765 - accuracy: 0.9840 - val_loss: 0.1899 - val_accuracy: 0.9749\n","Epoch 28/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0768 - accuracy: 0.9837 - val_loss: 0.1766 - val_accuracy: 0.9773\n","Epoch 29/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0720 - accuracy: 0.9849 - val_loss: 0.1915 - val_accuracy: 0.9743\n","Epoch 30/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0758 - accuracy: 0.9842 - val_loss: 0.1865 - val_accuracy: 0.9773\n","Epoch 31/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0700 - accuracy: 0.9848 - val_loss: 0.1876 - val_accuracy: 0.9747\n","Epoch 32/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0751 - accuracy: 0.9835 - val_loss: 0.2165 - val_accuracy: 0.9692\n","Epoch 33/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0735 - accuracy: 0.9856 - val_loss: 0.1776 - val_accuracy: 0.9802\n","Epoch 34/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0595 - accuracy: 0.9893 - val_loss: 0.2260 - val_accuracy: 0.9648\n","Epoch 35/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0700 - accuracy: 0.9861 - val_loss: 0.2553 - val_accuracy: 0.9595\n","Epoch 36/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0663 - accuracy: 0.9876 - val_loss: 0.1996 - val_accuracy: 0.9745\n","Epoch 37/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0620 - accuracy: 0.9879 - val_loss: 0.1674 - val_accuracy: 0.9828\n","Epoch 38/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0671 - accuracy: 0.9863 - val_loss: 0.1612 - val_accuracy: 0.9824\n","Epoch 39/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0636 - accuracy: 0.9893 - val_loss: 0.1583 - val_accuracy: 0.9833\n","Epoch 40/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0577 - accuracy: 0.9888 - val_loss: 0.1546 - val_accuracy: 0.9828\n","Epoch 41/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0719 - accuracy: 0.9844 - val_loss: 0.1597 - val_accuracy: 0.9795\n","Epoch 42/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0477 - accuracy: 0.9923 - val_loss: 0.1536 - val_accuracy: 0.9822\n","Epoch 43/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0641 - accuracy: 0.9857 - val_loss: 0.1557 - val_accuracy: 0.9828\n","Epoch 44/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0558 - accuracy: 0.9887 - val_loss: 0.1627 - val_accuracy: 0.9804\n","Epoch 45/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0551 - accuracy: 0.9879 - val_loss: 0.1667 - val_accuracy: 0.9787\n","Epoch 46/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0550 - accuracy: 0.9878 - val_loss: 0.1570 - val_accuracy: 0.9806\n","Epoch 47/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0519 - accuracy: 0.9897 - val_loss: 0.1576 - val_accuracy: 0.9804\n","Epoch 48/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0585 - accuracy: 0.9880 - val_loss: 0.1845 - val_accuracy: 0.9782\n","Epoch 49/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0553 - accuracy: 0.9888 - val_loss: 0.1729 - val_accuracy: 0.9767\n","Epoch 50/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0525 - accuracy: 0.9891 - val_loss: 0.1838 - val_accuracy: 0.9765\n","Epoch 51/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0531 - accuracy: 0.9901 - val_loss: 0.1558 - val_accuracy: 0.9835\n","Epoch 52/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0497 - accuracy: 0.9909 - val_loss: 0.2302 - val_accuracy: 0.9712\n","Epoch 53/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0573 - accuracy: 0.9884 - val_loss: 0.1676 - val_accuracy: 0.9760\n","Epoch 54/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0517 - accuracy: 0.9910 - val_loss: 0.1573 - val_accuracy: 0.9844\n","Epoch 55/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0461 - accuracy: 0.9917 - val_loss: 0.1524 - val_accuracy: 0.9877\n","Epoch 56/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0462 - accuracy: 0.9914 - val_loss: 0.1752 - val_accuracy: 0.9760\n","Epoch 57/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0584 - accuracy: 0.9872 - val_loss: 0.1498 - val_accuracy: 0.9842\n","Epoch 58/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0432 - accuracy: 0.9919 - val_loss: 0.1728 - val_accuracy: 0.9758\n","Epoch 59/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0582 - accuracy: 0.9871 - val_loss: 0.1475 - val_accuracy: 0.9861\n","Epoch 60/60\n","1846/1846 [==============================] - 4s 2ms/step - loss: 0.0429 - accuracy: 0.9924 - val_loss: 0.1520 - val_accuracy: 0.9846\n","Average Validation Accuracy: 0.9899793267250061\n","Average Validation Loss: 0.09502610564231873\n","Average Test Accuracy: 0.9891280233860016\n","------------------------------------------------------------------------\n"]}],"source":["# Define the number of folds for k-fold cross-validation\n","k = 2\n","\n","# Define the cross-validation method\n","cv_method = StratifiedKFold(n_splits=k)\n","\n","# Initialize the list to store the history, train & validation(accuracy & loss) for each model\n","models = []\n","model_history = []\n","model_accuracy = []\n","model_train_acc = []\n","model_train_loss = []\n","model_val_acc = []\n","model_val_loss = []\n","\n","for i in range(1, 21):\n","\n","  models_fold = []\n","  hist = []\n","  train_accuracy = []\n","  train_loss = []\n","  val_accuracy = []\n","  val_loss = []\n","  test_accuracy = []\n","\n","  print(\"\\nNumber of input features:\", i)\n","\n","  # Select the input features from the input data\n","  X_train_selected = X_train[:, :i]\n","  X_test_selected = X_test[:, :i]\n","\n","  X_train_selected = X_train_selected.reshape(27543, i, 1, 1)\n","  X_test_selected = X_test_selected.reshape(13567, i, 1, 1)\n","\n","  # Loop over the folds\n","  for fold, (train_index, val_index) in enumerate(cv_method.split(X_train_selected, y_train)):\n","\n","    print(\"Fold:\", fold+1)\n","\n","    # Build the model\n","    model = Sequential()\n","    model.add(Conv2D(60, kernel_size=(5,5), activation='relu',bias_initializer='normal', input_shape=X_train_selected.shape[1:], padding= \"same\")) #keeps the output size same as input size (prevent down or upsampling)\n","    model.add(MaxPooling2D(pool_size=(1,1))) #pool size 2 error, because 1 (1 feature) minus 2 (pool size) is negative)\n","    model.add(Flatten())\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(373, kernel_initializer='normal', activation='softmax'))\n","\n","    # compile model\n","    model.compile(loss = \"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy']) \n","\n","    # # Fit the model to the training data for the current fold\n","    history = model.fit(X_train_selected[train_index], to_categorical(y_train_enc[train_index], num_classes=373), batch_size = 5, epochs = 60, verbose = 1, validation_split = 0.33)\n","\n","    # Evaluate the model on the validation data for the current fold\n","    val_scores = model.evaluate(X_train_selected[val_index], to_categorical(y_train_enc[val_index],num_classes=373), verbose=0)\n","    val_accuracy.append(val_scores[1])\n","    val_loss.append(val_scores[0])\n","\n","    # Evaluate the model on the test data for the current fold\n","    test_scores = model.evaluate(X_test_selected, to_categorical(y_test_enc, num_classes=373), verbose=0)\n","    test_accuracy.append(test_scores[1])\n","\n","    # add the model to the list of models\n","    models_fold.append(model)\n","    hist.append(history)\n","\n","    # store the training accuracy and loss for each fold\n","    train_accuracy.append(history.history['accuracy'])\n","    train_loss.append(history.history['loss'])\n","  \n","  # Calculate the average test and validation accuracy and loss across all folds\n","  avg_test_acc = sum(test_accuracy) / len(test_accuracy)\n","  avg_val_acc = sum(val_accuracy) / len(val_accuracy)\n","  avg_val_loss = sum(val_loss) / len(val_loss)\n","\n","  # Print the average validation and test accuracy and loss\n","  print(\"Average Validation Accuracy:\", avg_val_acc)\n","  print(\"Average Validation Loss:\",avg_val_loss)\n","  print(\"Average Test Accuracy:\", avg_test_acc)\n","\n","  best_fold_index = test_accuracy.index(max(test_accuracy))\n","  model_accuracy.append(test_accuracy[best_fold_index])\n","  models.append(models_fold[best_fold_index])\n","  model_history.append(hist[best_fold_index])\n","  model_train_acc.append(train_accuracy[best_fold_index])\n","  model_train_loss.append(train_loss[best_fold_index])\n","  model_val_acc.append(val_accuracy[best_fold_index])\n","  model_val_loss.append(val_loss[best_fold_index])\n","  print('------------------------------------------------------------------------')"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"ZG29fO-C4TJH"},"outputs":[],"source":["#to show the no of input features and its corresponding model accuracy\n","model_list = []\n","\n","#Iterate through each model's accuracy \n","for i in range (len(model_accuracy)):\n","    #get the number of input features for the current model\n","    no_features = i + 1\n","\n","    #round the model accuries to 3 d.p.\n","    rounded_model_acc = round(model_accuracy[i], 3)\n","    \n","    model_list.append([no_features, rounded_model_acc])\n","\n","models_df = pd.DataFrame(model_list, columns=[\"No of input features\", \"Model accuracy\"])"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"M1aBlP3GmZ9o"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Final Test Accuracy: 0.9920395016670227\n"]}],"source":["# Select the final model based on the max test accuracy across all models\n","\n","best_model_index = model_accuracy.index(max(model_accuracy))\n","\n","best_model = models[best_model_index]\n","best_model_history = model_history[best_model_index]\n","best_model_train_acc = model_train_acc[best_model_index]\n","best_model_train_loss = model_train_loss[best_model_index]\n","best_model_val_acc = model_val_acc[best_model_index]\n","best_model_val_loss = model_val_loss[best_model_index]\n","\n","# summarize history for accuracy  \n","plt.subplot(211)  \n","plt.plot(best_model_history.history['accuracy'])  \n","plt.plot(best_model_history.history['val_accuracy'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='lower right')  \n","\n","# summarize history for loss\n","plt.subplot(212)  \n","plt.plot(best_model_history.history['loss'])  \n","plt.plot(best_model_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='upper right')  \n","plt.subplots_adjust(hspace=0.7)\n","\n","plt.show() \n","\n","print(\"Final Test Accuracy:\", model_accuracy[best_model_index])"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"RMkWBkrYmZ9s"},"outputs":[{"name":"stdout","output_type":"stream","text":["424/424 [==============================] - 1s 1ms/step\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       591\n","           1       1.00      1.00      1.00       430\n","           2       1.00      1.00      1.00       419\n","           3       1.00      1.00      1.00       384\n","           4       1.00      1.00      1.00       339\n","           5       1.00      1.00      1.00       342\n","           6       1.00      1.00      1.00       310\n","           7       1.00      1.00      1.00       325\n","           8       1.00      1.00      1.00       294\n","           9       1.00      1.00      1.00       269\n","          10       1.00      1.00      1.00       296\n","          11       1.00      1.00      1.00       258\n","          12       1.00      1.00      1.00       247\n","          13       1.00      1.00      1.00       237\n","          14       1.00      1.00      1.00       239\n","          15       1.00      1.00      1.00       235\n","          16       1.00      1.00      1.00       213\n","          17       1.00      1.00      1.00       202\n","          18       1.00      1.00      1.00       196\n","          19       1.00      1.00      1.00       181\n","          20       1.00      1.00      1.00       177\n","          21       1.00      1.00      1.00       177\n","          22       1.00      1.00      1.00       155\n","          23       1.00      1.00      1.00       155\n","          24       1.00      1.00      1.00       144\n","          25       1.00      1.00      1.00       126\n","          26       1.00      1.00      1.00       108\n","          27       1.00      1.00      1.00       121\n","          28       1.00      1.00      1.00        95\n","          29       1.00      1.00      1.00       102\n","          30       1.00      1.00      1.00       106\n","          31       1.00      1.00      1.00        86\n","          32       1.00      1.00      1.00       108\n","          33       1.00      1.00      1.00        88\n","          34       1.00      1.00      1.00       102\n","          35       1.00      1.00      1.00        88\n","          36       1.00      1.00      1.00        83\n","          37       1.00      1.00      1.00        93\n","          38       1.00      1.00      1.00        76\n","          39       1.00      1.00      1.00        85\n","          40       1.00      1.00      1.00        86\n","          41       1.00      1.00      1.00        85\n","          42       1.00      1.00      1.00        68\n","          43       1.00      1.00      1.00        75\n","          44       1.00      1.00      1.00        71\n","          45       0.87      1.00      0.93        58\n","          46       1.00      1.00      1.00        71\n","          47       0.79      0.84      0.81        57\n","          48       1.00      1.00      1.00        67\n","          49       0.92      0.96      0.94        47\n","          50       1.00      1.00      1.00        48\n","          51       1.00      1.00      1.00        47\n","          52       1.00      1.00      1.00        43\n","          53       1.00      1.00      1.00        51\n","          54       1.00      1.00      1.00        44\n","          55       0.96      1.00      0.98        51\n","          56       1.00      1.00      1.00        45\n","          57       1.00      1.00      1.00        44\n","          58       1.00      1.00      1.00        41\n","          59       1.00      1.00      1.00        52\n","          60       1.00      1.00      1.00        41\n","          61       1.00      1.00      1.00        43\n","          62       1.00      1.00      1.00        43\n","          63       1.00      1.00      1.00        37\n","          64       1.00      1.00      1.00        42\n","          65       1.00      1.00      1.00        46\n","          66       1.00      1.00      1.00        43\n","          67       1.00      1.00      1.00        44\n","          68       1.00      1.00      1.00        40\n","          69       1.00      1.00      1.00        43\n","          70       1.00      1.00      1.00        38\n","          71       1.00      1.00      1.00        33\n","          72       1.00      1.00      1.00        45\n","          73       1.00      1.00      1.00        38\n","          74       1.00      1.00      1.00        42\n","          75       1.00      1.00      1.00        39\n","          76       1.00      1.00      1.00        30\n","          77       1.00      1.00      1.00        28\n","          78       1.00      1.00      1.00        28\n","          79       1.00      1.00      1.00        32\n","          80       1.00      1.00      1.00        33\n","          81       1.00      1.00      1.00        35\n","          82       1.00      1.00      1.00        31\n","          83       1.00      1.00      1.00        27\n","          84       0.91      1.00      0.95        39\n","          85       1.00      1.00      1.00        36\n","          86       1.00      1.00      1.00        31\n","          87       1.00      1.00      1.00        20\n","          88       1.00      1.00      1.00        28\n","          89       1.00      1.00      1.00        33\n","          90       1.00      1.00      1.00        22\n","          91       1.00      1.00      1.00        24\n","          92       1.00      1.00      1.00        35\n","          93       1.00      1.00      1.00        26\n","          94       1.00      1.00      1.00        27\n","          95       1.00      1.00      1.00        23\n","          96       0.96      1.00      0.98        27\n","          97       1.00      1.00      1.00        28\n","          98       1.00      1.00      1.00        16\n","          99       1.00      1.00      1.00        35\n","         100       1.00      1.00      1.00        28\n","         101       1.00      1.00      1.00        25\n","         102       1.00      1.00      1.00        26\n","         103       1.00      1.00      1.00        33\n","         104       1.00      1.00      1.00        26\n","         105       1.00      1.00      1.00        24\n","         106       0.61      1.00      0.76        22\n","         107       1.00      1.00      1.00        26\n","         108       1.00      1.00      1.00        25\n","         109       1.00      1.00      1.00        16\n","         110       1.00      1.00      1.00        23\n","         111       1.00      1.00      1.00        20\n","         112       1.00      1.00      1.00        26\n","         113       1.00      1.00      1.00        18\n","         114       1.00      1.00      1.00        25\n","         115       1.00      1.00      1.00        18\n","         116       1.00      1.00      1.00        19\n","         117       1.00      1.00      1.00        16\n","         118       1.00      1.00      1.00        26\n","         119       0.79      1.00      0.88        22\n","         120       1.00      1.00      1.00        15\n","         121       1.00      1.00      1.00        27\n","         122       1.00      1.00      1.00        19\n","         123       1.00      1.00      1.00        18\n","         124       1.00      1.00      1.00        17\n","         125       1.00      1.00      1.00        21\n","         126       1.00      1.00      1.00        26\n","         127       1.00      1.00      1.00        22\n","         128       1.00      1.00      1.00        20\n","         129       1.00      1.00      1.00        14\n","         130       1.00      1.00      1.00        18\n","         131       1.00      1.00      1.00        18\n","         132       1.00      1.00      1.00        20\n","         133       1.00      1.00      1.00        20\n","         134       1.00      1.00      1.00        14\n","         135       1.00      1.00      1.00        14\n","         136       1.00      1.00      1.00        16\n","         137       1.00      1.00      1.00        19\n","         138       1.00      1.00      1.00        23\n","         139       0.00      0.00      0.00        14\n","         140       1.00      1.00      1.00        23\n","         141       1.00      1.00      1.00        11\n","         142       1.00      1.00      1.00        13\n","         143       1.00      1.00      1.00        23\n","         144       1.00      0.82      0.90        17\n","         145       0.77      1.00      0.87        24\n","         146       1.00      1.00      1.00        16\n","         147       1.00      1.00      1.00        19\n","         148       1.00      1.00      1.00        22\n","         149       1.00      1.00      1.00        15\n","         150       1.00      1.00      1.00        11\n","         151       1.00      1.00      1.00        24\n","         152       1.00      1.00      1.00        20\n","         153       1.00      1.00      1.00        19\n","         154       1.00      1.00      1.00        11\n","         155       1.00      1.00      1.00        17\n","         156       1.00      1.00      1.00        18\n","         157       1.00      1.00      1.00        12\n","         158       1.00      1.00      1.00        18\n","         159       1.00      1.00      1.00        20\n","         160       1.00      1.00      1.00        20\n","         161       1.00      1.00      1.00        16\n","         162       1.00      1.00      1.00        15\n","         163       1.00      1.00      1.00        19\n","         164       1.00      1.00      1.00        13\n","         165       1.00      1.00      1.00        15\n","         166       1.00      1.00      1.00        11\n","         167       1.00      1.00      1.00        11\n","         168       1.00      1.00      1.00        21\n","         169       1.00      1.00      1.00        15\n","         170       1.00      1.00      1.00        11\n","         171       1.00      1.00      1.00         9\n","         172       1.00      1.00      1.00        18\n","         173       1.00      1.00      1.00        16\n","         174       1.00      1.00      1.00        10\n","         175       1.00      1.00      1.00        11\n","         176       1.00      1.00      1.00        10\n","         177       1.00      1.00      1.00        11\n","         178       1.00      1.00      1.00        15\n","         179       1.00      1.00      1.00        15\n","         180       1.00      1.00      1.00        13\n","         181       1.00      1.00      1.00        15\n","         182       1.00      1.00      1.00         8\n","         183       0.60      1.00      0.75        12\n","         184       1.00      1.00      1.00        16\n","         185       1.00      1.00      1.00         9\n","         186       1.00      0.38      0.56        13\n","         187       1.00      1.00      1.00        14\n","         188       1.00      1.00      1.00        15\n","         189       1.00      1.00      1.00        15\n","         190       1.00      1.00      1.00         9\n","         191       1.00      1.00      1.00        11\n","         192       1.00      1.00      1.00         9\n","         193       1.00      1.00      1.00        17\n","         194       1.00      1.00      1.00         4\n","         195       1.00      1.00      1.00        10\n","         196       1.00      1.00      1.00        14\n","         197       1.00      1.00      1.00        12\n","         198       1.00      1.00      1.00         7\n","         199       1.00      1.00      1.00         7\n","         200       1.00      1.00      1.00        12\n","         201       1.00      1.00      1.00         9\n","         202       1.00      0.83      0.91         6\n","         203       1.00      1.00      1.00        11\n","         204       1.00      1.00      1.00        14\n","         205       1.00      1.00      1.00        12\n","         206       1.00      1.00      1.00         7\n","         207       1.00      1.00      1.00        14\n","         208       1.00      1.00      1.00         6\n","         209       1.00      1.00      1.00        19\n","         210       1.00      1.00      1.00         7\n","         211       1.00      1.00      1.00         7\n","         212       1.00      1.00      1.00         9\n","         213       1.00      1.00      1.00        11\n","         214       1.00      1.00      1.00         6\n","         215       1.00      1.00      1.00         7\n","         216       1.00      1.00      1.00        12\n","         217       1.00      1.00      1.00         5\n","         218       0.31      1.00      0.47         4\n","         219       0.62      1.00      0.76         8\n","         220       1.00      1.00      1.00        12\n","         221       1.00      1.00      1.00         6\n","         222       0.00      0.00      0.00         9\n","         223       1.00      1.00      1.00        10\n","         224       1.00      1.00      1.00        13\n","         225       1.00      1.00      1.00        14\n","         226       1.00      1.00      1.00        12\n","         227       1.00      1.00      1.00         4\n","         228       1.00      1.00      1.00        13\n","         229       1.00      1.00      1.00        11\n","         230       1.00      1.00      1.00         5\n","         231       1.00      1.00      1.00         6\n","         232       1.00      1.00      1.00        10\n","         233       0.00      0.00      0.00         9\n","         234       1.00      1.00      1.00         8\n","         235       1.00      1.00      1.00         4\n","         236       1.00      1.00      1.00         7\n","         237       1.00      1.00      1.00         8\n","         238       0.00      0.00      0.00         8\n","         239       1.00      1.00      1.00         7\n","         240       1.00      1.00      1.00        10\n","         241       1.00      1.00      1.00         8\n","         242       1.00      1.00      1.00         6\n","         243       1.00      1.00      1.00         9\n","         244       1.00      1.00      1.00         7\n","         245       1.00      0.44      0.62         9\n","         246       1.00      1.00      1.00        12\n","         247       1.00      1.00      1.00         7\n","         248       1.00      1.00      1.00         5\n","         249       1.00      1.00      1.00         6\n","         250       1.00      1.00      1.00         5\n","         251       1.00      1.00      1.00         7\n","         252       1.00      1.00      1.00        10\n","         253       1.00      1.00      1.00         6\n","         254       1.00      1.00      1.00         9\n","         255       1.00      1.00      1.00         8\n","         256       1.00      1.00      1.00        11\n","         257       1.00      1.00      1.00        10\n","         258       1.00      1.00      1.00         4\n","         259       1.00      1.00      1.00         3\n","         260       1.00      1.00      1.00         7\n","         261       1.00      1.00      1.00         7\n","         262       1.00      1.00      1.00         9\n","         263       1.00      1.00      1.00         2\n","         264       1.00      1.00      1.00         7\n","         265       1.00      1.00      1.00         8\n","         266       0.82      1.00      0.90         9\n","         267       1.00      1.00      1.00         5\n","         268       1.00      1.00      1.00        10\n","         269       1.00      1.00      1.00         7\n","         270       1.00      1.00      1.00         4\n","         271       0.00      0.00      0.00         4\n","         272       1.00      1.00      1.00         9\n","         273       1.00      1.00      1.00         4\n","         274       1.00      1.00      1.00         3\n","         275       1.00      1.00      1.00         6\n","         276       1.00      1.00      1.00         5\n","         277       1.00      1.00      1.00         3\n","         278       1.00      1.00      1.00        10\n","         279       1.00      1.00      1.00         6\n","         280       1.00      1.00      1.00         6\n","         281       1.00      1.00      1.00        11\n","         282       0.50      0.20      0.29         5\n","         283       1.00      1.00      1.00         4\n","         284       1.00      1.00      1.00         7\n","         285       1.00      1.00      1.00         9\n","         286       1.00      1.00      1.00         6\n","         287       1.00      1.00      1.00         7\n","         288       1.00      1.00      1.00         6\n","         289       1.00      1.00      1.00         2\n","         290       1.00      1.00      1.00         7\n","         291       1.00      1.00      1.00         5\n","         292       1.00      1.00      1.00         6\n","         293       1.00      1.00      1.00         8\n","         294       1.00      1.00      1.00         3\n","         295       1.00      1.00      1.00         7\n","         296       1.00      1.00      1.00         6\n","         297       1.00      1.00      1.00         8\n","         298       0.00      0.00      0.00         4\n","         299       1.00      1.00      1.00         3\n","         300       1.00      1.00      1.00         8\n","         301       1.00      1.00      1.00         6\n","         302       1.00      1.00      1.00         2\n","         303       0.25      0.60      0.35         5\n","         304       1.00      1.00      1.00         5\n","         305       1.00      1.00      1.00         5\n","         306       1.00      1.00      1.00         6\n","         307       1.00      1.00      1.00         4\n","         308       1.00      1.00      1.00         7\n","         309       0.00      0.00      0.00         9\n","         310       1.00      1.00      1.00         4\n","         311       1.00      1.00      1.00         6\n","         312       1.00      1.00      1.00         8\n","         313       1.00      1.00      1.00         4\n","         314       1.00      1.00      1.00         2\n","         315       1.00      1.00      1.00         4\n","         316       1.00      1.00      1.00         8\n","         317       1.00      1.00      1.00         6\n","         318       1.00      1.00      1.00         4\n","         319       1.00      1.00      1.00         7\n","         320       0.89      1.00      0.94         8\n","         321       1.00      1.00      1.00        10\n","         322       0.60      1.00      0.75         6\n","         323       1.00      1.00      1.00         3\n","         324       1.00      1.00      1.00         4\n","         325       1.00      1.00      1.00         7\n","         326       1.00      1.00      1.00         6\n","         327       1.00      1.00      1.00         7\n","         328       1.00      1.00      1.00         3\n","         329       1.00      1.00      1.00         8\n","         330       1.00      0.33      0.50         6\n","         331       1.00      1.00      1.00         3\n","         332       1.00      1.00      1.00         1\n","         333       1.00      1.00      1.00         4\n","         334       1.00      1.00      1.00         3\n","         335       1.00      1.00      1.00         6\n","         336       1.00      1.00      1.00         4\n","         337       1.00      1.00      1.00         1\n","         338       1.00      1.00      1.00         2\n","         339       1.00      1.00      1.00         4\n","         340       1.00      1.00      1.00         2\n","         341       1.00      1.00      1.00         4\n","         342       1.00      1.00      1.00         7\n","         343       1.00      1.00      1.00         4\n","         344       1.00      1.00      1.00         4\n","         345       1.00      1.00      1.00         4\n","         346       1.00      1.00      1.00         5\n","         347       1.00      1.00      1.00         6\n","         348       1.00      1.00      1.00         3\n","         349       1.00      1.00      1.00         5\n","         350       1.00      1.00      1.00         4\n","         351       1.00      1.00      1.00         7\n","         352       1.00      1.00      1.00         7\n","         353       1.00      1.00      1.00         2\n","         354       1.00      1.00      1.00         6\n","         355       1.00      1.00      1.00         4\n","         356       1.00      1.00      1.00         1\n","         357       1.00      1.00      1.00         1\n","         358       1.00      1.00      1.00         4\n","         359       1.00      1.00      1.00         3\n","         360       0.00      0.00      0.00         3\n","         361       1.00      1.00      1.00         3\n","         362       1.00      1.00      1.00         3\n","         363       1.00      1.00      1.00         3\n","         364       1.00      0.50      0.67         2\n","         365       1.00      1.00      1.00         2\n","         366       0.00      0.00      0.00         4\n","         367       0.25      1.00      0.40         3\n","         368       1.00      1.00      1.00         2\n","         370       1.00      1.00      1.00         1\n","         371       0.00      0.00      0.00         2\n","         372       0.00      0.00      0.00         3\n","\n","    accuracy                           0.99     13567\n","   macro avg       0.96      0.96      0.95     13567\n","weighted avg       0.99      0.99      0.99     13567\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["#Select only the optimal number of input features for X_test\n","X_test = X_test[:,:(best_model_index+1)]\n","\n","X_test = X_test.reshape(13567, best_model_index+1, 1, 1)\n","\n","# Evaluate the best model on the test data\n","y_pred = best_model.predict(X_test)\n","\n","# np.argmax() is used to convert the one-hot encoded predictions and test labels to class labels.\n","y_pred_label = np.argmax(y_pred, axis = 1)\n","\n","# Print the classification report\n","print(\"Classification report:\\n\", classification_report(y_test_enc, y_pred_label))"]},{"cell_type":"code","execution_count":18,"metadata":{"id":"FeifaQpJmZ9u"},"outputs":[{"name":"stdout","output_type":"stream","text":["           OsID  True Class  Predicted Class  True/False\n","0  Os03g0179400         335              335        True\n","1  Os01g0741900         161              161        True\n","2  Os01g0686800          17               17        True\n","3  Os04g0107900          34               34        True\n","4  Os04g0517100           7                7        True\n"]}],"source":["# extract class labels from test data\n","class_test = y_test_enc\n","\n","# Invert OsID_labels dictionary\n","inv_OsID_labels = {v: k for k, v in OsID_labels.items()}\n","\n","# map OsID values to the class labels\n","OsID_test = [inv_OsID_labels.get(value, 'Unknown') for value in class_test]\n","\n","# create dataframe with OsID, true class, predicted class, and true/false columns\n","results = pd.DataFrame({\n","    'OsID': OsID_test,\n","    'True Class': y_test_enc,\n","    'Predicted Class': y_pred_label,\n","    'True/False': class_test == y_pred_label\n","})\n","\n","# display dataframe\n","print(results.head())\n","\n","# save results_df to a CSV file\n","results.to_csv('MLP_gene classification.csv', index=False)"]},{"cell_type":"code","execution_count":19,"metadata":{"id":"HcBceHUp0-TI"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>No of input features</th>\n","      <th>Model accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.488</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.853</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.932</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.960</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.971</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.980</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.982</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>0.982</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>0.984</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0.985</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>0.965</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>0.984</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>0.980</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>0.990</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>0.984</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>0.992</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>0.990</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    No of input features  Model accuracy\n","0                      1           0.488\n","1                      2           0.853\n","2                      3           0.932\n","3                      4           0.960\n","4                      5           0.981\n","5                      6           0.971\n","6                      7           0.980\n","7                      8           0.982\n","8                      9           0.982\n","9                     10           0.984\n","10                    11           0.985\n","11                    12           0.965\n","12                    13           0.981\n","13                    14           0.981\n","14                    15           0.984\n","15                    16           0.980\n","16                    17           0.990\n","17                    18           0.984\n","18                    19           0.992\n","19                    20           0.990"]},"metadata":{},"output_type":"display_data"}],"source":["display(models_df)"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
