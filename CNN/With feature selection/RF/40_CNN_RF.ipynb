{"cells":[{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":12731,"status":"ok","timestamp":1682739185373,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"UsLpi_0MmZ9Z"},"outputs":[],"source":["from itertools import cycle\n","\n","import numpy as np\n","import pandas as pd \n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from sklearn.preprocessing import OneHotEncoder\n","from sklearn.preprocessing import OrdinalEncoder\n","from sklearn.preprocessing import MinMaxScaler\n","from keras.models import Model ,Sequential #for CNN\n","from keras.layers import Dense \n","from sklearn.model_selection import KFold\n","from keras.wrappers.scikit_learn import KerasClassifier\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import chi2\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import tensorflow as tf\n","from tensorflow.keras.utils import to_categorical\n","from keras.layers import Conv2D, Input, MaxPooling2D, Dropout, Flatten, Dense, Activation\n","from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\n","\n","from sklearn.metrics import ConfusionMatrixDisplay\n","from sklearn.model_selection import StratifiedKFold\n","from keras import regularizers"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":36,"status":"ok","timestamp":1682739185374,"user":{"displayName":"Good Notes UM","userId":"12493674840996884929"},"user_tz":-480},"id":"B95hUV4pmZ9g"},"outputs":[],"source":["#fixed random seed for reproducibility \n","np.random.seed(0)"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":0},"id":"EECGNCI3mZ9i","outputId":"76fe3d35-bbf6-4b5a-9bfd-0ba29b4997d9"},"outputs":[],"source":["# load dataset (input variables = X, output variables = Y)\n","df = pd.read_csv(\"TrainingData.csv\")\n","\n","#count the number of occurances for each osID\n","OsID_counts = df['OsID'].value_counts()\n","\n","#filter for osIDs that have 10 or more occurances\n","OsID_counts_filtered = OsID_counts[OsID_counts >= 10]\n","\n","#assign a label for each osID \n","OsID_labels = {}\n","class_no = 1\n","for osID in OsID_counts_filtered.index:\n","    OsID_labels[osID] = class_no\n","    class_no +=1\n","\n","#filter the dataset with osID that contain 10 or more occurances\n","dataGene = df[df['OsID'].isin(OsID_counts_filtered.index)]\n","\n","dataGene = dataGene.drop(['Class', 'Trait'],axis=1)\n","\n","# Add a new column 'class' to the filtered dataset\n","dataGene['class'] = dataGene['OsID'].map(OsID_labels)\n","\n","#print(\"Summary of dataGene:\\n\",dataGene.describe())"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"Vuf_bBJBUC1h"},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape of X:\n"," (41110, 20)\n","Shape of Y:\n"," (41110,)\n","class\n","1.0      1800\n","2.0      1296\n","3.0      1260\n","4.0      1218\n","5.0      1026\n","6.0      1008\n","7.0       930\n","8.0       912\n","9.0       880\n","10.0      798\n","11.0      792\n","12.0      759\n","13.0      729\n","14.0      720\n","15.0      702\n","16.0      693\n","17.0      672\n","18.0      640\n","19.0      625\n","20.0      570\n","21.0      546\n","22.0      506\n","23.0      483\n","24.0      448\n","25.0      432\n","26.0      384\n","27.0      360\n","28.0      360\n","29.0      320\n","30.0      312\n","         ... \n","344.0      12\n","345.0      12\n","346.0      12\n","347.0      12\n","348.0      12\n","349.0      12\n","350.0      12\n","351.0      12\n","352.0      12\n","353.0      12\n","354.0      12\n","355.0      12\n","356.0      11\n","357.0      11\n","358.0      11\n","359.0      11\n","360.0      11\n","361.0      11\n","362.0      10\n","363.0      10\n","364.0      10\n","365.0      10\n","366.0      10\n","367.0      10\n","368.0      10\n","369.0      10\n","370.0      10\n","371.0      10\n","372.0      10\n","373.0      10\n","Length: 373, dtype: int64\n"]}],"source":["X = dataGene.drop(['class','OsID'], axis=1) # exclude class & OsID column\n","Y = dataGene['class']\n","\n","#input feature names in order of descending importance scores in MI feature selection method\n","feature_names = ['Root10DaysSeedling', 'Leaf45DaysOldPlant', 'Shoot10DaysSeedling', 'Shoot35DaysSeedling', 'Root35DaysSeedling', \n","                 'Leaf21DaysSeedling', 'Root14DaysSeedling', 'Shoot3DaysSeedling', 'Root24DaysSeedling', 'Root52DaysSeedling', \n","                 'Root17DaysSeedling', 'Root21DaysSeedling', 'Shoot14DaysSeedling', 'Shoot21DaysSeedling', 'Shoot17DaysSeedling', \n","                 'ET', 'PCC', 'log_2FoldChange', 'PPI', 'CoExpression']\n","\n","X_fs = X.reindex(columns=feature_names)\n","\n","print(\"Shape of X:\\n\",X_fs.shape)\n","print(\"Shape of Y:\\n\",Y.shape)\n","\n","# Statistical summary of the variables\n","#print(\"Summary of X:\\n\",X_fs.describe())\n","#print(\"Summary of Y:\\n\",Y.describe())\n","\n","# Check for class imbalance\n","print(df.groupby(Y).size())\n","\n","# change both input and target variables datatype to ndarray\n","X_fs = X_fs.values # 2-D array\n","\n","# select target variable \n","\n","Y = Y.values #1-D array\n","Y = Y.reshape(-1, 1)"]},{"cell_type":"code","execution_count":8,"metadata":{"id":"W5zIyx8RVDJu"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:115: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]},{"name":"stdout","output_type":"stream","text":["Class=0, n=1800 (4.378%)\n","Class=1, n=1296 (3.153%)\n","Class=2, n=1260 (3.065%)\n","Class=3, n=1218 (2.963%)\n","Class=4, n=1026 (2.496%)\n","Class=5, n=1008 (2.452%)\n","Class=6, n=930 (2.262%)\n","Class=7, n=912 (2.218%)\n","Class=8, n=880 (2.141%)\n","Class=9, n=798 (1.941%)\n","Class=10, n=792 (1.927%)\n","Class=11, n=759 (1.846%)\n","Class=12, n=729 (1.773%)\n","Class=13, n=720 (1.751%)\n","Class=14, n=702 (1.708%)\n","Class=15, n=693 (1.686%)\n","Class=16, n=672 (1.635%)\n","Class=17, n=640 (1.557%)\n","Class=18, n=625 (1.520%)\n","Class=19, n=570 (1.387%)\n","Class=20, n=546 (1.328%)\n","Class=21, n=506 (1.231%)\n","Class=22, n=483 (1.175%)\n","Class=23, n=448 (1.090%)\n","Class=24, n=432 (1.051%)\n","Class=25, n=384 (0.934%)\n","Class=26, n=360 (0.876%)\n","Class=27, n=360 (0.876%)\n","Class=28, n=320 (0.778%)\n","Class=29, n=312 (0.759%)\n","Class=30, n=312 (0.759%)\n","Class=31, n=306 (0.744%)\n","Class=32, n=304 (0.739%)\n","Class=33, n=299 (0.727%)\n","Class=34, n=297 (0.722%)\n","Class=35, n=296 (0.720%)\n","Class=36, n=280 (0.681%)\n","Class=37, n=264 (0.642%)\n","Class=38, n=260 (0.632%)\n","Class=39, n=253 (0.615%)\n","Class=40, n=252 (0.613%)\n","Class=41, n=248 (0.603%)\n","Class=42, n=242 (0.589%)\n","Class=43, n=228 (0.555%)\n","Class=44, n=216 (0.525%)\n","Class=45, n=210 (0.511%)\n","Class=46, n=200 (0.486%)\n","Class=47, n=192 (0.467%)\n","Class=48, n=180 (0.438%)\n","Class=49, n=171 (0.416%)\n","Class=50, n=168 (0.409%)\n","Class=51, n=168 (0.409%)\n","Class=52, n=162 (0.394%)\n","Class=53, n=150 (0.365%)\n","Class=54, n=148 (0.360%)\n","Class=55, n=138 (0.336%)\n","Class=56, n=135 (0.328%)\n","Class=57, n=135 (0.328%)\n","Class=58, n=133 (0.324%)\n","Class=59, n=132 (0.321%)\n","Class=60, n=132 (0.321%)\n","Class=61, n=130 (0.316%)\n","Class=62, n=130 (0.316%)\n","Class=63, n=130 (0.316%)\n","Class=64, n=128 (0.311%)\n","Class=65, n=128 (0.311%)\n","Class=66, n=126 (0.306%)\n","Class=67, n=124 (0.302%)\n","Class=68, n=124 (0.302%)\n","Class=69, n=124 (0.302%)\n","Class=70, n=120 (0.292%)\n","Class=71, n=120 (0.292%)\n","Class=72, n=118 (0.287%)\n","Class=73, n=116 (0.282%)\n","Class=74, n=114 (0.277%)\n","Class=75, n=105 (0.255%)\n","Class=76, n=104 (0.253%)\n","Class=77, n=102 (0.248%)\n","Class=78, n=99 (0.241%)\n","Class=79, n=98 (0.238%)\n","Class=80, n=98 (0.238%)\n","Class=81, n=98 (0.238%)\n","Class=82, n=98 (0.238%)\n","Class=83, n=96 (0.234%)\n","Class=84, n=96 (0.234%)\n","Class=85, n=96 (0.234%)\n","Class=86, n=93 (0.226%)\n","Class=87, n=92 (0.224%)\n","Class=88, n=92 (0.224%)\n","Class=89, n=91 (0.221%)\n","Class=90, n=88 (0.214%)\n","Class=91, n=88 (0.214%)\n","Class=92, n=86 (0.209%)\n","Class=93, n=86 (0.209%)\n","Class=94, n=84 (0.204%)\n","Class=95, n=84 (0.204%)\n","Class=96, n=84 (0.204%)\n","Class=97, n=78 (0.190%)\n","Class=98, n=78 (0.190%)\n","Class=99, n=76 (0.185%)\n","Class=100, n=75 (0.182%)\n","Class=101, n=75 (0.182%)\n","Class=102, n=73 (0.178%)\n","Class=103, n=72 (0.175%)\n","Class=104, n=72 (0.175%)\n","Class=105, n=70 (0.170%)\n","Class=106, n=69 (0.168%)\n","Class=107, n=68 (0.165%)\n","Class=108, n=67 (0.163%)\n","Class=109, n=66 (0.161%)\n","Class=110, n=66 (0.161%)\n","Class=111, n=66 (0.161%)\n","Class=112, n=66 (0.161%)\n","Class=113, n=66 (0.161%)\n","Class=114, n=65 (0.158%)\n","Class=115, n=64 (0.156%)\n","Class=116, n=63 (0.153%)\n","Class=117, n=63 (0.153%)\n","Class=118, n=62 (0.151%)\n","Class=119, n=61 (0.148%)\n","Class=120, n=60 (0.146%)\n","Class=121, n=60 (0.146%)\n","Class=122, n=60 (0.146%)\n","Class=123, n=60 (0.146%)\n","Class=124, n=60 (0.146%)\n","Class=125, n=60 (0.146%)\n","Class=126, n=60 (0.146%)\n","Class=127, n=60 (0.146%)\n","Class=128, n=60 (0.146%)\n","Class=129, n=60 (0.146%)\n","Class=130, n=59 (0.144%)\n","Class=131, n=59 (0.144%)\n","Class=132, n=58 (0.141%)\n","Class=133, n=56 (0.136%)\n","Class=134, n=56 (0.136%)\n","Class=135, n=56 (0.136%)\n","Class=136, n=56 (0.136%)\n","Class=137, n=56 (0.136%)\n","Class=138, n=56 (0.136%)\n","Class=139, n=56 (0.136%)\n","Class=140, n=56 (0.136%)\n","Class=141, n=56 (0.136%)\n","Class=142, n=55 (0.134%)\n","Class=143, n=55 (0.134%)\n","Class=144, n=54 (0.131%)\n","Class=145, n=54 (0.131%)\n","Class=146, n=54 (0.131%)\n","Class=147, n=54 (0.131%)\n","Class=148, n=54 (0.131%)\n","Class=149, n=53 (0.129%)\n","Class=150, n=52 (0.126%)\n","Class=151, n=52 (0.126%)\n","Class=152, n=52 (0.126%)\n","Class=153, n=52 (0.126%)\n","Class=154, n=50 (0.122%)\n","Class=155, n=50 (0.122%)\n","Class=156, n=49 (0.119%)\n","Class=157, n=49 (0.119%)\n","Class=158, n=48 (0.117%)\n","Class=159, n=48 (0.117%)\n","Class=160, n=48 (0.117%)\n","Class=161, n=46 (0.112%)\n","Class=162, n=45 (0.109%)\n","Class=163, n=44 (0.107%)\n","Class=164, n=44 (0.107%)\n","Class=165, n=44 (0.107%)\n","Class=166, n=42 (0.102%)\n","Class=167, n=42 (0.102%)\n","Class=168, n=42 (0.102%)\n","Class=169, n=42 (0.102%)\n","Class=170, n=42 (0.102%)\n","Class=171, n=42 (0.102%)\n","Class=172, n=42 (0.102%)\n","Class=173, n=41 (0.100%)\n","Class=174, n=41 (0.100%)\n","Class=175, n=40 (0.097%)\n","Class=176, n=40 (0.097%)\n","Class=177, n=39 (0.095%)\n","Class=178, n=39 (0.095%)\n","Class=179, n=38 (0.092%)\n","Class=180, n=37 (0.090%)\n","Class=181, n=36 (0.088%)\n","Class=182, n=35 (0.085%)\n","Class=183, n=35 (0.085%)\n","Class=184, n=35 (0.085%)\n","Class=185, n=35 (0.085%)\n","Class=186, n=34 (0.083%)\n","Class=187, n=34 (0.083%)\n","Class=188, n=34 (0.083%)\n","Class=189, n=34 (0.083%)\n","Class=190, n=32 (0.078%)\n","Class=191, n=32 (0.078%)\n","Class=192, n=32 (0.078%)\n","Class=193, n=32 (0.078%)\n","Class=194, n=32 (0.078%)\n","Class=195, n=32 (0.078%)\n","Class=196, n=31 (0.075%)\n","Class=197, n=31 (0.075%)\n","Class=198, n=31 (0.075%)\n","Class=199, n=31 (0.075%)\n","Class=200, n=30 (0.073%)\n","Class=201, n=30 (0.073%)\n","Class=202, n=30 (0.073%)\n","Class=203, n=30 (0.073%)\n","Class=204, n=30 (0.073%)\n","Class=205, n=30 (0.073%)\n","Class=206, n=30 (0.073%)\n","Class=207, n=30 (0.073%)\n","Class=208, n=30 (0.073%)\n","Class=209, n=29 (0.071%)\n","Class=210, n=29 (0.071%)\n","Class=211, n=28 (0.068%)\n","Class=212, n=28 (0.068%)\n","Class=213, n=28 (0.068%)\n","Class=214, n=28 (0.068%)\n","Class=215, n=28 (0.068%)\n","Class=216, n=28 (0.068%)\n","Class=217, n=27 (0.066%)\n","Class=218, n=27 (0.066%)\n","Class=219, n=27 (0.066%)\n","Class=220, n=27 (0.066%)\n","Class=221, n=27 (0.066%)\n","Class=222, n=27 (0.066%)\n","Class=223, n=26 (0.063%)\n","Class=224, n=26 (0.063%)\n","Class=225, n=26 (0.063%)\n","Class=226, n=26 (0.063%)\n","Class=227, n=26 (0.063%)\n","Class=228, n=25 (0.061%)\n","Class=229, n=25 (0.061%)\n","Class=230, n=25 (0.061%)\n","Class=231, n=25 (0.061%)\n","Class=232, n=24 (0.058%)\n","Class=233, n=24 (0.058%)\n","Class=234, n=24 (0.058%)\n","Class=235, n=24 (0.058%)\n","Class=236, n=24 (0.058%)\n","Class=237, n=24 (0.058%)\n","Class=238, n=24 (0.058%)\n","Class=239, n=24 (0.058%)\n","Class=240, n=24 (0.058%)\n","Class=241, n=24 (0.058%)\n","Class=242, n=24 (0.058%)\n","Class=243, n=24 (0.058%)\n","Class=244, n=23 (0.056%)\n","Class=245, n=23 (0.056%)\n","Class=246, n=22 (0.054%)\n","Class=247, n=22 (0.054%)\n","Class=248, n=22 (0.054%)\n","Class=249, n=22 (0.054%)\n","Class=250, n=22 (0.054%)\n","Class=251, n=22 (0.054%)\n","Class=252, n=22 (0.054%)\n","Class=253, n=22 (0.054%)\n","Class=254, n=22 (0.054%)\n","Class=255, n=22 (0.054%)\n","Class=256, n=22 (0.054%)\n","Class=257, n=22 (0.054%)\n","Class=258, n=22 (0.054%)\n","Class=259, n=22 (0.054%)\n","Class=260, n=22 (0.054%)\n","Class=261, n=22 (0.054%)\n","Class=262, n=22 (0.054%)\n","Class=263, n=22 (0.054%)\n","Class=264, n=21 (0.051%)\n","Class=265, n=21 (0.051%)\n","Class=266, n=21 (0.051%)\n","Class=267, n=21 (0.051%)\n","Class=268, n=21 (0.051%)\n","Class=269, n=20 (0.049%)\n","Class=270, n=20 (0.049%)\n","Class=271, n=20 (0.049%)\n","Class=272, n=20 (0.049%)\n","Class=273, n=20 (0.049%)\n","Class=274, n=20 (0.049%)\n","Class=275, n=20 (0.049%)\n","Class=276, n=20 (0.049%)\n","Class=277, n=20 (0.049%)\n","Class=278, n=20 (0.049%)\n","Class=279, n=20 (0.049%)\n","Class=280, n=19 (0.046%)\n","Class=281, n=19 (0.046%)\n","Class=282, n=19 (0.046%)\n","Class=283, n=18 (0.044%)\n","Class=284, n=18 (0.044%)\n","Class=285, n=18 (0.044%)\n","Class=286, n=18 (0.044%)\n","Class=287, n=18 (0.044%)\n","Class=288, n=18 (0.044%)\n","Class=289, n=18 (0.044%)\n","Class=290, n=18 (0.044%)\n","Class=291, n=18 (0.044%)\n","Class=292, n=17 (0.041%)\n","Class=293, n=17 (0.041%)\n","Class=294, n=17 (0.041%)\n","Class=295, n=17 (0.041%)\n","Class=296, n=17 (0.041%)\n","Class=297, n=17 (0.041%)\n","Class=298, n=16 (0.039%)\n","Class=299, n=16 (0.039%)\n","Class=300, n=16 (0.039%)\n","Class=301, n=16 (0.039%)\n","Class=302, n=16 (0.039%)\n","Class=303, n=16 (0.039%)\n","Class=304, n=16 (0.039%)\n","Class=305, n=16 (0.039%)\n","Class=306, n=15 (0.036%)\n","Class=307, n=15 (0.036%)\n","Class=308, n=15 (0.036%)\n","Class=309, n=15 (0.036%)\n","Class=310, n=15 (0.036%)\n","Class=311, n=14 (0.034%)\n","Class=312, n=14 (0.034%)\n","Class=313, n=14 (0.034%)\n","Class=314, n=14 (0.034%)\n","Class=315, n=14 (0.034%)\n","Class=316, n=14 (0.034%)\n","Class=317, n=14 (0.034%)\n","Class=318, n=14 (0.034%)\n","Class=319, n=14 (0.034%)\n","Class=320, n=14 (0.034%)\n","Class=321, n=14 (0.034%)\n","Class=322, n=14 (0.034%)\n","Class=323, n=14 (0.034%)\n","Class=324, n=14 (0.034%)\n","Class=325, n=14 (0.034%)\n","Class=326, n=14 (0.034%)\n","Class=327, n=14 (0.034%)\n","Class=328, n=13 (0.032%)\n","Class=329, n=13 (0.032%)\n","Class=330, n=13 (0.032%)\n","Class=331, n=13 (0.032%)\n","Class=332, n=13 (0.032%)\n","Class=333, n=13 (0.032%)\n","Class=334, n=13 (0.032%)\n","Class=335, n=13 (0.032%)\n","Class=336, n=13 (0.032%)\n","Class=337, n=12 (0.029%)\n","Class=338, n=12 (0.029%)\n","Class=339, n=12 (0.029%)\n","Class=340, n=12 (0.029%)\n","Class=341, n=12 (0.029%)\n","Class=342, n=12 (0.029%)\n","Class=343, n=12 (0.029%)\n","Class=344, n=12 (0.029%)\n","Class=345, n=12 (0.029%)\n","Class=346, n=12 (0.029%)\n","Class=347, n=12 (0.029%)\n","Class=348, n=12 (0.029%)\n","Class=349, n=12 (0.029%)\n","Class=350, n=12 (0.029%)\n","Class=351, n=12 (0.029%)\n","Class=352, n=12 (0.029%)\n","Class=353, n=12 (0.029%)\n","Class=354, n=12 (0.029%)\n","Class=355, n=11 (0.027%)\n","Class=356, n=11 (0.027%)\n","Class=357, n=11 (0.027%)\n","Class=358, n=11 (0.027%)\n","Class=359, n=11 (0.027%)\n","Class=360, n=11 (0.027%)\n","Class=361, n=10 (0.024%)\n","Class=362, n=10 (0.024%)\n","Class=363, n=10 (0.024%)\n","Class=364, n=10 (0.024%)\n","Class=365, n=10 (0.024%)\n","Class=366, n=10 (0.024%)\n","Class=367, n=10 (0.024%)\n","Class=368, n=10 (0.024%)\n","Class=369, n=10 (0.024%)\n","Class=370, n=10 (0.024%)\n","Class=371, n=10 (0.024%)\n","Class=372, n=10 (0.024%)\n"]},{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"}],"source":["y_labelenc = LabelEncoder().fit_transform(Y)\n","\n","from collections import Counter\n","# summarize distribution\n","counter = Counter(y_labelenc)\n","\n","# sort counter by keys\n","counter = dict(sorted(counter.items()))\n","\n","\n","for k,v in counter.items():\n"," per = v / len(y_labelenc) * 100\n"," print('Class=%d, n=%d (%.3f%%)' % (k, v, per))\n","# plot the distribution\n","plt.bar( counter.keys(), counter.values())\n","\n","plt.ylabel('No of gene samples')\n","plt.xlabel('Class Index of OsID')\n","plt.title('Distribution of Target Classes (OsID)')\n","plt.show()"]},{"cell_type":"code","execution_count":9,"metadata":{"id":"W1WdWupjmZ9l"},"outputs":[],"source":["# prepare target data\n","def prepare_targets(y_train, y_test):\n","\tle = LabelEncoder()\n","\t\n","\t#fit the encoders only to the training data and then transform both train and test data\n","\ty_train_enc = le.fit_transform(y_train)\n","\ty_test_enc = le.transform(y_test)\n","\n","\treturn y_train_enc, y_test_enc"]},{"cell_type":"code","execution_count":10,"metadata":{"id":"JjjBaPUOtmlx"},"outputs":[{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\preprocessing\\_label.py:133: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n","  y = column_or_1d(y, warn=True)\n"]}],"source":["# split into train and test sets\n","X_train, X_test, y_train, y_test = train_test_split(X_fs, Y, test_size=0.33, random_state=1)\n","\n","# prepare output data\n","y_train_enc, y_test_enc = prepare_targets(y_train, y_test)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"POiHy56emZ9m"},"outputs":[{"name":"stdout","output_type":"stream","text":["\n","Number of input features: 1\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 4.5985 - accuracy: 0.0905 - val_loss: 4.2432 - val_accuracy: 0.1197\n","Epoch 2/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.9444 - accuracy: 0.1454 - val_loss: 3.9512 - val_accuracy: 0.1421\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.6525 - accuracy: 0.1835 - val_loss: 3.7438 - val_accuracy: 0.1738\n","Epoch 4/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.4073 - accuracy: 0.2119 - val_loss: 3.5517 - val_accuracy: 0.2464\n","Epoch 5/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.2078 - accuracy: 0.2346 - val_loss: 3.4470 - val_accuracy: 0.2222\n","Epoch 6/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 3.0499 - accuracy: 0.2551 - val_loss: 3.3420 - val_accuracy: 0.3102\n","Epoch 7/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.9262 - accuracy: 0.2783 - val_loss: 3.3063 - val_accuracy: 0.2174\n","Epoch 8/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.8260 - accuracy: 0.2994 - val_loss: 3.2187 - val_accuracy: 0.2983\n","Epoch 9/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.7545 - accuracy: 0.3127 - val_loss: 3.2075 - val_accuracy: 0.2900\n","Epoch 10/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.6915 - accuracy: 0.3248 - val_loss: 3.2203 - val_accuracy: 0.3327\n","Epoch 11/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 2.6551 - accuracy: 0.3359 - val_loss: 3.1446 - val_accuracy: 0.3162\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.6098 - accuracy: 0.3419 - val_loss: 3.0736 - val_accuracy: 0.3586\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.5897 - accuracy: 0.3475 - val_loss: 3.0667 - val_accuracy: 0.3624\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 2.5525 - accuracy: 0.3545 - val_loss: 3.0855 - val_accuracy: 0.3529\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.5393 - accuracy: 0.3520 - val_loss: 3.0626 - val_accuracy: 0.3501\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5119 - accuracy: 0.3579 - val_loss: 3.0235 - val_accuracy: 0.3589\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4905 - accuracy: 0.3627 - val_loss: 2.9544 - val_accuracy: 0.3683\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4865 - accuracy: 0.3606 - val_loss: 2.9532 - val_accuracy: 0.3641\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4575 - accuracy: 0.3675 - val_loss: 2.9065 - val_accuracy: 0.3415\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4507 - accuracy: 0.3675 - val_loss: 2.9131 - val_accuracy: 0.3107\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4375 - accuracy: 0.3731 - val_loss: 2.9227 - val_accuracy: 0.3639\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4378 - accuracy: 0.3681 - val_loss: 2.8904 - val_accuracy: 0.2961\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4134 - accuracy: 0.3768 - val_loss: 2.9287 - val_accuracy: 0.3318\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4129 - accuracy: 0.3719 - val_loss: 2.8540 - val_accuracy: 0.3622\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4026 - accuracy: 0.3750 - val_loss: 2.8960 - val_accuracy: 0.3586\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3891 - accuracy: 0.3789 - val_loss: 2.9829 - val_accuracy: 0.3380\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3875 - accuracy: 0.3741 - val_loss: 2.8246 - val_accuracy: 0.3925\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3794 - accuracy: 0.3744 - val_loss: 2.8034 - val_accuracy: 0.3738\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3656 - accuracy: 0.3770 - val_loss: 2.8128 - val_accuracy: 0.3932\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3581 - accuracy: 0.3799 - val_loss: 2.8503 - val_accuracy: 0.3615\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3539 - accuracy: 0.3814 - val_loss: 2.7459 - val_accuracy: 0.3703\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3474 - accuracy: 0.3868 - val_loss: 2.8574 - val_accuracy: 0.3606\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3550 - accuracy: 0.3808 - val_loss: 2.7880 - val_accuracy: 0.3382\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3331 - accuracy: 0.3837 - val_loss: 2.8030 - val_accuracy: 0.3406\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3292 - accuracy: 0.3845 - val_loss: 2.7330 - val_accuracy: 0.3582\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3267 - accuracy: 0.3845 - val_loss: 2.7284 - val_accuracy: 0.3872\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3160 - accuracy: 0.3862 - val_loss: 2.7447 - val_accuracy: 0.3886\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3245 - accuracy: 0.3837 - val_loss: 2.7272 - val_accuracy: 0.3740\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2997 - accuracy: 0.3941 - val_loss: 2.7359 - val_accuracy: 0.3613\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3145 - accuracy: 0.3914 - val_loss: 2.7255 - val_accuracy: 0.3716\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.6111 - accuracy: 0.0879 - val_loss: 4.2499 - val_accuracy: 0.1289\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.9199 - accuracy: 0.1512 - val_loss: 3.9108 - val_accuracy: 0.1936\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.5602 - accuracy: 0.2100 - val_loss: 3.5896 - val_accuracy: 0.2211\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.2505 - accuracy: 0.2557 - val_loss: 3.3699 - val_accuracy: 0.2739\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.0126 - accuracy: 0.2902 - val_loss: 3.1988 - val_accuracy: 0.2836\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.8434 - accuracy: 0.3196 - val_loss: 3.0900 - val_accuracy: 0.2796\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.7198 - accuracy: 0.3403 - val_loss: 3.0024 - val_accuracy: 0.3025\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.6180 - accuracy: 0.3560 - val_loss: 2.8899 - val_accuracy: 0.3584\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5344 - accuracy: 0.3761 - val_loss: 2.8482 - val_accuracy: 0.3800\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4716 - accuracy: 0.3795 - val_loss: 2.7737 - val_accuracy: 0.3600\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4209 - accuracy: 0.3906 - val_loss: 2.7230 - val_accuracy: 0.3919\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3769 - accuracy: 0.3907 - val_loss: 2.6517 - val_accuracy: 0.3738\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3355 - accuracy: 0.3981 - val_loss: 2.6636 - val_accuracy: 0.3947\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3013 - accuracy: 0.4052 - val_loss: 2.6364 - val_accuracy: 0.4244\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2804 - accuracy: 0.4071 - val_loss: 2.5463 - val_accuracy: 0.4328\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2515 - accuracy: 0.4128 - val_loss: 2.5634 - val_accuracy: 0.4414\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.2337 - accuracy: 0.4199 - val_loss: 2.5651 - val_accuracy: 0.4202\n","Epoch 18/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.2101 - accuracy: 0.4208 - val_loss: 2.4900 - val_accuracy: 0.4101\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1921 - accuracy: 0.4210 - val_loss: 2.4920 - val_accuracy: 0.3595\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1645 - accuracy: 0.4296 - val_loss: 2.4867 - val_accuracy: 0.4194\n","Epoch 21/40\n","1846/1846 [==============================] - 4s 2ms/step - loss: 2.1484 - accuracy: 0.4285 - val_loss: 2.4727 - val_accuracy: 0.4422\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1341 - accuracy: 0.4304 - val_loss: 2.4754 - val_accuracy: 0.4150\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1263 - accuracy: 0.4373 - val_loss: 2.4185 - val_accuracy: 0.4363\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.1097 - accuracy: 0.4369 - val_loss: 2.5650 - val_accuracy: 0.4279\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0967 - accuracy: 0.4434 - val_loss: 2.3815 - val_accuracy: 0.4552\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0772 - accuracy: 0.4525 - val_loss: 2.4410 - val_accuracy: 0.4310\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0843 - accuracy: 0.4478 - val_loss: 2.3443 - val_accuracy: 0.4337\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0584 - accuracy: 0.4512 - val_loss: 2.3882 - val_accuracy: 0.4112\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0581 - accuracy: 0.4514 - val_loss: 2.3622 - val_accuracy: 0.4150\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0441 - accuracy: 0.4544 - val_loss: 2.3507 - val_accuracy: 0.4242\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0390 - accuracy: 0.4569 - val_loss: 2.3916 - val_accuracy: 0.4436\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0164 - accuracy: 0.4570 - val_loss: 2.3067 - val_accuracy: 0.4405\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0176 - accuracy: 0.4601 - val_loss: 2.2917 - val_accuracy: 0.4735\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0033 - accuracy: 0.4699 - val_loss: 2.3269 - val_accuracy: 0.4898\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.0066 - accuracy: 0.4633 - val_loss: 2.2877 - val_accuracy: 0.4519\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9923 - accuracy: 0.4666 - val_loss: 2.2903 - val_accuracy: 0.4576\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9871 - accuracy: 0.4713 - val_loss: 2.2634 - val_accuracy: 0.5063\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9869 - accuracy: 0.4703 - val_loss: 2.2144 - val_accuracy: 0.5206\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9833 - accuracy: 0.4738 - val_loss: 2.3446 - val_accuracy: 0.4244\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9674 - accuracy: 0.4732 - val_loss: 2.2578 - val_accuracy: 0.4686\n","Average Validation Accuracy: 0.4335419535636902\n","Average Validation Loss: 2.2133896350860596\n","Average Test Accuracy: 0.43447335064411163\n","------------------------------------------------------------------------\n","\n","Number of input features: 2\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.5163 - accuracy: 0.1243 - val_loss: 3.8499 - val_accuracy: 0.2444\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.2089 - accuracy: 0.3289 - val_loss: 2.9724 - val_accuracy: 0.4044\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.4723 - accuracy: 0.4669 - val_loss: 2.4329 - val_accuracy: 0.4915\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9931 - accuracy: 0.5483 - val_loss: 2.1299 - val_accuracy: 0.5336\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6788 - accuracy: 0.5981 - val_loss: 1.8886 - val_accuracy: 0.6222\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4814 - accuracy: 0.6325 - val_loss: 1.7572 - val_accuracy: 0.6506\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3483 - accuracy: 0.6622 - val_loss: 1.6245 - val_accuracy: 0.6647\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2502 - accuracy: 0.6756 - val_loss: 1.5811 - val_accuracy: 0.6794\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1857 - accuracy: 0.6888 - val_loss: 1.4353 - val_accuracy: 0.7234\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1137 - accuracy: 0.7064 - val_loss: 1.4091 - val_accuracy: 0.7014\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0698 - accuracy: 0.7158 - val_loss: 1.3640 - val_accuracy: 0.7193\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0457 - accuracy: 0.7178 - val_loss: 1.3063 - val_accuracy: 0.7393\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0055 - accuracy: 0.7343 - val_loss: 1.3135 - val_accuracy: 0.7347\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9729 - accuracy: 0.7388 - val_loss: 1.2445 - val_accuracy: 0.7419\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9555 - accuracy: 0.7413 - val_loss: 1.2780 - val_accuracy: 0.7347\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9268 - accuracy: 0.7547 - val_loss: 1.2149 - val_accuracy: 0.7626\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9102 - accuracy: 0.7536 - val_loss: 1.1988 - val_accuracy: 0.7417\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8958 - accuracy: 0.7548 - val_loss: 1.1648 - val_accuracy: 0.7490\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8740 - accuracy: 0.7618 - val_loss: 1.1667 - val_accuracy: 0.7388\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8549 - accuracy: 0.7667 - val_loss: 1.1587 - val_accuracy: 0.7633\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8572 - accuracy: 0.7608 - val_loss: 1.1688 - val_accuracy: 0.7419\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8295 - accuracy: 0.7709 - val_loss: 1.2088 - val_accuracy: 0.7525\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8265 - accuracy: 0.7680 - val_loss: 1.0427 - val_accuracy: 0.8013\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.8008 - accuracy: 0.7740 - val_loss: 1.1392 - val_accuracy: 0.7459\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8020 - accuracy: 0.7764 - val_loss: 1.0819 - val_accuracy: 0.7635\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7923 - accuracy: 0.7761 - val_loss: 1.0689 - val_accuracy: 0.7778\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7755 - accuracy: 0.7808 - val_loss: 1.0660 - val_accuracy: 0.7903\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7647 - accuracy: 0.7845 - val_loss: 1.0663 - val_accuracy: 0.7723\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7595 - accuracy: 0.7853 - val_loss: 1.0492 - val_accuracy: 0.8046\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7491 - accuracy: 0.7861 - val_loss: 1.0690 - val_accuracy: 0.7622\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7356 - accuracy: 0.7900 - val_loss: 0.9846 - val_accuracy: 0.8189\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7283 - accuracy: 0.7940 - val_loss: 0.9965 - val_accuracy: 0.8022\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7233 - accuracy: 0.7940 - val_loss: 1.0280 - val_accuracy: 0.7824\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7154 - accuracy: 0.7936 - val_loss: 0.9894 - val_accuracy: 0.7938\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7087 - accuracy: 0.7975 - val_loss: 0.9613 - val_accuracy: 0.8009\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7034 - accuracy: 0.7977 - val_loss: 0.9945 - val_accuracy: 0.7963\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7007 - accuracy: 0.7997 - val_loss: 0.9898 - val_accuracy: 0.7938\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6927 - accuracy: 0.7982 - val_loss: 1.0726 - val_accuracy: 0.7677\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6893 - accuracy: 0.8036 - val_loss: 0.9664 - val_accuracy: 0.7864\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 2ms/step - loss: 0.6704 - accuracy: 0.8070 - val_loss: 0.9288 - val_accuracy: 0.8079\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.5047 - accuracy: 0.1183 - val_loss: 3.9733 - val_accuracy: 0.2669\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 3.3276 - accuracy: 0.2928 - val_loss: 3.1280 - val_accuracy: 0.3595\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.5289 - accuracy: 0.4489 - val_loss: 2.5831 - val_accuracy: 0.5080\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.9982 - accuracy: 0.5458 - val_loss: 2.2320 - val_accuracy: 0.6018\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6822 - accuracy: 0.6058 - val_loss: 2.0125 - val_accuracy: 0.6227\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.4749 - accuracy: 0.6373 - val_loss: 1.8748 - val_accuracy: 0.6768\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.3351 - accuracy: 0.6650 - val_loss: 1.7110 - val_accuracy: 0.7050\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2279 - accuracy: 0.6891 - val_loss: 1.6970 - val_accuracy: 0.6728\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1591 - accuracy: 0.7003 - val_loss: 1.5543 - val_accuracy: 0.7058\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1051 - accuracy: 0.7120 - val_loss: 1.5463 - val_accuracy: 0.7080\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0582 - accuracy: 0.7172 - val_loss: 1.5095 - val_accuracy: 0.6818\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.0221 - accuracy: 0.7276 - val_loss: 1.3665 - val_accuracy: 0.7551\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9932 - accuracy: 0.7361 - val_loss: 1.4324 - val_accuracy: 0.6876\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9701 - accuracy: 0.7322 - val_loss: 1.3270 - val_accuracy: 0.7360\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9412 - accuracy: 0.7400 - val_loss: 1.2897 - val_accuracy: 0.7296\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9200 - accuracy: 0.7435 - val_loss: 1.3521 - val_accuracy: 0.7003\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.9063 - accuracy: 0.7509 - val_loss: 1.3142 - val_accuracy: 0.7465\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8893 - accuracy: 0.7562 - val_loss: 1.2430 - val_accuracy: 0.7421\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8738 - accuracy: 0.7564 - val_loss: 1.2001 - val_accuracy: 0.7707\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8638 - accuracy: 0.7605 - val_loss: 1.2246 - val_accuracy: 0.7450\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8396 - accuracy: 0.7653 - val_loss: 1.2095 - val_accuracy: 0.7452\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8298 - accuracy: 0.7647 - val_loss: 1.1377 - val_accuracy: 0.7930\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8295 - accuracy: 0.7679 - val_loss: 1.1212 - val_accuracy: 0.7782\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8022 - accuracy: 0.7729 - val_loss: 1.1394 - val_accuracy: 0.7756\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7923 - accuracy: 0.7737 - val_loss: 1.0881 - val_accuracy: 0.7824\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7945 - accuracy: 0.7745 - val_loss: 1.2680 - val_accuracy: 0.7507\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7785 - accuracy: 0.7803 - val_loss: 1.2061 - val_accuracy: 0.7501\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7633 - accuracy: 0.7819 - val_loss: 1.0865 - val_accuracy: 0.7947\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7566 - accuracy: 0.7834 - val_loss: 1.0296 - val_accuracy: 0.8048\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7504 - accuracy: 0.7814 - val_loss: 1.0883 - val_accuracy: 0.7846\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7420 - accuracy: 0.7881 - val_loss: 1.0973 - val_accuracy: 0.7892\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7358 - accuracy: 0.7917 - val_loss: 1.0474 - val_accuracy: 0.7853\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7253 - accuracy: 0.7873 - val_loss: 1.0601 - val_accuracy: 0.7562\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7241 - accuracy: 0.7906 - val_loss: 0.9979 - val_accuracy: 0.8150\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7104 - accuracy: 0.7941 - val_loss: 1.0251 - val_accuracy: 0.8088\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7028 - accuracy: 0.7987 - val_loss: 1.0282 - val_accuracy: 0.7925\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6867 - accuracy: 0.8009 - val_loss: 1.0748 - val_accuracy: 0.7536\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7151 - accuracy: 0.7934 - val_loss: 1.0556 - val_accuracy: 0.7780\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6759 - accuracy: 0.8081 - val_loss: 1.0347 - val_accuracy: 0.7901\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6780 - accuracy: 0.8043 - val_loss: 1.0284 - val_accuracy: 0.8103\n","Average Validation Accuracy: 0.8213340640068054\n","Average Validation Loss: 0.746311217546463\n","Average Test Accuracy: 0.8154345154762268\n","------------------------------------------------------------------------\n","\n","Number of input features: 3\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.1307 - accuracy: 0.1929 - val_loss: 3.2210 - val_accuracy: 0.4004\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.4442 - accuracy: 0.5122 - val_loss: 2.1417 - val_accuracy: 0.5723\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.5694 - accuracy: 0.6565 - val_loss: 1.5441 - val_accuracy: 0.7164\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.1206 - accuracy: 0.7308 - val_loss: 1.2341 - val_accuracy: 0.7571\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8891 - accuracy: 0.7692 - val_loss: 1.0900 - val_accuracy: 0.7848\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7646 - accuracy: 0.7910 - val_loss: 0.9648 - val_accuracy: 0.7886\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6766 - accuracy: 0.8092 - val_loss: 0.8982 - val_accuracy: 0.7967\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6251 - accuracy: 0.8212 - val_loss: 0.8203 - val_accuracy: 0.8348\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5764 - accuracy: 0.8346 - val_loss: 0.7457 - val_accuracy: 0.8469\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5383 - accuracy: 0.8483 - val_loss: 0.7055 - val_accuracy: 0.8526\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5159 - accuracy: 0.8543 - val_loss: 0.7028 - val_accuracy: 0.8682\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5021 - accuracy: 0.8504 - val_loss: 0.6656 - val_accuracy: 0.8414\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4670 - accuracy: 0.8656 - val_loss: 0.6552 - val_accuracy: 0.8469\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4495 - accuracy: 0.8694 - val_loss: 0.6168 - val_accuracy: 0.8788\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4325 - accuracy: 0.8748 - val_loss: 0.6309 - val_accuracy: 0.8779\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4273 - accuracy: 0.8771 - val_loss: 0.5852 - val_accuracy: 0.8838\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4177 - accuracy: 0.8802 - val_loss: 0.6223 - val_accuracy: 0.8653\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3987 - accuracy: 0.8819 - val_loss: 0.5987 - val_accuracy: 0.8851\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3931 - accuracy: 0.8884 - val_loss: 0.6624 - val_accuracy: 0.8433\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4001 - accuracy: 0.8843 - val_loss: 0.5958 - val_accuracy: 0.8579\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3787 - accuracy: 0.8900 - val_loss: 0.6053 - val_accuracy: 0.8794\n","Epoch 22/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3640 - accuracy: 0.8913 - val_loss: 0.5412 - val_accuracy: 0.9063\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3513 - accuracy: 0.8979 - val_loss: 0.6891 - val_accuracy: 0.8451\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3591 - accuracy: 0.8985 - val_loss: 0.5526 - val_accuracy: 0.8889\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3542 - accuracy: 0.8981 - val_loss: 0.5838 - val_accuracy: 0.8913\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3343 - accuracy: 0.9010 - val_loss: 0.5149 - val_accuracy: 0.8983\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3350 - accuracy: 0.9056 - val_loss: 0.5580 - val_accuracy: 0.9008\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3315 - accuracy: 0.9058 - val_loss: 0.4991 - val_accuracy: 0.9111\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3178 - accuracy: 0.9065 - val_loss: 0.5060 - val_accuracy: 0.9168\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3222 - accuracy: 0.9083 - val_loss: 0.4928 - val_accuracy: 0.9111\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3193 - accuracy: 0.9087 - val_loss: 0.4920 - val_accuracy: 0.9245\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3107 - accuracy: 0.9112 - val_loss: 0.4841 - val_accuracy: 0.9182\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3129 - accuracy: 0.9112 - val_loss: 0.5497 - val_accuracy: 0.9032\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3004 - accuracy: 0.9123 - val_loss: 0.5356 - val_accuracy: 0.8906\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2944 - accuracy: 0.9185 - val_loss: 0.5485 - val_accuracy: 0.8812\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2991 - accuracy: 0.9127 - val_loss: 0.4786 - val_accuracy: 0.9074\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2884 - accuracy: 0.9151 - val_loss: 0.5191 - val_accuracy: 0.8990\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3010 - accuracy: 0.9140 - val_loss: 0.4806 - val_accuracy: 0.9074\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2844 - accuracy: 0.9155 - val_loss: 0.4664 - val_accuracy: 0.9327\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2898 - accuracy: 0.9153 - val_loss: 0.6295 - val_accuracy: 0.8744\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 4.0989 - accuracy: 0.2209 - val_loss: 3.2155 - val_accuracy: 0.4387\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3824 - accuracy: 0.5329 - val_loss: 2.1921 - val_accuracy: 0.6132\n","Epoch 3/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.6162 - accuracy: 0.6627 - val_loss: 1.7277 - val_accuracy: 0.6920\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 1.2440 - accuracy: 0.7243 - val_loss: 1.4836 - val_accuracy: 0.7252\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0219 - accuracy: 0.7580 - val_loss: 1.3587 - val_accuracy: 0.7483\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.8880 - accuracy: 0.7786 - val_loss: 1.1397 - val_accuracy: 0.7905\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7860 - accuracy: 0.8019 - val_loss: 1.0745 - val_accuracy: 0.7956\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.7250 - accuracy: 0.8121 - val_loss: 1.0456 - val_accuracy: 0.7848\n","Epoch 9/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.6699 - accuracy: 0.8230 - val_loss: 0.9358 - val_accuracy: 0.8315\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6298 - accuracy: 0.8305 - val_loss: 0.9481 - val_accuracy: 0.7949\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5900 - accuracy: 0.8398 - val_loss: 0.8717 - val_accuracy: 0.8282\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5653 - accuracy: 0.8457 - val_loss: 0.8373 - val_accuracy: 0.8550\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5425 - accuracy: 0.8497 - val_loss: 0.8206 - val_accuracy: 0.8524\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5268 - accuracy: 0.8537 - val_loss: 0.8124 - val_accuracy: 0.8629\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5043 - accuracy: 0.8624 - val_loss: 0.7820 - val_accuracy: 0.8444\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4858 - accuracy: 0.8642 - val_loss: 0.7380 - val_accuracy: 0.8627\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4780 - accuracy: 0.8659 - val_loss: 0.7324 - val_accuracy: 0.8612\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4596 - accuracy: 0.8719 - val_loss: 0.6802 - val_accuracy: 0.8884\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4446 - accuracy: 0.8775 - val_loss: 0.6971 - val_accuracy: 0.8574\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4359 - accuracy: 0.8780 - val_loss: 0.6886 - val_accuracy: 0.8704\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4314 - accuracy: 0.8781 - val_loss: 0.6929 - val_accuracy: 0.8755\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4159 - accuracy: 0.8831 - val_loss: 0.7281 - val_accuracy: 0.8563\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4156 - accuracy: 0.8809 - val_loss: 0.6711 - val_accuracy: 0.8594\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3951 - accuracy: 0.8871 - val_loss: 0.6797 - val_accuracy: 0.8821\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3986 - accuracy: 0.8838 - val_loss: 0.6134 - val_accuracy: 0.8961\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3809 - accuracy: 0.8938 - val_loss: 0.6471 - val_accuracy: 0.8682\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3779 - accuracy: 0.8918 - val_loss: 0.6694 - val_accuracy: 0.8473\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3726 - accuracy: 0.8968 - val_loss: 0.6293 - val_accuracy: 0.8735\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3707 - accuracy: 0.8954 - val_loss: 0.6101 - val_accuracy: 0.9017\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3635 - accuracy: 0.9008 - val_loss: 0.6546 - val_accuracy: 0.8794\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3578 - accuracy: 0.8971 - val_loss: 0.5819 - val_accuracy: 0.9006\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3532 - accuracy: 0.9012 - val_loss: 0.5941 - val_accuracy: 0.8939\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3456 - accuracy: 0.9035 - val_loss: 0.6294 - val_accuracy: 0.8717\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3417 - accuracy: 0.9034 - val_loss: 0.5842 - val_accuracy: 0.9003\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3430 - accuracy: 0.9034 - val_loss: 0.6042 - val_accuracy: 0.8906\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3227 - accuracy: 0.9107 - val_loss: 0.6732 - val_accuracy: 0.8625\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3374 - accuracy: 0.9048 - val_loss: 0.5964 - val_accuracy: 0.8931\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3265 - accuracy: 0.9084 - val_loss: 0.5845 - val_accuracy: 0.9076\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3205 - accuracy: 0.9108 - val_loss: 0.5818 - val_accuracy: 0.8957\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3184 - accuracy: 0.9109 - val_loss: 0.5418 - val_accuracy: 0.9204\n","Average Validation Accuracy: 0.9076362252235413\n","Average Validation Loss: 0.41501733660697937\n","Average Test Accuracy: 0.9059850871562958\n","------------------------------------------------------------------------\n","\n","Number of input features: 4\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.9983 - accuracy: 0.2587 - val_loss: 3.1415 - val_accuracy: 0.4354\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3236 - accuracy: 0.5804 - val_loss: 2.0037 - val_accuracy: 0.6398\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4103 - accuracy: 0.7226 - val_loss: 1.3794 - val_accuracy: 0.7644\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9254 - accuracy: 0.8066 - val_loss: 1.0865 - val_accuracy: 0.8205\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7064 - accuracy: 0.8378 - val_loss: 0.9378 - val_accuracy: 0.8106\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5856 - accuracy: 0.8570 - val_loss: 0.8028 - val_accuracy: 0.8521\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5200 - accuracy: 0.8647 - val_loss: 0.7224 - val_accuracy: 0.8609\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4666 - accuracy: 0.8774 - val_loss: 0.6904 - val_accuracy: 0.8636\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4322 - accuracy: 0.8840 - val_loss: 0.6163 - val_accuracy: 0.8814\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3993 - accuracy: 0.8910 - val_loss: 0.5961 - val_accuracy: 0.8887\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3819 - accuracy: 0.8950 - val_loss: 0.5525 - val_accuracy: 0.8880\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3555 - accuracy: 0.9010 - val_loss: 0.5466 - val_accuracy: 0.8994\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3506 - accuracy: 0.9029 - val_loss: 0.5153 - val_accuracy: 0.9094\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3381 - accuracy: 0.9085 - val_loss: 0.5065 - val_accuracy: 0.9012\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3126 - accuracy: 0.9139 - val_loss: 0.5122 - val_accuracy: 0.9039\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3075 - accuracy: 0.9149 - val_loss: 0.4505 - val_accuracy: 0.9109\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2931 - accuracy: 0.9207 - val_loss: 0.5159 - val_accuracy: 0.8761\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2907 - accuracy: 0.9168 - val_loss: 0.4477 - val_accuracy: 0.9146\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2705 - accuracy: 0.9298 - val_loss: 0.3899 - val_accuracy: 0.9404\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2686 - accuracy: 0.9261 - val_loss: 0.4303 - val_accuracy: 0.9160\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2565 - accuracy: 0.9310 - val_loss: 0.4273 - val_accuracy: 0.9329\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2491 - accuracy: 0.9334 - val_loss: 0.3909 - val_accuracy: 0.9426\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2422 - accuracy: 0.9344 - val_loss: 0.4028 - val_accuracy: 0.9292\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2452 - accuracy: 0.9332 - val_loss: 0.3619 - val_accuracy: 0.9474\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2288 - accuracy: 0.9404 - val_loss: 0.3438 - val_accuracy: 0.9503\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2280 - accuracy: 0.9392 - val_loss: 0.3878 - val_accuracy: 0.9355\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2196 - accuracy: 0.9410 - val_loss: 0.4190 - val_accuracy: 0.9256\n","Epoch 28/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2257 - accuracy: 0.9394 - val_loss: 0.3875 - val_accuracy: 0.9289\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2165 - accuracy: 0.9430 - val_loss: 0.3362 - val_accuracy: 0.9518\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2100 - accuracy: 0.9494 - val_loss: 0.3420 - val_accuracy: 0.9465\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2050 - accuracy: 0.9484 - val_loss: 0.3540 - val_accuracy: 0.9505\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2084 - accuracy: 0.9479 - val_loss: 0.3397 - val_accuracy: 0.9490\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2005 - accuracy: 0.9481 - val_loss: 0.3337 - val_accuracy: 0.9518\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1987 - accuracy: 0.9474 - val_loss: 0.3594 - val_accuracy: 0.9402\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1956 - accuracy: 0.9500 - val_loss: 0.3272 - val_accuracy: 0.9586\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1922 - accuracy: 0.9519 - val_loss: 0.3527 - val_accuracy: 0.9496\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1934 - accuracy: 0.9518 - val_loss: 0.3276 - val_accuracy: 0.9450\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1911 - accuracy: 0.9502 - val_loss: 0.3395 - val_accuracy: 0.9459\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1797 - accuracy: 0.9543 - val_loss: 0.3747 - val_accuracy: 0.9384\n","Epoch 40/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1865 - accuracy: 0.9543 - val_loss: 0.3565 - val_accuracy: 0.9465\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 4.0467 - accuracy: 0.2371 - val_loss: 3.1824 - val_accuracy: 0.4229\n","Epoch 2/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 2.3936 - accuracy: 0.5613 - val_loss: 2.1953 - val_accuracy: 0.6433\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5746 - accuracy: 0.6964 - val_loss: 1.6891 - val_accuracy: 0.7241\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.1125 - accuracy: 0.7725 - val_loss: 1.4079 - val_accuracy: 0.7622\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8529 - accuracy: 0.8121 - val_loss: 1.1956 - val_accuracy: 0.8117\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6955 - accuracy: 0.8399 - val_loss: 1.1111 - val_accuracy: 0.8249\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6055 - accuracy: 0.8567 - val_loss: 1.0248 - val_accuracy: 0.8026\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5385 - accuracy: 0.8670 - val_loss: 0.8980 - val_accuracy: 0.8378\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4953 - accuracy: 0.8733 - val_loss: 0.8614 - val_accuracy: 0.8495\n","Epoch 10/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4648 - accuracy: 0.8774 - val_loss: 0.7686 - val_accuracy: 0.8653\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4316 - accuracy: 0.8875 - val_loss: 0.7470 - val_accuracy: 0.8755\n","Epoch 12/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4143 - accuracy: 0.8911 - val_loss: 0.6847 - val_accuracy: 0.8785\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3874 - accuracy: 0.8986 - val_loss: 0.6792 - val_accuracy: 0.8917\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3778 - accuracy: 0.8966 - val_loss: 0.6476 - val_accuracy: 0.8999\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3648 - accuracy: 0.9022 - val_loss: 0.6598 - val_accuracy: 0.8790\n","Epoch 16/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3484 - accuracy: 0.9064 - val_loss: 0.6369 - val_accuracy: 0.9021\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3422 - accuracy: 0.9071 - val_loss: 0.6633 - val_accuracy: 0.8926\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3331 - accuracy: 0.9104 - val_loss: 0.5833 - val_accuracy: 0.9050\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3151 - accuracy: 0.9141 - val_loss: 0.6019 - val_accuracy: 0.8944\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3150 - accuracy: 0.9160 - val_loss: 0.5681 - val_accuracy: 0.9091\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3097 - accuracy: 0.9184 - val_loss: 0.5854 - val_accuracy: 0.8953\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2986 - accuracy: 0.9211 - val_loss: 0.6369 - val_accuracy: 0.9025\n","Epoch 23/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2960 - accuracy: 0.9211 - val_loss: 0.5651 - val_accuracy: 0.9098\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2898 - accuracy: 0.9193 - val_loss: 0.5186 - val_accuracy: 0.9111\n","Epoch 25/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2775 - accuracy: 0.9273 - val_loss: 0.5348 - val_accuracy: 0.9050\n","Epoch 26/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2738 - accuracy: 0.9278 - val_loss: 0.5404 - val_accuracy: 0.9217\n","Epoch 27/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2657 - accuracy: 0.9299 - val_loss: 0.5249 - val_accuracy: 0.9292\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2681 - accuracy: 0.9301 - val_loss: 0.5596 - val_accuracy: 0.9061\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2591 - accuracy: 0.9296 - val_loss: 0.4766 - val_accuracy: 0.9296\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2592 - accuracy: 0.9306 - val_loss: 0.5861 - val_accuracy: 0.9072\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2485 - accuracy: 0.9367 - val_loss: 0.5378 - val_accuracy: 0.9204\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2400 - accuracy: 0.9392 - val_loss: 0.6660 - val_accuracy: 0.9036\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2485 - accuracy: 0.9351 - val_loss: 0.5479 - val_accuracy: 0.9003\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2342 - accuracy: 0.9404 - val_loss: 0.4678 - val_accuracy: 0.9474\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2324 - accuracy: 0.9416 - val_loss: 0.4585 - val_accuracy: 0.9338\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2336 - accuracy: 0.9407 - val_loss: 0.5360 - val_accuracy: 0.9076\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2324 - accuracy: 0.9404 - val_loss: 0.4596 - val_accuracy: 0.9261\n","Epoch 38/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2300 - accuracy: 0.9416 - val_loss: 0.4365 - val_accuracy: 0.9397\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2250 - accuracy: 0.9409 - val_loss: 0.4509 - val_accuracy: 0.9377\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2251 - accuracy: 0.9435 - val_loss: 0.4572 - val_accuracy: 0.9353\n","Average Validation Accuracy: 0.9514939486980438\n","Average Validation Loss: 0.26054443418979645\n","Average Test Accuracy: 0.9484779238700867\n","------------------------------------------------------------------------\n","\n","Number of input features: 5\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.7645 - accuracy: 0.2940 - val_loss: 2.6433 - val_accuracy: 0.5751\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7922 - accuracy: 0.6707 - val_loss: 1.5135 - val_accuracy: 0.7663\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9848 - accuracy: 0.8018 - val_loss: 1.0470 - val_accuracy: 0.8205\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6386 - accuracy: 0.8604 - val_loss: 0.7645 - val_accuracy: 0.8766\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4735 - accuracy: 0.8834 - val_loss: 0.6642 - val_accuracy: 0.8845\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3937 - accuracy: 0.9030 - val_loss: 0.5560 - val_accuracy: 0.9012\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3429 - accuracy: 0.9124 - val_loss: 0.5034 - val_accuracy: 0.9140\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3036 - accuracy: 0.9224 - val_loss: 0.5078 - val_accuracy: 0.9010\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2797 - accuracy: 0.9285 - val_loss: 0.5242 - val_accuracy: 0.9047\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2730 - accuracy: 0.9294 - val_loss: 0.4374 - val_accuracy: 0.9157\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2420 - accuracy: 0.9377 - val_loss: 0.4262 - val_accuracy: 0.9243\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2342 - accuracy: 0.9382 - val_loss: 0.3892 - val_accuracy: 0.9377\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2235 - accuracy: 0.9432 - val_loss: 0.3732 - val_accuracy: 0.9292\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2250 - accuracy: 0.9426 - val_loss: 0.3768 - val_accuracy: 0.9360\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2142 - accuracy: 0.9468 - val_loss: 0.3454 - val_accuracy: 0.9388\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2082 - accuracy: 0.9484 - val_loss: 0.3599 - val_accuracy: 0.9430\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2017 - accuracy: 0.9494 - val_loss: 0.3429 - val_accuracy: 0.9498\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1896 - accuracy: 0.9534 - val_loss: 0.3975 - val_accuracy: 0.9197\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1900 - accuracy: 0.9529 - val_loss: 0.3228 - val_accuracy: 0.9600\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1898 - accuracy: 0.9519 - val_loss: 0.3038 - val_accuracy: 0.9644\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1791 - accuracy: 0.9549 - val_loss: 0.3254 - val_accuracy: 0.9454\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1730 - accuracy: 0.9562 - val_loss: 0.3183 - val_accuracy: 0.9509\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1799 - accuracy: 0.9536 - val_loss: 0.3032 - val_accuracy: 0.9586\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1620 - accuracy: 0.9607 - val_loss: 0.3138 - val_accuracy: 0.9509\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1659 - accuracy: 0.9595 - val_loss: 0.3405 - val_accuracy: 0.9415\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1606 - accuracy: 0.9614 - val_loss: 0.3134 - val_accuracy: 0.9494\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1638 - accuracy: 0.9603 - val_loss: 0.2918 - val_accuracy: 0.9470\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1532 - accuracy: 0.9623 - val_loss: 0.2959 - val_accuracy: 0.9525\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1518 - accuracy: 0.9622 - val_loss: 0.3003 - val_accuracy: 0.9529\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1511 - accuracy: 0.9624 - val_loss: 0.3089 - val_accuracy: 0.9567\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1454 - accuracy: 0.9651 - val_loss: 0.2828 - val_accuracy: 0.9617\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1418 - accuracy: 0.9666 - val_loss: 0.3048 - val_accuracy: 0.9611\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1472 - accuracy: 0.9648 - val_loss: 0.2802 - val_accuracy: 0.9650\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1410 - accuracy: 0.9646 - val_loss: 0.2781 - val_accuracy: 0.9646\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1432 - accuracy: 0.9640 - val_loss: 0.2643 - val_accuracy: 0.9732\n","Epoch 36/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1261 - accuracy: 0.9704 - val_loss: 0.2827 - val_accuracy: 0.9639\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1389 - accuracy: 0.9672 - val_loss: 0.2812 - val_accuracy: 0.9635\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1286 - accuracy: 0.9697 - val_loss: 0.2951 - val_accuracy: 0.9549\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1292 - accuracy: 0.9700 - val_loss: 0.2802 - val_accuracy: 0.9734\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1248 - accuracy: 0.9697 - val_loss: 0.2715 - val_accuracy: 0.9699\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.8318 - accuracy: 0.2960 - val_loss: 2.6810 - val_accuracy: 0.6051\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7985 - accuracy: 0.6782 - val_loss: 1.6164 - val_accuracy: 0.7450\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0024 - accuracy: 0.7991 - val_loss: 1.1688 - val_accuracy: 0.8132\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6661 - accuracy: 0.8540 - val_loss: 0.9217 - val_accuracy: 0.8730\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5094 - accuracy: 0.8800 - val_loss: 0.7779 - val_accuracy: 0.8689\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4200 - accuracy: 0.8974 - val_loss: 0.6649 - val_accuracy: 0.8788\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3686 - accuracy: 0.9074 - val_loss: 0.5776 - val_accuracy: 0.8986\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3291 - accuracy: 0.9148 - val_loss: 0.5725 - val_accuracy: 0.9032\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2980 - accuracy: 0.9216 - val_loss: 0.4976 - val_accuracy: 0.9135\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2850 - accuracy: 0.9258 - val_loss: 0.4610 - val_accuracy: 0.9283\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2583 - accuracy: 0.9329 - val_loss: 0.4731 - val_accuracy: 0.9241\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2437 - accuracy: 0.9377 - val_loss: 0.4475 - val_accuracy: 0.9223\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2357 - accuracy: 0.9400 - val_loss: 0.3721 - val_accuracy: 0.9459\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2180 - accuracy: 0.9430 - val_loss: 0.4108 - val_accuracy: 0.9355\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2168 - accuracy: 0.9445 - val_loss: 0.4636 - val_accuracy: 0.9149\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2076 - accuracy: 0.9468 - val_loss: 0.3674 - val_accuracy: 0.9303\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1883 - accuracy: 0.9543 - val_loss: 0.4200 - val_accuracy: 0.9153\n","Epoch 18/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1927 - accuracy: 0.9510 - val_loss: 0.3710 - val_accuracy: 0.9424\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1770 - accuracy: 0.9563 - val_loss: 0.3744 - val_accuracy: 0.9366\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1796 - accuracy: 0.9550 - val_loss: 0.4140 - val_accuracy: 0.9329\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1759 - accuracy: 0.9574 - val_loss: 0.3430 - val_accuracy: 0.9479\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1647 - accuracy: 0.9583 - val_loss: 0.3561 - val_accuracy: 0.9481\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1673 - accuracy: 0.9575 - val_loss: 0.3297 - val_accuracy: 0.9580\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1544 - accuracy: 0.9609 - val_loss: 0.3429 - val_accuracy: 0.9597\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1561 - accuracy: 0.9607 - val_loss: 0.3201 - val_accuracy: 0.9597\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1487 - accuracy: 0.9645 - val_loss: 0.3348 - val_accuracy: 0.9582\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1500 - accuracy: 0.9635 - val_loss: 0.3096 - val_accuracy: 0.9573\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1500 - accuracy: 0.9647 - val_loss: 0.3346 - val_accuracy: 0.9600\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1365 - accuracy: 0.9659 - val_loss: 0.3077 - val_accuracy: 0.9615\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1372 - accuracy: 0.9663 - val_loss: 0.3297 - val_accuracy: 0.9569\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1378 - accuracy: 0.9667 - val_loss: 0.3157 - val_accuracy: 0.9641\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1319 - accuracy: 0.9679 - val_loss: 0.3062 - val_accuracy: 0.9593\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1344 - accuracy: 0.9677 - val_loss: 0.3007 - val_accuracy: 0.9692\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1251 - accuracy: 0.9705 - val_loss: 0.3079 - val_accuracy: 0.9637\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1261 - accuracy: 0.9698 - val_loss: 0.3173 - val_accuracy: 0.9648\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1255 - accuracy: 0.9699 - val_loss: 0.3258 - val_accuracy: 0.9635\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1232 - accuracy: 0.9721 - val_loss: 0.3154 - val_accuracy: 0.9622\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1235 - accuracy: 0.9708 - val_loss: 0.3943 - val_accuracy: 0.9404\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1179 - accuracy: 0.9723 - val_loss: 0.3233 - val_accuracy: 0.9630\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1180 - accuracy: 0.9721 - val_loss: 0.2868 - val_accuracy: 0.9674\n","Average Validation Accuracy: 0.9724068343639374\n","Average Validation Loss: 0.16449397802352905\n","Average Test Accuracy: 0.9708115458488464\n","------------------------------------------------------------------------\n","\n","Number of input features: 6\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.8764 - accuracy: 0.2805 - val_loss: 2.6881 - val_accuracy: 0.5947\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7441 - accuracy: 0.6875 - val_loss: 1.3793 - val_accuracy: 0.7641\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8720 - accuracy: 0.8188 - val_loss: 0.8872 - val_accuracy: 0.8209\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5337 - accuracy: 0.8746 - val_loss: 0.6374 - val_accuracy: 0.8801\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3950 - accuracy: 0.9028 - val_loss: 0.5129 - val_accuracy: 0.9184\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3202 - accuracy: 0.9206 - val_loss: 0.4522 - val_accuracy: 0.9292\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2833 - accuracy: 0.9265 - val_loss: 0.4137 - val_accuracy: 0.9336\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2481 - accuracy: 0.9341 - val_loss: 0.4066 - val_accuracy: 0.9274\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2342 - accuracy: 0.9385 - val_loss: 0.3847 - val_accuracy: 0.9402\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2106 - accuracy: 0.9439 - val_loss: 0.3682 - val_accuracy: 0.9340\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1987 - accuracy: 0.9484 - val_loss: 0.3797 - val_accuracy: 0.9360\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1916 - accuracy: 0.9504 - val_loss: 0.3159 - val_accuracy: 0.9452\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1736 - accuracy: 0.9564 - val_loss: 0.3163 - val_accuracy: 0.9549\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1722 - accuracy: 0.9560 - val_loss: 0.3050 - val_accuracy: 0.9564\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1628 - accuracy: 0.9597 - val_loss: 0.2875 - val_accuracy: 0.9679\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1547 - accuracy: 0.9630 - val_loss: 0.2955 - val_accuracy: 0.9591\n","Epoch 17/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1549 - accuracy: 0.9602 - val_loss: 0.2821 - val_accuracy: 0.9663\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1559 - accuracy: 0.9603 - val_loss: 0.2489 - val_accuracy: 0.9683\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1299 - accuracy: 0.9691 - val_loss: 0.2890 - val_accuracy: 0.9538\n","Epoch 20/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1469 - accuracy: 0.9629 - val_loss: 0.2689 - val_accuracy: 0.9593\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1375 - accuracy: 0.9651 - val_loss: 0.2751 - val_accuracy: 0.9575\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1273 - accuracy: 0.9691 - val_loss: 0.2628 - val_accuracy: 0.9571\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1281 - accuracy: 0.9667 - val_loss: 0.2746 - val_accuracy: 0.9553\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1282 - accuracy: 0.9667 - val_loss: 0.2445 - val_accuracy: 0.9738\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1215 - accuracy: 0.9692 - val_loss: 0.2608 - val_accuracy: 0.9679\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1170 - accuracy: 0.9705 - val_loss: 0.2379 - val_accuracy: 0.9694\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1109 - accuracy: 0.9727 - val_loss: 0.2326 - val_accuracy: 0.9641\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1211 - accuracy: 0.9700 - val_loss: 0.2271 - val_accuracy: 0.9738\n","Epoch 29/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1088 - accuracy: 0.9733 - val_loss: 0.2205 - val_accuracy: 0.9725\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1088 - accuracy: 0.9731 - val_loss: 0.2173 - val_accuracy: 0.9694\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1026 - accuracy: 0.9751 - val_loss: 0.2279 - val_accuracy: 0.9633\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1085 - accuracy: 0.9733 - val_loss: 0.2594 - val_accuracy: 0.9644\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1043 - accuracy: 0.9732 - val_loss: 0.2386 - val_accuracy: 0.9661\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0994 - accuracy: 0.9768 - val_loss: 0.2103 - val_accuracy: 0.9652\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1055 - accuracy: 0.9737 - val_loss: 0.2084 - val_accuracy: 0.9749\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0920 - accuracy: 0.9783 - val_loss: 0.2248 - val_accuracy: 0.9701\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1023 - accuracy: 0.9739 - val_loss: 0.2150 - val_accuracy: 0.9635\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1008 - accuracy: 0.9749 - val_loss: 0.2087 - val_accuracy: 0.9769\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0905 - accuracy: 0.9775 - val_loss: 0.2281 - val_accuracy: 0.9694\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1007 - accuracy: 0.9750 - val_loss: 0.2220 - val_accuracy: 0.9679\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7982 - accuracy: 0.3037 - val_loss: 2.5982 - val_accuracy: 0.5688\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6834 - accuracy: 0.6906 - val_loss: 1.5933 - val_accuracy: 0.7369\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9315 - accuracy: 0.8166 - val_loss: 1.2371 - val_accuracy: 0.8394\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6053 - accuracy: 0.8758 - val_loss: 0.9388 - val_accuracy: 0.8992\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4484 - accuracy: 0.9001 - val_loss: 0.8658 - val_accuracy: 0.8673\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3521 - accuracy: 0.9216 - val_loss: 0.6605 - val_accuracy: 0.8979\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2989 - accuracy: 0.9285 - val_loss: 0.6049 - val_accuracy: 0.9118\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2518 - accuracy: 0.9404 - val_loss: 0.5289 - val_accuracy: 0.9219\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2230 - accuracy: 0.9452 - val_loss: 0.4959 - val_accuracy: 0.9289\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2058 - accuracy: 0.9493 - val_loss: 0.5279 - val_accuracy: 0.9340\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1931 - accuracy: 0.9543 - val_loss: 0.4677 - val_accuracy: 0.9386\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1771 - accuracy: 0.9557 - val_loss: 0.4384 - val_accuracy: 0.9516\n","Epoch 13/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1714 - accuracy: 0.9586 - val_loss: 0.4131 - val_accuracy: 0.9534\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1588 - accuracy: 0.9606 - val_loss: 0.4294 - val_accuracy: 0.9507\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1482 - accuracy: 0.9649 - val_loss: 0.4265 - val_accuracy: 0.9248\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1475 - accuracy: 0.9658 - val_loss: 0.3682 - val_accuracy: 0.9608\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1373 - accuracy: 0.9675 - val_loss: 0.3548 - val_accuracy: 0.9494\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1357 - accuracy: 0.9682 - val_loss: 0.4024 - val_accuracy: 0.9437\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1366 - accuracy: 0.9663 - val_loss: 0.3180 - val_accuracy: 0.9630\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1243 - accuracy: 0.9707 - val_loss: 0.3455 - val_accuracy: 0.9562\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1242 - accuracy: 0.9706 - val_loss: 0.3392 - val_accuracy: 0.9507\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1179 - accuracy: 0.9728 - val_loss: 0.3038 - val_accuracy: 0.9685\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1182 - accuracy: 0.9711 - val_loss: 0.3205 - val_accuracy: 0.9558\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1129 - accuracy: 0.9733 - val_loss: 0.2671 - val_accuracy: 0.9710\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1144 - accuracy: 0.9720 - val_loss: 0.3062 - val_accuracy: 0.9562\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1075 - accuracy: 0.9736 - val_loss: 0.2667 - val_accuracy: 0.9707\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1009 - accuracy: 0.9765 - val_loss: 0.2729 - val_accuracy: 0.9679\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1040 - accuracy: 0.9733 - val_loss: 0.2635 - val_accuracy: 0.9688\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0987 - accuracy: 0.9763 - val_loss: 0.2661 - val_accuracy: 0.9608\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0985 - accuracy: 0.9763 - val_loss: 0.2529 - val_accuracy: 0.9661\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0994 - accuracy: 0.9743 - val_loss: 0.2707 - val_accuracy: 0.9589\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0960 - accuracy: 0.9772 - val_loss: 0.2540 - val_accuracy: 0.9690\n","Epoch 33/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0934 - accuracy: 0.9776 - val_loss: 0.2811 - val_accuracy: 0.9633\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0914 - accuracy: 0.9790 - val_loss: 0.2577 - val_accuracy: 0.9734\n","Epoch 35/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0939 - accuracy: 0.9770 - val_loss: 0.2471 - val_accuracy: 0.9712\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0906 - accuracy: 0.9773 - val_loss: 0.2449 - val_accuracy: 0.9712\n","Epoch 37/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0870 - accuracy: 0.9791 - val_loss: 0.2499 - val_accuracy: 0.9595\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0917 - accuracy: 0.9777 - val_loss: 0.2489 - val_accuracy: 0.9721\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0815 - accuracy: 0.9811 - val_loss: 0.2375 - val_accuracy: 0.9694\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0860 - accuracy: 0.9782 - val_loss: 0.2652 - val_accuracy: 0.9657\n","Average Validation Accuracy: 0.9727335572242737\n","Average Validation Loss: 0.14364256709814072\n","Average Test Accuracy: 0.9724330902099609\n","------------------------------------------------------------------------\n","\n","Number of input features: 7\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.6334 - accuracy: 0.3363 - val_loss: 2.3542 - val_accuracy: 0.6046\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4964 - accuracy: 0.7286 - val_loss: 1.2534 - val_accuracy: 0.8015\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7916 - accuracy: 0.8442 - val_loss: 0.8576 - val_accuracy: 0.8528\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5240 - accuracy: 0.8845 - val_loss: 0.6705 - val_accuracy: 0.8931\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3913 - accuracy: 0.9060 - val_loss: 0.5567 - val_accuracy: 0.9025\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3144 - accuracy: 0.9198 - val_loss: 0.4622 - val_accuracy: 0.9184\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2741 - accuracy: 0.9282 - val_loss: 0.3955 - val_accuracy: 0.9355\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2337 - accuracy: 0.9420 - val_loss: 0.3796 - val_accuracy: 0.9347\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2170 - accuracy: 0.9433 - val_loss: 0.3668 - val_accuracy: 0.9267\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1973 - accuracy: 0.9513 - val_loss: 0.3336 - val_accuracy: 0.9419\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1841 - accuracy: 0.9563 - val_loss: 0.3122 - val_accuracy: 0.9382\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1744 - accuracy: 0.9568 - val_loss: 0.3209 - val_accuracy: 0.9492\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1682 - accuracy: 0.9583 - val_loss: 0.2966 - val_accuracy: 0.9595\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1511 - accuracy: 0.9648 - val_loss: 0.2977 - val_accuracy: 0.9586\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1553 - accuracy: 0.9614 - val_loss: 0.2823 - val_accuracy: 0.9556\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1359 - accuracy: 0.9665 - val_loss: 0.2607 - val_accuracy: 0.9674\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1384 - accuracy: 0.9657 - val_loss: 0.2673 - val_accuracy: 0.9540\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1315 - accuracy: 0.9689 - val_loss: 0.2607 - val_accuracy: 0.9663\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1234 - accuracy: 0.9706 - val_loss: 0.2747 - val_accuracy: 0.9406\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1219 - accuracy: 0.9699 - val_loss: 0.2636 - val_accuracy: 0.9644\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1164 - accuracy: 0.9718 - val_loss: 0.3357 - val_accuracy: 0.9558\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1214 - accuracy: 0.9711 - val_loss: 0.2525 - val_accuracy: 0.9633\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1096 - accuracy: 0.9739 - val_loss: 0.2433 - val_accuracy: 0.9672\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1065 - accuracy: 0.9737 - val_loss: 0.2276 - val_accuracy: 0.9749\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1033 - accuracy: 0.9749 - val_loss: 0.2440 - val_accuracy: 0.9732\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1036 - accuracy: 0.9758 - val_loss: 0.2233 - val_accuracy: 0.9747\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1020 - accuracy: 0.9732 - val_loss: 0.2657 - val_accuracy: 0.9494\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0952 - accuracy: 0.9757 - val_loss: 0.2264 - val_accuracy: 0.9677\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0924 - accuracy: 0.9781 - val_loss: 0.2270 - val_accuracy: 0.9747\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0981 - accuracy: 0.9759 - val_loss: 0.2155 - val_accuracy: 0.9729\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0853 - accuracy: 0.9798 - val_loss: 0.1995 - val_accuracy: 0.9817\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0912 - accuracy: 0.9779 - val_loss: 0.2573 - val_accuracy: 0.9551\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0942 - accuracy: 0.9765 - val_loss: 0.2103 - val_accuracy: 0.9795\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0865 - accuracy: 0.9775 - val_loss: 0.2276 - val_accuracy: 0.9633\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0862 - accuracy: 0.9792 - val_loss: 0.2091 - val_accuracy: 0.9743\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0836 - accuracy: 0.9793 - val_loss: 0.2113 - val_accuracy: 0.9756\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0874 - accuracy: 0.9778 - val_loss: 0.2284 - val_accuracy: 0.9668\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0873 - accuracy: 0.9781 - val_loss: 0.2214 - val_accuracy: 0.9690\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0809 - accuracy: 0.9807 - val_loss: 0.2581 - val_accuracy: 0.9738\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0812 - accuracy: 0.9810 - val_loss: 0.2209 - val_accuracy: 0.9694\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.8959 - accuracy: 0.2566 - val_loss: 2.7271 - val_accuracy: 0.5419\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7901 - accuracy: 0.6628 - val_loss: 1.5853 - val_accuracy: 0.7371\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.9977 - accuracy: 0.7870 - val_loss: 1.1806 - val_accuracy: 0.8134\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6938 - accuracy: 0.8371 - val_loss: 0.9505 - val_accuracy: 0.8409\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5248 - accuracy: 0.8738 - val_loss: 0.7896 - val_accuracy: 0.8741\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4343 - accuracy: 0.8928 - val_loss: 0.6871 - val_accuracy: 0.8898\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3628 - accuracy: 0.9102 - val_loss: 0.6379 - val_accuracy: 0.8944\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3190 - accuracy: 0.9186 - val_loss: 0.5699 - val_accuracy: 0.8928\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2801 - accuracy: 0.9278 - val_loss: 0.5068 - val_accuracy: 0.9173\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2573 - accuracy: 0.9349 - val_loss: 0.4787 - val_accuracy: 0.9285\n","Epoch 11/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2329 - accuracy: 0.9394 - val_loss: 0.4351 - val_accuracy: 0.9327\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2206 - accuracy: 0.9423 - val_loss: 0.4449 - val_accuracy: 0.9188\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1965 - accuracy: 0.9498 - val_loss: 0.4065 - val_accuracy: 0.9419\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1862 - accuracy: 0.9540 - val_loss: 0.3804 - val_accuracy: 0.9413\n","Epoch 15/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1837 - accuracy: 0.9560 - val_loss: 0.3662 - val_accuracy: 0.9463\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1686 - accuracy: 0.9579 - val_loss: 0.3433 - val_accuracy: 0.9448\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1645 - accuracy: 0.9589 - val_loss: 0.3238 - val_accuracy: 0.9538\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1540 - accuracy: 0.9622 - val_loss: 0.3278 - val_accuracy: 0.9531\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1485 - accuracy: 0.9650 - val_loss: 0.3479 - val_accuracy: 0.9404\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1455 - accuracy: 0.9621 - val_loss: 0.3288 - val_accuracy: 0.9446\n","Epoch 21/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1376 - accuracy: 0.9673 - val_loss: 0.2801 - val_accuracy: 0.9650\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1399 - accuracy: 0.9669 - val_loss: 0.2900 - val_accuracy: 0.9571\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1320 - accuracy: 0.9668 - val_loss: 0.2865 - val_accuracy: 0.9602\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1235 - accuracy: 0.9704 - val_loss: 0.2901 - val_accuracy: 0.9514\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1224 - accuracy: 0.9701 - val_loss: 0.2887 - val_accuracy: 0.9514\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1220 - accuracy: 0.9687 - val_loss: 0.2906 - val_accuracy: 0.9501\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1196 - accuracy: 0.9715 - val_loss: 0.2590 - val_accuracy: 0.9569\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1113 - accuracy: 0.9733 - val_loss: 0.2678 - val_accuracy: 0.9650\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1147 - accuracy: 0.9702 - val_loss: 0.2591 - val_accuracy: 0.9622\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1089 - accuracy: 0.9737 - val_loss: 0.2667 - val_accuracy: 0.9628\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1050 - accuracy: 0.9745 - val_loss: 0.2410 - val_accuracy: 0.9633\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1068 - accuracy: 0.9742 - val_loss: 0.2523 - val_accuracy: 0.9652\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1022 - accuracy: 0.9740 - val_loss: 0.2431 - val_accuracy: 0.9635\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0970 - accuracy: 0.9754 - val_loss: 0.2532 - val_accuracy: 0.9633\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1030 - accuracy: 0.9740 - val_loss: 0.2363 - val_accuracy: 0.9690\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0913 - accuracy: 0.9781 - val_loss: 0.2512 - val_accuracy: 0.9617\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0963 - accuracy: 0.9759 - val_loss: 0.2464 - val_accuracy: 0.9633\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0975 - accuracy: 0.9751 - val_loss: 0.2261 - val_accuracy: 0.9723\n","Epoch 39/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0901 - accuracy: 0.9776 - val_loss: 0.2147 - val_accuracy: 0.9778\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0891 - accuracy: 0.9770 - val_loss: 0.2365 - val_accuracy: 0.9622\n","Average Validation Accuracy: 0.9734233021736145\n","Average Validation Loss: 0.12966085970401764\n","Average Test Accuracy: 0.9738335609436035\n","------------------------------------------------------------------------\n","\n","Number of input features: 8\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.8846 - accuracy: 0.2859 - val_loss: 2.6023 - val_accuracy: 0.5688\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7694 - accuracy: 0.6809 - val_loss: 1.5073 - val_accuracy: 0.7344\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.0005 - accuracy: 0.8062 - val_loss: 1.0324 - val_accuracy: 0.8321\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6524 - accuracy: 0.8632 - val_loss: 0.7935 - val_accuracy: 0.8638\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4758 - accuracy: 0.8928 - val_loss: 0.7064 - val_accuracy: 0.8803\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3770 - accuracy: 0.9103 - val_loss: 0.5550 - val_accuracy: 0.9151\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3158 - accuracy: 0.9212 - val_loss: 0.5071 - val_accuracy: 0.9144\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2706 - accuracy: 0.9345 - val_loss: 0.4499 - val_accuracy: 0.9355\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2457 - accuracy: 0.9372 - val_loss: 0.4661 - val_accuracy: 0.9182\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2259 - accuracy: 0.9440 - val_loss: 0.4042 - val_accuracy: 0.9413\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2088 - accuracy: 0.9488 - val_loss: 0.3847 - val_accuracy: 0.9355\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1935 - accuracy: 0.9518 - val_loss: 0.3857 - val_accuracy: 0.9415\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1757 - accuracy: 0.9578 - val_loss: 0.3470 - val_accuracy: 0.9509\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1735 - accuracy: 0.9573 - val_loss: 0.3426 - val_accuracy: 0.9648\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1646 - accuracy: 0.9612 - val_loss: 0.3568 - val_accuracy: 0.9505\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1567 - accuracy: 0.9626 - val_loss: 0.3378 - val_accuracy: 0.9463\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1463 - accuracy: 0.9649 - val_loss: 0.3371 - val_accuracy: 0.9483\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1472 - accuracy: 0.9627 - val_loss: 0.3023 - val_accuracy: 0.9582\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1462 - accuracy: 0.9654 - val_loss: 0.3259 - val_accuracy: 0.9589\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1323 - accuracy: 0.9668 - val_loss: 0.3862 - val_accuracy: 0.9424\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1306 - accuracy: 0.9670 - val_loss: 0.2873 - val_accuracy: 0.9694\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1348 - accuracy: 0.9663 - val_loss: 0.3262 - val_accuracy: 0.9516\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1248 - accuracy: 0.9697 - val_loss: 0.3553 - val_accuracy: 0.9421\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1171 - accuracy: 0.9701 - val_loss: 0.2889 - val_accuracy: 0.9569\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1242 - accuracy: 0.9714 - val_loss: 0.2840 - val_accuracy: 0.9650\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1110 - accuracy: 0.9719 - val_loss: 0.2856 - val_accuracy: 0.9672\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1189 - accuracy: 0.9717 - val_loss: 0.2808 - val_accuracy: 0.9674\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1055 - accuracy: 0.9741 - val_loss: 0.2658 - val_accuracy: 0.9707\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1118 - accuracy: 0.9726 - val_loss: 0.2884 - val_accuracy: 0.9549\n","Epoch 30/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1030 - accuracy: 0.9763 - val_loss: 0.2964 - val_accuracy: 0.9540\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1089 - accuracy: 0.9720 - val_loss: 0.2833 - val_accuracy: 0.9663\n","Epoch 32/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0997 - accuracy: 0.9752 - val_loss: 0.2865 - val_accuracy: 0.9672\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1085 - accuracy: 0.9726 - val_loss: 0.2753 - val_accuracy: 0.9703\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9763 - val_loss: 0.2716 - val_accuracy: 0.9738\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0940 - accuracy: 0.9766 - val_loss: 0.2678 - val_accuracy: 0.9773\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0975 - accuracy: 0.9758 - val_loss: 0.2874 - val_accuracy: 0.9659\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0918 - accuracy: 0.9771 - val_loss: 0.2920 - val_accuracy: 0.9683\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1004 - accuracy: 0.9741 - val_loss: 0.3053 - val_accuracy: 0.9540\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0896 - accuracy: 0.9791 - val_loss: 0.2606 - val_accuracy: 0.9677\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0926 - accuracy: 0.9766 - val_loss: 0.2696 - val_accuracy: 0.9760\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 8s 3ms/step - loss: 3.8138 - accuracy: 0.3054 - val_loss: 2.5920 - val_accuracy: 0.5160\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5965 - accuracy: 0.7039 - val_loss: 1.4591 - val_accuracy: 0.7604\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8534 - accuracy: 0.8239 - val_loss: 1.0382 - val_accuracy: 0.8460\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5694 - accuracy: 0.8714 - val_loss: 0.8590 - val_accuracy: 0.8669\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4300 - accuracy: 0.8973 - val_loss: 0.7303 - val_accuracy: 0.8878\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3539 - accuracy: 0.9141 - val_loss: 0.6514 - val_accuracy: 0.8999\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3040 - accuracy: 0.9219 - val_loss: 0.5870 - val_accuracy: 0.9122\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2595 - accuracy: 0.9352 - val_loss: 0.5131 - val_accuracy: 0.9278\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2380 - accuracy: 0.9392 - val_loss: 0.4721 - val_accuracy: 0.9311\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2165 - accuracy: 0.9475 - val_loss: 0.4646 - val_accuracy: 0.9230\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1990 - accuracy: 0.9492 - val_loss: 0.4352 - val_accuracy: 0.9287\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1853 - accuracy: 0.9518 - val_loss: 0.3942 - val_accuracy: 0.9380\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1709 - accuracy: 0.9585 - val_loss: 0.3818 - val_accuracy: 0.9441\n","Epoch 14/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1608 - accuracy: 0.9595 - val_loss: 0.3505 - val_accuracy: 0.9626\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1522 - accuracy: 0.9653 - val_loss: 0.3628 - val_accuracy: 0.9450\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1571 - accuracy: 0.9612 - val_loss: 0.3473 - val_accuracy: 0.9551\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1368 - accuracy: 0.9658 - val_loss: 0.3541 - val_accuracy: 0.9485\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1324 - accuracy: 0.9686 - val_loss: 0.3622 - val_accuracy: 0.9536\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1305 - accuracy: 0.9686 - val_loss: 0.3274 - val_accuracy: 0.9560\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1291 - accuracy: 0.9704 - val_loss: 0.3071 - val_accuracy: 0.9571\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1175 - accuracy: 0.9719 - val_loss: 0.3033 - val_accuracy: 0.9507\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1242 - accuracy: 0.9723 - val_loss: 0.2714 - val_accuracy: 0.9718\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1193 - accuracy: 0.9708 - val_loss: 0.2790 - val_accuracy: 0.9663\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1046 - accuracy: 0.9767 - val_loss: 0.2661 - val_accuracy: 0.9677\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1117 - accuracy: 0.9737 - val_loss: 0.2931 - val_accuracy: 0.9595\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1069 - accuracy: 0.9738 - val_loss: 0.2679 - val_accuracy: 0.9628\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1034 - accuracy: 0.9754 - val_loss: 0.2591 - val_accuracy: 0.9622\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1014 - accuracy: 0.9773 - val_loss: 0.2541 - val_accuracy: 0.9650\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0967 - accuracy: 0.9781 - val_loss: 0.2441 - val_accuracy: 0.9696\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0986 - accuracy: 0.9755 - val_loss: 0.2472 - val_accuracy: 0.9716\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0955 - accuracy: 0.9776 - val_loss: 0.3031 - val_accuracy: 0.9483\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0902 - accuracy: 0.9790 - val_loss: 0.2448 - val_accuracy: 0.9727\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0927 - accuracy: 0.9765 - val_loss: 0.2792 - val_accuracy: 0.9644\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0925 - accuracy: 0.9763 - val_loss: 0.2169 - val_accuracy: 0.9782\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0851 - accuracy: 0.9803 - val_loss: 0.2474 - val_accuracy: 0.9639\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0907 - accuracy: 0.9790 - val_loss: 0.2252 - val_accuracy: 0.9694\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0826 - accuracy: 0.9798 - val_loss: 0.2652 - val_accuracy: 0.9650\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0863 - accuracy: 0.9793 - val_loss: 0.2246 - val_accuracy: 0.9635\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0836 - accuracy: 0.9804 - val_loss: 0.2059 - val_accuracy: 0.9760\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0791 - accuracy: 0.9813 - val_loss: 0.2213 - val_accuracy: 0.9721\n","Average Validation Accuracy: 0.981374591588974\n","Average Validation Loss: 0.13290517777204514\n","Average Test Accuracy: 0.9802461862564087\n","------------------------------------------------------------------------\n","\n","Number of input features: 9\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.8117 - accuracy: 0.2898 - val_loss: 2.4861 - val_accuracy: 0.5872\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5862 - accuracy: 0.7231 - val_loss: 1.3390 - val_accuracy: 0.7868\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8718 - accuracy: 0.8227 - val_loss: 0.9569 - val_accuracy: 0.8339\n","Epoch 4/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.5944 - accuracy: 0.8645 - val_loss: 0.7748 - val_accuracy: 0.8759\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4553 - accuracy: 0.8893 - val_loss: 0.7014 - val_accuracy: 0.8717\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3717 - accuracy: 0.9066 - val_loss: 0.6383 - val_accuracy: 0.8911\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3237 - accuracy: 0.9163 - val_loss: 0.5405 - val_accuracy: 0.9102\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2809 - accuracy: 0.9266 - val_loss: 0.5181 - val_accuracy: 0.9188\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2503 - accuracy: 0.9358 - val_loss: 0.4718 - val_accuracy: 0.9344\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2299 - accuracy: 0.9422 - val_loss: 0.5390 - val_accuracy: 0.8977\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2066 - accuracy: 0.9476 - val_loss: 0.4118 - val_accuracy: 0.9490\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1947 - accuracy: 0.9492 - val_loss: 0.4238 - val_accuracy: 0.9485\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1814 - accuracy: 0.9537 - val_loss: 0.4177 - val_accuracy: 0.9439\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1714 - accuracy: 0.9568 - val_loss: 0.4056 - val_accuracy: 0.9485\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1650 - accuracy: 0.9594 - val_loss: 0.4283 - val_accuracy: 0.9263\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1460 - accuracy: 0.9641 - val_loss: 0.3620 - val_accuracy: 0.9611\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1464 - accuracy: 0.9644 - val_loss: 0.3682 - val_accuracy: 0.9509\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1347 - accuracy: 0.9687 - val_loss: 0.3479 - val_accuracy: 0.9619\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1292 - accuracy: 0.9686 - val_loss: 0.3637 - val_accuracy: 0.9545\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1251 - accuracy: 0.9705 - val_loss: 0.3497 - val_accuracy: 0.9564\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1199 - accuracy: 0.9711 - val_loss: 0.3280 - val_accuracy: 0.9624\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1218 - accuracy: 0.9706 - val_loss: 0.3314 - val_accuracy: 0.9681\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1106 - accuracy: 0.9733 - val_loss: 0.3237 - val_accuracy: 0.9630\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1101 - accuracy: 0.9740 - val_loss: 0.3471 - val_accuracy: 0.9589\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1101 - accuracy: 0.9737 - val_loss: 0.3099 - val_accuracy: 0.9694\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1061 - accuracy: 0.9756 - val_loss: 0.3228 - val_accuracy: 0.9617\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0966 - accuracy: 0.9805 - val_loss: 0.3196 - val_accuracy: 0.9650\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0983 - accuracy: 0.9766 - val_loss: 0.2903 - val_accuracy: 0.9743\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1008 - accuracy: 0.9756 - val_loss: 0.2936 - val_accuracy: 0.9743\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1002 - accuracy: 0.9758 - val_loss: 0.2889 - val_accuracy: 0.9707\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0868 - accuracy: 0.9798 - val_loss: 0.3811 - val_accuracy: 0.9602\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0955 - accuracy: 0.9790 - val_loss: 0.3180 - val_accuracy: 0.9778\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0952 - accuracy: 0.9778 - val_loss: 0.3192 - val_accuracy: 0.9639\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0850 - accuracy: 0.9796 - val_loss: 0.2958 - val_accuracy: 0.9655\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0851 - accuracy: 0.9799 - val_loss: 0.3079 - val_accuracy: 0.9721\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0881 - accuracy: 0.9789 - val_loss: 0.2946 - val_accuracy: 0.9754\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0805 - accuracy: 0.9818 - val_loss: 0.2843 - val_accuracy: 0.9666\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0862 - accuracy: 0.9797 - val_loss: 0.3033 - val_accuracy: 0.9648\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0846 - accuracy: 0.9802 - val_loss: 0.2740 - val_accuracy: 0.9760\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0784 - accuracy: 0.9817 - val_loss: 0.2810 - val_accuracy: 0.9780\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.5649 - accuracy: 0.3427 - val_loss: 2.3335 - val_accuracy: 0.6431\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.3673 - accuracy: 0.7477 - val_loss: 1.2927 - val_accuracy: 0.8119\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7234 - accuracy: 0.8505 - val_loss: 0.9402 - val_accuracy: 0.8627\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4827 - accuracy: 0.8938 - val_loss: 0.7639 - val_accuracy: 0.8882\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3644 - accuracy: 0.9158 - val_loss: 0.6637 - val_accuracy: 0.8972\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2980 - accuracy: 0.9288 - val_loss: 0.5810 - val_accuracy: 0.9164\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2545 - accuracy: 0.9390 - val_loss: 0.4957 - val_accuracy: 0.9318\n","Epoch 8/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2250 - accuracy: 0.9416 - val_loss: 0.4371 - val_accuracy: 0.9296\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1982 - accuracy: 0.9492 - val_loss: 0.4537 - val_accuracy: 0.9223\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1897 - accuracy: 0.9525 - val_loss: 0.4628 - val_accuracy: 0.9248\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1762 - accuracy: 0.9557 - val_loss: 0.3513 - val_accuracy: 0.9575\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1570 - accuracy: 0.9606 - val_loss: 0.3678 - val_accuracy: 0.9531\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1550 - accuracy: 0.9621 - val_loss: 0.3398 - val_accuracy: 0.9545\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1366 - accuracy: 0.9659 - val_loss: 0.3448 - val_accuracy: 0.9415\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1301 - accuracy: 0.9677 - val_loss: 0.3368 - val_accuracy: 0.9490\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1254 - accuracy: 0.9701 - val_loss: 0.3285 - val_accuracy: 0.9520\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1218 - accuracy: 0.9710 - val_loss: 0.2943 - val_accuracy: 0.9666\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1166 - accuracy: 0.9733 - val_loss: 0.2916 - val_accuracy: 0.9626\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1112 - accuracy: 0.9734 - val_loss: 0.3040 - val_accuracy: 0.9595\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1082 - accuracy: 0.9756 - val_loss: 0.2802 - val_accuracy: 0.9580\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1061 - accuracy: 0.9743 - val_loss: 0.2655 - val_accuracy: 0.9712\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0937 - accuracy: 0.9790 - val_loss: 0.2669 - val_accuracy: 0.9652\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1066 - accuracy: 0.9726 - val_loss: 0.3122 - val_accuracy: 0.9481\n","Epoch 24/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0918 - accuracy: 0.9797 - val_loss: 0.2922 - val_accuracy: 0.9593\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0878 - accuracy: 0.9803 - val_loss: 0.2432 - val_accuracy: 0.9758\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0972 - accuracy: 0.9767 - val_loss: 0.2595 - val_accuracy: 0.9710\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0836 - accuracy: 0.9823 - val_loss: 0.2488 - val_accuracy: 0.9681\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0870 - accuracy: 0.9794 - val_loss: 0.2450 - val_accuracy: 0.9714\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0805 - accuracy: 0.9800 - val_loss: 0.2503 - val_accuracy: 0.9716\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0871 - accuracy: 0.9795 - val_loss: 0.2529 - val_accuracy: 0.9690\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0770 - accuracy: 0.9841 - val_loss: 0.2468 - val_accuracy: 0.9666\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0861 - accuracy: 0.9793 - val_loss: 0.2619 - val_accuracy: 0.9597\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0720 - accuracy: 0.9837 - val_loss: 0.2567 - val_accuracy: 0.9747\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0779 - accuracy: 0.9828 - val_loss: 0.2357 - val_accuracy: 0.9736\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0762 - accuracy: 0.9823 - val_loss: 0.2374 - val_accuracy: 0.9798\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0795 - accuracy: 0.9818 - val_loss: 0.2359 - val_accuracy: 0.9747\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0654 - accuracy: 0.9854 - val_loss: 0.2336 - val_accuracy: 0.9685\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0781 - accuracy: 0.9810 - val_loss: 0.2585 - val_accuracy: 0.9648\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0740 - accuracy: 0.9834 - val_loss: 0.2319 - val_accuracy: 0.9725\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0654 - accuracy: 0.9854 - val_loss: 0.2275 - val_accuracy: 0.9738\n","Average Validation Accuracy: 0.9821007549762726\n","Average Validation Loss: 0.13088028877973557\n","Average Test Accuracy: 0.9802830219268799\n","------------------------------------------------------------------------\n","\n","Number of input features: 10\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.6841 - accuracy: 0.3276 - val_loss: 2.5047 - val_accuracy: 0.5773\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.7028 - accuracy: 0.6772 - val_loss: 1.4964 - val_accuracy: 0.7344\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9844 - accuracy: 0.7902 - val_loss: 1.0512 - val_accuracy: 0.8293\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6720 - accuracy: 0.8441 - val_loss: 0.8510 - val_accuracy: 0.8350\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5097 - accuracy: 0.8742 - val_loss: 0.7084 - val_accuracy: 0.8686\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4167 - accuracy: 0.8920 - val_loss: 0.6354 - val_accuracy: 0.8812\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3554 - accuracy: 0.9073 - val_loss: 0.5686 - val_accuracy: 0.9054\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3097 - accuracy: 0.9170 - val_loss: 0.5429 - val_accuracy: 0.8999\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2868 - accuracy: 0.9204 - val_loss: 0.4929 - val_accuracy: 0.9248\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2684 - accuracy: 0.9287 - val_loss: 0.4934 - val_accuracy: 0.9175\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2405 - accuracy: 0.9312 - val_loss: 0.4420 - val_accuracy: 0.9311\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2247 - accuracy: 0.9377 - val_loss: 0.4160 - val_accuracy: 0.9404\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2118 - accuracy: 0.9424 - val_loss: 0.4177 - val_accuracy: 0.9395\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2034 - accuracy: 0.9450 - val_loss: 0.4434 - val_accuracy: 0.9250\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1871 - accuracy: 0.9488 - val_loss: 0.3990 - val_accuracy: 0.9424\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1715 - accuracy: 0.9568 - val_loss: 0.4106 - val_accuracy: 0.9459\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1788 - accuracy: 0.9539 - val_loss: 0.3469 - val_accuracy: 0.9558\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1693 - accuracy: 0.9539 - val_loss: 0.3543 - val_accuracy: 0.9514\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1595 - accuracy: 0.9588 - val_loss: 0.3406 - val_accuracy: 0.9622\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1500 - accuracy: 0.9620 - val_loss: 0.3492 - val_accuracy: 0.9575\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1490 - accuracy: 0.9616 - val_loss: 0.3429 - val_accuracy: 0.9479\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1531 - accuracy: 0.9592 - val_loss: 0.3729 - val_accuracy: 0.9437\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1391 - accuracy: 0.9648 - val_loss: 0.3062 - val_accuracy: 0.9694\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1345 - accuracy: 0.9656 - val_loss: 0.3119 - val_accuracy: 0.9718\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1290 - accuracy: 0.9678 - val_loss: 0.3220 - val_accuracy: 0.9575\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1316 - accuracy: 0.9639 - val_loss: 0.3502 - val_accuracy: 0.9558\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1231 - accuracy: 0.9678 - val_loss: 0.3158 - val_accuracy: 0.9619\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1253 - accuracy: 0.9704 - val_loss: 0.3034 - val_accuracy: 0.9652\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1182 - accuracy: 0.9713 - val_loss: 0.3479 - val_accuracy: 0.9604\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1159 - accuracy: 0.9701 - val_loss: 0.3141 - val_accuracy: 0.9736\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1154 - accuracy: 0.9698 - val_loss: 0.3220 - val_accuracy: 0.9659\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1129 - accuracy: 0.9710 - val_loss: 0.3206 - val_accuracy: 0.9569\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1093 - accuracy: 0.9721 - val_loss: 0.3101 - val_accuracy: 0.9650\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1101 - accuracy: 0.9725 - val_loss: 0.3033 - val_accuracy: 0.9646\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1048 - accuracy: 0.9738 - val_loss: 0.3427 - val_accuracy: 0.9558\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1038 - accuracy: 0.9744 - val_loss: 0.2945 - val_accuracy: 0.9648\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1014 - accuracy: 0.9746 - val_loss: 0.2873 - val_accuracy: 0.9795\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0969 - accuracy: 0.9767 - val_loss: 0.2872 - val_accuracy: 0.9659\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0962 - accuracy: 0.9767 - val_loss: 0.2880 - val_accuracy: 0.9699\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0953 - accuracy: 0.9757 - val_loss: 0.2891 - val_accuracy: 0.9736\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.6238 - accuracy: 0.3419 - val_loss: 2.3682 - val_accuracy: 0.5985\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.5382 - accuracy: 0.7117 - val_loss: 1.3559 - val_accuracy: 0.7641\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.7964 - accuracy: 0.8332 - val_loss: 0.9045 - val_accuracy: 0.8667\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4948 - accuracy: 0.8900 - val_loss: 0.7336 - val_accuracy: 0.8876\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3658 - accuracy: 0.9142 - val_loss: 0.6031 - val_accuracy: 0.8979\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2948 - accuracy: 0.9274 - val_loss: 0.5157 - val_accuracy: 0.9193\n","Epoch 7/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.2522 - accuracy: 0.9348 - val_loss: 0.4887 - val_accuracy: 0.9171\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2143 - accuracy: 0.9486 - val_loss: 0.4345 - val_accuracy: 0.9250\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1999 - accuracy: 0.9494 - val_loss: 0.3953 - val_accuracy: 0.9371\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1754 - accuracy: 0.9557 - val_loss: 0.3900 - val_accuracy: 0.9424\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1643 - accuracy: 0.9589 - val_loss: 0.3497 - val_accuracy: 0.9523\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1596 - accuracy: 0.9601 - val_loss: 0.3666 - val_accuracy: 0.9476\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1527 - accuracy: 0.9625 - val_loss: 0.3115 - val_accuracy: 0.9516\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1388 - accuracy: 0.9662 - val_loss: 0.3567 - val_accuracy: 0.9435\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1341 - accuracy: 0.9677 - val_loss: 0.3005 - val_accuracy: 0.9509\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1316 - accuracy: 0.9680 - val_loss: 0.2787 - val_accuracy: 0.9646\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1263 - accuracy: 0.9687 - val_loss: 0.2752 - val_accuracy: 0.9600\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1208 - accuracy: 0.9719 - val_loss: 0.2784 - val_accuracy: 0.9604\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1224 - accuracy: 0.9697 - val_loss: 0.3043 - val_accuracy: 0.9470\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1089 - accuracy: 0.9742 - val_loss: 0.2885 - val_accuracy: 0.9547\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1145 - accuracy: 0.9729 - val_loss: 0.2526 - val_accuracy: 0.9622\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1050 - accuracy: 0.9754 - val_loss: 0.2414 - val_accuracy: 0.9661\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1059 - accuracy: 0.9756 - val_loss: 0.2713 - val_accuracy: 0.9666\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0930 - accuracy: 0.9797 - val_loss: 0.3485 - val_accuracy: 0.9342\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0997 - accuracy: 0.9767 - val_loss: 0.2743 - val_accuracy: 0.9606\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0931 - accuracy: 0.9769 - val_loss: 0.2446 - val_accuracy: 0.9630\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0975 - accuracy: 0.9776 - val_loss: 0.2283 - val_accuracy: 0.9743\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0819 - accuracy: 0.9818 - val_loss: 0.2636 - val_accuracy: 0.9402\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0914 - accuracy: 0.9802 - val_loss: 0.2475 - val_accuracy: 0.9659\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0840 - accuracy: 0.9809 - val_loss: 0.2279 - val_accuracy: 0.9648\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0891 - accuracy: 0.9801 - val_loss: 0.2389 - val_accuracy: 0.9690\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0799 - accuracy: 0.9819 - val_loss: 0.2531 - val_accuracy: 0.9630\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0874 - accuracy: 0.9801 - val_loss: 0.2279 - val_accuracy: 0.9701\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0762 - accuracy: 0.9829 - val_loss: 0.2397 - val_accuracy: 0.9670\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0720 - accuracy: 0.9841 - val_loss: 0.2309 - val_accuracy: 0.9723\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0838 - accuracy: 0.9815 - val_loss: 0.2398 - val_accuracy: 0.9547\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0731 - accuracy: 0.9837 - val_loss: 0.2380 - val_accuracy: 0.9633\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0761 - accuracy: 0.9828 - val_loss: 0.2249 - val_accuracy: 0.9743\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0670 - accuracy: 0.9854 - val_loss: 0.2280 - val_accuracy: 0.9734\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0710 - accuracy: 0.9849 - val_loss: 0.2317 - val_accuracy: 0.9707\n","Average Validation Accuracy: 0.9786879420280457\n","Average Validation Loss: 0.13862524926662445\n","Average Test Accuracy: 0.9785877466201782\n","------------------------------------------------------------------------\n","\n","Number of input features: 11\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 4.1008 - accuracy: 0.2158 - val_loss: 3.0232 - val_accuracy: 0.4356\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 2.1648 - accuracy: 0.5843 - val_loss: 1.9256 - val_accuracy: 0.6409\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2834 - accuracy: 0.7425 - val_loss: 1.3664 - val_accuracy: 0.7916\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8068 - accuracy: 0.8392 - val_loss: 1.0187 - val_accuracy: 0.8568\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5694 - accuracy: 0.8752 - val_loss: 0.8295 - val_accuracy: 0.9019\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4367 - accuracy: 0.8994 - val_loss: 0.7805 - val_accuracy: 0.8774\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3638 - accuracy: 0.9130 - val_loss: 0.7104 - val_accuracy: 0.8972\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3130 - accuracy: 0.9203 - val_loss: 0.6081 - val_accuracy: 0.9289\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2751 - accuracy: 0.9307 - val_loss: 0.5905 - val_accuracy: 0.9305\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2420 - accuracy: 0.9390 - val_loss: 0.5455 - val_accuracy: 0.9340\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2282 - accuracy: 0.9410 - val_loss: 0.5186 - val_accuracy: 0.9428\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1995 - accuracy: 0.9492 - val_loss: 0.5303 - val_accuracy: 0.9239\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1952 - accuracy: 0.9510 - val_loss: 0.4742 - val_accuracy: 0.9547\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1822 - accuracy: 0.9529 - val_loss: 0.5014 - val_accuracy: 0.9336\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1731 - accuracy: 0.9548 - val_loss: 0.4694 - val_accuracy: 0.9432\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1650 - accuracy: 0.9591 - val_loss: 0.4381 - val_accuracy: 0.9454\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1553 - accuracy: 0.9616 - val_loss: 0.4527 - val_accuracy: 0.9571\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1474 - accuracy: 0.9637 - val_loss: 0.4099 - val_accuracy: 0.9633\n","Epoch 19/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.1446 - accuracy: 0.9648 - val_loss: 0.4289 - val_accuracy: 0.9534\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1394 - accuracy: 0.9648 - val_loss: 0.4024 - val_accuracy: 0.9527\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1320 - accuracy: 0.9684 - val_loss: 0.4101 - val_accuracy: 0.9663\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1297 - accuracy: 0.9678 - val_loss: 0.5513 - val_accuracy: 0.9325\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1307 - accuracy: 0.9682 - val_loss: 0.3726 - val_accuracy: 0.9646\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1140 - accuracy: 0.9729 - val_loss: 0.4116 - val_accuracy: 0.9531\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1203 - accuracy: 0.9706 - val_loss: 0.3741 - val_accuracy: 0.9628\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1143 - accuracy: 0.9726 - val_loss: 0.3774 - val_accuracy: 0.9573\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1090 - accuracy: 0.9739 - val_loss: 0.3586 - val_accuracy: 0.9705\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1106 - accuracy: 0.9734 - val_loss: 0.3520 - val_accuracy: 0.9635\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1074 - accuracy: 0.9741 - val_loss: 0.3555 - val_accuracy: 0.9670\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1079 - accuracy: 0.9736 - val_loss: 0.3321 - val_accuracy: 0.9703\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1061 - accuracy: 0.9746 - val_loss: 0.3376 - val_accuracy: 0.9778\n","Epoch 32/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0921 - accuracy: 0.9785 - val_loss: 0.3249 - val_accuracy: 0.9707\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0912 - accuracy: 0.9786 - val_loss: 0.3220 - val_accuracy: 0.9707\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0993 - accuracy: 0.9763 - val_loss: 0.3287 - val_accuracy: 0.9611\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0922 - accuracy: 0.9785 - val_loss: 0.3146 - val_accuracy: 0.9721\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0937 - accuracy: 0.9771 - val_loss: 0.3005 - val_accuracy: 0.9804\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0886 - accuracy: 0.9784 - val_loss: 0.3283 - val_accuracy: 0.9745\n","Epoch 38/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0888 - accuracy: 0.9798 - val_loss: 0.2993 - val_accuracy: 0.9765\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0837 - accuracy: 0.9805 - val_loss: 0.2965 - val_accuracy: 0.9707\n","Epoch 40/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0942 - accuracy: 0.9783 - val_loss: 0.2806 - val_accuracy: 0.9831\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 3ms/step - loss: 3.7524 - accuracy: 0.3059 - val_loss: 2.3381 - val_accuracy: 0.6480\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.4520 - accuracy: 0.7313 - val_loss: 1.3407 - val_accuracy: 0.7958\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.8147 - accuracy: 0.8359 - val_loss: 0.9248 - val_accuracy: 0.8460\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5578 - accuracy: 0.8720 - val_loss: 0.7577 - val_accuracy: 0.8799\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4320 - accuracy: 0.8971 - val_loss: 0.6115 - val_accuracy: 0.8939\n","Epoch 6/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.3537 - accuracy: 0.9124 - val_loss: 0.5412 - val_accuracy: 0.8992\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3044 - accuracy: 0.9231 - val_loss: 0.4793 - val_accuracy: 0.9144\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2693 - accuracy: 0.9319 - val_loss: 0.4330 - val_accuracy: 0.9219\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2444 - accuracy: 0.9379 - val_loss: 0.4481 - val_accuracy: 0.9021\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2266 - accuracy: 0.9436 - val_loss: 0.3986 - val_accuracy: 0.9351\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2041 - accuracy: 0.9490 - val_loss: 0.3711 - val_accuracy: 0.9303\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1907 - accuracy: 0.9520 - val_loss: 0.3311 - val_accuracy: 0.9454\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1810 - accuracy: 0.9564 - val_loss: 0.3143 - val_accuracy: 0.9483\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1656 - accuracy: 0.9588 - val_loss: 0.3135 - val_accuracy: 0.9518\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1662 - accuracy: 0.9594 - val_loss: 0.2963 - val_accuracy: 0.9529\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1524 - accuracy: 0.9634 - val_loss: 0.2804 - val_accuracy: 0.9501\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1451 - accuracy: 0.9663 - val_loss: 0.3062 - val_accuracy: 0.9483\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1340 - accuracy: 0.9694 - val_loss: 0.2926 - val_accuracy: 0.9470\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1338 - accuracy: 0.9687 - val_loss: 0.2720 - val_accuracy: 0.9569\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1280 - accuracy: 0.9699 - val_loss: 0.2518 - val_accuracy: 0.9600\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1161 - accuracy: 0.9719 - val_loss: 0.2679 - val_accuracy: 0.9494\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1229 - accuracy: 0.9718 - val_loss: 0.2457 - val_accuracy: 0.9617\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1104 - accuracy: 0.9741 - val_loss: 0.2411 - val_accuracy: 0.9666\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1098 - accuracy: 0.9752 - val_loss: 0.2275 - val_accuracy: 0.9591\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1057 - accuracy: 0.9754 - val_loss: 0.2246 - val_accuracy: 0.9727\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1105 - accuracy: 0.9749 - val_loss: 0.2080 - val_accuracy: 0.9760\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0937 - accuracy: 0.9802 - val_loss: 0.2455 - val_accuracy: 0.9663\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1030 - accuracy: 0.9755 - val_loss: 0.2159 - val_accuracy: 0.9692\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0956 - accuracy: 0.9786 - val_loss: 0.2314 - val_accuracy: 0.9685\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0898 - accuracy: 0.9802 - val_loss: 0.2244 - val_accuracy: 0.9688\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0949 - accuracy: 0.9777 - val_loss: 0.2038 - val_accuracy: 0.9714\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0844 - accuracy: 0.9816 - val_loss: 0.1911 - val_accuracy: 0.9802\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0916 - accuracy: 0.9797 - val_loss: 0.1872 - val_accuracy: 0.9789\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0868 - accuracy: 0.9817 - val_loss: 0.2024 - val_accuracy: 0.9718\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0888 - accuracy: 0.9802 - val_loss: 0.2189 - val_accuracy: 0.9701\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0799 - accuracy: 0.9829 - val_loss: 0.1895 - val_accuracy: 0.9743\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0772 - accuracy: 0.9836 - val_loss: 0.2016 - val_accuracy: 0.9732\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0816 - accuracy: 0.9807 - val_loss: 0.1968 - val_accuracy: 0.9668\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0674 - accuracy: 0.9860 - val_loss: 0.1932 - val_accuracy: 0.9723\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0840 - accuracy: 0.9811 - val_loss: 0.1905 - val_accuracy: 0.9762\n","Average Validation Accuracy: 0.9860218465328217\n","Average Validation Loss: 0.12067188695073128\n","Average Test Accuracy: 0.9847792387008667\n","------------------------------------------------------------------------\n","\n","Number of input features: 12\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.4663 - accuracy: 0.3744 - val_loss: 2.0901 - val_accuracy: 0.6389\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2598 - accuracy: 0.7705 - val_loss: 1.0253 - val_accuracy: 0.8330\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6113 - accuracy: 0.8719 - val_loss: 0.6855 - val_accuracy: 0.8730\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3781 - accuracy: 0.9112 - val_loss: 0.5432 - val_accuracy: 0.9067\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2841 - accuracy: 0.9326 - val_loss: 0.4336 - val_accuracy: 0.9340\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2267 - accuracy: 0.9448 - val_loss: 0.3781 - val_accuracy: 0.9347\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1977 - accuracy: 0.9519 - val_loss: 0.3522 - val_accuracy: 0.9391\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1870 - accuracy: 0.9536 - val_loss: 0.3642 - val_accuracy: 0.9243\n","Epoch 9/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1655 - accuracy: 0.9601 - val_loss: 0.3096 - val_accuracy: 0.9553\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1482 - accuracy: 0.9646 - val_loss: 0.3268 - val_accuracy: 0.9571\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1415 - accuracy: 0.9653 - val_loss: 0.3414 - val_accuracy: 0.9388\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1286 - accuracy: 0.9702 - val_loss: 0.2588 - val_accuracy: 0.9666\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1274 - accuracy: 0.9714 - val_loss: 0.3418 - val_accuracy: 0.9384\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1247 - accuracy: 0.9706 - val_loss: 0.2533 - val_accuracy: 0.9683\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1097 - accuracy: 0.9757 - val_loss: 0.2684 - val_accuracy: 0.9569\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1131 - accuracy: 0.9729 - val_loss: 0.2506 - val_accuracy: 0.9619\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1110 - accuracy: 0.9738 - val_loss: 0.2488 - val_accuracy: 0.9666\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1035 - accuracy: 0.9737 - val_loss: 0.2683 - val_accuracy: 0.9602\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0961 - accuracy: 0.9760 - val_loss: 0.2437 - val_accuracy: 0.9637\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1014 - accuracy: 0.9757 - val_loss: 0.2491 - val_accuracy: 0.9668\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0922 - accuracy: 0.9776 - val_loss: 0.2390 - val_accuracy: 0.9677\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0947 - accuracy: 0.9775 - val_loss: 0.2400 - val_accuracy: 0.9683\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0886 - accuracy: 0.9780 - val_loss: 0.2332 - val_accuracy: 0.9762\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0887 - accuracy: 0.9793 - val_loss: 0.2372 - val_accuracy: 0.9703\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0854 - accuracy: 0.9795 - val_loss: 0.2326 - val_accuracy: 0.9738\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0868 - accuracy: 0.9799 - val_loss: 0.2365 - val_accuracy: 0.9696\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0783 - accuracy: 0.9812 - val_loss: 0.2513 - val_accuracy: 0.9771\n","Epoch 28/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0823 - accuracy: 0.9796 - val_loss: 0.2338 - val_accuracy: 0.9727\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0775 - accuracy: 0.9824 - val_loss: 0.2188 - val_accuracy: 0.9800\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0702 - accuracy: 0.9828 - val_loss: 0.2489 - val_accuracy: 0.9718\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0857 - accuracy: 0.9798 - val_loss: 0.2294 - val_accuracy: 0.9716\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0766 - accuracy: 0.9817 - val_loss: 0.2264 - val_accuracy: 0.9839\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0717 - accuracy: 0.9844 - val_loss: 0.2268 - val_accuracy: 0.9795\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0759 - accuracy: 0.9824 - val_loss: 0.2299 - val_accuracy: 0.9837\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0621 - accuracy: 0.9868 - val_loss: 0.2101 - val_accuracy: 0.9850\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0750 - accuracy: 0.9817 - val_loss: 0.2238 - val_accuracy: 0.9738\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0683 - accuracy: 0.9845 - val_loss: 0.2208 - val_accuracy: 0.9727\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0735 - accuracy: 0.9830 - val_loss: 0.2250 - val_accuracy: 0.9800\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0618 - accuracy: 0.9860 - val_loss: 0.2083 - val_accuracy: 0.9850\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0682 - accuracy: 0.9829 - val_loss: 0.2103 - val_accuracy: 0.9831\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.7960 - accuracy: 0.2714 - val_loss: 2.5235 - val_accuracy: 0.5866\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6012 - accuracy: 0.7050 - val_loss: 1.3839 - val_accuracy: 0.7707\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8205 - accuracy: 0.8326 - val_loss: 0.9532 - val_accuracy: 0.8392\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5325 - accuracy: 0.8778 - val_loss: 0.7423 - val_accuracy: 0.8893\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4003 - accuracy: 0.9031 - val_loss: 0.5933 - val_accuracy: 0.9166\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3140 - accuracy: 0.9233 - val_loss: 0.6520 - val_accuracy: 0.8893\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2691 - accuracy: 0.9332 - val_loss: 0.4675 - val_accuracy: 0.9388\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2340 - accuracy: 0.9417 - val_loss: 0.4654 - val_accuracy: 0.9338\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2132 - accuracy: 0.9461 - val_loss: 0.4378 - val_accuracy: 0.9329\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1911 - accuracy: 0.9521 - val_loss: 0.4098 - val_accuracy: 0.9373\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1830 - accuracy: 0.9549 - val_loss: 0.3937 - val_accuracy: 0.9419\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1583 - accuracy: 0.9619 - val_loss: 0.3679 - val_accuracy: 0.9507\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1625 - accuracy: 0.9594 - val_loss: 0.3862 - val_accuracy: 0.9397\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1551 - accuracy: 0.9613 - val_loss: 0.3275 - val_accuracy: 0.9556\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1434 - accuracy: 0.9654 - val_loss: 0.3479 - val_accuracy: 0.9558\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1283 - accuracy: 0.9694 - val_loss: 0.3318 - val_accuracy: 0.9580\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1397 - accuracy: 0.9648 - val_loss: 0.2935 - val_accuracy: 0.9677\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1179 - accuracy: 0.9719 - val_loss: 0.3122 - val_accuracy: 0.9624\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1188 - accuracy: 0.9728 - val_loss: 0.3285 - val_accuracy: 0.9540\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1158 - accuracy: 0.9733 - val_loss: 0.2861 - val_accuracy: 0.9633\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1099 - accuracy: 0.9738 - val_loss: 0.2771 - val_accuracy: 0.9672\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1035 - accuracy: 0.9763 - val_loss: 0.3023 - val_accuracy: 0.9604\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1135 - accuracy: 0.9732 - val_loss: 0.2810 - val_accuracy: 0.9626\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1042 - accuracy: 0.9752 - val_loss: 0.2704 - val_accuracy: 0.9692\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0956 - accuracy: 0.9782 - val_loss: 0.2618 - val_accuracy: 0.9696\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9750 - val_loss: 0.2589 - val_accuracy: 0.9657\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0906 - accuracy: 0.9806 - val_loss: 0.2455 - val_accuracy: 0.9688\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0944 - accuracy: 0.9779 - val_loss: 0.2517 - val_accuracy: 0.9666\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0978 - accuracy: 0.9768 - val_loss: 0.2428 - val_accuracy: 0.9655\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0874 - accuracy: 0.9801 - val_loss: 0.2710 - val_accuracy: 0.9714\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0938 - accuracy: 0.9771 - val_loss: 0.2632 - val_accuracy: 0.9628\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0868 - accuracy: 0.9810 - val_loss: 0.2396 - val_accuracy: 0.9688\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0855 - accuracy: 0.9782 - val_loss: 0.2358 - val_accuracy: 0.9732\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0876 - accuracy: 0.9798 - val_loss: 0.2297 - val_accuracy: 0.9773\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0730 - accuracy: 0.9833 - val_loss: 0.2563 - val_accuracy: 0.9683\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0891 - accuracy: 0.9781 - val_loss: 0.2320 - val_accuracy: 0.9740\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0851 - accuracy: 0.9798 - val_loss: 0.2290 - val_accuracy: 0.9729\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0770 - accuracy: 0.9828 - val_loss: 0.2391 - val_accuracy: 0.9782\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0724 - accuracy: 0.9836 - val_loss: 0.2187 - val_accuracy: 0.9804\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0810 - accuracy: 0.9795 - val_loss: 0.2234 - val_accuracy: 0.9853\n","Average Validation Accuracy: 0.9881640076637268\n","Average Validation Loss: 0.11133941635489464\n","Average Test Accuracy: 0.9878749847412109\n","------------------------------------------------------------------------\n","\n","Number of input features: 13\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.3711 - accuracy: 0.3936 - val_loss: 2.0765 - val_accuracy: 0.6458\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2686 - accuracy: 0.7561 - val_loss: 1.0414 - val_accuracy: 0.8323\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6078 - accuracy: 0.8742 - val_loss: 0.7244 - val_accuracy: 0.8873\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3943 - accuracy: 0.9112 - val_loss: 0.5600 - val_accuracy: 0.9177\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3022 - accuracy: 0.9286 - val_loss: 0.5234 - val_accuracy: 0.9166\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2554 - accuracy: 0.9393 - val_loss: 0.4512 - val_accuracy: 0.9311\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2149 - accuracy: 0.9497 - val_loss: 0.4019 - val_accuracy: 0.9362\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1991 - accuracy: 0.9504 - val_loss: 0.3928 - val_accuracy: 0.9397\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1793 - accuracy: 0.9563 - val_loss: 0.4053 - val_accuracy: 0.9256\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1617 - accuracy: 0.9590 - val_loss: 0.3494 - val_accuracy: 0.9463\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1511 - accuracy: 0.9636 - val_loss: 0.3495 - val_accuracy: 0.9505\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1474 - accuracy: 0.9655 - val_loss: 0.3445 - val_accuracy: 0.9602\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1313 - accuracy: 0.9690 - val_loss: 0.3230 - val_accuracy: 0.9573\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1235 - accuracy: 0.9718 - val_loss: 0.3112 - val_accuracy: 0.9690\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1253 - accuracy: 0.9718 - val_loss: 0.3001 - val_accuracy: 0.9696\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1158 - accuracy: 0.9737 - val_loss: 0.3249 - val_accuracy: 0.9650\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1104 - accuracy: 0.9737 - val_loss: 0.2931 - val_accuracy: 0.9723\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1107 - accuracy: 0.9738 - val_loss: 0.2998 - val_accuracy: 0.9573\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1024 - accuracy: 0.9762 - val_loss: 0.2900 - val_accuracy: 0.9747\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1022 - accuracy: 0.9757 - val_loss: 0.2828 - val_accuracy: 0.9699\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0920 - accuracy: 0.9779 - val_loss: 0.2965 - val_accuracy: 0.9659\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0966 - accuracy: 0.9780 - val_loss: 0.2965 - val_accuracy: 0.9606\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1004 - accuracy: 0.9758 - val_loss: 0.2760 - val_accuracy: 0.9718\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0838 - accuracy: 0.9799 - val_loss: 0.2974 - val_accuracy: 0.9644\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0888 - accuracy: 0.9788 - val_loss: 0.2807 - val_accuracy: 0.9804\n","Epoch 26/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0837 - accuracy: 0.9814 - val_loss: 0.2735 - val_accuracy: 0.9703\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0832 - accuracy: 0.9814 - val_loss: 0.3130 - val_accuracy: 0.9646\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0878 - accuracy: 0.9786 - val_loss: 0.2869 - val_accuracy: 0.9732\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0845 - accuracy: 0.9797 - val_loss: 0.2620 - val_accuracy: 0.9815\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0728 - accuracy: 0.9844 - val_loss: 0.2795 - val_accuracy: 0.9813\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0812 - accuracy: 0.9806 - val_loss: 0.2712 - val_accuracy: 0.9831\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0725 - accuracy: 0.9839 - val_loss: 0.2639 - val_accuracy: 0.9839\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0724 - accuracy: 0.9823 - val_loss: 0.2642 - val_accuracy: 0.9800\n","Epoch 34/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0763 - accuracy: 0.9815 - val_loss: 0.2837 - val_accuracy: 0.9769\n","Epoch 35/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0737 - accuracy: 0.9827 - val_loss: 0.3398 - val_accuracy: 0.9468\n","Epoch 36/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0717 - accuracy: 0.9834 - val_loss: 0.2876 - val_accuracy: 0.9670\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0724 - accuracy: 0.9831 - val_loss: 0.2735 - val_accuracy: 0.9696\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0657 - accuracy: 0.9854 - val_loss: 0.2614 - val_accuracy: 0.9782\n","Epoch 39/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0749 - accuracy: 0.9820 - val_loss: 0.2976 - val_accuracy: 0.9710\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0666 - accuracy: 0.9843 - val_loss: 0.2835 - val_accuracy: 0.9822\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.9334 - accuracy: 0.2444 - val_loss: 2.6493 - val_accuracy: 0.4706\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6350 - accuracy: 0.6914 - val_loss: 1.5144 - val_accuracy: 0.7679\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.8766 - accuracy: 0.8176 - val_loss: 1.0830 - val_accuracy: 0.8383\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5936 - accuracy: 0.8663 - val_loss: 0.9045 - val_accuracy: 0.8693\n","Epoch 5/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.4526 - accuracy: 0.8970 - val_loss: 0.7837 - val_accuracy: 0.8882\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3644 - accuracy: 0.9112 - val_loss: 0.6748 - val_accuracy: 0.9182\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3078 - accuracy: 0.9255 - val_loss: 0.5847 - val_accuracy: 0.9197\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2734 - accuracy: 0.9324 - val_loss: 0.5719 - val_accuracy: 0.9124\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2425 - accuracy: 0.9399 - val_loss: 0.4795 - val_accuracy: 0.9261\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2254 - accuracy: 0.9431 - val_loss: 0.4956 - val_accuracy: 0.9375\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2013 - accuracy: 0.9498 - val_loss: 0.4643 - val_accuracy: 0.9413\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1899 - accuracy: 0.9542 - val_loss: 0.5250 - val_accuracy: 0.9109\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1810 - accuracy: 0.9543 - val_loss: 0.3981 - val_accuracy: 0.9481\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1729 - accuracy: 0.9576 - val_loss: 0.4093 - val_accuracy: 0.9483\n","Epoch 15/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1563 - accuracy: 0.9626 - val_loss: 0.4405 - val_accuracy: 0.9355\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1568 - accuracy: 0.9614 - val_loss: 0.4407 - val_accuracy: 0.9362\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1434 - accuracy: 0.9654 - val_loss: 0.3942 - val_accuracy: 0.9457\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1405 - accuracy: 0.9655 - val_loss: 0.3558 - val_accuracy: 0.9611\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1393 - accuracy: 0.9650 - val_loss: 0.3326 - val_accuracy: 0.9582\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1234 - accuracy: 0.9692 - val_loss: 0.3300 - val_accuracy: 0.9584\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1285 - accuracy: 0.9697 - val_loss: 0.3315 - val_accuracy: 0.9602\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1151 - accuracy: 0.9731 - val_loss: 0.3357 - val_accuracy: 0.9512\n","Epoch 23/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1218 - accuracy: 0.9707 - val_loss: 0.3389 - val_accuracy: 0.9556\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1098 - accuracy: 0.9742 - val_loss: 0.3135 - val_accuracy: 0.9615\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1108 - accuracy: 0.9747 - val_loss: 0.2983 - val_accuracy: 0.9586\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1052 - accuracy: 0.9747 - val_loss: 0.2936 - val_accuracy: 0.9641\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1078 - accuracy: 0.9738 - val_loss: 0.3148 - val_accuracy: 0.9624\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1012 - accuracy: 0.9759 - val_loss: 0.3094 - val_accuracy: 0.9608\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0975 - accuracy: 0.9773 - val_loss: 0.2746 - val_accuracy: 0.9699\n","Epoch 30/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0941 - accuracy: 0.9771 - val_loss: 0.2942 - val_accuracy: 0.9663\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0956 - accuracy: 0.9768 - val_loss: 0.2708 - val_accuracy: 0.9707\n","Epoch 32/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0844 - accuracy: 0.9811 - val_loss: 0.2959 - val_accuracy: 0.9630\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0960 - accuracy: 0.9768 - val_loss: 0.2820 - val_accuracy: 0.9740\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0926 - accuracy: 0.9792 - val_loss: 0.2884 - val_accuracy: 0.9670\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0847 - accuracy: 0.9802 - val_loss: 0.2637 - val_accuracy: 0.9734\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0893 - accuracy: 0.9792 - val_loss: 0.2826 - val_accuracy: 0.9652\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0847 - accuracy: 0.9809 - val_loss: 0.3044 - val_accuracy: 0.9465\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0828 - accuracy: 0.9808 - val_loss: 0.2695 - val_accuracy: 0.9677\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0756 - accuracy: 0.9829 - val_loss: 0.2633 - val_accuracy: 0.9738\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0894 - accuracy: 0.9785 - val_loss: 0.2660 - val_accuracy: 0.9692\n","Average Validation Accuracy: 0.9825000166893005\n","Average Validation Loss: 0.1371813341975212\n","Average Test Accuracy: 0.9810201227664948\n","------------------------------------------------------------------------\n","\n","Number of input features: 14\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.8564 - accuracy: 0.2778 - val_loss: 2.6100 - val_accuracy: 0.5468\n","Epoch 2/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.6170 - accuracy: 0.7095 - val_loss: 1.2846 - val_accuracy: 0.7802\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7600 - accuracy: 0.8483 - val_loss: 0.8168 - val_accuracy: 0.8777\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4493 - accuracy: 0.9031 - val_loss: 0.6379 - val_accuracy: 0.9120\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3182 - accuracy: 0.9250 - val_loss: 0.5105 - val_accuracy: 0.9221\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2468 - accuracy: 0.9432 - val_loss: 0.4741 - val_accuracy: 0.9241\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2124 - accuracy: 0.9506 - val_loss: 0.4084 - val_accuracy: 0.9360\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1933 - accuracy: 0.9550 - val_loss: 0.3689 - val_accuracy: 0.9516\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1739 - accuracy: 0.9585 - val_loss: 0.3406 - val_accuracy: 0.9399\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1531 - accuracy: 0.9650 - val_loss: 0.3323 - val_accuracy: 0.9569\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1500 - accuracy: 0.9656 - val_loss: 0.3205 - val_accuracy: 0.9562\n","Epoch 12/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1348 - accuracy: 0.9694 - val_loss: 0.2932 - val_accuracy: 0.9615\n","Epoch 13/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1272 - accuracy: 0.9711 - val_loss: 0.3888 - val_accuracy: 0.9353\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1243 - accuracy: 0.9702 - val_loss: 0.2809 - val_accuracy: 0.9707\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1210 - accuracy: 0.9720 - val_loss: 0.2808 - val_accuracy: 0.9584\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1106 - accuracy: 0.9738 - val_loss: 0.2735 - val_accuracy: 0.9648\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1040 - accuracy: 0.9760 - val_loss: 0.2702 - val_accuracy: 0.9679\n","Epoch 18/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1105 - accuracy: 0.9733 - val_loss: 0.2738 - val_accuracy: 0.9699\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0983 - accuracy: 0.9776 - val_loss: 0.2625 - val_accuracy: 0.9703\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1036 - accuracy: 0.9757 - val_loss: 0.3388 - val_accuracy: 0.9512\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0964 - accuracy: 0.9786 - val_loss: 0.2454 - val_accuracy: 0.9795\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0908 - accuracy: 0.9785 - val_loss: 0.2581 - val_accuracy: 0.9736\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0956 - accuracy: 0.9792 - val_loss: 0.2548 - val_accuracy: 0.9762\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0838 - accuracy: 0.9822 - val_loss: 0.2673 - val_accuracy: 0.9701\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0883 - accuracy: 0.9801 - val_loss: 0.2529 - val_accuracy: 0.9762\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0879 - accuracy: 0.9799 - val_loss: 0.2545 - val_accuracy: 0.9822\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0781 - accuracy: 0.9821 - val_loss: 0.2813 - val_accuracy: 0.9685\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0875 - accuracy: 0.9801 - val_loss: 0.2607 - val_accuracy: 0.9835\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0716 - accuracy: 0.9859 - val_loss: 0.2659 - val_accuracy: 0.9762\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0920 - accuracy: 0.9781 - val_loss: 0.2724 - val_accuracy: 0.9811\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0697 - accuracy: 0.9850 - val_loss: 0.2565 - val_accuracy: 0.9828\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0824 - accuracy: 0.9820 - val_loss: 0.2509 - val_accuracy: 0.9826\n","Epoch 33/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0700 - accuracy: 0.9848 - val_loss: 0.2583 - val_accuracy: 0.9839\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0771 - accuracy: 0.9839 - val_loss: 0.2476 - val_accuracy: 0.9868\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0675 - accuracy: 0.9863 - val_loss: 0.2607 - val_accuracy: 0.9802\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0723 - accuracy: 0.9841 - val_loss: 0.2932 - val_accuracy: 0.9738\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0713 - accuracy: 0.9836 - val_loss: 0.2578 - val_accuracy: 0.9848\n","Epoch 38/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0775 - accuracy: 0.9827 - val_loss: 0.2592 - val_accuracy: 0.9848\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0625 - accuracy: 0.9869 - val_loss: 0.2600 - val_accuracy: 0.9806\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0741 - accuracy: 0.9848 - val_loss: 0.2519 - val_accuracy: 0.9802\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.5228 - accuracy: 0.3565 - val_loss: 2.1173 - val_accuracy: 0.6515\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2710 - accuracy: 0.7651 - val_loss: 1.1672 - val_accuracy: 0.8207\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6650 - accuracy: 0.8586 - val_loss: 0.8477 - val_accuracy: 0.8506\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4390 - accuracy: 0.9052 - val_loss: 0.6630 - val_accuracy: 0.9014\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3361 - accuracy: 0.9211 - val_loss: 0.5994 - val_accuracy: 0.9047\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2757 - accuracy: 0.9313 - val_loss: 0.5191 - val_accuracy: 0.9230\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2398 - accuracy: 0.9423 - val_loss: 0.4422 - val_accuracy: 0.9410\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2134 - accuracy: 0.9477 - val_loss: 0.4291 - val_accuracy: 0.9254\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1911 - accuracy: 0.9548 - val_loss: 0.3668 - val_accuracy: 0.9388\n","Epoch 10/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1737 - accuracy: 0.9572 - val_loss: 0.3650 - val_accuracy: 0.9413\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1594 - accuracy: 0.9621 - val_loss: 0.3468 - val_accuracy: 0.9454\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1514 - accuracy: 0.9629 - val_loss: 0.3089 - val_accuracy: 0.9501\n","Epoch 13/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1378 - accuracy: 0.9672 - val_loss: 0.3161 - val_accuracy: 0.9672\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1344 - accuracy: 0.9671 - val_loss: 0.2980 - val_accuracy: 0.9518\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1224 - accuracy: 0.9720 - val_loss: 0.2806 - val_accuracy: 0.9542\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1277 - accuracy: 0.9712 - val_loss: 0.2747 - val_accuracy: 0.9615\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1126 - accuracy: 0.9732 - val_loss: 0.2687 - val_accuracy: 0.9575\n","Epoch 18/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1136 - accuracy: 0.9739 - val_loss: 0.2513 - val_accuracy: 0.9685\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1033 - accuracy: 0.9771 - val_loss: 0.2638 - val_accuracy: 0.9646\n","Epoch 20/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1045 - accuracy: 0.9771 - val_loss: 0.2541 - val_accuracy: 0.9701\n","Epoch 21/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0991 - accuracy: 0.9771 - val_loss: 0.2571 - val_accuracy: 0.9688\n","Epoch 22/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0963 - accuracy: 0.9785 - val_loss: 0.2542 - val_accuracy: 0.9679\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0896 - accuracy: 0.9794 - val_loss: 0.2630 - val_accuracy: 0.9619\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0885 - accuracy: 0.9805 - val_loss: 0.2469 - val_accuracy: 0.9685\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0882 - accuracy: 0.9804 - val_loss: 0.2257 - val_accuracy: 0.9655\n","Epoch 26/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0892 - accuracy: 0.9794 - val_loss: 0.2637 - val_accuracy: 0.9639\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0833 - accuracy: 0.9810 - val_loss: 0.2365 - val_accuracy: 0.9725\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0862 - accuracy: 0.9810 - val_loss: 0.2544 - val_accuracy: 0.9716\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0749 - accuracy: 0.9848 - val_loss: 0.2423 - val_accuracy: 0.9732\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0800 - accuracy: 0.9823 - val_loss: 0.2294 - val_accuracy: 0.9696\n","Epoch 31/40\n","1846/1846 [==============================] - 5s 3ms/step - loss: 0.0760 - accuracy: 0.9819 - val_loss: 0.2277 - val_accuracy: 0.9745\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0764 - accuracy: 0.9830 - val_loss: 0.2302 - val_accuracy: 0.9784\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0784 - accuracy: 0.9819 - val_loss: 0.2165 - val_accuracy: 0.9782\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0698 - accuracy: 0.9840 - val_loss: 0.2296 - val_accuracy: 0.9736\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0687 - accuracy: 0.9859 - val_loss: 0.2436 - val_accuracy: 0.9650\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0829 - accuracy: 0.9810 - val_loss: 0.2368 - val_accuracy: 0.9692\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0632 - accuracy: 0.9860 - val_loss: 0.2198 - val_accuracy: 0.9778\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0663 - accuracy: 0.9852 - val_loss: 0.2317 - val_accuracy: 0.9674\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0731 - accuracy: 0.9840 - val_loss: 0.2348 - val_accuracy: 0.9661\n","Epoch 40/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0635 - accuracy: 0.9861 - val_loss: 0.2188 - val_accuracy: 0.9727\n","Average Validation Accuracy: 0.9830446839332581\n","Average Validation Loss: 0.11649352684617043\n","Average Test Accuracy: 0.9821994602680206\n","------------------------------------------------------------------------\n","\n","Number of input features: 15\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 12s 5ms/step - loss: 3.6194 - accuracy: 0.3325 - val_loss: 2.2033 - val_accuracy: 0.6293\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.2734 - accuracy: 0.7729 - val_loss: 1.0297 - val_accuracy: 0.8189\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5877 - accuracy: 0.8781 - val_loss: 0.6707 - val_accuracy: 0.8880\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3845 - accuracy: 0.9144 - val_loss: 0.5530 - val_accuracy: 0.8981\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3034 - accuracy: 0.9279 - val_loss: 0.4648 - val_accuracy: 0.9219\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2565 - accuracy: 0.9383 - val_loss: 0.4288 - val_accuracy: 0.9256\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2268 - accuracy: 0.9458 - val_loss: 0.3811 - val_accuracy: 0.9413\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2018 - accuracy: 0.9498 - val_loss: 0.3672 - val_accuracy: 0.9426\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1854 - accuracy: 0.9534 - val_loss: 0.3655 - val_accuracy: 0.9347\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1748 - accuracy: 0.9564 - val_loss: 0.3321 - val_accuracy: 0.9448\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1644 - accuracy: 0.9584 - val_loss: 0.3098 - val_accuracy: 0.9549\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1567 - accuracy: 0.9603 - val_loss: 0.2857 - val_accuracy: 0.9584\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1473 - accuracy: 0.9640 - val_loss: 0.3215 - val_accuracy: 0.9468\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1347 - accuracy: 0.9663 - val_loss: 0.2792 - val_accuracy: 0.9567\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1335 - accuracy: 0.9661 - val_loss: 0.2907 - val_accuracy: 0.9595\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1201 - accuracy: 0.9692 - val_loss: 0.2731 - val_accuracy: 0.9639\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1210 - accuracy: 0.9710 - val_loss: 0.2585 - val_accuracy: 0.9659\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1142 - accuracy: 0.9723 - val_loss: 0.2683 - val_accuracy: 0.9637\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1088 - accuracy: 0.9732 - val_loss: 0.2550 - val_accuracy: 0.9670\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1060 - accuracy: 0.9737 - val_loss: 0.2602 - val_accuracy: 0.9644\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1017 - accuracy: 0.9752 - val_loss: 0.2588 - val_accuracy: 0.9791\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1025 - accuracy: 0.9754 - val_loss: 0.2498 - val_accuracy: 0.9685\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0982 - accuracy: 0.9747 - val_loss: 0.3195 - val_accuracy: 0.9472\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0928 - accuracy: 0.9767 - val_loss: 0.2410 - val_accuracy: 0.9815\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0911 - accuracy: 0.9765 - val_loss: 0.2520 - val_accuracy: 0.9782\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0953 - accuracy: 0.9770 - val_loss: 0.2911 - val_accuracy: 0.9628\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0874 - accuracy: 0.9789 - val_loss: 0.2560 - val_accuracy: 0.9778\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0871 - accuracy: 0.9788 - val_loss: 0.2536 - val_accuracy: 0.9710\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0816 - accuracy: 0.9804 - val_loss: 0.2596 - val_accuracy: 0.9765\n","Epoch 30/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0788 - accuracy: 0.9816 - val_loss: 0.2511 - val_accuracy: 0.9824\n","Epoch 31/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0927 - accuracy: 0.9778 - val_loss: 0.2468 - val_accuracy: 0.9732\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0750 - accuracy: 0.9824 - val_loss: 0.2513 - val_accuracy: 0.9705\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0795 - accuracy: 0.9802 - val_loss: 0.2388 - val_accuracy: 0.9864\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0727 - accuracy: 0.9828 - val_loss: 0.2646 - val_accuracy: 0.9745\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0792 - accuracy: 0.9812 - val_loss: 0.3099 - val_accuracy: 0.9648\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0771 - accuracy: 0.9821 - val_loss: 0.2300 - val_accuracy: 0.9853\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0751 - accuracy: 0.9825 - val_loss: 0.2502 - val_accuracy: 0.9732\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0733 - accuracy: 0.9818 - val_loss: 0.2421 - val_accuracy: 0.9835\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0770 - accuracy: 0.9814 - val_loss: 0.2389 - val_accuracy: 0.9822\n","Epoch 40/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0652 - accuracy: 0.9860 - val_loss: 0.2392 - val_accuracy: 0.9831\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 9s 4ms/step - loss: 3.8073 - accuracy: 0.2864 - val_loss: 2.4648 - val_accuracy: 0.6189\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.5768 - accuracy: 0.7107 - val_loss: 1.4940 - val_accuracy: 0.7633\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9010 - accuracy: 0.8177 - val_loss: 1.0965 - val_accuracy: 0.8398\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6138 - accuracy: 0.8705 - val_loss: 0.9047 - val_accuracy: 0.8733\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4645 - accuracy: 0.8951 - val_loss: 0.7573 - val_accuracy: 0.9076\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3722 - accuracy: 0.9138 - val_loss: 0.6661 - val_accuracy: 0.9047\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3153 - accuracy: 0.9280 - val_loss: 0.6070 - val_accuracy: 0.9113\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2689 - accuracy: 0.9370 - val_loss: 0.5669 - val_accuracy: 0.9164\n","Epoch 9/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2433 - accuracy: 0.9428 - val_loss: 0.4813 - val_accuracy: 0.9408\n","Epoch 10/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2213 - accuracy: 0.9468 - val_loss: 0.4977 - val_accuracy: 0.9386\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2050 - accuracy: 0.9524 - val_loss: 0.4435 - val_accuracy: 0.9419\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1916 - accuracy: 0.9557 - val_loss: 0.4349 - val_accuracy: 0.9476\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1714 - accuracy: 0.9603 - val_loss: 0.4100 - val_accuracy: 0.9472\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1696 - accuracy: 0.9602 - val_loss: 0.4047 - val_accuracy: 0.9505\n","Epoch 15/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1502 - accuracy: 0.9661 - val_loss: 0.3991 - val_accuracy: 0.9487\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1530 - accuracy: 0.9653 - val_loss: 0.4145 - val_accuracy: 0.9435\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1363 - accuracy: 0.9673 - val_loss: 0.3709 - val_accuracy: 0.9571\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1308 - accuracy: 0.9714 - val_loss: 0.3880 - val_accuracy: 0.9538\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1313 - accuracy: 0.9685 - val_loss: 0.3466 - val_accuracy: 0.9617\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1317 - accuracy: 0.9701 - val_loss: 0.3781 - val_accuracy: 0.9540\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1140 - accuracy: 0.9732 - val_loss: 0.3447 - val_accuracy: 0.9611\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1128 - accuracy: 0.9740 - val_loss: 0.3398 - val_accuracy: 0.9663\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1136 - accuracy: 0.9749 - val_loss: 0.3492 - val_accuracy: 0.9529\n","Epoch 24/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.1105 - accuracy: 0.9752 - val_loss: 0.3329 - val_accuracy: 0.9604\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1009 - accuracy: 0.9768 - val_loss: 0.4729 - val_accuracy: 0.9509\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0994 - accuracy: 0.9772 - val_loss: 0.3394 - val_accuracy: 0.9529\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1073 - accuracy: 0.9751 - val_loss: 0.3091 - val_accuracy: 0.9677\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0950 - accuracy: 0.9779 - val_loss: 0.3143 - val_accuracy: 0.9723\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0953 - accuracy: 0.9773 - val_loss: 0.3209 - val_accuracy: 0.9646\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0866 - accuracy: 0.9790 - val_loss: 0.3165 - val_accuracy: 0.9650\n","Epoch 31/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0921 - accuracy: 0.9784 - val_loss: 0.3225 - val_accuracy: 0.9699\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0944 - accuracy: 0.9784 - val_loss: 0.2925 - val_accuracy: 0.9747\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0913 - accuracy: 0.9786 - val_loss: 0.2909 - val_accuracy: 0.9714\n","Epoch 34/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0803 - accuracy: 0.9809 - val_loss: 0.2956 - val_accuracy: 0.9716\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0887 - accuracy: 0.9793 - val_loss: 0.2998 - val_accuracy: 0.9751\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0732 - accuracy: 0.9833 - val_loss: 0.2903 - val_accuracy: 0.9751\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0885 - accuracy: 0.9782 - val_loss: 0.2791 - val_accuracy: 0.9740\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0767 - accuracy: 0.9827 - val_loss: 0.3141 - val_accuracy: 0.9604\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0787 - accuracy: 0.9813 - val_loss: 0.2774 - val_accuracy: 0.9760\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0789 - accuracy: 0.9814 - val_loss: 0.3215 - val_accuracy: 0.9527\n","Average Validation Accuracy: 0.9726967513561249\n","Average Validation Loss: 0.1490986943244934\n","Average Test Accuracy: 0.9718065857887268\n","------------------------------------------------------------------------\n","\n","Number of input features: 16\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.5205 - accuracy: 0.3337 - val_loss: 2.1520 - val_accuracy: 0.6321\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4079 - accuracy: 0.7250 - val_loss: 1.2024 - val_accuracy: 0.7881\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7939 - accuracy: 0.8320 - val_loss: 0.8592 - val_accuracy: 0.8216\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5343 - accuracy: 0.8737 - val_loss: 0.6994 - val_accuracy: 0.8645\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4116 - accuracy: 0.8969 - val_loss: 0.5258 - val_accuracy: 0.9052\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3223 - accuracy: 0.9177 - val_loss: 0.5003 - val_accuracy: 0.9041\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.2823 - accuracy: 0.9273 - val_loss: 0.4070 - val_accuracy: 0.9157\n","Epoch 8/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2413 - accuracy: 0.9401 - val_loss: 0.3771 - val_accuracy: 0.9307\n","Epoch 9/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2244 - accuracy: 0.9423 - val_loss: 0.3454 - val_accuracy: 0.9402\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1914 - accuracy: 0.9524 - val_loss: 0.3364 - val_accuracy: 0.9371\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1901 - accuracy: 0.9524 - val_loss: 0.3135 - val_accuracy: 0.9485\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1721 - accuracy: 0.9582 - val_loss: 0.3031 - val_accuracy: 0.9487\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1550 - accuracy: 0.9637 - val_loss: 0.2834 - val_accuracy: 0.9580\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1484 - accuracy: 0.9630 - val_loss: 0.2957 - val_accuracy: 0.9562\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1430 - accuracy: 0.9647 - val_loss: 0.2958 - val_accuracy: 0.9483\n","Epoch 16/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1320 - accuracy: 0.9687 - val_loss: 0.2531 - val_accuracy: 0.9637\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1316 - accuracy: 0.9661 - val_loss: 0.2660 - val_accuracy: 0.9580\n","Epoch 18/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1243 - accuracy: 0.9703 - val_loss: 0.2418 - val_accuracy: 0.9725\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1150 - accuracy: 0.9724 - val_loss: 0.3097 - val_accuracy: 0.9509\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1158 - accuracy: 0.9721 - val_loss: 0.2363 - val_accuracy: 0.9668\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1138 - accuracy: 0.9739 - val_loss: 0.2221 - val_accuracy: 0.9787\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1049 - accuracy: 0.9755 - val_loss: 0.2301 - val_accuracy: 0.9732\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1121 - accuracy: 0.9742 - val_loss: 0.2557 - val_accuracy: 0.9648\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1004 - accuracy: 0.9764 - val_loss: 0.2530 - val_accuracy: 0.9633\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1023 - accuracy: 0.9756 - val_loss: 0.2435 - val_accuracy: 0.9721\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0926 - accuracy: 0.9785 - val_loss: 0.2225 - val_accuracy: 0.9732\n","Epoch 27/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0996 - accuracy: 0.9764 - val_loss: 0.2348 - val_accuracy: 0.9630\n","Epoch 28/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0893 - accuracy: 0.9795 - val_loss: 0.2243 - val_accuracy: 0.9727\n","Epoch 29/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0953 - accuracy: 0.9760 - val_loss: 0.2364 - val_accuracy: 0.9754\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0828 - accuracy: 0.9808 - val_loss: 0.2496 - val_accuracy: 0.9690\n","Epoch 31/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0875 - accuracy: 0.9798 - val_loss: 0.2159 - val_accuracy: 0.9773\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0896 - accuracy: 0.9795 - val_loss: 0.2147 - val_accuracy: 0.9771\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0829 - accuracy: 0.9804 - val_loss: 0.3074 - val_accuracy: 0.9562\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0788 - accuracy: 0.9811 - val_loss: 0.2153 - val_accuracy: 0.9738\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0853 - accuracy: 0.9798 - val_loss: 0.2010 - val_accuracy: 0.9833\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0728 - accuracy: 0.9840 - val_loss: 0.2258 - val_accuracy: 0.9754\n","Epoch 37/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.0799 - accuracy: 0.9816 - val_loss: 0.2455 - val_accuracy: 0.9657\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0791 - accuracy: 0.9809 - val_loss: 0.2213 - val_accuracy: 0.9762\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0711 - accuracy: 0.9827 - val_loss: 0.2269 - val_accuracy: 0.9754\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0716 - accuracy: 0.9844 - val_loss: 0.2343 - val_accuracy: 0.9736\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.9026 - accuracy: 0.2007 - val_loss: 2.7557 - val_accuracy: 0.4752\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7680 - accuracy: 0.6541 - val_loss: 1.5242 - val_accuracy: 0.7296\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9630 - accuracy: 0.7963 - val_loss: 1.2716 - val_accuracy: 0.7822\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6537 - accuracy: 0.8546 - val_loss: 0.8857 - val_accuracy: 0.8823\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 4ms/step - loss: 0.4812 - accuracy: 0.8865 - val_loss: 0.8136 - val_accuracy: 0.8453\n","Epoch 6/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3796 - accuracy: 0.9059 - val_loss: 0.6538 - val_accuracy: 0.8948\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.3143 - accuracy: 0.9245 - val_loss: 0.5729 - val_accuracy: 0.9206\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2827 - accuracy: 0.9304 - val_loss: 0.5333 - val_accuracy: 0.9199\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2426 - accuracy: 0.9388 - val_loss: 0.5068 - val_accuracy: 0.9314\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2243 - accuracy: 0.9413 - val_loss: 0.5097 - val_accuracy: 0.9210\n","Epoch 11/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2115 - accuracy: 0.9446 - val_loss: 0.4600 - val_accuracy: 0.9406\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1984 - accuracy: 0.9490 - val_loss: 0.4413 - val_accuracy: 0.9461\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1891 - accuracy: 0.9509 - val_loss: 0.4102 - val_accuracy: 0.9498\n","Epoch 14/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1829 - accuracy: 0.9538 - val_loss: 0.4707 - val_accuracy: 0.9292\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1592 - accuracy: 0.9609 - val_loss: 0.3942 - val_accuracy: 0.9430\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1692 - accuracy: 0.9557 - val_loss: 0.4293 - val_accuracy: 0.9303\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1485 - accuracy: 0.9632 - val_loss: 0.4080 - val_accuracy: 0.9373\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1492 - accuracy: 0.9621 - val_loss: 0.3891 - val_accuracy: 0.9492\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1501 - accuracy: 0.9619 - val_loss: 0.3462 - val_accuracy: 0.9569\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1385 - accuracy: 0.9651 - val_loss: 0.3500 - val_accuracy: 0.9551\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1376 - accuracy: 0.9662 - val_loss: 0.3408 - val_accuracy: 0.9670\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1331 - accuracy: 0.9669 - val_loss: 0.3840 - val_accuracy: 0.9459\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1287 - accuracy: 0.9686 - val_loss: 0.3310 - val_accuracy: 0.9655\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1233 - accuracy: 0.9695 - val_loss: 0.3393 - val_accuracy: 0.9538\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1248 - accuracy: 0.9691 - val_loss: 0.3294 - val_accuracy: 0.9507\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1137 - accuracy: 0.9714 - val_loss: 0.3184 - val_accuracy: 0.9626\n","Epoch 27/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1334 - accuracy: 0.9664 - val_loss: 0.3714 - val_accuracy: 0.9600\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1056 - accuracy: 0.9738 - val_loss: 0.3948 - val_accuracy: 0.9551\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1187 - accuracy: 0.9704 - val_loss: 0.3291 - val_accuracy: 0.9573\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1111 - accuracy: 0.9721 - val_loss: 0.3038 - val_accuracy: 0.9655\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1071 - accuracy: 0.9738 - val_loss: 0.3004 - val_accuracy: 0.9635\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1076 - accuracy: 0.9742 - val_loss: 0.2859 - val_accuracy: 0.9659\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0938 - accuracy: 0.9773 - val_loss: 0.2885 - val_accuracy: 0.9729\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1019 - accuracy: 0.9746 - val_loss: 0.3019 - val_accuracy: 0.9670\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0962 - accuracy: 0.9770 - val_loss: 0.3424 - val_accuracy: 0.9644\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0987 - accuracy: 0.9749 - val_loss: 0.2917 - val_accuracy: 0.9655\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0923 - accuracy: 0.9762 - val_loss: 0.2690 - val_accuracy: 0.9762\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0924 - accuracy: 0.9788 - val_loss: 0.2599 - val_accuracy: 0.9712\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1010 - accuracy: 0.9752 - val_loss: 0.2563 - val_accuracy: 0.9736\n","Epoch 40/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.0820 - accuracy: 0.9803 - val_loss: 0.2552 - val_accuracy: 0.9729\n","Average Validation Accuracy: 0.9804306030273438\n","Average Validation Loss: 0.13275005668401718\n","Average Test Accuracy: 0.9816097915172577\n","------------------------------------------------------------------------\n","\n","Number of input features: 17\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.5048 - accuracy: 0.3429 - val_loss: 2.1151 - val_accuracy: 0.6383\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3915 - accuracy: 0.7465 - val_loss: 1.2372 - val_accuracy: 0.7826\n","Epoch 3/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.8205 - accuracy: 0.8348 - val_loss: 0.8960 - val_accuracy: 0.8405\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5496 - accuracy: 0.8770 - val_loss: 0.7266 - val_accuracy: 0.8807\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4019 - accuracy: 0.9043 - val_loss: 0.6184 - val_accuracy: 0.9067\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3219 - accuracy: 0.9202 - val_loss: 0.5540 - val_accuracy: 0.9056\n","Epoch 7/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.2652 - accuracy: 0.9336 - val_loss: 0.4818 - val_accuracy: 0.9278\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2328 - accuracy: 0.9391 - val_loss: 0.4970 - val_accuracy: 0.9248\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2035 - accuracy: 0.9480 - val_loss: 0.4673 - val_accuracy: 0.9386\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1884 - accuracy: 0.9521 - val_loss: 0.4409 - val_accuracy: 0.9406\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1704 - accuracy: 0.9565 - val_loss: 0.4374 - val_accuracy: 0.9395\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1702 - accuracy: 0.9572 - val_loss: 0.4102 - val_accuracy: 0.9536\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1497 - accuracy: 0.9617 - val_loss: 0.4065 - val_accuracy: 0.9470\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1377 - accuracy: 0.9655 - val_loss: 0.4363 - val_accuracy: 0.9419\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1409 - accuracy: 0.9663 - val_loss: 0.3606 - val_accuracy: 0.9674\n","Epoch 16/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1312 - accuracy: 0.9682 - val_loss: 0.3628 - val_accuracy: 0.9613\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1246 - accuracy: 0.9690 - val_loss: 0.3697 - val_accuracy: 0.9608\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1172 - accuracy: 0.9718 - val_loss: 0.3523 - val_accuracy: 0.9661\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1149 - accuracy: 0.9721 - val_loss: 0.3528 - val_accuracy: 0.9677\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1204 - accuracy: 0.9713 - val_loss: 0.3510 - val_accuracy: 0.9652\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1040 - accuracy: 0.9741 - val_loss: 0.3554 - val_accuracy: 0.9652\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1044 - accuracy: 0.9736 - val_loss: 0.3484 - val_accuracy: 0.9619\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0991 - accuracy: 0.9766 - val_loss: 0.3722 - val_accuracy: 0.9540\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1021 - accuracy: 0.9746 - val_loss: 0.3351 - val_accuracy: 0.9661\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1027 - accuracy: 0.9762 - val_loss: 0.3312 - val_accuracy: 0.9721\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0954 - accuracy: 0.9765 - val_loss: 0.5560 - val_accuracy: 0.9173\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0923 - accuracy: 0.9786 - val_loss: 0.3383 - val_accuracy: 0.9622\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0954 - accuracy: 0.9769 - val_loss: 0.2958 - val_accuracy: 0.9762\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0904 - accuracy: 0.9791 - val_loss: 0.3267 - val_accuracy: 0.9650\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0855 - accuracy: 0.9791 - val_loss: 0.2816 - val_accuracy: 0.9809\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0837 - accuracy: 0.9802 - val_loss: 0.2943 - val_accuracy: 0.9773\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0928 - accuracy: 0.9777 - val_loss: 0.2859 - val_accuracy: 0.9749\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0804 - accuracy: 0.9812 - val_loss: 0.2788 - val_accuracy: 0.9784\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0805 - accuracy: 0.9810 - val_loss: 0.3009 - val_accuracy: 0.9721\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0839 - accuracy: 0.9802 - val_loss: 0.3823 - val_accuracy: 0.9520\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0794 - accuracy: 0.9810 - val_loss: 0.3012 - val_accuracy: 0.9714\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0762 - accuracy: 0.9816 - val_loss: 0.3099 - val_accuracy: 0.9696\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0795 - accuracy: 0.9812 - val_loss: 0.2769 - val_accuracy: 0.9782\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0697 - accuracy: 0.9843 - val_loss: 0.2670 - val_accuracy: 0.9813\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0810 - accuracy: 0.9808 - val_loss: 0.2793 - val_accuracy: 0.9696\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.2910 - accuracy: 0.3853 - val_loss: 2.0884 - val_accuracy: 0.6662\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3515 - accuracy: 0.7460 - val_loss: 1.2840 - val_accuracy: 0.8097\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7935 - accuracy: 0.8431 - val_loss: 0.8816 - val_accuracy: 0.8458\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5280 - accuracy: 0.8834 - val_loss: 0.6998 - val_accuracy: 0.8889\n","Epoch 5/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.4059 - accuracy: 0.9061 - val_loss: 0.5912 - val_accuracy: 0.8891\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3156 - accuracy: 0.9287 - val_loss: 0.5773 - val_accuracy: 0.9023\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2690 - accuracy: 0.9364 - val_loss: 0.4338 - val_accuracy: 0.9261\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2399 - accuracy: 0.9433 - val_loss: 0.3868 - val_accuracy: 0.9360\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2274 - accuracy: 0.9445 - val_loss: 0.3706 - val_accuracy: 0.9397\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1988 - accuracy: 0.9507 - val_loss: 0.3590 - val_accuracy: 0.9329\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1902 - accuracy: 0.9513 - val_loss: 0.3603 - val_accuracy: 0.9338\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1652 - accuracy: 0.9625 - val_loss: 0.3287 - val_accuracy: 0.9518\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1699 - accuracy: 0.9589 - val_loss: 0.2988 - val_accuracy: 0.9553\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1539 - accuracy: 0.9624 - val_loss: 0.2975 - val_accuracy: 0.9448\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1426 - accuracy: 0.9651 - val_loss: 0.3057 - val_accuracy: 0.9523\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1474 - accuracy: 0.9655 - val_loss: 0.3477 - val_accuracy: 0.9296\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1371 - accuracy: 0.9669 - val_loss: 0.4753 - val_accuracy: 0.9208\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1332 - accuracy: 0.9669 - val_loss: 0.2918 - val_accuracy: 0.9538\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1271 - accuracy: 0.9711 - val_loss: 0.2719 - val_accuracy: 0.9578\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1168 - accuracy: 0.9721 - val_loss: 0.2425 - val_accuracy: 0.9688\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1209 - accuracy: 0.9723 - val_loss: 0.2580 - val_accuracy: 0.9567\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1137 - accuracy: 0.9728 - val_loss: 0.3342 - val_accuracy: 0.9351\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1119 - accuracy: 0.9742 - val_loss: 0.2202 - val_accuracy: 0.9703\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1124 - accuracy: 0.9738 - val_loss: 0.2532 - val_accuracy: 0.9595\n","Epoch 25/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1071 - accuracy: 0.9766 - val_loss: 0.2182 - val_accuracy: 0.9710\n","Epoch 26/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0988 - accuracy: 0.9772 - val_loss: 0.2386 - val_accuracy: 0.9666\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1010 - accuracy: 0.9769 - val_loss: 0.2034 - val_accuracy: 0.9780\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0959 - accuracy: 0.9784 - val_loss: 0.2097 - val_accuracy: 0.9679\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0924 - accuracy: 0.9776 - val_loss: 0.2057 - val_accuracy: 0.9780\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0958 - accuracy: 0.9788 - val_loss: 0.2160 - val_accuracy: 0.9688\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0931 - accuracy: 0.9789 - val_loss: 0.2761 - val_accuracy: 0.9487\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0841 - accuracy: 0.9811 - val_loss: 0.2085 - val_accuracy: 0.9694\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0924 - accuracy: 0.9791 - val_loss: 0.1983 - val_accuracy: 0.9745\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0826 - accuracy: 0.9811 - val_loss: 0.2024 - val_accuracy: 0.9699\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0795 - accuracy: 0.9808 - val_loss: 0.1976 - val_accuracy: 0.9723\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0872 - accuracy: 0.9801 - val_loss: 0.2021 - val_accuracy: 0.9701\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0792 - accuracy: 0.9808 - val_loss: 0.2022 - val_accuracy: 0.9716\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0853 - accuracy: 0.9817 - val_loss: 0.2193 - val_accuracy: 0.9593\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0707 - accuracy: 0.9848 - val_loss: 0.2162 - val_accuracy: 0.9696\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0819 - accuracy: 0.9805 - val_loss: 0.2427 - val_accuracy: 0.9663\n","Average Validation Accuracy: 0.9754928350448608\n","Average Validation Loss: 0.14432404190301895\n","Average Test Accuracy: 0.9777401089668274\n","------------------------------------------------------------------------\n","\n","Number of input features: 18\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.5609 - accuracy: 0.3240 - val_loss: 2.1694 - val_accuracy: 0.6275\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4185 - accuracy: 0.7367 - val_loss: 1.2001 - val_accuracy: 0.7980\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7968 - accuracy: 0.8365 - val_loss: 0.7947 - val_accuracy: 0.8678\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.5265 - accuracy: 0.8833 - val_loss: 0.7061 - val_accuracy: 0.8702\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3897 - accuracy: 0.9077 - val_loss: 0.5909 - val_accuracy: 0.9023\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3062 - accuracy: 0.9275 - val_loss: 0.4984 - val_accuracy: 0.9193\n","Epoch 7/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2601 - accuracy: 0.9374 - val_loss: 0.4138 - val_accuracy: 0.9461\n","Epoch 8/40\n","1846/1846 [==============================] - 9s 5ms/step - loss: 0.2126 - accuracy: 0.9517 - val_loss: 0.4173 - val_accuracy: 0.9351\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2045 - accuracy: 0.9527 - val_loss: 0.3649 - val_accuracy: 0.9435\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1781 - accuracy: 0.9584 - val_loss: 0.3464 - val_accuracy: 0.9538\n","Epoch 11/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1657 - accuracy: 0.9609 - val_loss: 0.3240 - val_accuracy: 0.9589\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1507 - accuracy: 0.9654 - val_loss: 0.3417 - val_accuracy: 0.9525\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1479 - accuracy: 0.9650 - val_loss: 0.3172 - val_accuracy: 0.9595\n","Epoch 14/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1434 - accuracy: 0.9672 - val_loss: 0.3511 - val_accuracy: 0.9505\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1210 - accuracy: 0.9730 - val_loss: 0.2828 - val_accuracy: 0.9707\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1314 - accuracy: 0.9695 - val_loss: 0.2627 - val_accuracy: 0.9710\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1242 - accuracy: 0.9729 - val_loss: 0.2613 - val_accuracy: 0.9707\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1214 - accuracy: 0.9742 - val_loss: 0.2602 - val_accuracy: 0.9685\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1087 - accuracy: 0.9755 - val_loss: 0.4008 - val_accuracy: 0.9303\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1093 - accuracy: 0.9756 - val_loss: 0.3052 - val_accuracy: 0.9498\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1083 - accuracy: 0.9747 - val_loss: 0.2658 - val_accuracy: 0.9644\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1017 - accuracy: 0.9777 - val_loss: 0.2498 - val_accuracy: 0.9707\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0996 - accuracy: 0.9796 - val_loss: 0.2508 - val_accuracy: 0.9666\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0974 - accuracy: 0.9779 - val_loss: 0.3028 - val_accuracy: 0.9454\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0886 - accuracy: 0.9817 - val_loss: 0.2327 - val_accuracy: 0.9771\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0972 - accuracy: 0.9793 - val_loss: 0.2190 - val_accuracy: 0.9800\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0852 - accuracy: 0.9819 - val_loss: 0.2434 - val_accuracy: 0.9712\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0896 - accuracy: 0.9799 - val_loss: 0.2405 - val_accuracy: 0.9732\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0817 - accuracy: 0.9835 - val_loss: 0.2796 - val_accuracy: 0.9582\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0871 - accuracy: 0.9804 - val_loss: 0.2510 - val_accuracy: 0.9655\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0794 - accuracy: 0.9836 - val_loss: 0.2082 - val_accuracy: 0.9771\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0826 - accuracy: 0.9816 - val_loss: 0.1987 - val_accuracy: 0.9857\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0749 - accuracy: 0.9849 - val_loss: 0.2358 - val_accuracy: 0.9743\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0799 - accuracy: 0.9835 - val_loss: 0.2435 - val_accuracy: 0.9677\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0778 - accuracy: 0.9823 - val_loss: 0.2376 - val_accuracy: 0.9679\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0775 - accuracy: 0.9830 - val_loss: 0.2069 - val_accuracy: 0.9789\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0768 - accuracy: 0.9836 - val_loss: 0.1890 - val_accuracy: 0.9855\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0744 - accuracy: 0.9831 - val_loss: 0.2127 - val_accuracy: 0.9828\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0679 - accuracy: 0.9861 - val_loss: 0.2037 - val_accuracy: 0.9833\n","Epoch 40/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0742 - accuracy: 0.9846 - val_loss: 0.2741 - val_accuracy: 0.9549\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 10s 4ms/step - loss: 3.8696 - accuracy: 0.2532 - val_loss: 2.7605 - val_accuracy: 0.5201\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.9579 - accuracy: 0.6467 - val_loss: 1.8174 - val_accuracy: 0.7094\n","Epoch 3/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 1.2347 - accuracy: 0.7632 - val_loss: 1.3576 - val_accuracy: 0.7958\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8779 - accuracy: 0.8220 - val_loss: 1.1160 - val_accuracy: 0.8394\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.6669 - accuracy: 0.8629 - val_loss: 1.0234 - val_accuracy: 0.8262\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5409 - accuracy: 0.8843 - val_loss: 1.0057 - val_accuracy: 0.8169\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4554 - accuracy: 0.8947 - val_loss: 0.7665 - val_accuracy: 0.8867\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3849 - accuracy: 0.9096 - val_loss: 0.6910 - val_accuracy: 0.9120\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3430 - accuracy: 0.9188 - val_loss: 0.6920 - val_accuracy: 0.9069\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2967 - accuracy: 0.9301 - val_loss: 0.6255 - val_accuracy: 0.9243\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2819 - accuracy: 0.9336 - val_loss: 0.6115 - val_accuracy: 0.9248\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2552 - accuracy: 0.9389 - val_loss: 0.6093 - val_accuracy: 0.9138\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2411 - accuracy: 0.9414 - val_loss: 0.5611 - val_accuracy: 0.9309\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2302 - accuracy: 0.9472 - val_loss: 0.5532 - val_accuracy: 0.9294\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2163 - accuracy: 0.9486 - val_loss: 0.5236 - val_accuracy: 0.9327\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1997 - accuracy: 0.9519 - val_loss: 0.4871 - val_accuracy: 0.9428\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1876 - accuracy: 0.9562 - val_loss: 0.4780 - val_accuracy: 0.9428\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1928 - accuracy: 0.9542 - val_loss: 0.4762 - val_accuracy: 0.9509\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1737 - accuracy: 0.9578 - val_loss: 0.4433 - val_accuracy: 0.9479\n","Epoch 20/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1622 - accuracy: 0.9625 - val_loss: 0.4444 - val_accuracy: 0.9446\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1656 - accuracy: 0.9594 - val_loss: 0.4284 - val_accuracy: 0.9476\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1412 - accuracy: 0.9673 - val_loss: 0.4391 - val_accuracy: 0.9441\n","Epoch 23/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1568 - accuracy: 0.9600 - val_loss: 0.4244 - val_accuracy: 0.9538\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1400 - accuracy: 0.9685 - val_loss: 0.4066 - val_accuracy: 0.9465\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1405 - accuracy: 0.9680 - val_loss: 0.4472 - val_accuracy: 0.9459\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1404 - accuracy: 0.9678 - val_loss: 0.4030 - val_accuracy: 0.9545\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1301 - accuracy: 0.9699 - val_loss: 0.3794 - val_accuracy: 0.9516\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1288 - accuracy: 0.9713 - val_loss: 0.3813 - val_accuracy: 0.9586\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1295 - accuracy: 0.9692 - val_loss: 0.3592 - val_accuracy: 0.9663\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1217 - accuracy: 0.9713 - val_loss: 0.3519 - val_accuracy: 0.9690\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1230 - accuracy: 0.9719 - val_loss: 0.4057 - val_accuracy: 0.9450\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1212 - accuracy: 0.9720 - val_loss: 0.4667 - val_accuracy: 0.9371\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1158 - accuracy: 0.9729 - val_loss: 0.3636 - val_accuracy: 0.9648\n","Epoch 34/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.1080 - accuracy: 0.9734 - val_loss: 0.3371 - val_accuracy: 0.9641\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1131 - accuracy: 0.9746 - val_loss: 0.3572 - val_accuracy: 0.9573\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1110 - accuracy: 0.9738 - val_loss: 0.4248 - val_accuracy: 0.9373\n","Epoch 37/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1049 - accuracy: 0.9763 - val_loss: 0.3320 - val_accuracy: 0.9679\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1090 - accuracy: 0.9760 - val_loss: 0.3378 - val_accuracy: 0.9575\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1106 - accuracy: 0.9742 - val_loss: 0.3344 - val_accuracy: 0.9639\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1049 - accuracy: 0.9768 - val_loss: 0.3228 - val_accuracy: 0.9679\n","Average Validation Accuracy: 0.9680140316486359\n","Average Validation Loss: 0.1730416715145111\n","Average Test Accuracy: 0.9688582718372345\n","------------------------------------------------------------------------\n","\n","Number of input features: 19\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 12s 4ms/step - loss: 3.4367 - accuracy: 0.3348 - val_loss: 2.0142 - val_accuracy: 0.5982\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.3290 - accuracy: 0.7452 - val_loss: 1.1362 - val_accuracy: 0.7762\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.7107 - accuracy: 0.8460 - val_loss: 0.7097 - val_accuracy: 0.8616\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4898 - accuracy: 0.8801 - val_loss: 0.5690 - val_accuracy: 0.8924\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3747 - accuracy: 0.9000 - val_loss: 0.5124 - val_accuracy: 0.8869\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3155 - accuracy: 0.9137 - val_loss: 0.4325 - val_accuracy: 0.9199\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2776 - accuracy: 0.9246 - val_loss: 0.4235 - val_accuracy: 0.9217\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2637 - accuracy: 0.9247 - val_loss: 0.3508 - val_accuracy: 0.9371\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2223 - accuracy: 0.9365 - val_loss: 0.3859 - val_accuracy: 0.9261\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2105 - accuracy: 0.9465 - val_loss: 0.3488 - val_accuracy: 0.9395\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2053 - accuracy: 0.9476 - val_loss: 0.3295 - val_accuracy: 0.9270\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1734 - accuracy: 0.9550 - val_loss: 0.3124 - val_accuracy: 0.9402\n","Epoch 13/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1756 - accuracy: 0.9535 - val_loss: 0.3042 - val_accuracy: 0.9485\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1664 - accuracy: 0.9565 - val_loss: 0.2991 - val_accuracy: 0.9509\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1608 - accuracy: 0.9598 - val_loss: 0.2669 - val_accuracy: 0.9490\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1445 - accuracy: 0.9638 - val_loss: 0.2672 - val_accuracy: 0.9549\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1432 - accuracy: 0.9636 - val_loss: 0.2378 - val_accuracy: 0.9688\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1420 - accuracy: 0.9649 - val_loss: 0.2476 - val_accuracy: 0.9602\n","Epoch 19/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1333 - accuracy: 0.9657 - val_loss: 0.2423 - val_accuracy: 0.9681\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1316 - accuracy: 0.9687 - val_loss: 0.2449 - val_accuracy: 0.9593\n","Epoch 21/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1191 - accuracy: 0.9701 - val_loss: 0.2448 - val_accuracy: 0.9646\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1204 - accuracy: 0.9714 - val_loss: 0.3023 - val_accuracy: 0.9437\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1207 - accuracy: 0.9708 - val_loss: 0.2499 - val_accuracy: 0.9560\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1060 - accuracy: 0.9750 - val_loss: 0.2081 - val_accuracy: 0.9723\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1057 - accuracy: 0.9764 - val_loss: 0.3262 - val_accuracy: 0.9432\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1071 - accuracy: 0.9750 - val_loss: 0.2464 - val_accuracy: 0.9619\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1050 - accuracy: 0.9742 - val_loss: 0.2825 - val_accuracy: 0.9567\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0930 - accuracy: 0.9809 - val_loss: 0.2720 - val_accuracy: 0.9549\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0943 - accuracy: 0.9796 - val_loss: 0.2140 - val_accuracy: 0.9663\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1074 - accuracy: 0.9746 - val_loss: 0.1927 - val_accuracy: 0.9767\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0944 - accuracy: 0.9793 - val_loss: 0.2285 - val_accuracy: 0.9646\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0926 - accuracy: 0.9795 - val_loss: 0.2339 - val_accuracy: 0.9646\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0913 - accuracy: 0.9790 - val_loss: 0.2106 - val_accuracy: 0.9701\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0813 - accuracy: 0.9828 - val_loss: 0.2364 - val_accuracy: 0.9611\n","Epoch 35/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0818 - accuracy: 0.9815 - val_loss: 0.2706 - val_accuracy: 0.9446\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0857 - accuracy: 0.9821 - val_loss: 0.1790 - val_accuracy: 0.9806\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0773 - accuracy: 0.9832 - val_loss: 0.1670 - val_accuracy: 0.9853\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0788 - accuracy: 0.9827 - val_loss: 0.2149 - val_accuracy: 0.9705\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0858 - accuracy: 0.9805 - val_loss: 0.1846 - val_accuracy: 0.9765\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0685 - accuracy: 0.9849 - val_loss: 0.3286 - val_accuracy: 0.9450\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.9326 - accuracy: 0.2191 - val_loss: 2.6720 - val_accuracy: 0.4986\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.7613 - accuracy: 0.6455 - val_loss: 1.5140 - val_accuracy: 0.7487\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9541 - accuracy: 0.7981 - val_loss: 1.1434 - val_accuracy: 0.7991\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6339 - accuracy: 0.8553 - val_loss: 0.8360 - val_accuracy: 0.8700\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4721 - accuracy: 0.8837 - val_loss: 0.7194 - val_accuracy: 0.8695\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3760 - accuracy: 0.8985 - val_loss: 0.6065 - val_accuracy: 0.8926\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3210 - accuracy: 0.9107 - val_loss: 0.5821 - val_accuracy: 0.9006\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2729 - accuracy: 0.9259 - val_loss: 0.4714 - val_accuracy: 0.9215\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2411 - accuracy: 0.9344 - val_loss: 0.4615 - val_accuracy: 0.9166\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2191 - accuracy: 0.9414 - val_loss: 0.4483 - val_accuracy: 0.9228\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2047 - accuracy: 0.9457 - val_loss: 0.3878 - val_accuracy: 0.9373\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2029 - accuracy: 0.9455 - val_loss: 0.4311 - val_accuracy: 0.9219\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1806 - accuracy: 0.9519 - val_loss: 0.3462 - val_accuracy: 0.9435\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1664 - accuracy: 0.9555 - val_loss: 0.3189 - val_accuracy: 0.9545\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1671 - accuracy: 0.9566 - val_loss: 0.3015 - val_accuracy: 0.9476\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1461 - accuracy: 0.9620 - val_loss: 0.3513 - val_accuracy: 0.9430\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1462 - accuracy: 0.9624 - val_loss: 0.3727 - val_accuracy: 0.9318\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1385 - accuracy: 0.9649 - val_loss: 0.2829 - val_accuracy: 0.9542\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1295 - accuracy: 0.9681 - val_loss: 0.2689 - val_accuracy: 0.9619\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1323 - accuracy: 0.9678 - val_loss: 0.3148 - val_accuracy: 0.9395\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1253 - accuracy: 0.9678 - val_loss: 0.2531 - val_accuracy: 0.9679\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1121 - accuracy: 0.9736 - val_loss: 0.2714 - val_accuracy: 0.9573\n","Epoch 23/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1192 - accuracy: 0.9717 - val_loss: 0.2269 - val_accuracy: 0.9740\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1062 - accuracy: 0.9751 - val_loss: 0.2329 - val_accuracy: 0.9685\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1194 - accuracy: 0.9710 - val_loss: 0.2855 - val_accuracy: 0.9589\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1000 - accuracy: 0.9781 - val_loss: 0.2374 - val_accuracy: 0.9732\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1110 - accuracy: 0.9745 - val_loss: 0.2455 - val_accuracy: 0.9674\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1003 - accuracy: 0.9783 - val_loss: 0.2426 - val_accuracy: 0.9635\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1010 - accuracy: 0.9776 - val_loss: 0.2170 - val_accuracy: 0.9745\n","Epoch 30/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0867 - accuracy: 0.9803 - val_loss: 0.2145 - val_accuracy: 0.9740\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0976 - accuracy: 0.9770 - val_loss: 0.2659 - val_accuracy: 0.9611\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0889 - accuracy: 0.9800 - val_loss: 0.2606 - val_accuracy: 0.9600\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1038 - accuracy: 0.9750 - val_loss: 0.2063 - val_accuracy: 0.9804\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0816 - accuracy: 0.9832 - val_loss: 0.2425 - val_accuracy: 0.9688\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0837 - accuracy: 0.9819 - val_loss: 0.2580 - val_accuracy: 0.9558\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0876 - accuracy: 0.9803 - val_loss: 0.2506 - val_accuracy: 0.9602\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0855 - accuracy: 0.9805 - val_loss: 0.2141 - val_accuracy: 0.9734\n","Epoch 38/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0919 - accuracy: 0.9794 - val_loss: 0.2050 - val_accuracy: 0.9769\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0692 - accuracy: 0.9867 - val_loss: 0.1869 - val_accuracy: 0.9826\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0879 - accuracy: 0.9802 - val_loss: 0.2219 - val_accuracy: 0.9705\n","Average Validation Accuracy: 0.9628222286701202\n","Average Validation Loss: 0.1859450712800026\n","Average Test Accuracy: 0.9660942256450653\n","------------------------------------------------------------------------\n","\n","Number of input features: 20\n","Fold: 1\n","Epoch 1/40\n","1846/1846 [==============================] - 12s 5ms/step - loss: 3.3736 - accuracy: 0.3501 - val_loss: 2.0930 - val_accuracy: 0.5883\n","Epoch 2/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 1.4166 - accuracy: 0.7130 - val_loss: 1.2864 - val_accuracy: 0.7685\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.9117 - accuracy: 0.7990 - val_loss: 0.9724 - val_accuracy: 0.8185\n","Epoch 4/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.6710 - accuracy: 0.8382 - val_loss: 0.8316 - val_accuracy: 0.8469\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5292 - accuracy: 0.8680 - val_loss: 0.7262 - val_accuracy: 0.8565\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4618 - accuracy: 0.8775 - val_loss: 0.6872 - val_accuracy: 0.8592\n","Epoch 7/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.4074 - accuracy: 0.8880 - val_loss: 0.5741 - val_accuracy: 0.8968\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3523 - accuracy: 0.9016 - val_loss: 0.6060 - val_accuracy: 0.8836\n","Epoch 9/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3334 - accuracy: 0.9026 - val_loss: 0.5566 - val_accuracy: 0.8906\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3042 - accuracy: 0.9145 - val_loss: 0.4813 - val_accuracy: 0.9058\n","Epoch 11/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2877 - accuracy: 0.9172 - val_loss: 0.4684 - val_accuracy: 0.9179\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2597 - accuracy: 0.9250 - val_loss: 0.4487 - val_accuracy: 0.9228\n","Epoch 13/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2676 - accuracy: 0.9227 - val_loss: 0.4297 - val_accuracy: 0.9322\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2511 - accuracy: 0.9291 - val_loss: 0.4287 - val_accuracy: 0.9226\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2390 - accuracy: 0.9324 - val_loss: 0.4359 - val_accuracy: 0.9135\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2228 - accuracy: 0.9367 - val_loss: 0.4390 - val_accuracy: 0.9267\n","Epoch 17/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2197 - accuracy: 0.9351 - val_loss: 0.4303 - val_accuracy: 0.9230\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2087 - accuracy: 0.9397 - val_loss: 0.4140 - val_accuracy: 0.9314\n","Epoch 19/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.2086 - accuracy: 0.9417 - val_loss: 0.4015 - val_accuracy: 0.9358\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1953 - accuracy: 0.9443 - val_loss: 0.3835 - val_accuracy: 0.9417\n","Epoch 21/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1852 - accuracy: 0.9478 - val_loss: 0.3857 - val_accuracy: 0.9441\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1814 - accuracy: 0.9483 - val_loss: 0.3773 - val_accuracy: 0.9481\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1794 - accuracy: 0.9499 - val_loss: 0.3973 - val_accuracy: 0.9371\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1768 - accuracy: 0.9529 - val_loss: 0.3989 - val_accuracy: 0.9349\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1658 - accuracy: 0.9532 - val_loss: 0.3854 - val_accuracy: 0.9408\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1593 - accuracy: 0.9570 - val_loss: 0.3669 - val_accuracy: 0.9437\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1691 - accuracy: 0.9526 - val_loss: 0.3419 - val_accuracy: 0.9556\n","Epoch 28/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1501 - accuracy: 0.9577 - val_loss: 0.3962 - val_accuracy: 0.9437\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1509 - accuracy: 0.9576 - val_loss: 0.3266 - val_accuracy: 0.9628\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1496 - accuracy: 0.9607 - val_loss: 0.4029 - val_accuracy: 0.9525\n","Epoch 31/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1411 - accuracy: 0.9644 - val_loss: 0.3519 - val_accuracy: 0.9571\n","Epoch 32/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1364 - accuracy: 0.9649 - val_loss: 0.3549 - val_accuracy: 0.9496\n","Epoch 33/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1402 - accuracy: 0.9627 - val_loss: 0.3684 - val_accuracy: 0.9523\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1355 - accuracy: 0.9640 - val_loss: 0.4587 - val_accuracy: 0.9190\n","Epoch 35/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1341 - accuracy: 0.9652 - val_loss: 0.3194 - val_accuracy: 0.9677\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1228 - accuracy: 0.9704 - val_loss: 0.3511 - val_accuracy: 0.9600\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1341 - accuracy: 0.9634 - val_loss: 0.3165 - val_accuracy: 0.9718\n","Epoch 38/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1199 - accuracy: 0.9695 - val_loss: 0.3157 - val_accuracy: 0.9718\n","Epoch 39/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1243 - accuracy: 0.9694 - val_loss: 0.3121 - val_accuracy: 0.9723\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1189 - accuracy: 0.9712 - val_loss: 0.5342 - val_accuracy: 0.9131\n","Fold: 2\n","Epoch 1/40\n","1846/1846 [==============================] - 11s 4ms/step - loss: 3.5151 - accuracy: 0.3073 - val_loss: 2.2681 - val_accuracy: 0.6172\n","Epoch 2/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 1.4547 - accuracy: 0.7161 - val_loss: 1.3012 - val_accuracy: 0.7875\n","Epoch 3/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.8133 - accuracy: 0.8275 - val_loss: 0.9481 - val_accuracy: 0.8286\n","Epoch 4/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.5550 - accuracy: 0.8662 - val_loss: 0.7141 - val_accuracy: 0.8790\n","Epoch 5/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.4151 - accuracy: 0.8979 - val_loss: 0.7505 - val_accuracy: 0.8376\n","Epoch 6/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.3481 - accuracy: 0.9098 - val_loss: 0.5049 - val_accuracy: 0.9129\n","Epoch 7/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2995 - accuracy: 0.9205 - val_loss: 0.4832 - val_accuracy: 0.9085\n","Epoch 8/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2644 - accuracy: 0.9305 - val_loss: 0.4396 - val_accuracy: 0.9153\n","Epoch 9/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.2378 - accuracy: 0.9369 - val_loss: 0.3819 - val_accuracy: 0.9333\n","Epoch 10/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.2228 - accuracy: 0.9381 - val_loss: 0.3792 - val_accuracy: 0.9283\n","Epoch 11/40\n","1846/1846 [==============================] - 8s 5ms/step - loss: 0.2106 - accuracy: 0.9422 - val_loss: 0.3561 - val_accuracy: 0.9481\n","Epoch 12/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1957 - accuracy: 0.9471 - val_loss: 0.3372 - val_accuracy: 0.9342\n","Epoch 13/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1772 - accuracy: 0.9547 - val_loss: 0.3584 - val_accuracy: 0.9318\n","Epoch 14/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1758 - accuracy: 0.9524 - val_loss: 0.3114 - val_accuracy: 0.9432\n","Epoch 15/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1692 - accuracy: 0.9548 - val_loss: 0.2975 - val_accuracy: 0.9498\n","Epoch 16/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1674 - accuracy: 0.9558 - val_loss: 0.3163 - val_accuracy: 0.9406\n","Epoch 17/40\n","1846/1846 [==============================] - 6s 3ms/step - loss: 0.1497 - accuracy: 0.9608 - val_loss: 0.2853 - val_accuracy: 0.9459\n","Epoch 18/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1445 - accuracy: 0.9636 - val_loss: 0.2928 - val_accuracy: 0.9490\n","Epoch 19/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1402 - accuracy: 0.9658 - val_loss: 0.3294 - val_accuracy: 0.9329\n","Epoch 20/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1395 - accuracy: 0.9651 - val_loss: 0.2472 - val_accuracy: 0.9597\n","Epoch 21/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1331 - accuracy: 0.9650 - val_loss: 0.2590 - val_accuracy: 0.9580\n","Epoch 22/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1199 - accuracy: 0.9704 - val_loss: 0.2363 - val_accuracy: 0.9635\n","Epoch 23/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1259 - accuracy: 0.9679 - val_loss: 0.2478 - val_accuracy: 0.9650\n","Epoch 24/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1262 - accuracy: 0.9672 - val_loss: 0.2298 - val_accuracy: 0.9593\n","Epoch 25/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1147 - accuracy: 0.9718 - val_loss: 0.3265 - val_accuracy: 0.9316\n","Epoch 26/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1136 - accuracy: 0.9720 - val_loss: 0.2201 - val_accuracy: 0.9615\n","Epoch 27/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1148 - accuracy: 0.9721 - val_loss: 0.2869 - val_accuracy: 0.9529\n","Epoch 28/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1060 - accuracy: 0.9744 - val_loss: 0.2021 - val_accuracy: 0.9725\n","Epoch 29/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1202 - accuracy: 0.9704 - val_loss: 0.2600 - val_accuracy: 0.9556\n","Epoch 30/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0920 - accuracy: 0.9794 - val_loss: 0.2571 - val_accuracy: 0.9593\n","Epoch 31/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.1025 - accuracy: 0.9763 - val_loss: 0.3030 - val_accuracy: 0.9463\n","Epoch 32/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1004 - accuracy: 0.9767 - val_loss: 0.2353 - val_accuracy: 0.9606\n","Epoch 33/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.1007 - accuracy: 0.9764 - val_loss: 0.2506 - val_accuracy: 0.9608\n","Epoch 34/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0856 - accuracy: 0.9814 - val_loss: 0.2614 - val_accuracy: 0.9549\n","Epoch 35/40\n","1846/1846 [==============================] - 8s 4ms/step - loss: 0.0976 - accuracy: 0.9767 - val_loss: 0.1917 - val_accuracy: 0.9756\n","Epoch 36/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0808 - accuracy: 0.9821 - val_loss: 0.1955 - val_accuracy: 0.9765\n","Epoch 37/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0905 - accuracy: 0.9792 - val_loss: 0.2285 - val_accuracy: 0.9688\n","Epoch 38/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0859 - accuracy: 0.9811 - val_loss: 0.1899 - val_accuracy: 0.9732\n","Epoch 39/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0804 - accuracy: 0.9828 - val_loss: 0.1908 - val_accuracy: 0.9745\n","Epoch 40/40\n","1846/1846 [==============================] - 7s 4ms/step - loss: 0.0827 - accuracy: 0.9813 - val_loss: 0.1893 - val_accuracy: 0.9769\n","Average Validation Accuracy: 0.953746110200882\n","Average Validation Loss: 0.2379881665110588\n","Average Test Accuracy: 0.9566963911056519\n","------------------------------------------------------------------------\n"]}],"source":["# Define the number of folds for k-fold cross-validation\n","k = 2\n","\n","# Define the cross-validation method\n","cv_method = StratifiedKFold(n_splits=k)\n","\n","# Initialize the list to store the history, train & validation(accuracy & loss) for each model\n","models = []\n","model_history = []\n","model_accuracy = []\n","model_train_acc = []\n","model_train_loss = []\n","model_val_acc = []\n","model_val_loss = []\n","\n","for i in range(1, 21):\n","\n","  models_fold = []\n","  hist = []\n","  train_accuracy = []\n","  train_loss = []\n","  val_accuracy = []\n","  val_loss = []\n","  test_accuracy = []\n","\n","  print(\"\\nNumber of input features:\", i)\n","\n","  # Select the input features from the input data\n","  X_train_selected = X_train[:, :i]\n","  X_test_selected = X_test[:, :i]\n","\n","  X_train_selected = X_train_selected.reshape(27543, i, 1, 1)\n","  X_test_selected = X_test_selected.reshape(13567, i, 1, 1)\n","\n","  # Loop over the folds\n","  for fold, (train_index, val_index) in enumerate(cv_method.split(X_train_selected, y_train)):\n","\n","    print(\"Fold:\", fold+1)\n","\n","    # Build the model\n","    model = Sequential()\n","    model.add(Conv2D(60, kernel_size=(5,5), activation='relu',bias_initializer='normal', input_shape=X_train_selected.shape[1:], padding= \"same\")) #keeps the output size same as input size (prevent down or upsampling)\n","    model.add(MaxPooling2D(pool_size=(1,1))) #pool size 2 error, because 1 (1 feature) minus 2 (pool size) is negative)\n","    model.add(Flatten())\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(20, bias_initializer='normal', activation='relu',kernel_regularizer=regularizers.l2(0.0001)))\n","    model.add(Dense(373, kernel_initializer='normal', activation='softmax'))\n","\n","    # compile model\n","    model.compile(loss = \"categorical_crossentropy\", optimizer='adam', metrics = ['accuracy']) \n","\n","    # # Fit the model to the training data for the current fold\n","    history = model.fit(X_train_selected[train_index], to_categorical(y_train_enc[train_index], num_classes=373), batch_size = 5, epochs = 40, verbose = 1, validation_split = 0.33)\n","\n","    # Evaluate the model on the validation data for the current fold\n","    val_scores = model.evaluate(X_train_selected[val_index], to_categorical(y_train_enc[val_index],num_classes=373), verbose=0)\n","    val_accuracy.append(val_scores[1])\n","    val_loss.append(val_scores[0])\n","\n","    # Evaluate the model on the test data for the current fold\n","    test_scores = model.evaluate(X_test_selected, to_categorical(y_test_enc, num_classes=373), verbose=0)\n","    test_accuracy.append(test_scores[1])\n","\n","    # add the model to the list of models\n","    models_fold.append(model)\n","    hist.append(history)\n","\n","    # store the training accuracy and loss for each fold\n","    train_accuracy.append(history.history['accuracy'])\n","    train_loss.append(history.history['loss'])\n","  \n","  # Calculate the average test and validation accuracy and loss across all folds\n","  avg_test_acc = sum(test_accuracy) / len(test_accuracy)\n","  avg_val_acc = sum(val_accuracy) / len(val_accuracy)\n","  avg_val_loss = sum(val_loss) / len(val_loss)\n","\n","  # Print the average validation and test accuracy and loss\n","  print(\"Average Validation Accuracy:\", avg_val_acc)\n","  print(\"Average Validation Loss:\",avg_val_loss)\n","  print(\"Average Test Accuracy:\", avg_test_acc)\n","\n","  best_fold_index = test_accuracy.index(max(test_accuracy))\n","  model_accuracy.append(test_accuracy[best_fold_index])\n","  models.append(models_fold[best_fold_index])\n","  model_history.append(hist[best_fold_index])\n","  model_train_acc.append(train_accuracy[best_fold_index])\n","  model_train_loss.append(train_loss[best_fold_index])\n","  model_val_acc.append(val_accuracy[best_fold_index])\n","  model_val_loss.append(val_loss[best_fold_index])\n","  print('------------------------------------------------------------------------')"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"ZG29fO-C4TJH"},"outputs":[],"source":["#to show the no of input features and its corresponding model accuracy\n","model_list = []\n","\n","#Iterate through each model's accuracy \n","for i in range (len(model_accuracy)):\n","    #get the number of input features for the current model\n","    no_features = i + 1\n","\n","    #round the model accuries to 3 d.p.\n","    rounded_model_acc = round(model_accuracy[i], 3)\n","    \n","    model_list.append([no_features, rounded_model_acc])\n","\n","models_df = pd.DataFrame(model_list, columns=[\"No of input features\", \"Model accuracy\"])"]},{"cell_type":"code","execution_count":13,"metadata":{"id":"M1aBlP3GmZ9o"},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 432x288 with 2 Axes>"]},"metadata":{"needs_background":"light"},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["Final Test Accuracy: 0.9893122911453247\n"]}],"source":["# Select the final model based on the max test accuracy across all models\n","\n","best_model_index = model_accuracy.index(max(model_accuracy))\n","\n","best_model = models[best_model_index]\n","best_model_history = model_history[best_model_index]\n","best_model_train_acc = model_train_acc[best_model_index]\n","best_model_train_loss = model_train_loss[best_model_index]\n","best_model_val_acc = model_val_acc[best_model_index]\n","best_model_val_loss = model_val_loss[best_model_index]\n","\n","# summarize history for accuracy  \n","plt.subplot(211)  \n","plt.plot(best_model_history.history['accuracy'])  \n","plt.plot(best_model_history.history['val_accuracy'])  \n","plt.title('model accuracy')  \n","plt.ylabel('accuracy')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='lower right')  \n","\n","# summarize history for loss\n","plt.subplot(212)  \n","plt.plot(best_model_history.history['loss'])  \n","plt.plot(best_model_history.history['val_loss'])  \n","plt.title('model loss')  \n","plt.ylabel('loss')  \n","plt.xlabel('epoch')  \n","plt.legend(['train', 'test'], loc='upper right')  \n","plt.subplots_adjust(hspace=0.7)\n","\n","plt.show() \n","\n","print(\"Final Test Accuracy:\", model_accuracy[best_model_index])"]},{"cell_type":"code","execution_count":14,"metadata":{"id":"RMkWBkrYmZ9s"},"outputs":[{"name":"stdout","output_type":"stream","text":["424/424 [==============================] - 1s 3ms/step\n","Classification report:\n","               precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00       591\n","           1       1.00      1.00      1.00       430\n","           2       1.00      1.00      1.00       419\n","           3       1.00      1.00      1.00       384\n","           4       1.00      1.00      1.00       339\n","           5       1.00      1.00      1.00       342\n","           6       1.00      1.00      1.00       310\n","           7       1.00      1.00      1.00       325\n","           8       1.00      1.00      1.00       294\n","           9       1.00      1.00      1.00       269\n","          10       1.00      1.00      1.00       296\n","          11       1.00      1.00      1.00       258\n","          12       1.00      1.00      1.00       247\n","          13       1.00      1.00      1.00       237\n","          14       1.00      1.00      1.00       239\n","          15       1.00      1.00      1.00       235\n","          16       1.00      1.00      1.00       213\n","          17       1.00      1.00      1.00       202\n","          18       1.00      1.00      1.00       196\n","          19       1.00      1.00      1.00       181\n","          20       1.00      1.00      1.00       177\n","          21       1.00      1.00      1.00       177\n","          22       1.00      1.00      1.00       155\n","          23       1.00      1.00      1.00       155\n","          24       1.00      1.00      1.00       144\n","          25       1.00      1.00      1.00       126\n","          26       1.00      1.00      1.00       108\n","          27       1.00      1.00      1.00       121\n","          28       1.00      1.00      1.00        95\n","          29       1.00      1.00      1.00       106\n","          30       1.00      1.00      1.00       102\n","          31       1.00      1.00      1.00        86\n","          32       1.00      1.00      1.00       108\n","          33       1.00      1.00      1.00        88\n","          34       1.00      1.00      1.00       102\n","          35       1.00      1.00      1.00        88\n","          36       1.00      1.00      1.00        83\n","          37       1.00      1.00      1.00        93\n","          38       1.00      1.00      1.00        76\n","          39       1.00      1.00      1.00        85\n","          40       1.00      1.00      1.00        86\n","          41       1.00      1.00      1.00        85\n","          42       1.00      1.00      1.00        68\n","          43       1.00      1.00      1.00        75\n","          44       0.95      1.00      0.97        71\n","          45       1.00      1.00      1.00        58\n","          46       1.00      1.00      1.00        71\n","          47       0.76      1.00      0.86        57\n","          48       1.00      1.00      1.00        67\n","          49       1.00      1.00      1.00        47\n","          50       1.00      1.00      1.00        47\n","          51       1.00      1.00      1.00        48\n","          52       1.00      1.00      1.00        43\n","          53       1.00      1.00      1.00        51\n","          54       1.00      1.00      1.00        44\n","          55       1.00      1.00      1.00        51\n","          56       1.00      1.00      1.00        44\n","          57       1.00      1.00      1.00        45\n","          58       1.00      1.00      1.00        41\n","          59       1.00      1.00      1.00        52\n","          60       1.00      1.00      1.00        41\n","          61       1.00      1.00      1.00        37\n","          62       1.00      1.00      1.00        43\n","          63       1.00      1.00      1.00        43\n","          64       1.00      1.00      1.00        42\n","          65       1.00      1.00      1.00        46\n","          66       1.00      1.00      1.00        43\n","          67       1.00      1.00      1.00        40\n","          68       1.00      1.00      1.00        43\n","          69       1.00      1.00      1.00        44\n","          70       1.00      1.00      1.00        33\n","          71       1.00      1.00      1.00        38\n","          72       0.76      1.00      0.87        45\n","          73       1.00      1.00      1.00        38\n","          74       1.00      1.00      1.00        42\n","          75       1.00      1.00      1.00        39\n","          76       0.65      1.00      0.79        30\n","          77       1.00      1.00      1.00        28\n","          78       1.00      1.00      1.00        28\n","          79       1.00      1.00      1.00        33\n","          80       1.00      1.00      1.00        35\n","          81       1.00      1.00      1.00        31\n","          82       1.00      1.00      1.00        32\n","          83       1.00      1.00      1.00        39\n","          84       1.00      1.00      1.00        36\n","          85       1.00      1.00      1.00        27\n","          86       1.00      1.00      1.00        31\n","          87       1.00      1.00      1.00        28\n","          88       1.00      1.00      1.00        20\n","          89       1.00      1.00      1.00        33\n","          90       1.00      1.00      1.00        24\n","          91       1.00      1.00      1.00        22\n","          92       1.00      1.00      1.00        35\n","          93       1.00      1.00      1.00        26\n","          94       1.00      1.00      1.00        27\n","          95       1.00      1.00      1.00        27\n","          96       1.00      1.00      1.00        23\n","          97       0.67      1.00      0.80        16\n","          98       1.00      1.00      1.00        28\n","          99       1.00      1.00      1.00        35\n","         100       0.44      1.00      0.61        25\n","         101       1.00      1.00      1.00        28\n","         102       1.00      1.00      1.00        26\n","         103       1.00      1.00      1.00        33\n","         104       1.00      1.00      1.00        26\n","         105       1.00      1.00      1.00        24\n","         106       1.00      1.00      1.00        22\n","         107       1.00      1.00      1.00        26\n","         108       1.00      1.00      1.00        25\n","         109       1.00      1.00      1.00        26\n","         110       1.00      1.00      1.00        20\n","         111       1.00      1.00      1.00        18\n","         112       0.64      1.00      0.78        23\n","         113       1.00      1.00      1.00        16\n","         114       1.00      1.00      1.00        25\n","         115       1.00      1.00      1.00        18\n","         116       1.00      1.00      1.00        16\n","         117       1.00      1.00      1.00        19\n","         118       1.00      1.00      1.00        26\n","         119       1.00      1.00      1.00        22\n","         120       0.87      1.00      0.93        26\n","         121       1.00      1.00      1.00        14\n","         122       1.00      1.00      1.00        18\n","         123       1.00      1.00      1.00        15\n","         124       1.00      1.00      1.00        27\n","         125       1.00      1.00      1.00        19\n","         126       1.00      1.00      1.00        20\n","         127       1.00      1.00      1.00        21\n","         128       1.00      1.00      1.00        22\n","         129       1.00      1.00      1.00        17\n","         130       1.00      1.00      1.00        18\n","         131       1.00      1.00      1.00        18\n","         132       1.00      1.00      1.00        20\n","         133       1.00      1.00      1.00        11\n","         134       1.00      1.00      1.00        14\n","         135       1.00      1.00      1.00        19\n","         136       0.59      1.00      0.74        23\n","         137       1.00      1.00      1.00        14\n","         138       1.00      1.00      1.00        20\n","         139       1.00      1.00      1.00        23\n","         140       0.00      0.00      0.00        16\n","         141       1.00      1.00      1.00        14\n","         142       1.00      1.00      1.00        23\n","         143       1.00      1.00      1.00        13\n","         144       1.00      1.00      1.00        16\n","         145       1.00      1.00      1.00        17\n","         146       1.00      1.00      1.00        24\n","         147       1.00      1.00      1.00        22\n","         148       1.00      1.00      1.00        19\n","         149       1.00      1.00      1.00        15\n","         150       1.00      1.00      1.00        20\n","         151       1.00      1.00      1.00        24\n","         152       1.00      1.00      1.00        11\n","         153       1.00      1.00      1.00        19\n","         154       1.00      1.00      1.00        17\n","         155       1.00      1.00      1.00        11\n","         156       1.00      1.00      1.00        12\n","         157       1.00      1.00      1.00        18\n","         158       1.00      1.00      1.00        18\n","         159       1.00      1.00      1.00        20\n","         160       1.00      1.00      1.00        20\n","         161       1.00      1.00      1.00        16\n","         162       1.00      1.00      1.00        15\n","         163       1.00      1.00      1.00        13\n","         164       1.00      1.00      1.00        19\n","         165       1.00      1.00      1.00        15\n","         166       1.00      1.00      1.00         9\n","         167       1.00      1.00      1.00        11\n","         168       1.00      1.00      1.00        11\n","         169       1.00      1.00      1.00        15\n","         170       1.00      1.00      1.00        11\n","         171       1.00      1.00      1.00        21\n","         172       1.00      1.00      1.00        18\n","         173       1.00      1.00      1.00        10\n","         174       1.00      1.00      1.00        16\n","         175       1.00      1.00      1.00        11\n","         176       1.00      1.00      1.00        10\n","         177       1.00      1.00      1.00        11\n","         178       1.00      1.00      1.00        15\n","         179       1.00      1.00      1.00        15\n","         180       1.00      1.00      1.00        13\n","         181       1.00      1.00      1.00        15\n","         182       1.00      1.00      1.00         8\n","         183       1.00      1.00      1.00        16\n","         184       1.00      1.00      1.00         9\n","         185       0.60      1.00      0.75        12\n","         186       1.00      1.00      1.00        14\n","         187       1.00      1.00      1.00        15\n","         188       0.00      0.00      0.00        13\n","         189       1.00      1.00      1.00        15\n","         190       1.00      1.00      1.00        17\n","         191       1.00      1.00      1.00         9\n","         192       1.00      1.00      1.00         9\n","         193       1.00      1.00      1.00        11\n","         194       1.00      1.00      1.00         4\n","         195       1.00      1.00      1.00        10\n","         196       1.00      1.00      1.00         7\n","         197       1.00      1.00      1.00        14\n","         198       1.00      1.00      1.00        12\n","         199       1.00      1.00      1.00         7\n","         200       1.00      1.00      1.00         9\n","         201       1.00      1.00      1.00        11\n","         202       1.00      1.00      1.00        12\n","         203       1.00      1.00      1.00        12\n","         204       1.00      1.00      1.00        14\n","         205       1.00      1.00      1.00        14\n","         206       1.00      1.00      1.00         6\n","         207       1.00      1.00      1.00         7\n","         208       1.00      1.00      1.00         6\n","         209       1.00      1.00      1.00         7\n","         210       1.00      1.00      1.00        19\n","         211       1.00      1.00      1.00         7\n","         212       1.00      1.00      1.00         6\n","         213       1.00      1.00      1.00        11\n","         214       1.00      1.00      1.00         7\n","         215       1.00      1.00      1.00        12\n","         216       1.00      1.00      1.00         9\n","         217       1.00      1.00      1.00         8\n","         218       1.00      1.00      1.00        12\n","         219       1.00      1.00      1.00         5\n","         220       1.00      1.00      1.00         6\n","         221       0.69      1.00      0.82         9\n","         222       0.00      0.00      0.00         4\n","         223       1.00      1.00      1.00        13\n","         224       1.00      1.00      1.00         4\n","         225       0.00      0.00      0.00        14\n","         226       1.00      1.00      1.00        10\n","         227       1.00      1.00      1.00        12\n","         228       1.00      1.00      1.00        11\n","         229       1.00      1.00      1.00         6\n","         230       1.00      1.00      1.00         5\n","         231       1.00      1.00      1.00        13\n","         232       1.00      1.00      1.00        10\n","         233       1.00      1.00      1.00         6\n","         234       1.00      1.00      1.00         8\n","         235       1.00      1.00      1.00         4\n","         236       1.00      1.00      1.00         8\n","         237       1.00      1.00      1.00         7\n","         238       1.00      1.00      1.00         7\n","         239       0.00      0.00      0.00         9\n","         240       1.00      1.00      1.00         8\n","         241       1.00      1.00      1.00        10\n","         242       0.00      0.00      0.00         8\n","         243       1.00      1.00      1.00         9\n","         244       1.00      1.00      1.00         9\n","         245       1.00      1.00      1.00         7\n","         246       1.00      1.00      1.00         8\n","         247       1.00      1.00      1.00         6\n","         248       1.00      1.00      1.00         7\n","         249       1.00      1.00      1.00         5\n","         250       1.00      1.00      1.00         6\n","         251       1.00      1.00      1.00        11\n","         252       1.00      1.00      1.00        10\n","         253       1.00      1.00      1.00         9\n","         254       1.00      1.00      1.00        12\n","         255       1.00      1.00      1.00         7\n","         256       0.00      0.00      0.00         3\n","         257       1.00      1.00      1.00         9\n","         258       1.00      1.00      1.00         5\n","         259       1.00      1.00      1.00         2\n","         260       1.00      1.00      1.00         7\n","         261       1.00      1.00      1.00         7\n","         262       1.00      1.00      1.00         4\n","         263       1.00      1.00      1.00        10\n","         264       1.00      1.00      1.00         5\n","         265       1.00      1.00      1.00         7\n","         266       1.00      1.00      1.00         8\n","         267       1.00      1.00      1.00        10\n","         268       0.00      0.00      0.00         9\n","         269       1.00      1.00      1.00         9\n","         270       1.00      1.00      1.00        10\n","         271       1.00      1.00      1.00         4\n","         272       1.00      1.00      1.00         6\n","         273       1.00      1.00      1.00         6\n","         274       1.00      1.00      1.00         7\n","         275       1.00      1.00      1.00         3\n","         276       1.00      1.00      1.00         4\n","         277       1.00      1.00      1.00         3\n","         278       0.00      0.00      0.00         4\n","         279       1.00      1.00      1.00         5\n","         280       1.00      1.00      1.00        11\n","         281       1.00      1.00      1.00         6\n","         282       0.00      0.00      0.00         5\n","         283       1.00      1.00      1.00         7\n","         284       1.00      1.00      1.00         7\n","         285       1.00      1.00      1.00         6\n","         286       1.00      1.00      1.00         4\n","         287       1.00      1.00      1.00         6\n","         288       1.00      1.00      1.00         2\n","         289       1.00      1.00      1.00         5\n","         290       1.00      1.00      1.00         9\n","         291       1.00      1.00      1.00         7\n","         292       1.00      1.00      1.00         6\n","         293       1.00      1.00      1.00         7\n","         294       0.00      0.00      0.00         6\n","         295       1.00      1.00      1.00         3\n","         296       1.00      1.00      1.00         8\n","         297       1.00      1.00      1.00         8\n","         298       1.00      1.00      1.00         2\n","         299       0.00      0.00      0.00         5\n","         300       1.00      1.00      1.00         3\n","         301       1.00      1.00      1.00         5\n","         302       1.00      1.00      1.00         6\n","         303       1.00      1.00      1.00         5\n","         304       1.00      1.00      1.00         8\n","         305       1.00      1.00      1.00         4\n","         306       1.00      1.00      1.00         7\n","         307       1.00      1.00      1.00         9\n","         308       1.00      1.00      1.00         6\n","         309       1.00      1.00      1.00         4\n","         310       1.00      1.00      1.00         4\n","         311       1.00      1.00      1.00        10\n","         312       1.00      1.00      1.00         2\n","         313       1.00      1.00      1.00         4\n","         314       1.00      1.00      1.00         8\n","         315       1.00      1.00      1.00         6\n","         316       1.00      1.00      1.00         4\n","         317       0.00      0.00      0.00         8\n","         318       1.00      1.00      1.00         7\n","         319       1.00      1.00      1.00         6\n","         320       1.00      1.00      1.00         7\n","         321       1.00      1.00      1.00         4\n","         322       1.00      1.00      1.00         6\n","         323       1.00      1.00      1.00         3\n","         324       1.00      1.00      1.00         4\n","         325       1.00      1.00      1.00         8\n","         326       1.00      1.00      1.00         6\n","         327       1.00      1.00      1.00         7\n","         328       1.00      1.00      1.00         4\n","         329       1.00      1.00      1.00         4\n","         330       1.00      1.00      1.00         3\n","         331       0.00      0.00      0.00         6\n","         332       0.00      0.00      0.00         3\n","         333       1.00      1.00      1.00         3\n","         334       1.00      1.00      1.00         1\n","         335       0.00      0.00      0.00         8\n","         336       0.00      0.00      0.00         6\n","         337       1.00      1.00      1.00         7\n","         338       1.00      1.00      1.00         4\n","         339       1.00      1.00      1.00         4\n","         340       1.00      1.00      1.00         2\n","         341       0.00      0.00      0.00         1\n","         342       1.00      1.00      1.00         2\n","         343       1.00      1.00      1.00         5\n","         344       1.00      1.00      1.00         3\n","         345       1.00      1.00      1.00         6\n","         346       1.00      1.00      1.00         4\n","         347       0.00      0.00      0.00         4\n","         348       1.00      1.00      1.00         7\n","         349       0.38      1.00      0.56         5\n","         350       1.00      1.00      1.00         4\n","         351       1.00      1.00      1.00         4\n","         352       1.00      1.00      1.00         6\n","         353       1.00      1.00      1.00         7\n","         354       0.00      0.00      0.00         2\n","         355       1.00      1.00      1.00         1\n","         356       1.00      1.00      1.00         4\n","         357       1.00      1.00      1.00         3\n","         358       1.00      1.00      1.00         1\n","         359       1.00      1.00      1.00         3\n","         360       1.00      1.00      1.00         4\n","         361       1.00      1.00      1.00         3\n","         362       1.00      1.00      1.00         1\n","         363       1.00      1.00      1.00         2\n","         364       0.00      0.00      0.00         4\n","         365       1.00      1.00      1.00         2\n","         366       1.00      1.00      1.00         3\n","         367       1.00      1.00      1.00         3\n","         369       1.00      1.00      1.00         3\n","         370       0.00      0.00      0.00         3\n","         371       0.00      0.00      0.00         2\n","         372       0.00      0.00      0.00         2\n","\n","    accuracy                           0.99     13567\n","   macro avg       0.92      0.94      0.93     13567\n","weighted avg       0.98      0.99      0.99     13567\n","\n"]},{"name":"stderr","output_type":"stream","text":["C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","C:\\Users\\yoongsim\\AppData\\Roaming\\Python\\Python37\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["#Select only the optimal number of input features for X_test\n","X_test = X_test[:,:(best_model_index+1)]\n","\n","X_test = X_test.reshape(13567, best_model_index+1, 1, 1)\n","\n","# Evaluate the best model on the test data\n","y_pred = best_model.predict(X_test)\n","\n","# np.argmax() is used to convert the one-hot encoded predictions and test labels to class labels.\n","y_pred_label = np.argmax(y_pred, axis = 1)\n","\n","# Print the classification report\n","print(\"Classification report:\\n\", classification_report(y_test_enc, y_pred_label))"]},{"cell_type":"code","execution_count":15,"metadata":{"id":"FeifaQpJmZ9u"},"outputs":[{"name":"stdout","output_type":"stream","text":["           OsID  True Class  Predicted Class  True/False\n","0  Os03g0179400         331              100       False\n","1  Os04g0659100         161              161        True\n","2  Os01g0686800          17               17        True\n","3  Os04g0107900          34               34        True\n","4  Os04g0517100           7                7        True\n"]}],"source":["# extract class labels from test data\n","class_test = y_test_enc\n","\n","# Invert OsID_labels dictionary\n","inv_OsID_labels = {v: k for k, v in OsID_labels.items()}\n","\n","# map OsID values to the class labels\n","OsID_test = [inv_OsID_labels.get(value, 'Unknown') for value in class_test]\n","\n","# create dataframe with OsID, true class, predicted class, and true/false columns\n","results = pd.DataFrame({\n","    'OsID': OsID_test,\n","    'True Class': y_test_enc,\n","    'Predicted Class': y_pred_label,\n","    'True/False': class_test == y_pred_label\n","})\n","\n","# display dataframe\n","print(results.head())\n","\n","# save results_df to a CSV file\n","results.to_csv('MLP_gene classification.csv', index=False)"]},{"cell_type":"code","execution_count":16,"metadata":{"id":"HcBceHUp0-TI"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>No of input features</th>\n","      <th>Model accuracy</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.475</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.821</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.927</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.951</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.974</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.972</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.975</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>9</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>10</td>\n","      <td>0.981</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>11</td>\n","      <td>0.985</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>12</td>\n","      <td>0.989</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>13</td>\n","      <td>0.983</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>14</td>\n","      <td>0.984</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>15</td>\n","      <td>0.986</td>\n","    </tr>\n","    <tr>\n","      <th>15</th>\n","      <td>16</td>\n","      <td>0.982</td>\n","    </tr>\n","    <tr>\n","      <th>16</th>\n","      <td>17</td>\n","      <td>0.978</td>\n","    </tr>\n","    <tr>\n","      <th>17</th>\n","      <td>18</td>\n","      <td>0.979</td>\n","    </tr>\n","    <tr>\n","      <th>18</th>\n","      <td>19</td>\n","      <td>0.977</td>\n","    </tr>\n","    <tr>\n","      <th>19</th>\n","      <td>20</td>\n","      <td>0.983</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    No of input features  Model accuracy\n","0                      1           0.475\n","1                      2           0.821\n","2                      3           0.927\n","3                      4           0.951\n","4                      5           0.974\n","5                      6           0.972\n","6                      7           0.975\n","7                      8           0.981\n","8                      9           0.981\n","9                     10           0.981\n","10                    11           0.985\n","11                    12           0.989\n","12                    13           0.983\n","13                    14           0.984\n","14                    15           0.986\n","15                    16           0.982\n","16                    17           0.978\n","17                    18           0.979\n","18                    19           0.977\n","19                    20           0.983"]},"metadata":{},"output_type":"display_data"}],"source":["display(models_df)"]}],"metadata":{"accelerator":"TPU","colab":{"provenance":[]},"gpuClass":"standard","kernelspec":{"display_name":"tf","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":0}
